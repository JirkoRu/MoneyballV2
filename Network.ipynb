{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallMLP(nn.Module):\n",
    "    \"\"\"A small MLP for small experiments.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model_path: str = r'.\\models',\n",
    "                 model_name: str = 'MLP',\n",
    "                 num_units: tuple = (8, 100, 1),  # first layer is the input size\n",
    "                 activation_fn: Module = nn.ReLU,\n",
    "                 output_fn: Module = nn.Linear,\n",
    "                 cuda: bool = False):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "\n",
    "        # encoder\n",
    "        layer_stack = []\n",
    "        for layer, units in enumerate(num_units[1:]):\n",
    "            activation = activation_fn if layer != len(num_units) else output_fn\n",
    "            layer_stack.append(nn.Sequential(nn.Linear(in_features=num_units[layer], out_features=units),\n",
    "                                             activation()))\n",
    "        self.encoder = nn.ModuleList(layer_stack)\n",
    "\n",
    "        # Option for CUDA in case we want it. But for small nets usually not good\n",
    "        if cuda:\n",
    "            self.to('cuda')\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def save_model(self, checkpoint_number: int, optimizer: Optimizer):\n",
    "        \"\"\"Saves model and optimizer state.\"\"\"\n",
    "        checkpoint_number = str(checkpoint_number)\n",
    "        saveroot = os.path.join(self.model_path)\n",
    "        savepath = os.path.join(saveroot, f'{self.model_name}_{checkpoint_number}.pth')\n",
    "        if not os.path.exists(saveroot):\n",
    "            os.mkdir(saveroot)\n",
    "\n",
    "        torch.save({\n",
    "            'model_name': self.model_name,\n",
    "            'model_params': self.state_dict(),\n",
    "            'optimizer': optimizer,\n",
    "            'optimizer_params': optimizer.state_dict()},\n",
    "            savepath)\n",
    "        print(fr'Saved model to {savepath}')\n",
    "\n",
    "    def load_model(self, checkpoint_number: int, full_loadpath: str = 'default') -> Optimizer:\n",
    "        \"\"\"Loads model and optimizer state. Returns optimizer.\"\"\"\n",
    "        if full_loadpath != 'default':\n",
    "            load_directory = full_loadpath\n",
    "        else:\n",
    "            load_directory = os.path.join(self.model_path,\n",
    "                                          f'{self.model_name}_{str(checkpoint_number)}.pth')\n",
    "        saved_dict = torch.load(load_directory)\n",
    "        self.load_state_dict(saved_dict['model_params'])\n",
    "        optimizer = saved_dict['optimizer']\n",
    "        optimizer.load_state_dict(saved_dict['optimizer_params'])\n",
    "        return optimizer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the x inputs and y labels into a simple pytorch Dataset, for data loading\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_tensors):\n",
    "        assert input_tensors[0].size(0) == input_tensors[0].size(0)\n",
    "        self.input_tensors = input_tensors\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.input_tensors[0][index]\n",
    "        y = self.input_tensors[1][index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_tensors[0].size(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>org_uuid</th>\n",
       "      <th>org_name</th>\n",
       "      <th>domain</th>\n",
       "      <th>status</th>\n",
       "      <th>founded_on</th>\n",
       "      <th>category_list</th>\n",
       "      <th>category_groups_list</th>\n",
       "      <th>country_code</th>\n",
       "      <th>city</th>\n",
       "      <th>short_description</th>\n",
       "      <th>earliest_funding</th>\n",
       "      <th>time_first_funding</th>\n",
       "      <th>seed_funding</th>\n",
       "      <th>seed_funding_log</th>\n",
       "      <th>series_a_funding_date</th>\n",
       "      <th>time_till_series_a</th>\n",
       "      <th>series_a_funding</th>\n",
       "      <th>series_a_funding_log</th>\n",
       "      <th>seed_n_rounds</th>\n",
       "      <th>series_a_n_rounds</th>\n",
       "      <th>angel_n_rounds</th>\n",
       "      <th>pre_seed_n_rounds</th>\n",
       "      <th>success_flag</th>\n",
       "      <th>time_first_funding_normalised</th>\n",
       "      <th>seed_funding_normalised</th>\n",
       "      <th>series_a_funding_normalised</th>\n",
       "      <th>time_till_series_a_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86bd89a7-fe3f-12d4-817c-8157c8592194</td>\n",
       "      <td>i.Sec</td>\n",
       "      <td>isec.ng</td>\n",
       "      <td>operating</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Finance,FinTech</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NGA</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>i.Sec is a financial security service that all...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58fd74f2-9ebb-4a41-cd75-05f9214a9a11</td>\n",
       "      <td>Kukua</td>\n",
       "      <td>kukua.me</td>\n",
       "      <td>operating</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Content,EdTech,Franchise,Media and Entertainment</td>\n",
       "      <td>Education,Media and Entertainment,Other,Software</td>\n",
       "      <td>KEN</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>The edutainment company for children of the 21...</td>\n",
       "      <td>2018-11-08</td>\n",
       "      <td>1407 days</td>\n",
       "      <td>2500961.0</td>\n",
       "      <td>6.398107</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>2736 days</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>6.778151</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300448</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.619706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e8772824-d8d5-7636-0bd5-40b76511213b</td>\n",
       "      <td>Airdog</td>\n",
       "      <td>airdog.com</td>\n",
       "      <td>operating</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Artificial Intelligence,Drones,Robotics</td>\n",
       "      <td>Artificial Intelligence,Consumer Electronics,C...</td>\n",
       "      <td>LVA</td>\n",
       "      <td>Riga</td>\n",
       "      <td>We build smart robots that bring unprecedented...</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>442 days</td>\n",
       "      <td>2499329.0</td>\n",
       "      <td>6.397823</td>\n",
       "      <td>2016-07-18</td>\n",
       "      <td>929 days</td>\n",
       "      <td>3506665.0</td>\n",
       "      <td>6.544894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094384</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.210419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>be72d0fa-b5b0-eb2d-f8aa-3cb290f97b33</td>\n",
       "      <td>Ubiq.ai</td>\n",
       "      <td>ubiq.ai</td>\n",
       "      <td>operating</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Autonomous Vehicles,Car Sharing,Internet,Last ...</td>\n",
       "      <td>Internet Services,Real Estate,Software,Transpo...</td>\n",
       "      <td>AUT</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>Ubiq is shaping the future of urban mobility b...</td>\n",
       "      <td>2015-04-09</td>\n",
       "      <td>98 days</td>\n",
       "      <td>1440559.0</td>\n",
       "      <td>6.158531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7c9e6d25-8cf0-80a5-dfd6-d1a21337534d</td>\n",
       "      <td>ANKA</td>\n",
       "      <td>anka.africa</td>\n",
       "      <td>operating</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Art,E-Commerce,Fashion,Handmade</td>\n",
       "      <td>Clothing and Apparel,Commerce and Shopping,Con...</td>\n",
       "      <td>CIV</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>ANKA is a platform to discover, buy, and sell ...</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>537 days</td>\n",
       "      <td>8076881.0</td>\n",
       "      <td>6.907244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114670</td>\n",
       "      <td>0.017949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              org_uuid org_name       domain  \\\n",
       "0           0  86bd89a7-fe3f-12d4-817c-8157c8592194    i.Sec      isec.ng   \n",
       "1           1  58fd74f2-9ebb-4a41-cd75-05f9214a9a11    Kukua     kukua.me   \n",
       "2           2  e8772824-d8d5-7636-0bd5-40b76511213b   Airdog   airdog.com   \n",
       "3           3  be72d0fa-b5b0-eb2d-f8aa-3cb290f97b33  Ubiq.ai      ubiq.ai   \n",
       "4           4  7c9e6d25-8cf0-80a5-dfd6-d1a21337534d     ANKA  anka.africa   \n",
       "\n",
       "      status  founded_on                                      category_list  \\\n",
       "0  operating  2013-01-01                                    Finance,FinTech   \n",
       "1  operating  2015-01-01   Content,EdTech,Franchise,Media and Entertainment   \n",
       "2  operating  2014-01-01            Artificial Intelligence,Drones,Robotics   \n",
       "3  operating  2015-01-01  Autonomous Vehicles,Car Sharing,Internet,Last ...   \n",
       "4  operating  2016-01-01                    Art,E-Commerce,Fashion,Handmade   \n",
       "\n",
       "                                category_groups_list country_code     city  \\\n",
       "0                                 Financial Services          NGA    Lagos   \n",
       "1   Education,Media and Entertainment,Other,Software          KEN  Nairobi   \n",
       "2  Artificial Intelligence,Consumer Electronics,C...          LVA     Riga   \n",
       "3  Internet Services,Real Estate,Software,Transpo...          AUT   Vienna   \n",
       "4  Clothing and Apparel,Commerce and Shopping,Con...          CIV  Abidjan   \n",
       "\n",
       "                                   short_description earliest_funding  \\\n",
       "0  i.Sec is a financial security service that all...              NaN   \n",
       "1  The edutainment company for children of the 21...       2018-11-08   \n",
       "2  We build smart robots that bring unprecedented...       2015-03-19   \n",
       "3  Ubiq is shaping the future of urban mobility b...       2015-04-09   \n",
       "4  ANKA is a platform to discover, buy, and sell ...       2017-06-21   \n",
       "\n",
       "  time_first_funding  seed_funding  seed_funding_log series_a_funding_date  \\\n",
       "0                NaN           0.0          0.000000                   NaN   \n",
       "1          1407 days     2500961.0          6.398107            2022-06-29   \n",
       "2           442 days     2499329.0          6.397823            2016-07-18   \n",
       "3            98 days     1440559.0          6.158531                   NaN   \n",
       "4           537 days     8076881.0          6.907244                   NaN   \n",
       "\n",
       "  time_till_series_a  series_a_funding  series_a_funding_log  seed_n_rounds  \\\n",
       "0                NaN               0.0              0.000000            0.0   \n",
       "1          2736 days         6000000.0              6.778151            3.0   \n",
       "2           929 days         3506665.0              6.544894            1.0   \n",
       "3                NaN               0.0              0.000000            1.0   \n",
       "4                NaN               0.0              0.000000            5.0   \n",
       "\n",
       "   series_a_n_rounds  angel_n_rounds  pre_seed_n_rounds  success_flag  \\\n",
       "0                0.0             0.0                0.0             0   \n",
       "1                1.0             0.0                0.0             0   \n",
       "2                1.0             0.0                0.0             0   \n",
       "3                0.0             0.0                1.0             0   \n",
       "4                0.0             0.0                1.0             0   \n",
       "\n",
       "   time_first_funding_normalised  seed_funding_normalised  \\\n",
       "0                       0.410421                 0.000000   \n",
       "1                       0.300448                 0.005558   \n",
       "2                       0.094384                 0.005554   \n",
       "3                       0.020927                 0.003201   \n",
       "4                       0.114670                 0.017949   \n",
       "\n",
       "   series_a_funding_normalised  time_till_series_a_normalised  \n",
       "0                     0.000000                       0.323669  \n",
       "1                     0.003985                       0.619706  \n",
       "2                     0.002329                       0.210419  \n",
       "3                     0.000000                       0.290283  \n",
       "4                     0.000000                       0.557327  "
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_all_merged = pd.read_csv('data/Data_merged_temp_features_v3.csv')\n",
    "df_all_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_list = ['earliest_funding', \n",
    "                 'domain', \n",
    "                 'org_uuid',\n",
    "                 'country_code',\n",
    "                 'series_a_funding_log',\n",
    "                 'org_name',\n",
    "                 'seed_funding_log',\n",
    "                 'series_a_funding', \n",
    "                 'city', \n",
    "                 'short_description', \n",
    "                 'founded_on', \n",
    "                 'category_list', \n",
    "                 'seed_funding', \n",
    "                 'time_first_funding', \n",
    "                 'status', \n",
    "                 'Unnamed: 0', \n",
    "                 'time_till_series_a', \n",
    "                 'category_groups_list', \n",
    "                 'series_a_funding_date']\n",
    "\n",
    "\n",
    "df_all_clean = df_all_merged.drop(labels = drop_col_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_n_rounds</th>\n",
       "      <th>series_a_n_rounds</th>\n",
       "      <th>angel_n_rounds</th>\n",
       "      <th>pre_seed_n_rounds</th>\n",
       "      <th>success_flag</th>\n",
       "      <th>time_first_funding_normalised</th>\n",
       "      <th>seed_funding_normalised</th>\n",
       "      <th>series_a_funding_normalised</th>\n",
       "      <th>time_till_series_a_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300448</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.619706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094384</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.210419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114670</td>\n",
       "      <td>0.017949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed_n_rounds  series_a_n_rounds  angel_n_rounds  pre_seed_n_rounds  \\\n",
       "0            0.0                0.0             0.0                0.0   \n",
       "1            3.0                1.0             0.0                0.0   \n",
       "2            1.0                1.0             0.0                0.0   \n",
       "3            1.0                0.0             0.0                1.0   \n",
       "4            5.0                0.0             0.0                1.0   \n",
       "\n",
       "   success_flag  time_first_funding_normalised  seed_funding_normalised  \\\n",
       "0             0                       0.410421                 0.000000   \n",
       "1             0                       0.300448                 0.005558   \n",
       "2             0                       0.094384                 0.005554   \n",
       "3             0                       0.020927                 0.003201   \n",
       "4             0                       0.114670                 0.017949   \n",
       "\n",
       "   series_a_funding_normalised  time_till_series_a_normalised  \n",
       "0                     0.000000                       0.323669  \n",
       "1                     0.003985                       0.619706  \n",
       "2                     0.002329                       0.210419  \n",
       "3                     0.000000                       0.290283  \n",
       "4                     0.000000                       0.557327  "
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0]\n",
      "[1]\n",
      "torch.Size([3647, 8]) torch.Size([3647, 1])\n"
     ]
    }
   ],
   "source": [
    "# data, model wants all features in range [0,1] hence we use max-min norm again\n",
    "y_all = df_all_clean.pop('success_flag').to_frame()\n",
    "X_all = df_all_clean\n",
    "X_all = X_all.to_numpy()\n",
    "y_all = y_all.to_numpy()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_all[:,0:4] = min_max_scaler.fit_transform(X_all[:,0:4])\n",
    "print(X_all.min(axis=0))\n",
    "print(X_all.max(axis=0))\n",
    "y_all[:,0:4] = min_max_scaler.fit_transform(y_all[:,0:4])\n",
    "print(y_all.min(axis=0))\n",
    "print(y_all.max(axis=0))\n",
    "\n",
    "# make the train, test, and validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "X_train = torch.from_numpy(X_train).to(torch.float32)\n",
    "Y_train = torch.from_numpy(y_train).to(torch.float32)\n",
    "X_val = torch.from_numpy(X_val).to(torch.float32)\n",
    "Y_val = torch.from_numpy(y_val).to(torch.float32)\n",
    "X_test = torch.from_numpy(X_test).to(torch.float32)\n",
    "Y_test = torch.from_numpy(y_test).to(torch.float32)\n",
    "\n",
    "print(X_train.size(), Y_train.size())\n",
    "train_set_all = CustomDataset(input_tensors=(X_train, Y_train))\n",
    "train_loader = DataLoader(train_set_all,\n",
    "                              batch_size=4,\n",
    "                              shuffle=True)\n",
    "validation_set_all = CustomDataset(input_tensors=(X_val, Y_val))\n",
    "validation_loader = DataLoader(validation_set_all,\n",
    "                                batch_size=4,\n",
    "                                shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def training_loop(hyperparams: dict, model, train_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    :param hyperparams:     Should contain hyperparameters, including loss function, optimizer, number of epochs, etc.\n",
    "    :param model:\n",
    "    :param train_loader:\n",
    "    :param valid_loader:\n",
    "    :param device:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    optimizer = hyperparams['optimizer']\n",
    "    loss_fn = hyperparams['loss_fn']\n",
    "    train_loss_values = []\n",
    "    train_acc_values = []\n",
    "    val_loss_values = []\n",
    "    val_acc_values = []\n",
    "    for epoch in range(hyperparams['num_epochs']):\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        epoch_loss_train = 0.0\n",
    "        epoch_loss_val = 0.0\n",
    "        correct_train = 0\n",
    "        correct_val = 0\n",
    "        total_count_train = 0\n",
    "        total_count_val = 0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calculate accuracy and loss\n",
    "            total_count_train += labels.size(0)\n",
    "            predictions = (outputs > 0.5)\n",
    "            correct_train += (predictions == labels).sum().item()\n",
    "            epoch_loss_train += loss.item()\n",
    "\n",
    "        for data in validation_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # calculate accuracy and loss\n",
    "            total_count_val += labels.size(0)\n",
    "            predictions = (outputs > 0.5)\n",
    "            correct_val += (predictions == labels).sum().item()\n",
    "            epoch_loss_val += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch} train loss: {epoch_loss_train / len(train_loader)}')\n",
    "        print(f'Epoch {epoch} train accuracy: {100 * correct_train / total_count_train}')\n",
    "        print(f'Epoch {epoch} val loss: {epoch_loss_val / len(validation_loader)}')\n",
    "        print(f'Epoch {epoch} val accuracy: {100 * correct_val / total_count_val}')\n",
    "        if epoch % hyperparams['model_save_interval'] == 0:\n",
    "            \n",
    "            model.save_model(checkpoint_number=epoch, optimizer=optimizer)\n",
    "            train_loss_values.append(epoch_loss_train / len(train_loader))\n",
    "            train_acc_values.append(correct_train / total_count_train)\n",
    "            val_loss_values.append(epoch_loss_val / len(validation_loader))\n",
    "            val_acc_values.append(correct_val / total_count_val)\n",
    "    return train_loss_values, train_acc_values, val_loss_values, val_acc_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallMLP(model_path=r'.\\test_models')\n",
    "hyperparams = {'optimizer': Adam(model.parameters(), lr=1e-5),\n",
    "                       'loss_fn': torch.nn.BCEWithLogitsLoss(),\n",
    "                       'num_epochs': 2500,\n",
    "                       'model_save_interval': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.6931483628587765\n",
      "Epoch 0 train accuracy: 64.68330134357005\n",
      "Epoch 0 val loss: 0.6931471824645996\n",
      "Epoch 0 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_0.pth\n",
      "Epoch 1 train loss: 0.6931486121264466\n",
      "Epoch 1 train accuracy: 64.68330134357005\n",
      "Epoch 1 val loss: 0.6931471824645996\n",
      "Epoch 1 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_1.pth\n",
      "Epoch 2 train loss: 0.6931482511000675\n",
      "Epoch 2 train accuracy: 64.68330134357005\n",
      "Epoch 2 val loss: 0.6931471824645996\n",
      "Epoch 2 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_2.pth\n",
      "Epoch 3 train loss: 0.6931482595309877\n",
      "Epoch 3 train accuracy: 64.68330134357005\n",
      "Epoch 3 val loss: 0.6931471824645996\n",
      "Epoch 3 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_3.pth\n",
      "Epoch 4 train loss: 0.6931475223156444\n",
      "Epoch 4 train accuracy: 64.68330134357005\n",
      "Epoch 4 val loss: 0.6931478651730638\n",
      "Epoch 4 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_4.pth\n",
      "Epoch 5 train loss: 0.6931480674497914\n",
      "Epoch 5 train accuracy: 64.68330134357005\n",
      "Epoch 5 val loss: 0.6931471824645996\n",
      "Epoch 5 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_5.pth\n",
      "Epoch 6 train loss: 0.6931475372168056\n",
      "Epoch 6 train accuracy: 64.68330134357005\n",
      "Epoch 6 val loss: 0.6931471824645996\n",
      "Epoch 6 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_6.pth\n",
      "Epoch 7 train loss: 0.6931475913969048\n",
      "Epoch 7 train accuracy: 64.68330134357005\n",
      "Epoch 7 val loss: 0.6931471824645996\n",
      "Epoch 7 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_7.pth\n",
      "Epoch 8 train loss: 0.6931479846437772\n",
      "Epoch 8 train accuracy: 64.68330134357005\n",
      "Epoch 8 val loss: 0.6931471824645996\n",
      "Epoch 8 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_8.pth\n",
      "Epoch 9 train loss: 0.6931477248537958\n",
      "Epoch 9 train accuracy: 64.68330134357005\n",
      "Epoch 9 val loss: 0.6931471824645996\n",
      "Epoch 9 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_9.pth\n",
      "Epoch 10 train loss: 0.6931478862830421\n",
      "Epoch 10 train accuracy: 64.68330134357005\n",
      "Epoch 10 val loss: 0.6931471824645996\n",
      "Epoch 10 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_10.pth\n",
      "Epoch 11 train loss: 0.6931478166789339\n",
      "Epoch 11 train accuracy: 64.68330134357005\n",
      "Epoch 11 val loss: 0.6931471824645996\n",
      "Epoch 11 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_11.pth\n",
      "Epoch 12 train loss: 0.6931481152903616\n",
      "Epoch 12 train accuracy: 64.68330134357005\n",
      "Epoch 12 val loss: 0.6931471824645996\n",
      "Epoch 12 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_12.pth\n",
      "Epoch 13 train loss: 0.6931471740990355\n",
      "Epoch 13 train accuracy: 64.68330134357005\n",
      "Epoch 13 val loss: 0.6931471922679951\n",
      "Epoch 13 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_13.pth\n",
      "Epoch 14 train loss: 0.693147862362757\n",
      "Epoch 14 train accuracy: 64.68330134357005\n",
      "Epoch 14 val loss: 0.6931471824645996\n",
      "Epoch 14 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_14.pth\n",
      "Epoch 15 train loss: 0.6931472267105914\n",
      "Epoch 15 train accuracy: 64.68330134357005\n",
      "Epoch 15 val loss: 0.6931471824645996\n",
      "Epoch 15 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_15.pth\n",
      "Epoch 16 train loss: 0.6931475470202011\n",
      "Epoch 16 train accuracy: 64.68330134357005\n",
      "Epoch 16 val loss: 0.6931471824645996\n",
      "Epoch 16 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_16.pth\n",
      "Epoch 17 train loss: 0.6931473814081728\n",
      "Epoch 17 train accuracy: 64.68330134357005\n",
      "Epoch 17 val loss: 0.6931471824645996\n",
      "Epoch 17 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_17.pth\n",
      "Epoch 18 train loss: 0.6931472957264959\n",
      "Epoch 18 train accuracy: 64.68330134357005\n",
      "Epoch 18 val loss: 0.6931471824645996\n",
      "Epoch 18 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_18.pth\n",
      "Epoch 19 train loss: 0.6931469466602593\n",
      "Epoch 19 train accuracy: 64.68330134357005\n",
      "Epoch 19 val loss: 0.6931471824645996\n",
      "Epoch 19 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_19.pth\n",
      "Epoch 20 train loss: 0.6931475401578242\n",
      "Epoch 20 train accuracy: 64.68330134357005\n",
      "Epoch 20 val loss: 0.6931471824645996\n",
      "Epoch 20 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_20.pth\n",
      "Epoch 21 train loss: 0.6931472893869668\n",
      "Epoch 21 train accuracy: 64.68330134357005\n",
      "Epoch 21 val loss: 0.6931471824645996\n",
      "Epoch 21 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_21.pth\n",
      "Epoch 22 train loss: 0.693147580090322\n",
      "Epoch 22 train accuracy: 64.68330134357005\n",
      "Epoch 22 val loss: 0.6931474322551175\n",
      "Epoch 22 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_22.pth\n",
      "Epoch 23 train loss: 0.6931473925186876\n",
      "Epoch 23 train accuracy: 64.68330134357005\n",
      "Epoch 23 val loss: 0.6931474849973854\n",
      "Epoch 23 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_23.pth\n",
      "Epoch 24 train loss: 0.6931471011617727\n",
      "Epoch 24 train accuracy: 64.68330134357005\n",
      "Epoch 24 val loss: 0.693148493178581\n",
      "Epoch 24 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_24.pth\n",
      "Epoch 25 train loss: 0.6931468015046496\n",
      "Epoch 25 train accuracy: 64.68330134357005\n",
      "Epoch 25 val loss: 0.6931492686271667\n",
      "Epoch 25 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_25.pth\n",
      "Epoch 26 train loss: 0.6931456641147011\n",
      "Epoch 26 train accuracy: 64.68330134357005\n",
      "Epoch 26 val loss: 0.6931488396305787\n",
      "Epoch 26 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_26.pth\n",
      "Epoch 27 train loss: 0.6931477183181989\n",
      "Epoch 27 train accuracy: 64.68330134357005\n",
      "Epoch 27 val loss: 0.69314909942056\n",
      "Epoch 27 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_27.pth\n",
      "Epoch 28 train loss: 0.693145695158787\n",
      "Epoch 28 train accuracy: 64.68330134357005\n",
      "Epoch 28 val loss: 0.6931484572981533\n",
      "Epoch 28 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_28.pth\n",
      "Epoch 29 train loss: 0.693143626054128\n",
      "Epoch 29 train accuracy: 64.68330134357005\n",
      "Epoch 29 val loss: 0.6931432450288221\n",
      "Epoch 29 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_29.pth\n",
      "Epoch 30 train loss: 0.6931275095986692\n",
      "Epoch 30 train accuracy: 64.68330134357005\n",
      "Epoch 30 val loss: 0.6930000093814573\n",
      "Epoch 30 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_30.pth\n",
      "Epoch 31 train loss: 0.6926446653118259\n",
      "Epoch 31 train accuracy: 64.68330134357005\n",
      "Epoch 31 val loss: 0.6922927728216899\n",
      "Epoch 31 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_31.pth\n",
      "Epoch 32 train loss: 0.6922960626451593\n",
      "Epoch 32 train accuracy: 64.68330134357005\n",
      "Epoch 32 val loss: 0.6919259078016406\n",
      "Epoch 32 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_32.pth\n",
      "Epoch 33 train loss: 0.6920170268337977\n",
      "Epoch 33 train accuracy: 64.68330134357005\n",
      "Epoch 33 val loss: 0.6915866642406112\n",
      "Epoch 33 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_33.pth\n",
      "Epoch 34 train loss: 0.6917578868829367\n",
      "Epoch 34 train accuracy: 64.68330134357005\n",
      "Epoch 34 val loss: 0.6912828221132881\n",
      "Epoch 34 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_34.pth\n",
      "Epoch 35 train loss: 0.6915145826182867\n",
      "Epoch 35 train accuracy: 64.68330134357005\n",
      "Epoch 35 val loss: 0.6909826288097783\n",
      "Epoch 35 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_35.pth\n",
      "Epoch 36 train loss: 0.6912771896050688\n",
      "Epoch 36 train accuracy: 64.68330134357005\n",
      "Epoch 36 val loss: 0.6906793966497246\n",
      "Epoch 36 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_36.pth\n",
      "Epoch 37 train loss: 0.6910267613436046\n",
      "Epoch 37 train accuracy: 64.68330134357005\n",
      "Epoch 37 val loss: 0.690361569586553\n",
      "Epoch 37 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_37.pth\n",
      "Epoch 38 train loss: 0.690749512299111\n",
      "Epoch 38 train accuracy: 64.68330134357005\n",
      "Epoch 38 val loss: 0.6900358660832832\n",
      "Epoch 38 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_38.pth\n",
      "Epoch 39 train loss: 0.6904916541095365\n",
      "Epoch 39 train accuracy: 64.68330134357005\n",
      "Epoch 39 val loss: 0.6897112831081215\n",
      "Epoch 39 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_39.pth\n",
      "Epoch 40 train loss: 0.6902318136080315\n",
      "Epoch 40 train accuracy: 64.68330134357005\n",
      "Epoch 40 val loss: 0.6894212349465019\n",
      "Epoch 40 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_40.pth\n",
      "Epoch 41 train loss: 0.6899767249430481\n",
      "Epoch 41 train accuracy: 64.68330134357005\n",
      "Epoch 41 val loss: 0.6891002502096327\n",
      "Epoch 41 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_41.pth\n",
      "Epoch 42 train loss: 0.6897205346378318\n",
      "Epoch 42 train accuracy: 64.68330134357005\n",
      "Epoch 42 val loss: 0.6887951954022834\n",
      "Epoch 42 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_42.pth\n",
      "Epoch 43 train loss: 0.6894746583543325\n",
      "Epoch 43 train accuracy: 64.68330134357005\n",
      "Epoch 43 val loss: 0.6884783004459581\n",
      "Epoch 43 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_43.pth\n",
      "Epoch 44 train loss: 0.689225157232661\n",
      "Epoch 44 train accuracy: 64.68330134357005\n",
      "Epoch 44 val loss: 0.6881858733923811\n",
      "Epoch 44 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_44.pth\n",
      "Epoch 45 train loss: 0.6889829293154833\n",
      "Epoch 45 train accuracy: 64.68330134357005\n",
      "Epoch 45 val loss: 0.6878937753407579\n",
      "Epoch 45 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_45.pth\n",
      "Epoch 46 train loss: 0.6887388173163983\n",
      "Epoch 46 train accuracy: 64.68330134357005\n",
      "Epoch 46 val loss: 0.6875701185904051\n",
      "Epoch 46 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_46.pth\n",
      "Epoch 47 train loss: 0.6885012129419729\n",
      "Epoch 47 train accuracy: 64.68330134357005\n",
      "Epoch 47 val loss: 0.6872892687587362\n",
      "Epoch 47 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_47.pth\n",
      "Epoch 48 train loss: 0.6882788936950659\n",
      "Epoch 48 train accuracy: 64.68330134357005\n",
      "Epoch 48 val loss: 0.6870082034484336\n",
      "Epoch 48 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_48.pth\n",
      "Epoch 49 train loss: 0.6880395573874315\n",
      "Epoch 49 train accuracy: 64.68330134357005\n",
      "Epoch 49 val loss: 0.6867113119285357\n",
      "Epoch 49 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_49.pth\n",
      "Epoch 50 train loss: 0.6878093544459134\n",
      "Epoch 50 train accuracy: 64.68330134357005\n",
      "Epoch 50 val loss: 0.6864271222760803\n",
      "Epoch 50 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_50.pth\n",
      "Epoch 51 train loss: 0.6876007923039428\n",
      "Epoch 51 train accuracy: 64.68330134357005\n",
      "Epoch 51 val loss: 0.6861364761073339\n",
      "Epoch 51 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_51.pth\n",
      "Epoch 52 train loss: 0.687355976682483\n",
      "Epoch 52 train accuracy: 64.68330134357005\n",
      "Epoch 52 val loss: 0.6858707282103991\n",
      "Epoch 52 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_52.pth\n",
      "Epoch 53 train loss: 0.6871375099085925\n",
      "Epoch 53 train accuracy: 64.68330134357005\n",
      "Epoch 53 val loss: 0.6855960551061129\n",
      "Epoch 53 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_53.pth\n",
      "Epoch 54 train loss: 0.6869075123808885\n",
      "Epoch 54 train accuracy: 64.68330134357005\n",
      "Epoch 54 val loss: 0.6853435723797271\n",
      "Epoch 54 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_54.pth\n",
      "Epoch 55 train loss: 0.6867009498701807\n",
      "Epoch 55 train accuracy: 64.68330134357005\n",
      "Epoch 55 val loss: 0.6850522189940277\n",
      "Epoch 55 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_55.pth\n",
      "Epoch 56 train loss: 0.6864748364477827\n",
      "Epoch 56 train accuracy: 64.68330134357005\n",
      "Epoch 56 val loss: 0.6847888744975391\n",
      "Epoch 56 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_56.pth\n",
      "Epoch 57 train loss: 0.6862516040472608\n",
      "Epoch 57 train accuracy: 64.68330134357005\n",
      "Epoch 57 val loss: 0.6844943124604853\n",
      "Epoch 57 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_57.pth\n",
      "Epoch 58 train loss: 0.6860565903286139\n",
      "Epoch 58 train accuracy: 64.68330134357005\n",
      "Epoch 58 val loss: 0.6842272609080139\n",
      "Epoch 58 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_58.pth\n",
      "Epoch 59 train loss: 0.6858284617202324\n",
      "Epoch 59 train accuracy: 64.68330134357005\n",
      "Epoch 59 val loss: 0.6839596938930059\n",
      "Epoch 59 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_59.pth\n",
      "Epoch 60 train loss: 0.6856182735870805\n",
      "Epoch 60 train accuracy: 64.68330134357005\n",
      "Epoch 60 val loss: 0.6836748897637192\n",
      "Epoch 60 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_60.pth\n",
      "Epoch 61 train loss: 0.6854020587838533\n",
      "Epoch 61 train accuracy: 64.68330134357005\n",
      "Epoch 61 val loss: 0.6833955302442375\n",
      "Epoch 61 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_61.pth\n",
      "Epoch 62 train loss: 0.6851952375288595\n",
      "Epoch 62 train accuracy: 64.68330134357005\n",
      "Epoch 62 val loss: 0.6831463326356912\n",
      "Epoch 62 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_62.pth\n",
      "Epoch 63 train loss: 0.6849853810119001\n",
      "Epoch 63 train accuracy: 64.68330134357005\n",
      "Epoch 63 val loss: 0.682892134511157\n",
      "Epoch 63 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_63.pth\n",
      "Epoch 64 train loss: 0.6847686425766402\n",
      "Epoch 64 train accuracy: 64.68330134357005\n",
      "Epoch 64 val loss: 0.6826301942530432\n",
      "Epoch 64 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_64.pth\n",
      "Epoch 65 train loss: 0.6845746763834828\n",
      "Epoch 65 train accuracy: 64.68330134357005\n",
      "Epoch 65 val loss: 0.6823683583030575\n",
      "Epoch 65 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_65.pth\n",
      "Epoch 66 train loss: 0.6843765414597696\n",
      "Epoch 66 train accuracy: 64.68330134357005\n",
      "Epoch 66 val loss: 0.6821175862691904\n",
      "Epoch 66 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_66.pth\n",
      "Epoch 67 train loss: 0.6841710718969504\n",
      "Epoch 67 train accuracy: 64.68330134357005\n",
      "Epoch 67 val loss: 0.6818618260716137\n",
      "Epoch 67 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_67.pth\n",
      "Epoch 68 train loss: 0.6839609367021343\n",
      "Epoch 68 train accuracy: 64.71072114066357\n",
      "Epoch 68 val loss: 0.6816022870571989\n",
      "Epoch 68 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_68.pth\n",
      "Epoch 69 train loss: 0.6837606194772219\n",
      "Epoch 69 train accuracy: 64.73814093775707\n",
      "Epoch 69 val loss: 0.6813508509413192\n",
      "Epoch 69 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_69.pth\n",
      "Epoch 70 train loss: 0.683586080542259\n",
      "Epoch 70 train accuracy: 64.73814093775707\n",
      "Epoch 70 val loss: 0.681111671814793\n",
      "Epoch 70 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_70.pth\n",
      "Epoch 71 train loss: 0.6833777030962601\n",
      "Epoch 71 train accuracy: 64.76556073485057\n",
      "Epoch 71 val loss: 0.6808442526349896\n",
      "Epoch 71 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_71.pth\n",
      "Epoch 72 train loss: 0.6831828359056983\n",
      "Epoch 72 train accuracy: 64.76556073485057\n",
      "Epoch 72 val loss: 0.6805957977316881\n",
      "Epoch 72 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_72.pth\n",
      "Epoch 73 train loss: 0.6829902574158552\n",
      "Epoch 73 train accuracy: 64.76556073485057\n",
      "Epoch 73 val loss: 0.680343926933251\n",
      "Epoch 73 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_73.pth\n",
      "Epoch 74 train loss: 0.682800244866756\n",
      "Epoch 74 train accuracy: 64.76556073485057\n",
      "Epoch 74 val loss: 0.6800896117561742\n",
      "Epoch 74 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_74.pth\n",
      "Epoch 75 train loss: 0.6825974658785159\n",
      "Epoch 75 train accuracy: 64.79298053194407\n",
      "Epoch 75 val loss: 0.6798549278786308\n",
      "Epoch 75 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_75.pth\n",
      "Epoch 76 train loss: 0.6823964786895534\n",
      "Epoch 76 train accuracy: 64.79298053194407\n",
      "Epoch 76 val loss: 0.6796037793943757\n",
      "Epoch 76 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_76.pth\n",
      "Epoch 77 train loss: 0.6821877462299246\n",
      "Epoch 77 train accuracy: 64.79298053194407\n",
      "Epoch 77 val loss: 0.6793766049178023\n",
      "Epoch 77 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_77.pth\n",
      "Epoch 78 train loss: 0.6820024840141597\n",
      "Epoch 78 train accuracy: 64.82040032903757\n",
      "Epoch 78 val loss: 0.6791188087510435\n",
      "Epoch 78 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_78.pth\n",
      "Epoch 79 train loss: 0.681835857530435\n",
      "Epoch 79 train accuracy: 64.79298053194407\n",
      "Epoch 79 val loss: 0.6788858077243755\n",
      "Epoch 79 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_models/MLP_79.pth\n",
      "Epoch 80 train loss: 0.6816385215181008\n",
      "Epoch 80 train accuracy: 64.79298053194407\n",
      "Epoch 80 val loss: 0.6786401589450083\n",
      "Epoch 80 val accuracy: 64.72039473684211\n",
      "Saved model to .\\test_models/MLP_80.pth\n",
      "Epoch 81 train loss: 0.6814672477674066\n",
      "Epoch 81 train accuracy: 64.90265972031807\n",
      "Epoch 81 val loss: 0.6784314219104616\n",
      "Epoch 81 val accuracy: 64.72039473684211\n",
      "Saved model to .\\test_models/MLP_81.pth\n",
      "Epoch 82 train loss: 0.6812918653482931\n",
      "Epoch 82 train accuracy: 64.93007951741157\n",
      "Epoch 82 val loss: 0.6782009336901339\n",
      "Epoch 82 val accuracy: 64.72039473684211\n",
      "Saved model to .\\test_models/MLP_82.pth\n",
      "Epoch 83 train loss: 0.6811052322256983\n",
      "Epoch 83 train accuracy: 64.93007951741157\n",
      "Epoch 83 val loss: 0.6779774129390717\n",
      "Epoch 83 val accuracy: 64.72039473684211\n",
      "Saved model to .\\test_models/MLP_83.pth\n",
      "Epoch 84 train loss: 0.6809123334262455\n",
      "Epoch 84 train accuracy: 64.93007951741157\n",
      "Epoch 84 val loss: 0.6777444619097208\n",
      "Epoch 84 val accuracy: 64.80263157894737\n",
      "Saved model to .\\test_models/MLP_84.pth\n",
      "Epoch 85 train loss: 0.6807367989891454\n",
      "Epoch 85 train accuracy: 65.01233890869207\n",
      "Epoch 85 val loss: 0.6775386231510263\n",
      "Epoch 85 val accuracy: 64.80263157894737\n",
      "Saved model to .\\test_models/MLP_85.pth\n",
      "Epoch 86 train loss: 0.6805405972950291\n",
      "Epoch 86 train accuracy: 65.06717850287907\n",
      "Epoch 86 val loss: 0.6773256851654303\n",
      "Epoch 86 val accuracy: 64.96710526315789\n",
      "Saved model to .\\test_models/MLP_86.pth\n",
      "Epoch 87 train loss: 0.6803689768309134\n",
      "Epoch 87 train accuracy: 65.17685769125309\n",
      "Epoch 87 val loss: 0.6770897778241258\n",
      "Epoch 87 val accuracy: 65.21381578947368\n",
      "Saved model to .\\test_models/MLP_87.pth\n",
      "Epoch 88 train loss: 0.6802015157514497\n",
      "Epoch 88 train accuracy: 65.23169728544009\n",
      "Epoch 88 val loss: 0.6768655263279614\n",
      "Epoch 88 val accuracy: 65.29605263157895\n",
      "Saved model to .\\test_models/MLP_88.pth\n",
      "Epoch 89 train loss: 0.6800272922243988\n",
      "Epoch 89 train accuracy: 65.28653687962709\n",
      "Epoch 89 val loss: 0.6766333436887515\n",
      "Epoch 89 val accuracy: 65.3782894736842\n",
      "Saved model to .\\test_models/MLP_89.pth\n",
      "Epoch 90 train loss: 0.6798350716238482\n",
      "Epoch 90 train accuracy: 65.28653687962709\n",
      "Epoch 90 val loss: 0.676406765062558\n",
      "Epoch 90 val accuracy: 65.46052631578948\n",
      "Saved model to .\\test_models/MLP_90.pth\n",
      "Epoch 91 train loss: 0.6796746753940457\n",
      "Epoch 91 train accuracy: 65.3413764738141\n",
      "Epoch 91 val loss: 0.6761947172252756\n",
      "Epoch 91 val accuracy: 65.54276315789474\n",
      "Saved model to .\\test_models/MLP_91.pth\n",
      "Epoch 92 train loss: 0.6794844917430166\n",
      "Epoch 92 train accuracy: 65.4236358650946\n",
      "Epoch 92 val loss: 0.6759797032726439\n",
      "Epoch 92 val accuracy: 65.54276315789474\n",
      "Saved model to .\\test_models/MLP_92.pth\n",
      "Epoch 93 train loss: 0.679316363052318\n",
      "Epoch 93 train accuracy: 65.5333150534686\n",
      "Epoch 93 val loss: 0.6757833200849985\n",
      "Epoch 93 val accuracy: 65.70723684210526\n",
      "Saved model to .\\test_models/MLP_93.pth\n",
      "Epoch 94 train loss: 0.6791342300804037\n",
      "Epoch 94 train accuracy: 65.58815464765561\n",
      "Epoch 94 val loss: 0.6755572549606624\n",
      "Epoch 94 val accuracy: 65.8717105263158\n",
      "Saved model to .\\test_models/MLP_94.pth\n",
      "Epoch 95 train loss: 0.6789817567587945\n",
      "Epoch 95 train accuracy: 65.67041403893612\n",
      "Epoch 95 val loss: 0.6753316798100346\n",
      "Epoch 95 val accuracy: 65.95394736842105\n",
      "Saved model to .\\test_models/MLP_95.pth\n",
      "Epoch 96 train loss: 0.6787905916571617\n",
      "Epoch 96 train accuracy: 65.75267343021662\n",
      "Epoch 96 val loss: 0.6751185555599237\n",
      "Epoch 96 val accuracy: 66.28289473684211\n",
      "Saved model to .\\test_models/MLP_96.pth\n",
      "Epoch 97 train loss: 0.6786246877490428\n",
      "Epoch 97 train accuracy: 65.86235261859062\n",
      "Epoch 97 val loss: 0.6749346954257864\n",
      "Epoch 97 val accuracy: 66.44736842105263\n",
      "Saved model to .\\test_models/MLP_97.pth\n",
      "Epoch 98 train loss: 0.6784838057662311\n",
      "Epoch 98 train accuracy: 65.88977241568412\n",
      "Epoch 98 val loss: 0.6747195642245444\n",
      "Epoch 98 val accuracy: 66.61184210526316\n",
      "Saved model to .\\test_models/MLP_98.pth\n",
      "Epoch 99 train loss: 0.6783300457162815\n",
      "Epoch 99 train accuracy: 65.97203180696462\n",
      "Epoch 99 val loss: 0.6744899112535151\n",
      "Epoch 99 val accuracy: 66.69407894736842\n",
      "Saved model to .\\test_models/MLP_99.pth\n",
      "Epoch 100 train loss: 0.6781600831370604\n",
      "Epoch 100 train accuracy: 66.19139018371264\n",
      "Epoch 100 val loss: 0.6742924622407085\n",
      "Epoch 100 val accuracy: 66.69407894736842\n",
      "Saved model to .\\test_models/MLP_100.pth\n",
      "Epoch 101 train loss: 0.6779941749154476\n",
      "Epoch 101 train accuracy: 66.32848916918014\n",
      "Epoch 101 val loss: 0.6740881184998312\n",
      "Epoch 101 val accuracy: 66.77631578947368\n",
      "Saved model to .\\test_models/MLP_101.pth\n",
      "Epoch 102 train loss: 0.6778201577171945\n",
      "Epoch 102 train accuracy: 66.41074856046065\n",
      "Epoch 102 val loss: 0.6738872128097635\n",
      "Epoch 102 val accuracy: 66.77631578947368\n",
      "Saved model to .\\test_models/MLP_102.pth\n",
      "Epoch 103 train loss: 0.677627875485964\n",
      "Epoch 103 train accuracy: 66.57526734302166\n",
      "Epoch 103 val loss: 0.6736822053790092\n",
      "Epoch 103 val accuracy: 67.26973684210526\n",
      "Saved model to .\\test_models/MLP_103.pth\n",
      "Epoch 104 train loss: 0.6774998248407715\n",
      "Epoch 104 train accuracy: 66.63010693720867\n",
      "Epoch 104 val loss: 0.6734922381215974\n",
      "Epoch 104 val accuracy: 67.26973684210526\n",
      "Saved model to .\\test_models/MLP_104.pth\n",
      "Epoch 105 train loss: 0.6772874184279588\n",
      "Epoch 105 train accuracy: 66.73978612558267\n",
      "Epoch 105 val loss: 0.6733071621703474\n",
      "Epoch 105 val accuracy: 67.4342105263158\n",
      "Saved model to .\\test_models/MLP_105.pth\n",
      "Epoch 106 train loss: 0.6771830834056202\n",
      "Epoch 106 train accuracy: 66.84946531395667\n",
      "Epoch 106 val loss: 0.6730950996279716\n",
      "Epoch 106 val accuracy: 67.35197368421052\n",
      "Saved model to .\\test_models/MLP_106.pth\n",
      "Epoch 107 train loss: 0.677027259871625\n",
      "Epoch 107 train accuracy: 66.98656429942419\n",
      "Epoch 107 val loss: 0.6728996956034711\n",
      "Epoch 107 val accuracy: 67.4342105263158\n",
      "Saved model to .\\test_models/MLP_107.pth\n",
      "Epoch 108 train loss: 0.6768675409910971\n",
      "Epoch 108 train accuracy: 67.15108308198519\n",
      "Epoch 108 val loss: 0.6727026585293444\n",
      "Epoch 108 val accuracy: 67.4342105263158\n",
      "Saved model to .\\test_models/MLP_108.pth\n",
      "Epoch 109 train loss: 0.6766818877505628\n",
      "Epoch 109 train accuracy: 67.34302166163971\n",
      "Epoch 109 val loss: 0.672511304287534\n",
      "Epoch 109 val accuracy: 67.4342105263158\n",
      "Saved model to .\\test_models/MLP_109.pth\n",
      "Epoch 110 train loss: 0.6765611272370606\n",
      "Epoch 110 train accuracy: 67.50754044420071\n",
      "Epoch 110 val loss: 0.6723157196844879\n",
      "Epoch 110 val accuracy: 67.76315789473684\n",
      "Saved model to .\\test_models/MLP_110.pth\n",
      "Epoch 111 train loss: 0.676387844443844\n",
      "Epoch 111 train accuracy: 67.61721963257472\n",
      "Epoch 111 val loss: 0.6721355748411856\n",
      "Epoch 111 val accuracy: 67.92763157894737\n",
      "Saved model to .\\test_models/MLP_111.pth\n",
      "Epoch 112 train loss: 0.6762516216227883\n",
      "Epoch 112 train accuracy: 67.61721963257472\n",
      "Epoch 112 val loss: 0.671922012281261\n",
      "Epoch 112 val accuracy: 68.09210526315789\n",
      "Saved model to .\\test_models/MLP_112.pth\n",
      "Epoch 113 train loss: 0.6760839290851564\n",
      "Epoch 113 train accuracy: 67.91883740060324\n",
      "Epoch 113 val loss: 0.6717319833604913\n",
      "Epoch 113 val accuracy: 68.00986842105263\n",
      "Saved model to .\\test_models/MLP_113.pth\n",
      "Epoch 114 train loss: 0.6759302708271303\n",
      "Epoch 114 train accuracy: 68.13819577735124\n",
      "Epoch 114 val loss: 0.6715301436028982\n",
      "Epoch 114 val accuracy: 68.25657894736842\n",
      "Saved model to .\\test_models/MLP_114.pth\n",
      "Epoch 115 train loss: 0.6757838868846496\n",
      "Epoch 115 train accuracy: 68.22045516863176\n",
      "Epoch 115 val loss: 0.6713474031145635\n",
      "Epoch 115 val accuracy: 68.58552631578948\n",
      "Saved model to .\\test_models/MLP_115.pth\n",
      "Epoch 116 train loss: 0.6756537964142728\n",
      "Epoch 116 train accuracy: 68.22045516863176\n",
      "Epoch 116 val loss: 0.6711616376905065\n",
      "Epoch 116 val accuracy: 68.83223684210526\n",
      "Saved model to .\\test_models/MLP_116.pth\n",
      "Epoch 117 train loss: 0.6754708676353881\n",
      "Epoch 117 train accuracy: 68.41239374828626\n",
      "Epoch 117 val loss: 0.670982042817693\n",
      "Epoch 117 val accuracy: 68.91447368421052\n",
      "Saved model to .\\test_models/MLP_117.pth\n",
      "Epoch 118 train loss: 0.6753377593530897\n",
      "Epoch 118 train accuracy: 68.52207293666027\n",
      "Epoch 118 val loss: 0.6707783282587403\n",
      "Epoch 118 val accuracy: 69.57236842105263\n",
      "Saved model to .\\test_models/MLP_118.pth\n",
      "Epoch 119 train loss: 0.6752349049048988\n",
      "Epoch 119 train accuracy: 68.76885111050179\n",
      "Epoch 119 val loss: 0.6705828795307561\n",
      "Epoch 119 val accuracy: 69.65460526315789\n",
      "Saved model to .\\test_models/MLP_119.pth\n",
      "Epoch 120 train loss: 0.6750705134973192\n",
      "Epoch 120 train accuracy: 68.82369070468879\n",
      "Epoch 120 val loss: 0.6704111686466556\n",
      "Epoch 120 val accuracy: 69.98355263157895\n",
      "Saved model to .\\test_models/MLP_120.pth\n",
      "Epoch 121 train loss: 0.6749327639608007\n",
      "Epoch 121 train accuracy: 69.0978886756238\n",
      "Epoch 121 val loss: 0.6702383548805588\n",
      "Epoch 121 val accuracy: 70.14802631578948\n",
      "Saved model to .\\test_models/MLP_121.pth\n",
      "Epoch 122 train loss: 0.6747985116876009\n",
      "Epoch 122 train accuracy: 69.26240745818481\n",
      "Epoch 122 val loss: 0.6700546659137073\n",
      "Epoch 122 val accuracy: 70.5592105263158\n",
      "Saved model to .\\test_models/MLP_122.pth\n",
      "Epoch 123 train loss: 0.6746644090795726\n",
      "Epoch 123 train accuracy: 69.37208664655881\n",
      "Epoch 123 val loss: 0.6698635577371246\n",
      "Epoch 123 val accuracy: 70.64144736842105\n",
      "Saved model to .\\test_models/MLP_123.pth\n",
      "Epoch 124 train loss: 0.6745162502976886\n",
      "Epoch 124 train accuracy: 69.67370441458733\n",
      "Epoch 124 val loss: 0.6696891780746611\n",
      "Epoch 124 val accuracy: 70.64144736842105\n",
      "Saved model to .\\test_models/MLP_124.pth\n",
      "Epoch 125 train loss: 0.6743728190725833\n",
      "Epoch 125 train accuracy: 69.70112421168083\n",
      "Epoch 125 val loss: 0.6695145096041655\n",
      "Epoch 125 val accuracy: 70.80592105263158\n",
      "Saved model to .\\test_models/MLP_125.pth\n",
      "Epoch 126 train loss: 0.6742609388342029\n",
      "Epoch 126 train accuracy: 69.75596380586784\n",
      "Epoch 126 val loss: 0.6693555414676666\n",
      "Epoch 126 val accuracy: 71.05263157894737\n",
      "Saved model to .\\test_models/MLP_126.pth\n",
      "Epoch 127 train loss: 0.6740969065250012\n",
      "Epoch 127 train accuracy: 69.81080340005484\n",
      "Epoch 127 val loss: 0.6691755738697553\n",
      "Epoch 127 val accuracy: 71.46381578947368\n",
      "Saved model to .\\test_models/MLP_127.pth\n",
      "Epoch 128 train loss: 0.6739569148212149\n",
      "Epoch 128 train accuracy: 69.89306279133534\n",
      "Epoch 128 val loss: 0.6690190254073394\n",
      "Epoch 128 val accuracy: 71.54605263157895\n",
      "Saved model to .\\test_models/MLP_128.pth\n",
      "Epoch 129 train loss: 0.6738671507490309\n",
      "Epoch 129 train accuracy: 70.16726076227036\n",
      "Epoch 129 val loss: 0.6688472220772191\n",
      "Epoch 129 val accuracy: 71.79276315789474\n",
      "Saved model to .\\test_models/MLP_129.pth\n",
      "Epoch 130 train loss: 0.6736888191417644\n",
      "Epoch 130 train accuracy: 70.19468055936386\n",
      "Epoch 130 val loss: 0.6686757497097316\n",
      "Epoch 130 val accuracy: 71.95723684210526\n",
      "Saved model to .\\test_models/MLP_130.pth\n",
      "Epoch 131 train loss: 0.673575055997884\n",
      "Epoch 131 train accuracy: 70.30435974773786\n",
      "Epoch 131 val loss: 0.6685023299957576\n",
      "Epoch 131 val accuracy: 72.03947368421052\n",
      "Saved model to .\\test_models/MLP_131.pth\n",
      "Epoch 132 train loss: 0.6734408953864324\n",
      "Epoch 132 train accuracy: 70.41403893611188\n",
      "Epoch 132 val loss: 0.668325708688874\n",
      "Epoch 132 val accuracy: 72.53289473684211\n",
      "Saved model to .\\test_models/MLP_132.pth\n",
      "Epoch 133 train loss: 0.6733136668213104\n",
      "Epoch 133 train accuracy: 70.60597751576638\n",
      "Epoch 133 val loss: 0.668168420266164\n",
      "Epoch 133 val accuracy: 72.53289473684211\n",
      "Saved model to .\\test_models/MLP_133.pth\n",
      "Epoch 134 train loss: 0.6731776186967628\n",
      "Epoch 134 train accuracy: 70.77049629832739\n",
      "Epoch 134 val loss: 0.6679978893187485\n",
      "Epoch 134 val accuracy: 72.45065789473684\n",
      "Saved model to .\\test_models/MLP_134.pth\n",
      "Epoch 135 train loss: 0.6730157589833987\n",
      "Epoch 135 train accuracy: 70.9624348779819\n",
      "Epoch 135 val loss: 0.6678326768114379\n",
      "Epoch 135 val accuracy: 72.53289473684211\n",
      "Saved model to .\\test_models/MLP_135.pth\n",
      "Epoch 136 train loss: 0.6728770184543049\n",
      "Epoch 136 train accuracy: 70.9075952837949\n",
      "Epoch 136 val loss: 0.6676698928992999\n",
      "Epoch 136 val accuracy: 72.53289473684211\n",
      "Saved model to .\\test_models/MLP_136.pth\n",
      "Epoch 137 train loss: 0.6727825137868262\n",
      "Epoch 137 train accuracy: 70.9350150808884\n",
      "Epoch 137 val loss: 0.6675002029851863\n",
      "Epoch 137 val accuracy: 72.69736842105263\n",
      "Saved model to .\\test_models/MLP_137.pth\n",
      "Epoch 138 train loss: 0.6726761689376936\n",
      "Epoch 138 train accuracy: 71.23663284891691\n",
      "Epoch 138 val loss: 0.6673383960794461\n",
      "Epoch 138 val accuracy: 72.69736842105263\n",
      "Saved model to .\\test_models/MLP_138.pth\n",
      "Epoch 139 train loss: 0.6725102305869785\n",
      "Epoch 139 train accuracy: 71.53825061694543\n",
      "Epoch 139 val loss: 0.6671822339688477\n",
      "Epoch 139 val accuracy: 72.69736842105263\n",
      "Saved model to .\\test_models/MLP_139.pth\n",
      "Epoch 140 train loss: 0.672399594040032\n",
      "Epoch 140 train accuracy: 71.62051000822593\n",
      "Epoch 140 val loss: 0.6670300895838361\n",
      "Epoch 140 val accuracy: 72.53289473684211\n",
      "Saved model to .\\test_models/MLP_140.pth\n",
      "Epoch 141 train loss: 0.6722923044049949\n",
      "Epoch 141 train accuracy: 71.59309021113243\n",
      "Epoch 141 val loss: 0.6668582423345039\n",
      "Epoch 141 val accuracy: 72.69736842105263\n",
      "Saved model to .\\test_models/MLP_141.pth\n",
      "Epoch 142 train loss: 0.6721412811689732\n",
      "Epoch 142 train accuracy: 71.78502879078695\n",
      "Epoch 142 val loss: 0.6667232248736056\n",
      "Epoch 142 val accuracy: 72.77960526315789\n",
      "Saved model to .\\test_models/MLP_142.pth\n",
      "Epoch 143 train loss: 0.6720233415171766\n",
      "Epoch 143 train accuracy: 71.64792980531944\n",
      "Epoch 143 val loss: 0.6665520094531147\n",
      "Epoch 143 val accuracy: 72.94407894736842\n",
      "Saved model to .\\test_models/MLP_143.pth\n",
      "Epoch 144 train loss: 0.6718530278456839\n",
      "Epoch 144 train accuracy: 71.89470797916096\n",
      "Epoch 144 val loss: 0.6664051642935527\n",
      "Epoch 144 val accuracy: 73.02631578947368\n",
      "Saved model to .\\test_models/MLP_144.pth\n",
      "Epoch 145 train loss: 0.6717771931240956\n",
      "Epoch 145 train accuracy: 71.92212777625446\n",
      "Epoch 145 val loss: 0.6662540486768672\n",
      "Epoch 145 val accuracy: 73.10855263157895\n",
      "Saved model to .\\test_models/MLP_145.pth\n",
      "Epoch 146 train loss: 0.6716587700995437\n",
      "Epoch 146 train accuracy: 71.92212777625446\n",
      "Epoch 146 val loss: 0.6661011210985874\n",
      "Epoch 146 val accuracy: 73.1907894736842\n",
      "Saved model to .\\test_models/MLP_146.pth\n",
      "Epoch 147 train loss: 0.6715046607219336\n",
      "Epoch 147 train accuracy: 72.05922676172196\n",
      "Epoch 147 val loss: 0.665943804932268\n",
      "Epoch 147 val accuracy: 73.27302631578948\n",
      "Saved model to .\\test_models/MLP_147.pth\n",
      "Epoch 148 train loss: 0.6714048404573348\n",
      "Epoch 148 train accuracy: 72.22374554428298\n",
      "Epoch 148 val loss: 0.6658136354465234\n",
      "Epoch 148 val accuracy: 73.35526315789474\n",
      "Saved model to .\\test_models/MLP_148.pth\n",
      "Epoch 149 train loss: 0.6712924792970482\n",
      "Epoch 149 train accuracy: 72.25116534137648\n",
      "Epoch 149 val loss: 0.6656342126233014\n",
      "Epoch 149 val accuracy: 73.35526315789474\n",
      "Saved model to .\\test_models/MLP_149.pth\n",
      "Epoch 150 train loss: 0.6711486988423163\n",
      "Epoch 150 train accuracy: 72.36084452975048\n",
      "Epoch 150 val loss: 0.6654840717582327\n",
      "Epoch 150 val accuracy: 73.35526315789474\n",
      "Saved model to .\\test_models/MLP_150.pth\n",
      "Epoch 151 train loss: 0.6710607872851062\n",
      "Epoch 151 train accuracy: 72.49794351521798\n",
      "Epoch 151 val loss: 0.6653291662468722\n",
      "Epoch 151 val accuracy: 73.4375\n",
      "Saved model to .\\test_models/MLP_151.pth\n",
      "Epoch 152 train loss: 0.6709220175745717\n",
      "Epoch 152 train accuracy: 72.662462297779\n",
      "Epoch 152 val loss: 0.6651901066499321\n",
      "Epoch 152 val accuracy: 73.4375\n",
      "Saved model to .\\test_models/MLP_152.pth\n",
      "Epoch 153 train loss: 0.670809402539019\n",
      "Epoch 153 train accuracy: 72.607622703592\n",
      "Epoch 153 val loss: 0.6650329143004982\n",
      "Epoch 153 val accuracy: 73.76644736842105\n",
      "Saved model to .\\test_models/MLP_153.pth\n",
      "Epoch 154 train loss: 0.6706769027861587\n",
      "Epoch 154 train accuracy: 72.772141486153\n",
      "Epoch 154 val loss: 0.6649008448186674\n",
      "Epoch 154 val accuracy: 73.76644736842105\n",
      "Saved model to .\\test_models/MLP_154.pth\n",
      "Epoch 155 train loss: 0.6705785948913872\n",
      "Epoch 155 train accuracy: 72.6898820948725\n",
      "Epoch 155 val loss: 0.6647602769693262\n",
      "Epoch 155 val accuracy: 73.6842105263158\n",
      "Saved model to .\\test_models/MLP_155.pth\n",
      "Epoch 156 train loss: 0.6704317711359054\n",
      "Epoch 156 train accuracy: 72.7995612832465\n",
      "Epoch 156 val loss: 0.6646125660719056\n",
      "Epoch 156 val accuracy: 74.09539473684211\n",
      "Saved model to .\\test_models/MLP_156.pth\n",
      "Epoch 157 train loss: 0.6703775311705836\n",
      "Epoch 157 train accuracy: 72.7447216890595\n",
      "Epoch 157 val loss: 0.6644635837721197\n",
      "Epoch 157 val accuracy: 74.25986842105263\n",
      "Saved model to .\\test_models/MLP_157.pth\n",
      "Epoch 158 train loss: 0.6702303933796653\n",
      "Epoch 158 train accuracy: 72.7447216890595\n",
      "Epoch 158 val loss: 0.6643227248599655\n",
      "Epoch 158 val accuracy: 74.34210526315789\n",
      "Saved model to .\\test_models/MLP_158.pth\n",
      "Epoch 159 train loss: 0.6700797412348422\n",
      "Epoch 159 train accuracy: 72.8544008774335\n",
      "Epoch 159 val loss: 0.6641971334618958\n",
      "Epoch 159 val accuracy: 74.34210526315789\n",
      "Saved model to .\\test_models/MLP_159.pth\n",
      "Epoch 160 train loss: 0.6699447327277117\n",
      "Epoch 160 train accuracy: 72.8544008774335\n",
      "Epoch 160 val loss: 0.6640612100692171\n",
      "Epoch 160 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_models/MLP_160.pth\n",
      "Epoch 161 train loss: 0.6699095535696599\n",
      "Epoch 161 train accuracy: 72.93666026871401\n",
      "Epoch 161 val loss: 0.6639213354179734\n",
      "Epoch 161 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_models/MLP_161.pth\n",
      "Epoch 162 train loss: 0.6697403512764395\n",
      "Epoch 162 train accuracy: 72.99149986290101\n",
      "Epoch 162 val loss: 0.6637708359446964\n",
      "Epoch 162 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_models/MLP_162.pth\n",
      "Epoch 163 train loss: 0.6696291839409816\n",
      "Epoch 163 train accuracy: 73.04633945708802\n",
      "Epoch 163 val loss: 0.6636446280110824\n",
      "Epoch 163 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_models/MLP_163.pth\n",
      "Epoch 164 train loss: 0.6695464324663606\n",
      "Epoch 164 train accuracy: 73.15601864546203\n",
      "Epoch 164 val loss: 0.6635094482059541\n",
      "Epoch 164 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_models/MLP_164.pth\n",
      "Epoch 165 train loss: 0.6694337966802874\n",
      "Epoch 165 train accuracy: 73.10117905127503\n",
      "Epoch 165 val loss: 0.6633691884773342\n",
      "Epoch 165 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_models/MLP_165.pth\n",
      "Epoch 166 train loss: 0.6693161854749186\n",
      "Epoch 166 train accuracy: 73.18343844255553\n",
      "Epoch 166 val loss: 0.6632336576126123\n",
      "Epoch 166 val accuracy: 74.58881578947368\n",
      "Saved model to .\\test_models/MLP_166.pth\n",
      "Epoch 167 train loss: 0.6691617695124525\n",
      "Epoch 167 train accuracy: 73.04633945708802\n",
      "Epoch 167 val loss: 0.6631057168308058\n",
      "Epoch 167 val accuracy: 74.58881578947368\n",
      "Saved model to .\\test_models/MLP_167.pth\n",
      "Epoch 168 train loss: 0.6690884552111751\n",
      "Epoch 168 train accuracy: 73.23827803674253\n",
      "Epoch 168 val loss: 0.6629496795174322\n",
      "Epoch 168 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_models/MLP_168.pth\n",
      "Epoch 169 train loss: 0.668944040509431\n",
      "Epoch 169 train accuracy: 73.23827803674253\n",
      "Epoch 169 val loss: 0.6628045434818456\n",
      "Epoch 169 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_models/MLP_169.pth\n",
      "Epoch 170 train loss: 0.6688704987693774\n",
      "Epoch 170 train accuracy: 73.18343844255553\n",
      "Epoch 170 val loss: 0.6626710183918476\n",
      "Epoch 170 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_models/MLP_170.pth\n",
      "Epoch 171 train loss: 0.6687631566208183\n",
      "Epoch 171 train accuracy: 73.37537702221003\n",
      "Epoch 171 val loss: 0.6625504033934129\n",
      "Epoch 171 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_models/MLP_171.pth\n",
      "Epoch 172 train loss: 0.668644975282644\n",
      "Epoch 172 train accuracy: 73.23827803674253\n",
      "Epoch 172 val loss: 0.6624294445898972\n",
      "Epoch 172 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_models/MLP_172.pth\n",
      "Epoch 173 train loss: 0.6685283645464662\n",
      "Epoch 173 train accuracy: 73.29311763092953\n",
      "Epoch 173 val loss: 0.6622988611067596\n",
      "Epoch 173 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_models/MLP_173.pth\n",
      "Epoch 174 train loss: 0.6684586522414496\n",
      "Epoch 174 train accuracy: 73.34795722511653\n",
      "Epoch 174 val loss: 0.6621489264070988\n",
      "Epoch 174 val accuracy: 75.0\n",
      "Saved model to .\\test_models/MLP_174.pth\n",
      "Epoch 175 train loss: 0.6683223759265322\n",
      "Epoch 175 train accuracy: 73.34795722511653\n",
      "Epoch 175 val loss: 0.6620314463384842\n",
      "Epoch 175 val accuracy: 75.0\n",
      "Saved model to .\\test_models/MLP_175.pth\n",
      "Epoch 176 train loss: 0.668227986285561\n",
      "Epoch 176 train accuracy: 73.45763641349053\n",
      "Epoch 176 val loss: 0.6619092992653972\n",
      "Epoch 176 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_models/MLP_176.pth\n",
      "Epoch 177 train loss: 0.6680582516352859\n",
      "Epoch 177 train accuracy: 73.32053742802303\n",
      "Epoch 177 val loss: 0.6617883401677797\n",
      "Epoch 177 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_models/MLP_177.pth\n",
      "Epoch 178 train loss: 0.667973835968919\n",
      "Epoch 178 train accuracy: 73.48505621058405\n",
      "Epoch 178 val loss: 0.6616438425293094\n",
      "Epoch 178 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_models/MLP_178.pth\n",
      "Epoch 179 train loss: 0.6678478740351764\n",
      "Epoch 179 train accuracy: 73.53989580477105\n",
      "Epoch 179 val loss: 0.6615294028857821\n",
      "Epoch 179 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_models/MLP_179.pth\n",
      "Epoch 180 train loss: 0.6677762398398236\n",
      "Epoch 180 train accuracy: 73.48505621058405\n",
      "Epoch 180 val loss: 0.6614162000386339\n",
      "Epoch 180 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_models/MLP_180.pth\n",
      "Epoch 181 train loss: 0.6676752898646029\n",
      "Epoch 181 train accuracy: 73.51247600767755\n",
      "Epoch 181 val loss: 0.6612629014018335\n",
      "Epoch 181 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_models/MLP_181.pth\n",
      "Epoch 182 train loss: 0.6675293779882946\n",
      "Epoch 182 train accuracy: 73.56731560186455\n",
      "Epoch 182 val loss: 0.6611542537024147\n",
      "Epoch 182 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_182.pth\n",
      "Epoch 183 train loss: 0.6674375678167531\n",
      "Epoch 183 train accuracy: 73.56731560186455\n",
      "Epoch 183 val loss: 0.6609946272679066\n",
      "Epoch 183 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_models/MLP_183.pth\n",
      "Epoch 184 train loss: 0.6673502658346766\n",
      "Epoch 184 train accuracy: 73.73183438442555\n",
      "Epoch 184 val loss: 0.6608732522122169\n",
      "Epoch 184 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_models/MLP_184.pth\n",
      "Epoch 185 train loss: 0.6672215222201326\n",
      "Epoch 185 train accuracy: 73.75925418151905\n",
      "Epoch 185 val loss: 0.6607380372128988\n",
      "Epoch 185 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_models/MLP_185.pth\n",
      "Epoch 186 train loss: 0.6671494966078746\n",
      "Epoch 186 train accuracy: 73.73183438442555\n",
      "Epoch 186 val loss: 0.6606103938661123\n",
      "Epoch 186 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_186.pth\n",
      "Epoch 187 train loss: 0.6670357403590491\n",
      "Epoch 187 train accuracy: 73.75925418151905\n",
      "Epoch 187 val loss: 0.6604921826602597\n",
      "Epoch 187 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_187.pth\n",
      "Epoch 188 train loss: 0.6669319013885239\n",
      "Epoch 188 train accuracy: 73.75925418151905\n",
      "Epoch 188 val loss: 0.6603655232802818\n",
      "Epoch 188 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_models/MLP_188.pth\n",
      "Epoch 189 train loss: 0.6668322445138505\n",
      "Epoch 189 train accuracy: 73.75925418151905\n",
      "Epoch 189 val loss: 0.6602353616372535\n",
      "Epoch 189 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_189.pth\n",
      "Epoch 190 train loss: 0.6667238353637227\n",
      "Epoch 190 train accuracy: 73.97861255826707\n",
      "Epoch 190 val loss: 0.6601342432396976\n",
      "Epoch 190 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_190.pth\n",
      "Epoch 191 train loss: 0.6666441674164513\n",
      "Epoch 191 train accuracy: 73.81409377570606\n",
      "Epoch 191 val loss: 0.6600076170932305\n",
      "Epoch 191 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_191.pth\n",
      "Epoch 192 train loss: 0.6664584000317151\n",
      "Epoch 192 train accuracy: 73.92377296408007\n",
      "Epoch 192 val loss: 0.6599053538551456\n",
      "Epoch 192 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_192.pth\n",
      "Epoch 193 train loss: 0.6663908337553343\n",
      "Epoch 193 train accuracy: 73.84151357279956\n",
      "Epoch 193 val loss: 0.659765857418901\n",
      "Epoch 193 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_193.pth\n",
      "Epoch 194 train loss: 0.6663219455564231\n",
      "Epoch 194 train accuracy: 74.03345215245407\n",
      "Epoch 194 val loss: 0.6596385401330496\n",
      "Epoch 194 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_194.pth\n",
      "Epoch 195 train loss: 0.6661982714084157\n",
      "Epoch 195 train accuracy: 74.11571154373458\n",
      "Epoch 195 val loss: 0.659499722483911\n",
      "Epoch 195 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_195.pth\n",
      "Epoch 196 train loss: 0.6661234623507449\n",
      "Epoch 196 train accuracy: 74.17055113792158\n",
      "Epoch 196 val loss: 0.6593879921067702\n",
      "Epoch 196 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_models/MLP_196.pth\n",
      "Epoch 197 train loss: 0.6660871584491249\n",
      "Epoch 197 train accuracy: 74.14313134082808\n",
      "Epoch 197 val loss: 0.6592487451669417\n",
      "Epoch 197 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_models/MLP_197.pth\n",
      "Epoch 198 train loss: 0.6659238853475504\n",
      "Epoch 198 train accuracy: 74.11571154373458\n",
      "Epoch 198 val loss: 0.659161752089858\n",
      "Epoch 198 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_models/MLP_198.pth\n",
      "Epoch 199 train loss: 0.6658125969728357\n",
      "Epoch 199 train accuracy: 74.14313134082808\n",
      "Epoch 199 val loss: 0.6590460061438774\n",
      "Epoch 199 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_models/MLP_199.pth\n",
      "Epoch 200 train loss: 0.6657093948635616\n",
      "Epoch 200 train accuracy: 74.14313134082808\n",
      "Epoch 200 val loss: 0.6589302107887832\n",
      "Epoch 200 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_models/MLP_200.pth\n",
      "Epoch 201 train loss: 0.6656347207659692\n",
      "Epoch 201 train accuracy: 74.14313134082808\n",
      "Epoch 201 val loss: 0.6587929537421778\n",
      "Epoch 201 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_201.pth\n",
      "Epoch 202 train loss: 0.665510325806967\n",
      "Epoch 202 train accuracy: 74.19797093501508\n",
      "Epoch 202 val loss: 0.6586875616523781\n",
      "Epoch 202 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_202.pth\n",
      "Epoch 203 train loss: 0.6654472453683092\n",
      "Epoch 203 train accuracy: 74.19797093501508\n",
      "Epoch 203 val loss: 0.6585628692256776\n",
      "Epoch 203 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_203.pth\n",
      "Epoch 204 train loss: 0.6653133663757328\n",
      "Epoch 204 train accuracy: 74.25281052920208\n",
      "Epoch 204 val loss: 0.6584406409804758\n",
      "Epoch 204 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_204.pth\n",
      "Epoch 205 train loss: 0.6652236722017589\n",
      "Epoch 205 train accuracy: 74.28023032629558\n",
      "Epoch 205 val loss: 0.6583345282430711\n",
      "Epoch 205 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_models/MLP_205.pth\n",
      "Epoch 206 train loss: 0.6651972340125787\n",
      "Epoch 206 train accuracy: 74.28023032629558\n",
      "Epoch 206 val loss: 0.6582201436946267\n",
      "Epoch 206 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_models/MLP_206.pth\n",
      "Epoch 207 train loss: 0.6650847463231337\n",
      "Epoch 207 train accuracy: 74.25281052920208\n",
      "Epoch 207 val loss: 0.6581109887675235\n",
      "Epoch 207 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_models/MLP_207.pth\n",
      "Epoch 208 train loss: 0.6649899727485159\n",
      "Epoch 208 train accuracy: 74.30765012338908\n",
      "Epoch 208 val loss: 0.6580071981604162\n",
      "Epoch 208 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_models/MLP_208.pth\n",
      "Epoch 209 train loss: 0.6649280752855957\n",
      "Epoch 209 train accuracy: 74.33506992048258\n",
      "Epoch 209 val loss: 0.6578955625821101\n",
      "Epoch 209 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_models/MLP_209.pth\n",
      "Epoch 210 train loss: 0.66478822694013\n",
      "Epoch 210 train accuracy: 74.25281052920208\n",
      "Epoch 210 val loss: 0.6577729556317392\n",
      "Epoch 210 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_models/MLP_210.pth\n",
      "Epoch 211 train loss: 0.6646626971073841\n",
      "Epoch 211 train accuracy: 74.3624897175761\n",
      "Epoch 211 val loss: 0.6576584360905384\n",
      "Epoch 211 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_models/MLP_211.pth\n",
      "Epoch 212 train loss: 0.6645745387006747\n",
      "Epoch 212 train accuracy: 74.4173293117631\n",
      "Epoch 212 val loss: 0.6575473862651148\n",
      "Epoch 212 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_212.pth\n",
      "Epoch 213 train loss: 0.664468699772107\n",
      "Epoch 213 train accuracy: 74.4447491088566\n",
      "Epoch 213 val loss: 0.6574230685241913\n",
      "Epoch 213 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_213.pth\n",
      "Epoch 214 train loss: 0.6644042133304634\n",
      "Epoch 214 train accuracy: 74.5270085001371\n",
      "Epoch 214 val loss: 0.6573323252561846\n",
      "Epoch 214 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_214.pth\n",
      "Epoch 215 train loss: 0.6643406889287004\n",
      "Epoch 215 train accuracy: 74.4173293117631\n",
      "Epoch 215 val loss: 0.6572233623775997\n",
      "Epoch 215 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_215.pth\n",
      "Epoch 216 train loss: 0.6642884551629162\n",
      "Epoch 216 train accuracy: 74.5270085001371\n",
      "Epoch 216 val loss: 0.6571173867896983\n",
      "Epoch 216 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_216.pth\n",
      "Epoch 217 train loss: 0.6641086843518311\n",
      "Epoch 217 train accuracy: 74.5270085001371\n",
      "Epoch 217 val loss: 0.6570195110612794\n",
      "Epoch 217 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_217.pth\n",
      "Epoch 218 train loss: 0.6640946709861358\n",
      "Epoch 218 train accuracy: 74.5544282972306\n",
      "Epoch 218 val loss: 0.6568980127769081\n",
      "Epoch 218 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_218.pth\n",
      "Epoch 219 train loss: 0.6639594891876505\n",
      "Epoch 219 train accuracy: 74.5270085001371\n",
      "Epoch 219 val loss: 0.6567892940028718\n",
      "Epoch 219 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_219.pth\n",
      "Epoch 220 train loss: 0.6638936281138867\n",
      "Epoch 220 train accuracy: 74.5544282972306\n",
      "Epoch 220 val loss: 0.6566863069800954\n",
      "Epoch 220 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_models/MLP_220.pth\n",
      "Epoch 221 train loss: 0.663792220516163\n",
      "Epoch 221 train accuracy: 74.5818480943241\n",
      "Epoch 221 val loss: 0.6565919691990865\n",
      "Epoch 221 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_models/MLP_221.pth\n",
      "Epoch 222 train loss: 0.6637004123379787\n",
      "Epoch 222 train accuracy: 74.5270085001371\n",
      "Epoch 222 val loss: 0.6564830111241654\n",
      "Epoch 222 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_models/MLP_222.pth\n",
      "Epoch 223 train loss: 0.6636232710851911\n",
      "Epoch 223 train accuracy: 74.6092678914176\n",
      "Epoch 223 val loss: 0.6563659865213068\n",
      "Epoch 223 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_models/MLP_223.pth\n",
      "Epoch 224 train loss: 0.6635516155184361\n",
      "Epoch 224 train accuracy: 74.6092678914176\n",
      "Epoch 224 val loss: 0.6562437138667232\n",
      "Epoch 224 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_224.pth\n",
      "Epoch 225 train loss: 0.6634462586555042\n",
      "Epoch 225 train accuracy: 74.6641074856046\n",
      "Epoch 225 val loss: 0.6561554746800348\n",
      "Epoch 225 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_225.pth\n",
      "Epoch 226 train loss: 0.663395145973354\n",
      "Epoch 226 train accuracy: 74.80120647107212\n",
      "Epoch 226 val loss: 0.6560595344359937\n",
      "Epoch 226 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_226.pth\n",
      "Epoch 227 train loss: 0.6632865224556442\n",
      "Epoch 227 train accuracy: 74.7189470797916\n",
      "Epoch 227 val loss: 0.6559570749339304\n",
      "Epoch 227 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_227.pth\n",
      "Epoch 228 train loss: 0.6631861706509402\n",
      "Epoch 228 train accuracy: 74.80120647107212\n",
      "Epoch 228 val loss: 0.6558390032303961\n",
      "Epoch 228 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_228.pth\n",
      "Epoch 229 train loss: 0.6631344083958027\n",
      "Epoch 229 train accuracy: 74.88346586235262\n",
      "Epoch 229 val loss: 0.6557428958384615\n",
      "Epoch 229 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_229.pth\n",
      "Epoch 230 train loss: 0.6629590022197941\n",
      "Epoch 230 train accuracy: 74.80120647107212\n",
      "Epoch 230 val loss: 0.6556545766560655\n",
      "Epoch 230 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_230.pth\n",
      "Epoch 231 train loss: 0.6629280766570255\n",
      "Epoch 231 train accuracy: 74.82862626816562\n",
      "Epoch 231 val loss: 0.6555323594887006\n",
      "Epoch 231 val accuracy: 76.15131578947368\n",
      "Saved model to .\\test_models/MLP_231.pth\n",
      "Epoch 232 train loss: 0.6628325200525292\n",
      "Epoch 232 train accuracy: 74.96572525363312\n",
      "Epoch 232 val loss: 0.6554392532102371\n",
      "Epoch 232 val accuracy: 76.15131578947368\n",
      "Saved model to .\\test_models/MLP_232.pth\n",
      "Epoch 233 train loss: 0.6627149160689952\n",
      "Epoch 233 train accuracy: 74.80120647107212\n",
      "Epoch 233 val loss: 0.6553183400905446\n",
      "Epoch 233 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_233.pth\n",
      "Epoch 234 train loss: 0.6626721915968677\n",
      "Epoch 234 train accuracy: 75.04798464491363\n",
      "Epoch 234 val loss: 0.6552100273731508\n",
      "Epoch 234 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_234.pth\n",
      "Epoch 235 train loss: 0.662552117321052\n",
      "Epoch 235 train accuracy: 74.99314505072662\n",
      "Epoch 235 val loss: 0.6551251427123421\n",
      "Epoch 235 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_235.pth\n",
      "Epoch 236 train loss: 0.6625096660368798\n",
      "Epoch 236 train accuracy: 75.02056484782013\n",
      "Epoch 236 val loss: 0.6550267081903783\n",
      "Epoch 236 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_236.pth\n",
      "Epoch 237 train loss: 0.6623959490669924\n",
      "Epoch 237 train accuracy: 74.99314505072662\n",
      "Epoch 237 val loss: 0.6549169971166473\n",
      "Epoch 237 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_237.pth\n",
      "Epoch 238 train loss: 0.6623301508656719\n",
      "Epoch 238 train accuracy: 75.04798464491363\n",
      "Epoch 238 val loss: 0.6548214961627596\n",
      "Epoch 238 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_238.pth\n",
      "Epoch 239 train loss: 0.6622308822054612\n",
      "Epoch 239 train accuracy: 75.07540444200713\n",
      "Epoch 239 val loss: 0.6547142436825916\n",
      "Epoch 239 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_239.pth\n",
      "Epoch 240 train loss: 0.6621442969823093\n",
      "Epoch 240 train accuracy: 75.07540444200713\n",
      "Epoch 240 val loss: 0.6546232795440837\n",
      "Epoch 240 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_models/MLP_240.pth\n",
      "Epoch 241 train loss: 0.66209875661553\n",
      "Epoch 241 train accuracy: 75.10282423910063\n",
      "Epoch 241 val loss: 0.654527465665811\n",
      "Epoch 241 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_241.pth\n",
      "Epoch 242 train loss: 0.6619821306840893\n",
      "Epoch 242 train accuracy: 75.15766383328763\n",
      "Epoch 242 val loss: 0.6544378825316304\n",
      "Epoch 242 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_242.pth\n",
      "Epoch 243 train loss: 0.6618876451985878\n",
      "Epoch 243 train accuracy: 75.18508363038113\n",
      "Epoch 243 val loss: 0.6543548762014038\n",
      "Epoch 243 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_243.pth\n",
      "Epoch 244 train loss: 0.661822922789214\n",
      "Epoch 244 train accuracy: 75.13024403619413\n",
      "Epoch 244 val loss: 0.654250944229333\n",
      "Epoch 244 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_244.pth\n",
      "Epoch 245 train loss: 0.6617356102194702\n",
      "Epoch 245 train accuracy: 75.10282423910063\n",
      "Epoch 245 val loss: 0.6541502320844876\n",
      "Epoch 245 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_245.pth\n",
      "Epoch 246 train loss: 0.6616523326946455\n",
      "Epoch 246 train accuracy: 75.18508363038113\n",
      "Epoch 246 val loss: 0.6540661467925498\n",
      "Epoch 246 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_246.pth\n",
      "Epoch 247 train loss: 0.6615533444115467\n",
      "Epoch 247 train accuracy: 75.23992322456814\n",
      "Epoch 247 val loss: 0.6539773704778207\n",
      "Epoch 247 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_247.pth\n",
      "Epoch 248 train loss: 0.6614081533462332\n",
      "Epoch 248 train accuracy: 75.15766383328763\n",
      "Epoch 248 val loss: 0.6538742533639857\n",
      "Epoch 248 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_248.pth\n",
      "Epoch 249 train loss: 0.6613925464385957\n",
      "Epoch 249 train accuracy: 75.23992322456814\n",
      "Epoch 249 val loss: 0.653779249834387\n",
      "Epoch 249 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_models/MLP_249.pth\n",
      "Epoch 250 train loss: 0.6612925829463884\n",
      "Epoch 250 train accuracy: 75.26734302166165\n",
      "Epoch 250 val loss: 0.653678389952371\n",
      "Epoch 250 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_250.pth\n",
      "Epoch 251 train loss: 0.6612128369314106\n",
      "Epoch 251 train accuracy: 75.26734302166165\n",
      "Epoch 251 val loss: 0.6535667147683469\n",
      "Epoch 251 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_251.pth\n",
      "Epoch 252 train loss: 0.6611928247046053\n",
      "Epoch 252 train accuracy: 75.26734302166165\n",
      "Epoch 252 val loss: 0.6534808404547604\n",
      "Epoch 252 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_252.pth\n",
      "Epoch 253 train loss: 0.6610705707418291\n",
      "Epoch 253 train accuracy: 75.23992322456814\n",
      "Epoch 253 val loss: 0.6534114862351041\n",
      "Epoch 253 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_253.pth\n",
      "Epoch 254 train loss: 0.6609744761269867\n",
      "Epoch 254 train accuracy: 75.26734302166165\n",
      "Epoch 254 val loss: 0.6533240303397179\n",
      "Epoch 254 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_254.pth\n",
      "Epoch 255 train loss: 0.6609397830212849\n",
      "Epoch 255 train accuracy: 75.26734302166165\n",
      "Epoch 255 val loss: 0.6532326511254436\n",
      "Epoch 255 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_255.pth\n",
      "Epoch 256 train loss: 0.6608231686578508\n",
      "Epoch 256 train accuracy: 75.29476281875515\n",
      "Epoch 256 val loss: 0.6531386960689959\n",
      "Epoch 256 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_256.pth\n",
      "Epoch 257 train loss: 0.6607123899943473\n",
      "Epoch 257 train accuracy: 75.26734302166165\n",
      "Epoch 257 val loss: 0.6530379400049385\n",
      "Epoch 257 val accuracy: 76.3157894736842\n",
      "Saved model to .\\test_models/MLP_257.pth\n",
      "Epoch 258 train loss: 0.6606249306350946\n",
      "Epoch 258 train accuracy: 75.29476281875515\n",
      "Epoch 258 val loss: 0.6529378749822315\n",
      "Epoch 258 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_258.pth\n",
      "Epoch 259 train loss: 0.6605801897352201\n",
      "Epoch 259 train accuracy: 75.34960241294215\n",
      "Epoch 259 val loss: 0.652835188433528\n",
      "Epoch 259 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_259.pth\n",
      "Epoch 260 train loss: 0.6605069259541076\n",
      "Epoch 260 train accuracy: 75.32218261584865\n",
      "Epoch 260 val loss: 0.6527332168464598\n",
      "Epoch 260 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_260.pth\n",
      "Epoch 261 train loss: 0.6604018478343884\n",
      "Epoch 261 train accuracy: 75.40444200712915\n",
      "Epoch 261 val loss: 0.6526525980351787\n",
      "Epoch 261 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_models/MLP_261.pth\n",
      "Epoch 262 train loss: 0.6603347479382105\n",
      "Epoch 262 train accuracy: 75.43186180422265\n",
      "Epoch 262 val loss: 0.6525569938515362\n",
      "Epoch 262 val accuracy: 76.3157894736842\n",
      "Saved model to .\\test_models/MLP_262.pth\n",
      "Epoch 263 train loss: 0.6602210823707936\n",
      "Epoch 263 train accuracy: 75.45928160131615\n",
      "Epoch 263 val loss: 0.6524547215943274\n",
      "Epoch 263 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_263.pth\n",
      "Epoch 264 train loss: 0.6601289553535089\n",
      "Epoch 264 train accuracy: 75.45928160131615\n",
      "Epoch 264 val loss: 0.652348159567306\n",
      "Epoch 264 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_264.pth\n",
      "Epoch 265 train loss: 0.6600567735404822\n",
      "Epoch 265 train accuracy: 75.51412119550315\n",
      "Epoch 265 val loss: 0.6522500439497986\n",
      "Epoch 265 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_265.pth\n",
      "Epoch 266 train loss: 0.6599603181933624\n",
      "Epoch 266 train accuracy: 75.51412119550315\n",
      "Epoch 266 val loss: 0.6521370363862891\n",
      "Epoch 266 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_266.pth\n",
      "Epoch 267 train loss: 0.6598948552681688\n",
      "Epoch 267 train accuracy: 75.59638058678365\n",
      "Epoch 267 val loss: 0.652052097904839\n",
      "Epoch 267 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_267.pth\n",
      "Epoch 268 train loss: 0.6598166304460743\n",
      "Epoch 268 train accuracy: 75.54154099259665\n",
      "Epoch 268 val loss: 0.6519709400048381\n",
      "Epoch 268 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_268.pth\n",
      "Epoch 269 train loss: 0.6597424678243043\n",
      "Epoch 269 train accuracy: 75.59638058678365\n",
      "Epoch 269 val loss: 0.6518765461484068\n",
      "Epoch 269 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_models/MLP_269.pth\n",
      "Epoch 270 train loss: 0.6596950340297139\n",
      "Epoch 270 train accuracy: 75.59638058678365\n",
      "Epoch 270 val loss: 0.6517723207607081\n",
      "Epoch 270 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_models/MLP_270.pth\n",
      "Epoch 271 train loss: 0.6595934411804927\n",
      "Epoch 271 train accuracy: 75.54154099259665\n",
      "Epoch 271 val loss: 0.6516679307739985\n",
      "Epoch 271 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_271.pth\n",
      "Epoch 272 train loss: 0.6595166094209018\n",
      "Epoch 272 train accuracy: 75.59638058678365\n",
      "Epoch 272 val loss: 0.6515742897203094\n",
      "Epoch 272 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_272.pth\n",
      "Epoch 273 train loss: 0.6594125573899139\n",
      "Epoch 273 train accuracy: 75.67863997806417\n",
      "Epoch 273 val loss: 0.6514910476184205\n",
      "Epoch 273 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_273.pth\n",
      "Epoch 274 train loss: 0.6593801456977401\n",
      "Epoch 274 train accuracy: 75.70605977515767\n",
      "Epoch 274 val loss: 0.6514115624717975\n",
      "Epoch 274 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_274.pth\n",
      "Epoch 275 train loss: 0.6593780270205778\n",
      "Epoch 275 train accuracy: 75.65122018097065\n",
      "Epoch 275 val loss: 0.6512892389375913\n",
      "Epoch 275 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_275.pth\n",
      "Epoch 276 train loss: 0.6591997577302289\n",
      "Epoch 276 train accuracy: 75.67863997806417\n",
      "Epoch 276 val loss: 0.651198194705342\n",
      "Epoch 276 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_models/MLP_276.pth\n",
      "Epoch 277 train loss: 0.6591518177536496\n",
      "Epoch 277 train accuracy: 75.73347957225117\n",
      "Epoch 277 val loss: 0.6510982224227566\n",
      "Epoch 277 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_models/MLP_277.pth\n",
      "Epoch 278 train loss: 0.6591081620569814\n",
      "Epoch 278 train accuracy: 75.76089936934467\n",
      "Epoch 278 val loss: 0.6509979533913889\n",
      "Epoch 278 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_models/MLP_278.pth\n",
      "Epoch 279 train loss: 0.6590267151202026\n",
      "Epoch 279 train accuracy: 75.87057855771867\n",
      "Epoch 279 val loss: 0.6509217094433936\n",
      "Epoch 279 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_models/MLP_279.pth\n",
      "Epoch 280 train loss: 0.6589256558044437\n",
      "Epoch 280 train accuracy: 75.70605977515767\n",
      "Epoch 280 val loss: 0.6508260604582334\n",
      "Epoch 280 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_models/MLP_280.pth\n",
      "Epoch 281 train loss: 0.6588458875520972\n",
      "Epoch 281 train accuracy: 75.70605977515767\n",
      "Epoch 281 val loss: 0.6507363953676663\n",
      "Epoch 281 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_models/MLP_281.pth\n",
      "Epoch 282 train loss: 0.6587500329080381\n",
      "Epoch 282 train accuracy: 75.78831916643817\n",
      "Epoch 282 val loss: 0.650649042505967\n",
      "Epoch 282 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_models/MLP_282.pth\n",
      "Epoch 283 train loss: 0.6587450008904725\n",
      "Epoch 283 train accuracy: 75.73347957225117\n",
      "Epoch 283 val loss: 0.6505487698473429\n",
      "Epoch 283 val accuracy: 76.5625\n",
      "Saved model to .\\test_models/MLP_283.pth\n",
      "Epoch 284 train loss: 0.6586491034545919\n",
      "Epoch 284 train accuracy: 75.76089936934467\n",
      "Epoch 284 val loss: 0.650455005466938\n",
      "Epoch 284 val accuracy: 76.5625\n",
      "Saved model to .\\test_models/MLP_284.pth\n",
      "Epoch 285 train loss: 0.6585539651283047\n",
      "Epoch 285 train accuracy: 75.84315876062517\n",
      "Epoch 285 val loss: 0.6503640604450515\n",
      "Epoch 285 val accuracy: 76.5625\n",
      "Saved model to .\\test_models/MLP_285.pth\n",
      "Epoch 286 train loss: 0.6584583878713218\n",
      "Epoch 286 train accuracy: 75.81573896353167\n",
      "Epoch 286 val loss: 0.6502829952851722\n",
      "Epoch 286 val accuracy: 76.5625\n",
      "Saved model to .\\test_models/MLP_286.pth\n",
      "Epoch 287 train loss: 0.6583856521991261\n",
      "Epoch 287 train accuracy: 75.84315876062517\n",
      "Epoch 287 val loss: 0.6501894295215607\n",
      "Epoch 287 val accuracy: 76.5625\n",
      "Saved model to .\\test_models/MLP_287.pth\n",
      "Epoch 288 train loss: 0.6582566132082751\n",
      "Epoch 288 train accuracy: 75.92541815190567\n",
      "Epoch 288 val loss: 0.6501025851619872\n",
      "Epoch 288 val accuracy: 76.5625\n",
      "Saved model to .\\test_models/MLP_288.pth\n",
      "Epoch 289 train loss: 0.6582408408846772\n",
      "Epoch 289 train accuracy: 75.87057855771867\n",
      "Epoch 289 val loss: 0.6500100522841278\n",
      "Epoch 289 val accuracy: 76.5625\n",
      "Saved model to .\\test_models/MLP_289.pth\n",
      "Epoch 290 train loss: 0.6581035115543687\n",
      "Epoch 290 train accuracy: 75.89799835481217\n",
      "Epoch 290 val loss: 0.649942365524016\n",
      "Epoch 290 val accuracy: 76.5625\n",
      "Saved model to .\\test_models/MLP_290.pth\n",
      "Epoch 291 train loss: 0.6581462208312332\n",
      "Epoch 291 train accuracy: 75.87057855771867\n",
      "Epoch 291 val loss: 0.6498387381434441\n",
      "Epoch 291 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_291.pth\n",
      "Epoch 292 train loss: 0.6579964588347235\n",
      "Epoch 292 train accuracy: 75.84315876062517\n",
      "Epoch 292 val loss: 0.6497448468090672\n",
      "Epoch 292 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_292.pth\n",
      "Epoch 293 train loss: 0.657930809481625\n",
      "Epoch 293 train accuracy: 75.84315876062517\n",
      "Epoch 293 val loss: 0.6496528804694351\n",
      "Epoch 293 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_293.pth\n",
      "Epoch 294 train loss: 0.6578846052615789\n",
      "Epoch 294 train accuracy: 75.87057855771867\n",
      "Epoch 294 val loss: 0.6495489966320364\n",
      "Epoch 294 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_294.pth\n",
      "Epoch 295 train loss: 0.6577577632443424\n",
      "Epoch 295 train accuracy: 75.92541815190567\n",
      "Epoch 295 val loss: 0.6494896835402438\n",
      "Epoch 295 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_295.pth\n",
      "Epoch 296 train loss: 0.6577013591794592\n",
      "Epoch 296 train accuracy: 75.87057855771867\n",
      "Epoch 296 val loss: 0.649380889182028\n",
      "Epoch 296 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_296.pth\n",
      "Epoch 297 train loss: 0.6575637252249739\n",
      "Epoch 297 train accuracy: 75.95283794899917\n",
      "Epoch 297 val loss: 0.6493003992853981\n",
      "Epoch 297 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_297.pth\n",
      "Epoch 298 train loss: 0.6574784245407372\n",
      "Epoch 298 train accuracy: 75.95283794899917\n",
      "Epoch 298 val loss: 0.6492217938954893\n",
      "Epoch 298 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_298.pth\n",
      "Epoch 299 train loss: 0.6574063746160582\n",
      "Epoch 299 train accuracy: 75.95283794899917\n",
      "Epoch 299 val loss: 0.6491332326672579\n",
      "Epoch 299 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_299.pth\n",
      "Epoch 300 train loss: 0.6574037700172579\n",
      "Epoch 300 train accuracy: 75.95283794899917\n",
      "Epoch 300 val loss: 0.6490500525228287\n",
      "Epoch 300 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_300.pth\n",
      "Epoch 301 train loss: 0.6573260767352685\n",
      "Epoch 301 train accuracy: 75.95283794899917\n",
      "Epoch 301 val loss: 0.6489616855978966\n",
      "Epoch 301 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_301.pth\n",
      "Epoch 302 train loss: 0.6572911797189399\n",
      "Epoch 302 train accuracy: 76.00767754318618\n",
      "Epoch 302 val loss: 0.6488600710504934\n",
      "Epoch 302 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_302.pth\n",
      "Epoch 303 train loss: 0.6571316594878832\n",
      "Epoch 303 train accuracy: 75.92541815190567\n",
      "Epoch 303 val loss: 0.6487638158233542\n",
      "Epoch 303 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_303.pth\n",
      "Epoch 304 train loss: 0.6570894961947935\n",
      "Epoch 304 train accuracy: 75.95283794899917\n",
      "Epoch 304 val loss: 0.6486649700489483\n",
      "Epoch 304 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_304.pth\n",
      "Epoch 305 train loss: 0.6569866412237548\n",
      "Epoch 305 train accuracy: 76.11735673156019\n",
      "Epoch 305 val loss: 0.6485929242090175\n",
      "Epoch 305 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_305.pth\n",
      "Epoch 306 train loss: 0.6569475285512837\n",
      "Epoch 306 train accuracy: 75.95283794899917\n",
      "Epoch 306 val loss: 0.6485111900654278\n",
      "Epoch 306 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_306.pth\n",
      "Epoch 307 train loss: 0.6568727262579558\n",
      "Epoch 307 train accuracy: 76.03509734027968\n",
      "Epoch 307 val loss: 0.6484359027327675\n",
      "Epoch 307 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_307.pth\n",
      "Epoch 308 train loss: 0.6567943053352728\n",
      "Epoch 308 train accuracy: 76.11735673156019\n",
      "Epoch 308 val loss: 0.6483545747438544\n",
      "Epoch 308 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_models/MLP_308.pth\n",
      "Epoch 309 train loss: 0.6566441808745527\n",
      "Epoch 309 train accuracy: 75.98025774609268\n",
      "Epoch 309 val loss: 0.6482637500096309\n",
      "Epoch 309 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_309.pth\n",
      "Epoch 310 train loss: 0.6566272338100693\n",
      "Epoch 310 train accuracy: 76.00767754318618\n",
      "Epoch 310 val loss: 0.64815560591064\n",
      "Epoch 310 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_310.pth\n",
      "Epoch 311 train loss: 0.65655070530218\n",
      "Epoch 311 train accuracy: 76.08993693446668\n",
      "Epoch 311 val loss: 0.6480830190213103\n",
      "Epoch 311 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_311.pth\n",
      "Epoch 312 train loss: 0.6564565528707024\n",
      "Epoch 312 train accuracy: 76.2270359199342\n",
      "Epoch 312 val loss: 0.6480117021618705\n",
      "Epoch 312 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_312.pth\n",
      "Epoch 313 train loss: 0.6564287196910172\n",
      "Epoch 313 train accuracy: 76.03509734027968\n",
      "Epoch 313 val loss: 0.6479129419711075\n",
      "Epoch 313 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_313.pth\n",
      "Epoch 314 train loss: 0.6564126514355865\n",
      "Epoch 314 train accuracy: 76.06251713737318\n",
      "Epoch 314 val loss: 0.6478312088078574\n",
      "Epoch 314 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_314.pth\n",
      "Epoch 315 train loss: 0.6562813794273034\n",
      "Epoch 315 train accuracy: 76.08993693446668\n",
      "Epoch 315 val loss: 0.6477445426740145\n",
      "Epoch 315 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_315.pth\n",
      "Epoch 316 train loss: 0.6562005887298208\n",
      "Epoch 316 train accuracy: 76.03509734027968\n",
      "Epoch 316 val loss: 0.6476538576381771\n",
      "Epoch 316 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_316.pth\n",
      "Epoch 317 train loss: 0.6561270085277787\n",
      "Epoch 317 train accuracy: 76.08993693446668\n",
      "Epoch 317 val loss: 0.6475757532998135\n",
      "Epoch 317 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_317.pth\n",
      "Epoch 318 train loss: 0.6560849977428453\n",
      "Epoch 318 train accuracy: 76.06251713737318\n",
      "Epoch 318 val loss: 0.6474812327835121\n",
      "Epoch 318 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_318.pth\n",
      "Epoch 319 train loss: 0.65595518441446\n",
      "Epoch 319 train accuracy: 76.1721963257472\n",
      "Epoch 319 val loss: 0.6474050522634858\n",
      "Epoch 319 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_319.pth\n",
      "Epoch 320 train loss: 0.6558756303172886\n",
      "Epoch 320 train accuracy: 76.11735673156019\n",
      "Epoch 320 val loss: 0.6473197404687342\n",
      "Epoch 320 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_320.pth\n",
      "Epoch 321 train loss: 0.6557691000205906\n",
      "Epoch 321 train accuracy: 76.1447765286537\n",
      "Epoch 321 val loss: 0.6472337004777632\n",
      "Epoch 321 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_321.pth\n",
      "Epoch 322 train loss: 0.6557550910337452\n",
      "Epoch 322 train accuracy: 76.2270359199342\n",
      "Epoch 322 val loss: 0.6471707291508976\n",
      "Epoch 322 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_322.pth\n",
      "Epoch 323 train loss: 0.6556650047239504\n",
      "Epoch 323 train accuracy: 76.11735673156019\n",
      "Epoch 323 val loss: 0.6470838304805128\n",
      "Epoch 323 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_323.pth\n",
      "Epoch 324 train loss: 0.6556022328961837\n",
      "Epoch 324 train accuracy: 76.11735673156019\n",
      "Epoch 324 val loss: 0.647004859718053\n",
      "Epoch 324 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_324.pth\n",
      "Epoch 325 train loss: 0.6554944246942014\n",
      "Epoch 325 train accuracy: 76.11735673156019\n",
      "Epoch 325 val loss: 0.6469152451149727\n",
      "Epoch 325 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_325.pth\n",
      "Epoch 326 train loss: 0.6554505161352848\n",
      "Epoch 326 train accuracy: 76.1447765286537\n",
      "Epoch 326 val loss: 0.6468469724059105\n",
      "Epoch 326 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_326.pth\n",
      "Epoch 327 train loss: 0.6553890484532243\n",
      "Epoch 327 train accuracy: 76.1721963257472\n",
      "Epoch 327 val loss: 0.6467338711219398\n",
      "Epoch 327 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_327.pth\n",
      "Epoch 328 train loss: 0.6552720870495888\n",
      "Epoch 328 train accuracy: 76.2544557170277\n",
      "Epoch 328 val loss: 0.6466581723407695\n",
      "Epoch 328 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_328.pth\n",
      "Epoch 329 train loss: 0.6551955544569513\n",
      "Epoch 329 train accuracy: 76.1721963257472\n",
      "Epoch 329 val loss: 0.6465753331584366\n",
      "Epoch 329 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_models/MLP_329.pth\n",
      "Epoch 330 train loss: 0.6551052303821371\n",
      "Epoch 330 train accuracy: 76.2544557170277\n",
      "Epoch 330 val loss: 0.6464805070702967\n",
      "Epoch 330 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_models/MLP_330.pth\n",
      "Epoch 331 train loss: 0.655065211369411\n",
      "Epoch 331 train accuracy: 76.2818755141212\n",
      "Epoch 331 val loss: 0.6464080390961546\n",
      "Epoch 331 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_models/MLP_331.pth\n",
      "Epoch 332 train loss: 0.6550039931674275\n",
      "Epoch 332 train accuracy: 76.2270359199342\n",
      "Epoch 332 val loss: 0.6463128007752331\n",
      "Epoch 332 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_models/MLP_332.pth\n",
      "Epoch 333 train loss: 0.6549229935922644\n",
      "Epoch 333 train accuracy: 76.2818755141212\n",
      "Epoch 333 val loss: 0.6462356511895594\n",
      "Epoch 333 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_models/MLP_333.pth\n",
      "Epoch 334 train loss: 0.6548486579405634\n",
      "Epoch 334 train accuracy: 76.2270359199342\n",
      "Epoch 334 val loss: 0.6461515632507048\n",
      "Epoch 334 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_models/MLP_334.pth\n",
      "Epoch 335 train loss: 0.6546779748771274\n",
      "Epoch 335 train accuracy: 76.3092953112147\n",
      "Epoch 335 val loss: 0.6460811365395784\n",
      "Epoch 335 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_models/MLP_335.pth\n",
      "Epoch 336 train loss: 0.6546959255152104\n",
      "Epoch 336 train accuracy: 76.2544557170277\n",
      "Epoch 336 val loss: 0.6460073289314383\n",
      "Epoch 336 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_models/MLP_336.pth\n",
      "Epoch 337 train loss: 0.6545872371643782\n",
      "Epoch 337 train accuracy: 76.1996161228407\n",
      "Epoch 337 val loss: 0.6459317224982538\n",
      "Epoch 337 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_models/MLP_337.pth\n",
      "Epoch 338 train loss: 0.6545135222636816\n",
      "Epoch 338 train accuracy: 76.2818755141212\n",
      "Epoch 338 val loss: 0.6458515241546067\n",
      "Epoch 338 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_models/MLP_338.pth\n",
      "Epoch 339 train loss: 0.6544403560263546\n",
      "Epoch 339 train accuracy: 76.1721963257472\n",
      "Epoch 339 val loss: 0.6457597802540189\n",
      "Epoch 339 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_models/MLP_339.pth\n",
      "Epoch 340 train loss: 0.654406047769283\n",
      "Epoch 340 train accuracy: 76.2818755141212\n",
      "Epoch 340 val loss: 0.6456819230592564\n",
      "Epoch 340 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_models/MLP_340.pth\n",
      "Epoch 341 train loss: 0.6543651398990238\n",
      "Epoch 341 train accuracy: 76.3367151083082\n",
      "Epoch 341 val loss: 0.645600210287069\n",
      "Epoch 341 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_models/MLP_341.pth\n",
      "Epoch 342 train loss: 0.6541763350955749\n",
      "Epoch 342 train accuracy: 76.2544557170277\n",
      "Epoch 342 val loss: 0.6455285820717874\n",
      "Epoch 342 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_models/MLP_342.pth\n",
      "Epoch 343 train loss: 0.6541434606831324\n",
      "Epoch 343 train accuracy: 76.3092953112147\n",
      "Epoch 343 val loss: 0.6454372049162262\n",
      "Epoch 343 val accuracy: 77.22039473684211\n",
      "Saved model to .\\test_models/MLP_343.pth\n",
      "Epoch 344 train loss: 0.6541097113176396\n",
      "Epoch 344 train accuracy: 76.2544557170277\n",
      "Epoch 344 val loss: 0.6453590137197783\n",
      "Epoch 344 val accuracy: 77.22039473684211\n",
      "Saved model to .\\test_models/MLP_344.pth\n",
      "Epoch 345 train loss: 0.6540264135978201\n",
      "Epoch 345 train accuracy: 76.2818755141212\n",
      "Epoch 345 val loss: 0.6452760066052801\n",
      "Epoch 345 val accuracy: 77.22039473684211\n",
      "Saved model to .\\test_models/MLP_345.pth\n",
      "Epoch 346 train loss: 0.6539549909270647\n",
      "Epoch 346 train accuracy: 76.3367151083082\n",
      "Epoch 346 val loss: 0.6451926210797146\n",
      "Epoch 346 val accuracy: 77.30263157894737\n",
      "Saved model to .\\test_models/MLP_346.pth\n",
      "Epoch 347 train loss: 0.6538459393277503\n",
      "Epoch 347 train accuracy: 76.3641349054017\n",
      "Epoch 347 val loss: 0.6451204246596286\n",
      "Epoch 347 val accuracy: 77.30263157894737\n",
      "Saved model to .\\test_models/MLP_347.pth\n",
      "Epoch 348 train loss: 0.6537980611125628\n",
      "Epoch 348 train accuracy: 76.4463942966822\n",
      "Epoch 348 val loss: 0.6450352756992767\n",
      "Epoch 348 val accuracy: 77.30263157894737\n",
      "Saved model to .\\test_models/MLP_348.pth\n",
      "Epoch 349 train loss: 0.653735944151617\n",
      "Epoch 349 train accuracy: 76.3367151083082\n",
      "Epoch 349 val loss: 0.6449555270373821\n",
      "Epoch 349 val accuracy: 77.30263157894737\n",
      "Saved model to .\\test_models/MLP_349.pth\n",
      "Epoch 350 train loss: 0.6536474284764967\n",
      "Epoch 350 train accuracy: 76.3915547024952\n",
      "Epoch 350 val loss: 0.6448660376236627\n",
      "Epoch 350 val accuracy: 77.30263157894737\n",
      "Saved model to .\\test_models/MLP_350.pth\n",
      "Epoch 351 train loss: 0.6535689746797607\n",
      "Epoch 351 train accuracy: 76.3367151083082\n",
      "Epoch 351 val loss: 0.6447984088016184\n",
      "Epoch 351 val accuracy: 77.30263157894737\n",
      "Saved model to .\\test_models/MLP_351.pth\n",
      "Epoch 352 train loss: 0.6534082225867008\n",
      "Epoch 352 train accuracy: 76.3092953112147\n",
      "Epoch 352 val loss: 0.6447175525520977\n",
      "Epoch 352 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_352.pth\n",
      "Epoch 353 train loss: 0.6534139940417126\n",
      "Epoch 353 train accuracy: 76.4463942966822\n",
      "Epoch 353 val loss: 0.6446490021128404\n",
      "Epoch 353 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_353.pth\n",
      "Epoch 354 train loss: 0.6533049723754326\n",
      "Epoch 354 train accuracy: 76.3367151083082\n",
      "Epoch 354 val loss: 0.6445427619312939\n",
      "Epoch 354 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_354.pth\n",
      "Epoch 355 train loss: 0.6532037849946503\n",
      "Epoch 355 train accuracy: 76.3915547024952\n",
      "Epoch 355 val loss: 0.6444643460410205\n",
      "Epoch 355 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_355.pth\n",
      "Epoch 356 train loss: 0.6531526533265909\n",
      "Epoch 356 train accuracy: 76.3641349054017\n",
      "Epoch 356 val loss: 0.6443695533824595\n",
      "Epoch 356 val accuracy: 77.30263157894737\n",
      "Saved model to .\\test_models/MLP_356.pth\n",
      "Epoch 357 train loss: 0.6530344289841882\n",
      "Epoch 357 train accuracy: 76.3915547024952\n",
      "Epoch 357 val loss: 0.6442897589387078\n",
      "Epoch 357 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_357.pth\n",
      "Epoch 358 train loss: 0.6531365365443522\n",
      "Epoch 358 train accuracy: 76.4738140937757\n",
      "Epoch 358 val loss: 0.6442014497557753\n",
      "Epoch 358 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_358.pth\n",
      "Epoch 359 train loss: 0.6529395255145797\n",
      "Epoch 359 train accuracy: 76.3092953112147\n",
      "Epoch 359 val loss: 0.6441234074729053\n",
      "Epoch 359 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_359.pth\n",
      "Epoch 360 train loss: 0.6528624337035835\n",
      "Epoch 360 train accuracy: 76.55607348505622\n",
      "Epoch 360 val loss: 0.6440614669730789\n",
      "Epoch 360 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_360.pth\n",
      "Epoch 361 train loss: 0.6527834643789551\n",
      "Epoch 361 train accuracy: 76.3092953112147\n",
      "Epoch 361 val loss: 0.6439877522030943\n",
      "Epoch 361 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_361.pth\n",
      "Epoch 362 train loss: 0.6527071189658161\n",
      "Epoch 362 train accuracy: 76.4463942966822\n",
      "Epoch 362 val loss: 0.643896379851197\n",
      "Epoch 362 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_362.pth\n",
      "Epoch 363 train loss: 0.6526852387019939\n",
      "Epoch 363 train accuracy: 76.3641349054017\n",
      "Epoch 363 val loss: 0.6438026708599768\n",
      "Epoch 363 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_363.pth\n",
      "Epoch 364 train loss: 0.652470739819763\n",
      "Epoch 364 train accuracy: 76.5286536879627\n",
      "Epoch 364 val loss: 0.6437371226125642\n",
      "Epoch 364 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_364.pth\n",
      "Epoch 365 train loss: 0.6524760333919212\n",
      "Epoch 365 train accuracy: 76.4738140937757\n",
      "Epoch 365 val loss: 0.6436543863658842\n",
      "Epoch 365 val accuracy: 77.38486842105263\n",
      "Saved model to .\\test_models/MLP_365.pth\n",
      "Epoch 366 train loss: 0.6523801413805861\n",
      "Epoch 366 train accuracy: 76.5286536879627\n",
      "Epoch 366 val loss: 0.6435773523622438\n",
      "Epoch 366 val accuracy: 77.46710526315789\n",
      "Saved model to .\\test_models/MLP_366.pth\n",
      "Epoch 367 train loss: 0.6522925597403133\n",
      "Epoch 367 train accuracy: 76.3915547024952\n",
      "Epoch 367 val loss: 0.6434723272135383\n",
      "Epoch 367 val accuracy: 77.46710526315789\n",
      "Saved model to .\\test_models/MLP_367.pth\n",
      "Epoch 368 train loss: 0.6522399048860136\n",
      "Epoch 368 train accuracy: 76.66575267343022\n",
      "Epoch 368 val loss: 0.6434250763176304\n",
      "Epoch 368 val accuracy: 77.46710526315789\n",
      "Saved model to .\\test_models/MLP_368.pth\n",
      "Epoch 369 train loss: 0.6521670378156399\n",
      "Epoch 369 train accuracy: 76.55607348505622\n",
      "Epoch 369 val loss: 0.6433411181757325\n",
      "Epoch 369 val accuracy: 77.54934210526316\n",
      "Saved model to .\\test_models/MLP_369.pth\n",
      "Epoch 370 train loss: 0.6520914648120341\n",
      "Epoch 370 train accuracy: 76.58349328214972\n",
      "Epoch 370 val loss: 0.6432588474923059\n",
      "Epoch 370 val accuracy: 77.54934210526316\n",
      "Saved model to .\\test_models/MLP_370.pth\n",
      "Epoch 371 train loss: 0.6520228825444192\n",
      "Epoch 371 train accuracy: 76.4463942966822\n",
      "Epoch 371 val loss: 0.6431830288156083\n",
      "Epoch 371 val accuracy: 77.54934210526316\n",
      "Saved model to .\\test_models/MLP_371.pth\n",
      "Epoch 372 train loss: 0.6519231527324831\n",
      "Epoch 372 train accuracy: 76.5286536879627\n",
      "Epoch 372 val loss: 0.6431053010256667\n",
      "Epoch 372 val accuracy: 77.54934210526316\n",
      "Saved model to .\\test_models/MLP_372.pth\n",
      "Epoch 373 train loss: 0.651752933990537\n",
      "Epoch 373 train accuracy: 76.5286536879627\n",
      "Epoch 373 val loss: 0.6430453366943096\n",
      "Epoch 373 val accuracy: 77.54934210526316\n",
      "Saved model to .\\test_models/MLP_373.pth\n",
      "Epoch 374 train loss: 0.6517314737041792\n",
      "Epoch 374 train accuracy: 76.4463942966822\n",
      "Epoch 374 val loss: 0.6429540949236405\n",
      "Epoch 374 val accuracy: 77.54934210526316\n",
      "Saved model to .\\test_models/MLP_374.pth\n",
      "Epoch 375 train loss: 0.6517096645476526\n",
      "Epoch 375 train accuracy: 76.66575267343022\n",
      "Epoch 375 val loss: 0.6428607279728902\n",
      "Epoch 375 val accuracy: 77.63157894736842\n",
      "Saved model to .\\test_models/MLP_375.pth\n",
      "Epoch 376 train loss: 0.6516318944723982\n",
      "Epoch 376 train accuracy: 76.5286536879627\n",
      "Epoch 376 val loss: 0.642784764009871\n",
      "Epoch 376 val accuracy: 77.63157894736842\n",
      "Saved model to .\\test_models/MLP_376.pth\n",
      "Epoch 377 train loss: 0.6515243449493459\n",
      "Epoch 377 train accuracy: 76.85769125308472\n",
      "Epoch 377 val loss: 0.6427269946587714\n",
      "Epoch 377 val accuracy: 77.63157894736842\n",
      "Saved model to .\\test_models/MLP_377.pth\n",
      "Epoch 378 train loss: 0.6514848653031023\n",
      "Epoch 378 train accuracy: 76.55607348505622\n",
      "Epoch 378 val loss: 0.6426397937497026\n",
      "Epoch 378 val accuracy: 77.71381578947368\n",
      "Saved model to .\\test_models/MLP_378.pth\n",
      "Epoch 379 train loss: 0.6513682740430037\n",
      "Epoch 379 train accuracy: 76.55607348505622\n",
      "Epoch 379 val loss: 0.6425254704724801\n",
      "Epoch 379 val accuracy: 77.79605263157895\n",
      "Saved model to .\\test_models/MLP_379.pth\n",
      "Epoch 380 train loss: 0.6513112339664969\n",
      "Epoch 380 train accuracy: 76.72059226761722\n",
      "Epoch 380 val loss: 0.6424596465535855\n",
      "Epoch 380 val accuracy: 77.79605263157895\n",
      "Saved model to .\\test_models/MLP_380.pth\n",
      "Epoch 381 train loss: 0.6512671274770248\n",
      "Epoch 381 train accuracy: 76.83027145599122\n",
      "Epoch 381 val loss: 0.6423862666675919\n",
      "Epoch 381 val accuracy: 77.79605263157895\n",
      "Saved model to .\\test_models/MLP_381.pth\n",
      "Epoch 382 train loss: 0.6512023746771248\n",
      "Epoch 382 train accuracy: 76.72059226761722\n",
      "Epoch 382 val loss: 0.6423265109524915\n",
      "Epoch 382 val accuracy: 77.79605263157895\n",
      "Saved model to .\\test_models/MLP_382.pth\n",
      "Epoch 383 train loss: 0.6511167265605509\n",
      "Epoch 383 train accuracy: 76.72059226761722\n",
      "Epoch 383 val loss: 0.6422298423161632\n",
      "Epoch 383 val accuracy: 77.8782894736842\n",
      "Saved model to .\\test_models/MLP_383.pth\n",
      "Epoch 384 train loss: 0.6510462393297961\n",
      "Epoch 384 train accuracy: 76.77543186180422\n",
      "Epoch 384 val loss: 0.642163467740542\n",
      "Epoch 384 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_384.pth\n",
      "Epoch 385 train loss: 0.6509553560366234\n",
      "Epoch 385 train accuracy: 76.69317247052372\n",
      "Epoch 385 val loss: 0.6420928590783948\n",
      "Epoch 385 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_385.pth\n",
      "Epoch 386 train loss: 0.6508383085428361\n",
      "Epoch 386 train accuracy: 76.80285165889772\n",
      "Epoch 386 val loss: 0.6420014851579541\n",
      "Epoch 386 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_386.pth\n",
      "Epoch 387 train loss: 0.6508534759805914\n",
      "Epoch 387 train accuracy: 76.85769125308472\n",
      "Epoch 387 val loss: 0.6419112568623141\n",
      "Epoch 387 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_387.pth\n",
      "Epoch 388 train loss: 0.6507080298309263\n",
      "Epoch 388 train accuracy: 76.83027145599122\n",
      "Epoch 388 val loss: 0.6418101114073866\n",
      "Epoch 388 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_388.pth\n",
      "Epoch 389 train loss: 0.6506322879801717\n",
      "Epoch 389 train accuracy: 76.96737044145873\n",
      "Epoch 389 val loss: 0.6417381142903316\n",
      "Epoch 389 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_389.pth\n",
      "Epoch 390 train loss: 0.6505420101447064\n",
      "Epoch 390 train accuracy: 76.99479023855224\n",
      "Epoch 390 val loss: 0.6416853263385986\n",
      "Epoch 390 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_390.pth\n",
      "Epoch 391 train loss: 0.6505025921291426\n",
      "Epoch 391 train accuracy: 77.04962983273924\n",
      "Epoch 391 val loss: 0.6416060277505925\n",
      "Epoch 391 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_391.pth\n",
      "Epoch 392 train loss: 0.650430167093873\n",
      "Epoch 392 train accuracy: 76.93995064436523\n",
      "Epoch 392 val loss: 0.6415341378826844\n",
      "Epoch 392 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_392.pth\n",
      "Epoch 393 train loss: 0.650408814122018\n",
      "Epoch 393 train accuracy: 76.99479023855224\n",
      "Epoch 393 val loss: 0.6414472415651146\n",
      "Epoch 393 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_393.pth\n",
      "Epoch 394 train loss: 0.6502294025400228\n",
      "Epoch 394 train accuracy: 76.91253084727173\n",
      "Epoch 394 val loss: 0.6413868151997265\n",
      "Epoch 394 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_394.pth\n",
      "Epoch 395 train loss: 0.6501995299272892\n",
      "Epoch 395 train accuracy: 77.04962983273924\n",
      "Epoch 395 val loss: 0.6413147022065363\n",
      "Epoch 395 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_395.pth\n",
      "Epoch 396 train loss: 0.6501633020673405\n",
      "Epoch 396 train accuracy: 76.96737044145873\n",
      "Epoch 396 val loss: 0.6411959129924837\n",
      "Epoch 396 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_396.pth\n",
      "Epoch 397 train loss: 0.6500182541642796\n",
      "Epoch 397 train accuracy: 76.93995064436523\n",
      "Epoch 397 val loss: 0.6411330606788397\n",
      "Epoch 397 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_397.pth\n",
      "Epoch 398 train loss: 0.6499448367312812\n",
      "Epoch 398 train accuracy: 77.10446942692624\n",
      "Epoch 398 val loss: 0.6410608685722476\n",
      "Epoch 398 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_398.pth\n",
      "Epoch 399 train loss: 0.6499036272922367\n",
      "Epoch 399 train accuracy: 76.99479023855224\n",
      "Epoch 399 val loss: 0.6409783949585337\n",
      "Epoch 399 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_399.pth\n",
      "Epoch 400 train loss: 0.6497944438699306\n",
      "Epoch 400 train accuracy: 76.99479023855224\n",
      "Epoch 400 val loss: 0.6408899607823083\n",
      "Epoch 400 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_400.pth\n",
      "Epoch 401 train loss: 0.6497816497688753\n",
      "Epoch 401 train accuracy: 77.02221003564574\n",
      "Epoch 401 val loss: 0.6407976166198128\n",
      "Epoch 401 val accuracy: 77.8782894736842\n",
      "Saved model to .\\test_models/MLP_401.pth\n",
      "Epoch 402 train loss: 0.6496548781726967\n",
      "Epoch 402 train accuracy: 76.96737044145873\n",
      "Epoch 402 val loss: 0.6407177188482723\n",
      "Epoch 402 val accuracy: 77.8782894736842\n",
      "Saved model to .\\test_models/MLP_402.pth\n",
      "Epoch 403 train loss: 0.6496542360829679\n",
      "Epoch 403 train accuracy: 77.04962983273924\n",
      "Epoch 403 val loss: 0.6406400548784357\n",
      "Epoch 403 val accuracy: 77.8782894736842\n",
      "Saved model to .\\test_models/MLP_403.pth\n",
      "Epoch 404 train loss: 0.6494284756808427\n",
      "Epoch 404 train accuracy: 77.07704962983274\n",
      "Epoch 404 val loss: 0.6405697921781164\n",
      "Epoch 404 val accuracy: 77.8782894736842\n",
      "Saved model to .\\test_models/MLP_404.pth\n",
      "Epoch 405 train loss: 0.6494102258431284\n",
      "Epoch 405 train accuracy: 77.02221003564574\n",
      "Epoch 405 val loss: 0.6404800126819234\n",
      "Epoch 405 val accuracy: 77.8782894736842\n",
      "Saved model to .\\test_models/MLP_405.pth\n",
      "Epoch 406 train loss: 0.6493335231289006\n",
      "Epoch 406 train accuracy: 76.93995064436523\n",
      "Epoch 406 val loss: 0.6404020362778714\n",
      "Epoch 406 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_406.pth\n",
      "Epoch 407 train loss: 0.6492947934424145\n",
      "Epoch 407 train accuracy: 76.96737044145873\n",
      "Epoch 407 val loss: 0.6403013833455349\n",
      "Epoch 407 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_407.pth\n",
      "Epoch 408 train loss: 0.6492341922171283\n",
      "Epoch 408 train accuracy: 77.02221003564574\n",
      "Epoch 408 val loss: 0.6402174674562717\n",
      "Epoch 408 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_408.pth\n",
      "Epoch 409 train loss: 0.6491229998830118\n",
      "Epoch 409 train accuracy: 77.02221003564574\n",
      "Epoch 409 val loss: 0.6401322062470411\n",
      "Epoch 409 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_409.pth\n",
      "Epoch 410 train loss: 0.64904729561194\n",
      "Epoch 410 train accuracy: 77.07704962983274\n",
      "Epoch 410 val loss: 0.6400542170005409\n",
      "Epoch 410 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_410.pth\n",
      "Epoch 411 train loss: 0.6489712139754965\n",
      "Epoch 411 train accuracy: 77.13188922401974\n",
      "Epoch 411 val loss: 0.6399910509782402\n",
      "Epoch 411 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_411.pth\n",
      "Epoch 412 train loss: 0.6488920865874541\n",
      "Epoch 412 train accuracy: 77.15930902111324\n",
      "Epoch 412 val loss: 0.6399242191722518\n",
      "Epoch 412 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_412.pth\n",
      "Epoch 413 train loss: 0.6488391869096902\n",
      "Epoch 413 train accuracy: 77.07704962983274\n",
      "Epoch 413 val loss: 0.6398417009530883\n",
      "Epoch 413 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_413.pth\n",
      "Epoch 414 train loss: 0.6487270697232401\n",
      "Epoch 414 train accuracy: 77.10446942692624\n",
      "Epoch 414 val loss: 0.6397791413688346\n",
      "Epoch 414 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_414.pth\n",
      "Epoch 415 train loss: 0.6485873900451943\n",
      "Epoch 415 train accuracy: 76.96737044145873\n",
      "Epoch 415 val loss: 0.6396655965792505\n",
      "Epoch 415 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_415.pth\n",
      "Epoch 416 train loss: 0.648544417694211\n",
      "Epoch 416 train accuracy: 77.15930902111324\n",
      "Epoch 416 val loss: 0.6395868669803205\n",
      "Epoch 416 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_416.pth\n",
      "Epoch 417 train loss: 0.6484644102880306\n",
      "Epoch 417 train accuracy: 77.13188922401974\n",
      "Epoch 417 val loss: 0.63951197001887\n",
      "Epoch 417 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_417.pth\n",
      "Epoch 418 train loss: 0.6484818580446013\n",
      "Epoch 418 train accuracy: 77.13188922401974\n",
      "Epoch 418 val loss: 0.6394108009377593\n",
      "Epoch 418 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_418.pth\n",
      "Epoch 419 train loss: 0.6483673390262482\n",
      "Epoch 419 train accuracy: 77.04962983273924\n",
      "Epoch 419 val loss: 0.6393216277815794\n",
      "Epoch 419 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_419.pth\n",
      "Epoch 420 train loss: 0.6483336996875311\n",
      "Epoch 420 train accuracy: 77.15930902111324\n",
      "Epoch 420 val loss: 0.639230866181223\n",
      "Epoch 420 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_420.pth\n",
      "Epoch 421 train loss: 0.6481901379792314\n",
      "Epoch 421 train accuracy: 77.18672881820675\n",
      "Epoch 421 val loss: 0.6391722716783222\n",
      "Epoch 421 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_421.pth\n",
      "Epoch 422 train loss: 0.6480968730491504\n",
      "Epoch 422 train accuracy: 77.18672881820675\n",
      "Epoch 422 val loss: 0.6391088723352081\n",
      "Epoch 422 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_422.pth\n",
      "Epoch 423 train loss: 0.6480453096722302\n",
      "Epoch 423 train accuracy: 77.21414861530025\n",
      "Epoch 423 val loss: 0.6390167770809249\n",
      "Epoch 423 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_423.pth\n",
      "Epoch 424 train loss: 0.6478883224425086\n",
      "Epoch 424 train accuracy: 77.07704962983274\n",
      "Epoch 424 val loss: 0.638932652673439\n",
      "Epoch 424 val accuracy: 77.96052631578948\n",
      "Saved model to .\\test_models/MLP_424.pth\n",
      "Epoch 425 train loss: 0.647860912802188\n",
      "Epoch 425 train accuracy: 77.13188922401974\n",
      "Epoch 425 val loss: 0.6388456837127083\n",
      "Epoch 425 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_425.pth\n",
      "Epoch 426 train loss: 0.6477855618781688\n",
      "Epoch 426 train accuracy: 77.13188922401974\n",
      "Epoch 426 val loss: 0.6387536158098986\n",
      "Epoch 426 val accuracy: 78.04276315789474\n",
      "Saved model to .\\test_models/MLP_426.pth\n",
      "Epoch 427 train loss: 0.6476751361042261\n",
      "Epoch 427 train accuracy: 77.24156841239375\n",
      "Epoch 427 val loss: 0.6386617094670471\n",
      "Epoch 427 val accuracy: 78.125\n",
      "Saved model to .\\test_models/MLP_427.pth\n",
      "Epoch 428 train loss: 0.6475515932563627\n",
      "Epoch 428 train accuracy: 77.21414861530025\n",
      "Epoch 428 val loss: 0.6385979294580849\n",
      "Epoch 428 val accuracy: 78.125\n",
      "Saved model to .\\test_models/MLP_428.pth\n",
      "Epoch 429 train loss: 0.6475185596694549\n",
      "Epoch 429 train accuracy: 77.24156841239375\n",
      "Epoch 429 val loss: 0.6384989582982502\n",
      "Epoch 429 val accuracy: 78.20723684210526\n",
      "Saved model to .\\test_models/MLP_429.pth\n",
      "Epoch 430 train loss: 0.6474136370642666\n",
      "Epoch 430 train accuracy: 77.13188922401974\n",
      "Epoch 430 val loss: 0.6383887231349945\n",
      "Epoch 430 val accuracy: 78.28947368421052\n",
      "Saved model to .\\test_models/MLP_430.pth\n",
      "Epoch 431 train loss: 0.6473106670993984\n",
      "Epoch 431 train accuracy: 77.29640800658075\n",
      "Epoch 431 val loss: 0.6383203662147647\n",
      "Epoch 431 val accuracy: 78.20723684210526\n",
      "Saved model to .\\test_models/MLP_431.pth\n",
      "Epoch 432 train loss: 0.6472838928824977\n",
      "Epoch 432 train accuracy: 77.18672881820675\n",
      "Epoch 432 val loss: 0.6382364396398005\n",
      "Epoch 432 val accuracy: 78.28947368421052\n",
      "Saved model to .\\test_models/MLP_432.pth\n",
      "Epoch 433 train loss: 0.6471475496757448\n",
      "Epoch 433 train accuracy: 77.21414861530025\n",
      "Epoch 433 val loss: 0.6381546848110462\n",
      "Epoch 433 val accuracy: 78.28947368421052\n",
      "Saved model to .\\test_models/MLP_433.pth\n",
      "Epoch 434 train loss: 0.647078050186106\n",
      "Epoch 434 train accuracy: 77.21414861530025\n",
      "Epoch 434 val loss: 0.638048945583011\n",
      "Epoch 434 val accuracy: 78.3717105263158\n",
      "Saved model to .\\test_models/MLP_434.pth\n",
      "Epoch 435 train loss: 0.6470621076265448\n",
      "Epoch 435 train accuracy: 77.32382780367425\n",
      "Epoch 435 val loss: 0.6379719267746335\n",
      "Epoch 435 val accuracy: 78.3717105263158\n",
      "Saved model to .\\test_models/MLP_435.pth\n",
      "Epoch 436 train loss: 0.6469636211792628\n",
      "Epoch 436 train accuracy: 77.26898820948725\n",
      "Epoch 436 val loss: 0.637904348832212\n",
      "Epoch 436 val accuracy: 78.45394736842105\n",
      "Saved model to .\\test_models/MLP_436.pth\n",
      "Epoch 437 train loss: 0.6468823055753059\n",
      "Epoch 437 train accuracy: 77.24156841239375\n",
      "Epoch 437 val loss: 0.6378317551785394\n",
      "Epoch 437 val accuracy: 78.45394736842105\n",
      "Saved model to .\\test_models/MLP_437.pth\n",
      "Epoch 438 train loss: 0.6468337042289868\n",
      "Epoch 438 train accuracy: 77.26898820948725\n",
      "Epoch 438 val loss: 0.6377174694483217\n",
      "Epoch 438 val accuracy: 78.53618421052632\n",
      "Saved model to .\\test_models/MLP_438.pth\n",
      "Epoch 439 train loss: 0.6467530882606903\n",
      "Epoch 439 train accuracy: 77.26898820948725\n",
      "Epoch 439 val loss: 0.6376467615758118\n",
      "Epoch 439 val accuracy: 78.53618421052632\n",
      "Saved model to .\\test_models/MLP_439.pth\n",
      "Epoch 440 train loss: 0.6466330294742396\n",
      "Epoch 440 train accuracy: 77.29640800658075\n",
      "Epoch 440 val loss: 0.6375671388875497\n",
      "Epoch 440 val accuracy: 78.53618421052632\n",
      "Saved model to .\\test_models/MLP_440.pth\n",
      "Epoch 441 train loss: 0.6465331353900725\n",
      "Epoch 441 train accuracy: 77.29640800658075\n",
      "Epoch 441 val loss: 0.6374829961477142\n",
      "Epoch 441 val accuracy: 78.53618421052632\n",
      "Saved model to .\\test_models/MLP_441.pth\n",
      "Epoch 442 train loss: 0.6464965407524192\n",
      "Epoch 442 train accuracy: 77.29640800658075\n",
      "Epoch 442 val loss: 0.6374048179407653\n",
      "Epoch 442 val accuracy: 78.53618421052632\n",
      "Saved model to .\\test_models/MLP_442.pth\n",
      "Epoch 443 train loss: 0.6464307677294863\n",
      "Epoch 443 train accuracy: 77.32382780367425\n",
      "Epoch 443 val loss: 0.6373092425300887\n",
      "Epoch 443 val accuracy: 78.45394736842105\n",
      "Saved model to .\\test_models/MLP_443.pth\n",
      "Epoch 444 train loss: 0.6463438593047229\n",
      "Epoch 444 train accuracy: 77.32382780367425\n",
      "Epoch 444 val loss: 0.6372291286917109\n",
      "Epoch 444 val accuracy: 78.53618421052632\n",
      "Saved model to .\\test_models/MLP_444.pth\n",
      "Epoch 445 train loss: 0.6462305963464212\n",
      "Epoch 445 train accuracy: 77.29640800658075\n",
      "Epoch 445 val loss: 0.637159436647045\n",
      "Epoch 445 val accuracy: 78.61842105263158\n",
      "Saved model to .\\test_models/MLP_445.pth\n",
      "Epoch 446 train loss: 0.6462316619591755\n",
      "Epoch 446 train accuracy: 77.40608719495475\n",
      "Epoch 446 val loss: 0.6370967373644051\n",
      "Epoch 446 val accuracy: 78.61842105263158\n",
      "Saved model to .\\test_models/MLP_446.pth\n",
      "Epoch 447 train loss: 0.6461108486543883\n",
      "Epoch 447 train accuracy: 77.21414861530025\n",
      "Epoch 447 val loss: 0.6369963825533265\n",
      "Epoch 447 val accuracy: 78.61842105263158\n",
      "Saved model to .\\test_models/MLP_447.pth\n",
      "Epoch 448 train loss: 0.6460345857368227\n",
      "Epoch 448 train accuracy: 77.35124760076775\n",
      "Epoch 448 val loss: 0.6368997638162813\n",
      "Epoch 448 val accuracy: 78.53618421052632\n",
      "Saved model to .\\test_models/MLP_448.pth\n",
      "Epoch 449 train loss: 0.6459493148549084\n",
      "Epoch 449 train accuracy: 77.32382780367425\n",
      "Epoch 449 val loss: 0.6368296300306132\n",
      "Epoch 449 val accuracy: 78.61842105263158\n",
      "Saved model to .\\test_models/MLP_449.pth\n",
      "Epoch 450 train loss: 0.6458213602829921\n",
      "Epoch 450 train accuracy: 77.32382780367425\n",
      "Epoch 450 val loss: 0.63674061294449\n",
      "Epoch 450 val accuracy: 78.61842105263158\n",
      "Saved model to .\\test_models/MLP_450.pth\n",
      "Epoch 451 train loss: 0.6457561224110817\n",
      "Epoch 451 train accuracy: 77.37866739786125\n",
      "Epoch 451 val loss: 0.6366536147696408\n",
      "Epoch 451 val accuracy: 78.61842105263158\n",
      "Saved model to .\\test_models/MLP_451.pth\n",
      "Epoch 452 train loss: 0.6457045946041482\n",
      "Epoch 452 train accuracy: 77.32382780367425\n",
      "Epoch 452 val loss: 0.6365704200181522\n",
      "Epoch 452 val accuracy: 78.61842105263158\n",
      "Saved model to .\\test_models/MLP_452.pth\n",
      "Epoch 453 train loss: 0.645599630220156\n",
      "Epoch 453 train accuracy: 77.43350699204827\n",
      "Epoch 453 val loss: 0.6364944094890043\n",
      "Epoch 453 val accuracy: 78.61842105263158\n",
      "Saved model to .\\test_models/MLP_453.pth\n",
      "Epoch 454 train loss: 0.6455186078684372\n",
      "Epoch 454 train accuracy: 77.40608719495475\n",
      "Epoch 454 val loss: 0.6364398154577142\n",
      "Epoch 454 val accuracy: 78.78289473684211\n",
      "Saved model to .\\test_models/MLP_454.pth\n",
      "Epoch 455 train loss: 0.6454938708951599\n",
      "Epoch 455 train accuracy: 77.46092678914177\n",
      "Epoch 455 val loss: 0.6363734292160523\n",
      "Epoch 455 val accuracy: 78.86513157894737\n",
      "Saved model to .\\test_models/MLP_455.pth\n",
      "Epoch 456 train loss: 0.6454382349589938\n",
      "Epoch 456 train accuracy: 77.46092678914177\n",
      "Epoch 456 val loss: 0.636264530941844\n",
      "Epoch 456 val accuracy: 78.78289473684211\n",
      "Saved model to .\\test_models/MLP_456.pth\n",
      "Epoch 457 train loss: 0.6453141263244968\n",
      "Epoch 457 train accuracy: 77.46092678914177\n",
      "Epoch 457 val loss: 0.6362078840795317\n",
      "Epoch 457 val accuracy: 78.86513157894737\n",
      "Saved model to .\\test_models/MLP_457.pth\n",
      "Epoch 458 train loss: 0.6452121346077898\n",
      "Epoch 458 train accuracy: 77.40608719495475\n",
      "Epoch 458 val loss: 0.6361323957282462\n",
      "Epoch 458 val accuracy: 78.86513157894737\n",
      "Saved model to .\\test_models/MLP_458.pth\n",
      "Epoch 459 train loss: 0.6451788213953638\n",
      "Epoch 459 train accuracy: 77.43350699204827\n",
      "Epoch 459 val loss: 0.6360536187298989\n",
      "Epoch 459 val accuracy: 78.86513157894737\n",
      "Saved model to .\\test_models/MLP_459.pth\n",
      "Epoch 460 train loss: 0.645039850682543\n",
      "Epoch 460 train accuracy: 77.43350699204827\n",
      "Epoch 460 val loss: 0.6359640259883905\n",
      "Epoch 460 val accuracy: 78.86513157894737\n",
      "Saved model to .\\test_models/MLP_460.pth\n",
      "Epoch 461 train loss: 0.6449713365158491\n",
      "Epoch 461 train accuracy: 77.40608719495475\n",
      "Epoch 461 val loss: 0.6358521268948129\n",
      "Epoch 461 val accuracy: 78.86513157894737\n",
      "Saved model to .\\test_models/MLP_461.pth\n",
      "Epoch 462 train loss: 0.6449423488392904\n",
      "Epoch 462 train accuracy: 77.43350699204827\n",
      "Epoch 462 val loss: 0.6357567595612061\n",
      "Epoch 462 val accuracy: 78.94736842105263\n",
      "Saved model to .\\test_models/MLP_462.pth\n",
      "Epoch 463 train loss: 0.6448276412853023\n",
      "Epoch 463 train accuracy: 77.43350699204827\n",
      "Epoch 463 val loss: 0.6356626879423857\n",
      "Epoch 463 val accuracy: 79.02960526315789\n",
      "Saved model to .\\test_models/MLP_463.pth\n",
      "Epoch 464 train loss: 0.6447764771026477\n",
      "Epoch 464 train accuracy: 77.43350699204827\n",
      "Epoch 464 val loss: 0.635615252203455\n",
      "Epoch 464 val accuracy: 79.02960526315789\n",
      "Saved model to .\\test_models/MLP_464.pth\n",
      "Epoch 465 train loss: 0.6446575094667966\n",
      "Epoch 465 train accuracy: 77.40608719495475\n",
      "Epoch 465 val loss: 0.635508748555654\n",
      "Epoch 465 val accuracy: 79.11184210526316\n",
      "Saved model to .\\test_models/MLP_465.pth\n",
      "Epoch 466 train loss: 0.6446360649312275\n",
      "Epoch 466 train accuracy: 77.48834658623527\n",
      "Epoch 466 val loss: 0.6354180086208018\n",
      "Epoch 466 val accuracy: 79.19407894736842\n",
      "Saved model to .\\test_models/MLP_466.pth\n",
      "Epoch 467 train loss: 0.644510389746804\n",
      "Epoch 467 train accuracy: 77.43350699204827\n",
      "Epoch 467 val loss: 0.6353462713917619\n",
      "Epoch 467 val accuracy: 79.27631578947368\n",
      "Saved model to .\\test_models/MLP_467.pth\n",
      "Epoch 468 train loss: 0.6444768819042987\n",
      "Epoch 468 train accuracy: 77.32382780367425\n",
      "Epoch 468 val loss: 0.6352904540927786\n",
      "Epoch 468 val accuracy: 79.27631578947368\n",
      "Saved model to .\\test_models/MLP_468.pth\n",
      "Epoch 469 train loss: 0.6444151311982096\n",
      "Epoch 469 train accuracy: 77.43350699204827\n",
      "Epoch 469 val loss: 0.635217234394268\n",
      "Epoch 469 val accuracy: 79.27631578947368\n",
      "Saved model to .\\test_models/MLP_469.pth\n",
      "Epoch 470 train loss: 0.6443396431737041\n",
      "Epoch 470 train accuracy: 77.43350699204827\n",
      "Epoch 470 val loss: 0.6351235073648\n",
      "Epoch 470 val accuracy: 79.27631578947368\n",
      "Saved model to .\\test_models/MLP_470.pth\n",
      "Epoch 471 train loss: 0.6442773173840945\n",
      "Epoch 471 train accuracy: 77.46092678914177\n",
      "Epoch 471 val loss: 0.6350248621678666\n",
      "Epoch 471 val accuracy: 79.27631578947368\n",
      "Saved model to .\\test_models/MLP_471.pth\n",
      "Epoch 472 train loss: 0.6441167796912947\n",
      "Epoch 472 train accuracy: 77.43350699204827\n",
      "Epoch 472 val loss: 0.6349518311847198\n",
      "Epoch 472 val accuracy: 79.27631578947368\n",
      "Saved model to .\\test_models/MLP_472.pth\n",
      "Epoch 473 train loss: 0.6440512370318174\n",
      "Epoch 473 train accuracy: 77.40608719495475\n",
      "Epoch 473 val loss: 0.6348652133816167\n",
      "Epoch 473 val accuracy: 79.35855263157895\n",
      "Saved model to .\\test_models/MLP_473.pth\n",
      "Epoch 474 train loss: 0.6440174884996132\n",
      "Epoch 474 train accuracy: 77.46092678914177\n",
      "Epoch 474 val loss: 0.6347648507278216\n",
      "Epoch 474 val accuracy: 79.35855263157895\n",
      "Saved model to .\\test_models/MLP_474.pth\n",
      "Epoch 475 train loss: 0.6439226160904294\n",
      "Epoch 475 train accuracy: 77.48834658623527\n",
      "Epoch 475 val loss: 0.6346771167101044\n",
      "Epoch 475 val accuracy: 79.35855263157895\n",
      "Saved model to .\\test_models/MLP_475.pth\n",
      "Epoch 476 train loss: 0.6437899016105292\n",
      "Epoch 476 train accuracy: 77.57060597751577\n",
      "Epoch 476 val loss: 0.6346294916185894\n",
      "Epoch 476 val accuracy: 79.35855263157895\n",
      "Saved model to .\\test_models/MLP_476.pth\n",
      "Epoch 477 train loss: 0.6437265546502251\n",
      "Epoch 477 train accuracy: 77.51576638332877\n",
      "Epoch 477 val loss: 0.634527934323016\n",
      "Epoch 477 val accuracy: 79.35855263157895\n",
      "Saved model to .\\test_models/MLP_477.pth\n",
      "Epoch 478 train loss: 0.6436883142512095\n",
      "Epoch 478 train accuracy: 77.51576638332877\n",
      "Epoch 478 val loss: 0.6344256738298818\n",
      "Epoch 478 val accuracy: 79.52302631578948\n",
      "Saved model to .\\test_models/MLP_478.pth\n",
      "Epoch 479 train loss: 0.6435134251716367\n",
      "Epoch 479 train accuracy: 77.54318618042227\n",
      "Epoch 479 val loss: 0.63436647068317\n",
      "Epoch 479 val accuracy: 79.4407894736842\n",
      "Saved model to .\\test_models/MLP_479.pth\n",
      "Epoch 480 train loss: 0.6434712779887936\n",
      "Epoch 480 train accuracy: 77.57060597751577\n",
      "Epoch 480 val loss: 0.6342848177607122\n",
      "Epoch 480 val accuracy: 79.4407894736842\n",
      "Saved model to .\\test_models/MLP_480.pth\n",
      "Epoch 481 train loss: 0.6434286059321541\n",
      "Epoch 481 train accuracy: 77.57060597751577\n",
      "Epoch 481 val loss: 0.6341884329326843\n",
      "Epoch 481 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_481.pth\n",
      "Epoch 482 train loss: 0.6433757377232898\n",
      "Epoch 482 train accuracy: 77.57060597751577\n",
      "Epoch 482 val loss: 0.6341129857066431\n",
      "Epoch 482 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_482.pth\n",
      "Epoch 483 train loss: 0.6433240936971024\n",
      "Epoch 483 train accuracy: 77.57060597751577\n",
      "Epoch 483 val loss: 0.6340244780049512\n",
      "Epoch 483 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_483.pth\n",
      "Epoch 484 train loss: 0.6432000270864943\n",
      "Epoch 484 train accuracy: 77.62544557170277\n",
      "Epoch 484 val loss: 0.6339657485583111\n",
      "Epoch 484 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_484.pth\n",
      "Epoch 485 train loss: 0.6431459667193785\n",
      "Epoch 485 train accuracy: 77.70770496298327\n",
      "Epoch 485 val loss: 0.6338821812287757\n",
      "Epoch 485 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_485.pth\n",
      "Epoch 486 train loss: 0.6430672160758261\n",
      "Epoch 486 train accuracy: 77.62544557170277\n",
      "Epoch 486 val loss: 0.6337923950662738\n",
      "Epoch 486 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_486.pth\n",
      "Epoch 487 train loss: 0.6429810985726746\n",
      "Epoch 487 train accuracy: 77.70770496298327\n",
      "Epoch 487 val loss: 0.6337284507524026\n",
      "Epoch 487 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_487.pth\n",
      "Epoch 488 train loss: 0.6429489363115608\n",
      "Epoch 488 train accuracy: 77.68028516588977\n",
      "Epoch 488 val loss: 0.6336573207456815\n",
      "Epoch 488 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_488.pth\n",
      "Epoch 489 train loss: 0.6428385170241981\n",
      "Epoch 489 train accuracy: 77.70770496298327\n",
      "Epoch 489 val loss: 0.6336102299392223\n",
      "Epoch 489 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_489.pth\n",
      "Epoch 490 train loss: 0.6427759220660255\n",
      "Epoch 490 train accuracy: 77.68028516588977\n",
      "Epoch 490 val loss: 0.633521640281144\n",
      "Epoch 490 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_490.pth\n",
      "Epoch 491 train loss: 0.6426689816606149\n",
      "Epoch 491 train accuracy: 77.76254455717027\n",
      "Epoch 491 val loss: 0.6334345461310524\n",
      "Epoch 491 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_491.pth\n",
      "Epoch 492 train loss: 0.6426153520546984\n",
      "Epoch 492 train accuracy: 77.68028516588977\n",
      "Epoch 492 val loss: 0.6333570531324336\n",
      "Epoch 492 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_492.pth\n",
      "Epoch 493 train loss: 0.6424990071375903\n",
      "Epoch 493 train accuracy: 77.62544557170277\n",
      "Epoch 493 val loss: 0.6332609660335278\n",
      "Epoch 493 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_493.pth\n",
      "Epoch 494 train loss: 0.642458743203366\n",
      "Epoch 494 train accuracy: 77.73512476007677\n",
      "Epoch 494 val loss: 0.6331851317694313\n",
      "Epoch 494 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_494.pth\n",
      "Epoch 495 train loss: 0.6423797759374505\n",
      "Epoch 495 train accuracy: 77.62544557170277\n",
      "Epoch 495 val loss: 0.6330951665969271\n",
      "Epoch 495 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_495.pth\n",
      "Epoch 496 train loss: 0.6423480521495405\n",
      "Epoch 496 train accuracy: 77.68028516588977\n",
      "Epoch 496 val loss: 0.6330173914565852\n",
      "Epoch 496 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_496.pth\n",
      "Epoch 497 train loss: 0.6422285177140382\n",
      "Epoch 497 train accuracy: 77.70770496298327\n",
      "Epoch 497 val loss: 0.63297145676456\n",
      "Epoch 497 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_497.pth\n",
      "Epoch 498 train loss: 0.6421518238555444\n",
      "Epoch 498 train accuracy: 77.70770496298327\n",
      "Epoch 498 val loss: 0.6328877285122871\n",
      "Epoch 498 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_498.pth\n",
      "Epoch 499 train loss: 0.642078308029133\n",
      "Epoch 499 train accuracy: 77.68028516588977\n",
      "Epoch 499 val loss: 0.6327878543616909\n",
      "Epoch 499 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_499.pth\n",
      "Epoch 500 train loss: 0.6420057316457755\n",
      "Epoch 500 train accuracy: 77.68028516588977\n",
      "Epoch 500 val loss: 0.632739077469236\n",
      "Epoch 500 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_500.pth\n",
      "Epoch 501 train loss: 0.6419715930364633\n",
      "Epoch 501 train accuracy: 77.70770496298327\n",
      "Epoch 501 val loss: 0.6326652336375493\n",
      "Epoch 501 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_501.pth\n",
      "Epoch 502 train loss: 0.6418610229565386\n",
      "Epoch 502 train accuracy: 77.76254455717027\n",
      "Epoch 502 val loss: 0.6326021622670325\n",
      "Epoch 502 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_502.pth\n",
      "Epoch 503 train loss: 0.6417264151795391\n",
      "Epoch 503 train accuracy: 77.73512476007677\n",
      "Epoch 503 val loss: 0.6325164295144772\n",
      "Epoch 503 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_503.pth\n",
      "Epoch 504 train loss: 0.6416488138207218\n",
      "Epoch 504 train accuracy: 77.76254455717027\n",
      "Epoch 504 val loss: 0.632458757413061\n",
      "Epoch 504 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_504.pth\n",
      "Epoch 505 train loss: 0.6416494013708934\n",
      "Epoch 505 train accuracy: 77.68028516588977\n",
      "Epoch 505 val loss: 0.6323659066110849\n",
      "Epoch 505 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_505.pth\n",
      "Epoch 506 train loss: 0.6415573892003873\n",
      "Epoch 506 train accuracy: 77.73512476007677\n",
      "Epoch 506 val loss: 0.6322672923928813\n",
      "Epoch 506 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_506.pth\n",
      "Epoch 507 train loss: 0.6414800997692764\n",
      "Epoch 507 train accuracy: 77.76254455717027\n",
      "Epoch 507 val loss: 0.6321848936771092\n",
      "Epoch 507 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_507.pth\n",
      "Epoch 508 train loss: 0.6414083243069941\n",
      "Epoch 508 train accuracy: 77.70770496298327\n",
      "Epoch 508 val loss: 0.632107432049356\n",
      "Epoch 508 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_508.pth\n",
      "Epoch 509 train loss: 0.6412960460507556\n",
      "Epoch 509 train accuracy: 77.76254455717027\n",
      "Epoch 509 val loss: 0.6320254740942466\n",
      "Epoch 509 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_509.pth\n",
      "Epoch 510 train loss: 0.6412003981112911\n",
      "Epoch 510 train accuracy: 77.73512476007677\n",
      "Epoch 510 val loss: 0.6319505670352986\n",
      "Epoch 510 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_510.pth\n",
      "Epoch 511 train loss: 0.6411956437912426\n",
      "Epoch 511 train accuracy: 77.78996435426377\n",
      "Epoch 511 val loss: 0.6318519476212954\n",
      "Epoch 511 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_511.pth\n",
      "Epoch 512 train loss: 0.6411022182652041\n",
      "Epoch 512 train accuracy: 77.78996435426377\n",
      "Epoch 512 val loss: 0.6317653245243587\n",
      "Epoch 512 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_512.pth\n",
      "Epoch 513 train loss: 0.6410342967464474\n",
      "Epoch 513 train accuracy: 77.87222374554429\n",
      "Epoch 513 val loss: 0.6316904484441406\n",
      "Epoch 513 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_513.pth\n",
      "Epoch 514 train loss: 0.6409357398944465\n",
      "Epoch 514 train accuracy: 77.84480394845077\n",
      "Epoch 514 val loss: 0.6316154977600825\n",
      "Epoch 514 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_514.pth\n",
      "Epoch 515 train loss: 0.6408487831879603\n",
      "Epoch 515 train accuracy: 77.78996435426377\n",
      "Epoch 515 val loss: 0.6315432626165842\n",
      "Epoch 515 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_515.pth\n",
      "Epoch 516 train loss: 0.6407208085190832\n",
      "Epoch 516 train accuracy: 77.87222374554429\n",
      "Epoch 516 val loss: 0.6314678378403187\n",
      "Epoch 516 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_516.pth\n",
      "Epoch 517 train loss: 0.6407031088806036\n",
      "Epoch 517 train accuracy: 77.84480394845077\n",
      "Epoch 517 val loss: 0.6313656233251095\n",
      "Epoch 517 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_517.pth\n",
      "Epoch 518 train loss: 0.6406806307240275\n",
      "Epoch 518 train accuracy: 77.87222374554429\n",
      "Epoch 518 val loss: 0.6313257422298193\n",
      "Epoch 518 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_518.pth\n",
      "Epoch 519 train loss: 0.6406052288713685\n",
      "Epoch 519 train accuracy: 77.89964354263779\n",
      "Epoch 519 val loss: 0.6312312600447944\n",
      "Epoch 519 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_519.pth\n",
      "Epoch 520 train loss: 0.6405062766647652\n",
      "Epoch 520 train accuracy: 77.78996435426377\n",
      "Epoch 520 val loss: 0.6311473482729573\n",
      "Epoch 520 val accuracy: 79.60526315789474\n",
      "Saved model to .\\test_models/MLP_520.pth\n",
      "Epoch 521 train loss: 0.6404311538657599\n",
      "Epoch 521 train accuracy: 77.84480394845077\n",
      "Epoch 521 val loss: 0.6310857049140491\n",
      "Epoch 521 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_521.pth\n",
      "Epoch 522 train loss: 0.6402601748378131\n",
      "Epoch 522 train accuracy: 77.89964354263779\n",
      "Epoch 522 val loss: 0.6310107670724392\n",
      "Epoch 522 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_522.pth\n",
      "Epoch 523 train loss: 0.6402198782746207\n",
      "Epoch 523 train accuracy: 77.84480394845077\n",
      "Epoch 523 val loss: 0.6309025485656763\n",
      "Epoch 523 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_523.pth\n",
      "Epoch 524 train loss: 0.6401818652980422\n",
      "Epoch 524 train accuracy: 77.92706333973129\n",
      "Epoch 524 val loss: 0.6308428498573209\n",
      "Epoch 524 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_524.pth\n",
      "Epoch 525 train loss: 0.6400808288078559\n",
      "Epoch 525 train accuracy: 77.89964354263779\n",
      "Epoch 525 val loss: 0.6307533630415013\n",
      "Epoch 525 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_525.pth\n",
      "Epoch 526 train loss: 0.6400138737405079\n",
      "Epoch 526 train accuracy: 77.89964354263779\n",
      "Epoch 526 val loss: 0.6306603552871629\n",
      "Epoch 526 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_526.pth\n",
      "Epoch 527 train loss: 0.6400450151086899\n",
      "Epoch 527 train accuracy: 77.89964354263779\n",
      "Epoch 527 val loss: 0.6305917992599701\n",
      "Epoch 527 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_527.pth\n",
      "Epoch 528 train loss: 0.6399039015369979\n",
      "Epoch 528 train accuracy: 77.87222374554429\n",
      "Epoch 528 val loss: 0.630503804471932\n",
      "Epoch 528 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_528.pth\n",
      "Epoch 529 train loss: 0.6398184968387348\n",
      "Epoch 529 train accuracy: 77.89964354263779\n",
      "Epoch 529 val loss: 0.630438366512719\n",
      "Epoch 529 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_529.pth\n",
      "Epoch 530 train loss: 0.6397514315158651\n",
      "Epoch 530 train accuracy: 77.95448313682479\n",
      "Epoch 530 val loss: 0.6303567791259602\n",
      "Epoch 530 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_530.pth\n",
      "Epoch 531 train loss: 0.63965805329121\n",
      "Epoch 531 train accuracy: 77.87222374554429\n",
      "Epoch 531 val loss: 0.6303113281334701\n",
      "Epoch 531 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_531.pth\n",
      "Epoch 532 train loss: 0.6396162176602765\n",
      "Epoch 532 train accuracy: 77.84480394845077\n",
      "Epoch 532 val loss: 0.6302113975153157\n",
      "Epoch 532 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_532.pth\n",
      "Epoch 533 train loss: 0.6395674893926633\n",
      "Epoch 533 train accuracy: 77.89964354263779\n",
      "Epoch 533 val loss: 0.6301445020852905\n",
      "Epoch 533 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_533.pth\n",
      "Epoch 534 train loss: 0.6394478261242049\n",
      "Epoch 534 train accuracy: 77.89964354263779\n",
      "Epoch 534 val loss: 0.6301094692592558\n",
      "Epoch 534 val accuracy: 79.76973684210526\n",
      "Saved model to .\\test_models/MLP_534.pth\n",
      "Epoch 535 train loss: 0.639393185902583\n",
      "Epoch 535 train accuracy: 77.87222374554429\n",
      "Epoch 535 val loss: 0.6300083539987865\n",
      "Epoch 535 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_535.pth\n",
      "Epoch 536 train loss: 0.639294905146878\n",
      "Epoch 536 train accuracy: 77.92706333973129\n",
      "Epoch 536 val loss: 0.6299474443259993\n",
      "Epoch 536 val accuracy: 79.76973684210526\n",
      "Saved model to .\\test_models/MLP_536.pth\n",
      "Epoch 537 train loss: 0.6392041638640589\n",
      "Epoch 537 train accuracy: 77.95448313682479\n",
      "Epoch 537 val loss: 0.6298584124367488\n",
      "Epoch 537 val accuracy: 79.76973684210526\n",
      "Saved model to .\\test_models/MLP_537.pth\n",
      "Epoch 538 train loss: 0.6391650108751237\n",
      "Epoch 538 train accuracy: 77.98190293391829\n",
      "Epoch 538 val loss: 0.6297439684797275\n",
      "Epoch 538 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_538.pth\n",
      "Epoch 539 train loss: 0.639100176200532\n",
      "Epoch 539 train accuracy: 77.89964354263779\n",
      "Epoch 539 val loss: 0.6296652898584542\n",
      "Epoch 539 val accuracy: 79.6875\n",
      "Saved model to .\\test_models/MLP_539.pth\n",
      "Epoch 540 train loss: 0.638985635222573\n",
      "Epoch 540 train accuracy: 78.0915821222923\n",
      "Epoch 540 val loss: 0.6295716857635661\n",
      "Epoch 540 val accuracy: 79.76973684210526\n",
      "Saved model to .\\test_models/MLP_540.pth\n",
      "Epoch 541 train loss: 0.6389496111098611\n",
      "Epoch 541 train accuracy: 77.92706333973129\n",
      "Epoch 541 val loss: 0.6295179924192397\n",
      "Epoch 541 val accuracy: 79.76973684210526\n",
      "Saved model to .\\test_models/MLP_541.pth\n",
      "Epoch 542 train loss: 0.6388667269299427\n",
      "Epoch 542 train accuracy: 77.92706333973129\n",
      "Epoch 542 val loss: 0.6294218023356638\n",
      "Epoch 542 val accuracy: 79.85197368421052\n",
      "Saved model to .\\test_models/MLP_542.pth\n",
      "Epoch 543 train loss: 0.6387571719589463\n",
      "Epoch 543 train accuracy: 77.92706333973129\n",
      "Epoch 543 val loss: 0.6293432779218021\n",
      "Epoch 543 val accuracy: 79.85197368421052\n",
      "Saved model to .\\test_models/MLP_543.pth\n",
      "Epoch 544 train loss: 0.6386314366797083\n",
      "Epoch 544 train accuracy: 77.98190293391829\n",
      "Epoch 544 val loss: 0.6292952967709616\n",
      "Epoch 544 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_544.pth\n",
      "Epoch 545 train loss: 0.6386499991150278\n",
      "Epoch 545 train accuracy: 78.00932273101179\n",
      "Epoch 545 val loss: 0.6292266478075793\n",
      "Epoch 545 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_545.pth\n",
      "Epoch 546 train loss: 0.6385998359407511\n",
      "Epoch 546 train accuracy: 77.92706333973129\n",
      "Epoch 546 val loss: 0.6291658003863535\n",
      "Epoch 546 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_546.pth\n",
      "Epoch 547 train loss: 0.6384594916905227\n",
      "Epoch 547 train accuracy: 78.0367425281053\n",
      "Epoch 547 val loss: 0.6290723687331927\n",
      "Epoch 547 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_547.pth\n",
      "Epoch 548 train loss: 0.6383763086377529\n",
      "Epoch 548 train accuracy: 77.98190293391829\n",
      "Epoch 548 val loss: 0.6289973378573593\n",
      "Epoch 548 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_548.pth\n",
      "Epoch 549 train loss: 0.6383422277704404\n",
      "Epoch 549 train accuracy: 78.00932273101179\n",
      "Epoch 549 val loss: 0.6289330755213374\n",
      "Epoch 549 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_549.pth\n",
      "Epoch 550 train loss: 0.6382621151248091\n",
      "Epoch 550 train accuracy: 78.0641623251988\n",
      "Epoch 550 val loss: 0.6288994156608456\n",
      "Epoch 550 val accuracy: 79.9342105263158\n",
      "Saved model to .\\test_models/MLP_550.pth\n",
      "Epoch 551 train loss: 0.638152480844343\n",
      "Epoch 551 train accuracy: 78.00932273101179\n",
      "Epoch 551 val loss: 0.6287895869463682\n",
      "Epoch 551 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_551.pth\n",
      "Epoch 552 train loss: 0.6380474281480961\n",
      "Epoch 552 train accuracy: 78.0641623251988\n",
      "Epoch 552 val loss: 0.6287055976296726\n",
      "Epoch 552 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_552.pth\n",
      "Epoch 553 train loss: 0.638072608071461\n",
      "Epoch 553 train accuracy: 78.0641623251988\n",
      "Epoch 553 val loss: 0.628627988068681\n",
      "Epoch 553 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_553.pth\n",
      "Epoch 554 train loss: 0.6379542940279894\n",
      "Epoch 554 train accuracy: 78.1738415135728\n",
      "Epoch 554 val loss: 0.6285575198891916\n",
      "Epoch 554 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_554.pth\n",
      "Epoch 555 train loss: 0.6378802437858101\n",
      "Epoch 555 train accuracy: 78.0915821222923\n",
      "Epoch 555 val loss: 0.6284896037296245\n",
      "Epoch 555 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_555.pth\n",
      "Epoch 556 train loss: 0.6378057711479956\n",
      "Epoch 556 train accuracy: 78.1464217164793\n",
      "Epoch 556 val loss: 0.6283911915594026\n",
      "Epoch 556 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_556.pth\n",
      "Epoch 557 train loss: 0.6377366457395909\n",
      "Epoch 557 train accuracy: 78.1738415135728\n",
      "Epoch 557 val loss: 0.6283103892285573\n",
      "Epoch 557 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_557.pth\n",
      "Epoch 558 train loss: 0.6375963781682545\n",
      "Epoch 558 train accuracy: 78.2286811077598\n",
      "Epoch 558 val loss: 0.628268610293928\n",
      "Epoch 558 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_558.pth\n",
      "Epoch 559 train loss: 0.6375868157401943\n",
      "Epoch 559 train accuracy: 78.2286811077598\n",
      "Epoch 559 val loss: 0.6282166233776432\n",
      "Epoch 559 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_559.pth\n",
      "Epoch 560 train loss: 0.6374324303970003\n",
      "Epoch 560 train accuracy: 78.31094049904031\n",
      "Epoch 560 val loss: 0.6281512815897402\n",
      "Epoch 560 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_560.pth\n",
      "Epoch 561 train loss: 0.6374270442154324\n",
      "Epoch 561 train accuracy: 78.2835207019468\n",
      "Epoch 561 val loss: 0.6280640152920234\n",
      "Epoch 561 val accuracy: 80.01644736842105\n",
      "Saved model to .\\test_models/MLP_561.pth\n",
      "Epoch 562 train loss: 0.6373630307876227\n",
      "Epoch 562 train accuracy: 78.31094049904031\n",
      "Epoch 562 val loss: 0.627966457879857\n",
      "Epoch 562 val accuracy: 80.09868421052632\n",
      "Saved model to .\\test_models/MLP_562.pth\n",
      "Epoch 563 train loss: 0.6372285999619124\n",
      "Epoch 563 train accuracy: 78.33836029613381\n",
      "Epoch 563 val loss: 0.6279074392820659\n",
      "Epoch 563 val accuracy: 80.09868421052632\n",
      "Saved model to .\\test_models/MLP_563.pth\n",
      "Epoch 564 train loss: 0.6372019414250788\n",
      "Epoch 564 train accuracy: 78.2561009048533\n",
      "Epoch 564 val loss: 0.6278359039049399\n",
      "Epoch 564 val accuracy: 80.09868421052632\n",
      "Saved model to .\\test_models/MLP_564.pth\n",
      "Epoch 565 train loss: 0.6371213001313439\n",
      "Epoch 565 train accuracy: 78.33836029613381\n",
      "Epoch 565 val loss: 0.6277593871284473\n",
      "Epoch 565 val accuracy: 80.09868421052632\n",
      "Saved model to .\\test_models/MLP_565.pth\n",
      "Epoch 566 train loss: 0.6369933909491489\n",
      "Epoch 566 train accuracy: 78.33836029613381\n",
      "Epoch 566 val loss: 0.6276578825751418\n",
      "Epoch 566 val accuracy: 80.09868421052632\n",
      "Saved model to .\\test_models/MLP_566.pth\n",
      "Epoch 567 train loss: 0.6369525439906538\n",
      "Epoch 567 train accuracy: 78.39319989032082\n",
      "Epoch 567 val loss: 0.627584673856434\n",
      "Epoch 567 val accuracy: 80.09868421052632\n",
      "Saved model to .\\test_models/MLP_567.pth\n",
      "Epoch 568 train loss: 0.6369302607092419\n",
      "Epoch 568 train accuracy: 78.33836029613381\n",
      "Epoch 568 val loss: 0.627504245525128\n",
      "Epoch 568 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_568.pth\n",
      "Epoch 569 train loss: 0.6368701914161966\n",
      "Epoch 569 train accuracy: 78.39319989032082\n",
      "Epoch 569 val loss: 0.6274166738516406\n",
      "Epoch 569 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_569.pth\n",
      "Epoch 570 train loss: 0.6367628038779163\n",
      "Epoch 570 train accuracy: 78.42061968741432\n",
      "Epoch 570 val loss: 0.6273606791602153\n",
      "Epoch 570 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_570.pth\n",
      "Epoch 571 train loss: 0.636659398462558\n",
      "Epoch 571 train accuracy: 78.36578009322731\n",
      "Epoch 571 val loss: 0.6272980524717193\n",
      "Epoch 571 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_571.pth\n",
      "Epoch 572 train loss: 0.6365380402523697\n",
      "Epoch 572 train accuracy: 78.42061968741432\n",
      "Epoch 572 val loss: 0.6272096274126517\n",
      "Epoch 572 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_572.pth\n",
      "Epoch 573 train loss: 0.6365574107489043\n",
      "Epoch 573 train accuracy: 78.44803948450782\n",
      "Epoch 573 val loss: 0.6271390730613157\n",
      "Epoch 573 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_573.pth\n",
      "Epoch 574 train loss: 0.6365049447733582\n",
      "Epoch 574 train accuracy: 78.42061968741432\n",
      "Epoch 574 val loss: 0.627051442910574\n",
      "Epoch 574 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_574.pth\n",
      "Epoch 575 train loss: 0.6364026226822221\n",
      "Epoch 575 train accuracy: 78.47545928160132\n",
      "Epoch 575 val loss: 0.6269795876486521\n",
      "Epoch 575 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_575.pth\n",
      "Epoch 576 train loss: 0.6363014919977439\n",
      "Epoch 576 train accuracy: 78.44803948450782\n",
      "Epoch 576 val loss: 0.6269169701753479\n",
      "Epoch 576 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_576.pth\n",
      "Epoch 577 train loss: 0.6362160089376726\n",
      "Epoch 577 train accuracy: 78.47545928160132\n",
      "Epoch 577 val loss: 0.6268592388614228\n",
      "Epoch 577 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_577.pth\n",
      "Epoch 578 train loss: 0.6361623442029221\n",
      "Epoch 578 train accuracy: 78.58513846997532\n",
      "Epoch 578 val loss: 0.6267764066395006\n",
      "Epoch 578 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_578.pth\n",
      "Epoch 579 train loss: 0.6360984155744837\n",
      "Epoch 579 train accuracy: 78.50287907869482\n",
      "Epoch 579 val loss: 0.6266919930318469\n",
      "Epoch 579 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_579.pth\n",
      "Epoch 580 train loss: 0.6359990226072177\n",
      "Epoch 580 train accuracy: 78.53029887578832\n",
      "Epoch 580 val loss: 0.6266128144374019\n",
      "Epoch 580 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_580.pth\n",
      "Epoch 581 train loss: 0.6359489550323862\n",
      "Epoch 581 train accuracy: 78.50287907869482\n",
      "Epoch 581 val loss: 0.626575408993583\n",
      "Epoch 581 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_581.pth\n",
      "Epoch 582 train loss: 0.6358663320966196\n",
      "Epoch 582 train accuracy: 78.47545928160132\n",
      "Epoch 582 val loss: 0.6265080560390887\n",
      "Epoch 582 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_582.pth\n",
      "Epoch 583 train loss: 0.6357937815288702\n",
      "Epoch 583 train accuracy: 78.61255826706882\n",
      "Epoch 583 val loss: 0.6264356262981892\n",
      "Epoch 583 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_583.pth\n",
      "Epoch 584 train loss: 0.6357166991944898\n",
      "Epoch 584 train accuracy: 78.50287907869482\n",
      "Epoch 584 val loss: 0.6263814873405193\n",
      "Epoch 584 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_584.pth\n",
      "Epoch 585 train loss: 0.6355819755413553\n",
      "Epoch 585 train accuracy: 78.61255826706882\n",
      "Epoch 585 val loss: 0.6263410318642855\n",
      "Epoch 585 val accuracy: 80.09868421052632\n",
      "Saved model to .\\test_models/MLP_585.pth\n",
      "Epoch 586 train loss: 0.6355756235292607\n",
      "Epoch 586 train accuracy: 78.61255826706882\n",
      "Epoch 586 val loss: 0.6262331392223898\n",
      "Epoch 586 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_586.pth\n",
      "Epoch 587 train loss: 0.6354948498243302\n",
      "Epoch 587 train accuracy: 78.66739786125582\n",
      "Epoch 587 val loss: 0.6261379940337256\n",
      "Epoch 587 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_587.pth\n",
      "Epoch 588 train loss: 0.6354212682171348\n",
      "Epoch 588 train accuracy: 78.61255826706882\n",
      "Epoch 588 val loss: 0.6260490018482271\n",
      "Epoch 588 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_588.pth\n",
      "Epoch 589 train loss: 0.6353140187760195\n",
      "Epoch 589 train accuracy: 78.69481765834932\n",
      "Epoch 589 val loss: 0.6259786690536299\n",
      "Epoch 589 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_589.pth\n",
      "Epoch 590 train loss: 0.6352361281190002\n",
      "Epoch 590 train accuracy: 78.66739786125582\n",
      "Epoch 590 val loss: 0.6258893852171145\n",
      "Epoch 590 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_590.pth\n",
      "Epoch 591 train loss: 0.6352111152128169\n",
      "Epoch 591 train accuracy: 78.69481765834932\n",
      "Epoch 591 val loss: 0.6258231815146772\n",
      "Epoch 591 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_591.pth\n",
      "Epoch 592 train loss: 0.6351235522316736\n",
      "Epoch 592 train accuracy: 78.80449684672334\n",
      "Epoch 592 val loss: 0.6257502600354584\n",
      "Epoch 592 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_592.pth\n",
      "Epoch 593 train loss: 0.6350109730438706\n",
      "Epoch 593 train accuracy: 78.72223745544282\n",
      "Epoch 593 val loss: 0.6256840533920025\n",
      "Epoch 593 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_593.pth\n",
      "Epoch 594 train loss: 0.6349698376368013\n",
      "Epoch 594 train accuracy: 78.83191664381684\n",
      "Epoch 594 val loss: 0.6256030649927101\n",
      "Epoch 594 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_594.pth\n",
      "Epoch 595 train loss: 0.6348685277135748\n",
      "Epoch 595 train accuracy: 78.77707704962984\n",
      "Epoch 595 val loss: 0.625513485191684\n",
      "Epoch 595 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_595.pth\n",
      "Epoch 596 train loss: 0.6348245966395265\n",
      "Epoch 596 train accuracy: 78.80449684672334\n",
      "Epoch 596 val loss: 0.6254438281451401\n",
      "Epoch 596 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_596.pth\n",
      "Epoch 597 train loss: 0.6347718580969071\n",
      "Epoch 597 train accuracy: 78.80449684672334\n",
      "Epoch 597 val loss: 0.6253709278412556\n",
      "Epoch 597 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_597.pth\n",
      "Epoch 598 train loss: 0.6346266588784362\n",
      "Epoch 598 train accuracy: 78.85933644091034\n",
      "Epoch 598 val loss: 0.6252686277424034\n",
      "Epoch 598 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_598.pth\n",
      "Epoch 599 train loss: 0.6345775618397614\n",
      "Epoch 599 train accuracy: 78.88675623800384\n",
      "Epoch 599 val loss: 0.6252012074385819\n",
      "Epoch 599 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_599.pth\n",
      "Epoch 600 train loss: 0.634531281888485\n",
      "Epoch 600 train accuracy: 78.83191664381684\n",
      "Epoch 600 val loss: 0.6251113303986034\n",
      "Epoch 600 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_600.pth\n",
      "Epoch 601 train loss: 0.6344536459726984\n",
      "Epoch 601 train accuracy: 78.88675623800384\n",
      "Epoch 601 val loss: 0.6250308682455828\n",
      "Epoch 601 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_601.pth\n",
      "Epoch 602 train loss: 0.6344076824586904\n",
      "Epoch 602 train accuracy: 78.83191664381684\n",
      "Epoch 602 val loss: 0.6249354692470086\n",
      "Epoch 602 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_602.pth\n",
      "Epoch 603 train loss: 0.6343148240264047\n",
      "Epoch 603 train accuracy: 78.94159583219084\n",
      "Epoch 603 val loss: 0.6248943330229897\n",
      "Epoch 603 val accuracy: 80.18092105263158\n",
      "Saved model to .\\test_models/MLP_603.pth\n",
      "Epoch 604 train loss: 0.6342286542384771\n",
      "Epoch 604 train accuracy: 78.88675623800384\n",
      "Epoch 604 val loss: 0.6248354850532977\n",
      "Epoch 604 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_604.pth\n",
      "Epoch 605 train loss: 0.6341356410595932\n",
      "Epoch 605 train accuracy: 78.85933644091034\n",
      "Epoch 605 val loss: 0.6247649849637559\n",
      "Epoch 605 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_605.pth\n",
      "Epoch 606 train loss: 0.6341096465639248\n",
      "Epoch 606 train accuracy: 78.77707704962984\n",
      "Epoch 606 val loss: 0.6246993678965067\n",
      "Epoch 606 val accuracy: 80.26315789473684\n",
      "Saved model to .\\test_models/MLP_606.pth\n",
      "Epoch 607 train loss: 0.6340755611135248\n",
      "Epoch 607 train accuracy: 78.88675623800384\n",
      "Epoch 607 val loss: 0.6246139913993446\n",
      "Epoch 607 val accuracy: 80.34539473684211\n",
      "Saved model to .\\test_models/MLP_607.pth\n",
      "Epoch 608 train loss: 0.6338831886256996\n",
      "Epoch 608 train accuracy: 78.91417603509734\n",
      "Epoch 608 val loss: 0.6245092738811907\n",
      "Epoch 608 val accuracy: 80.34539473684211\n",
      "Saved model to .\\test_models/MLP_608.pth\n",
      "Epoch 609 train loss: 0.6338383264088056\n",
      "Epoch 609 train accuracy: 78.94159583219084\n",
      "Epoch 609 val loss: 0.6244547415132585\n",
      "Epoch 609 val accuracy: 80.34539473684211\n",
      "Saved model to .\\test_models/MLP_609.pth\n",
      "Epoch 610 train loss: 0.6338151211017057\n",
      "Epoch 610 train accuracy: 78.96901562928434\n",
      "Epoch 610 val loss: 0.6243651054407421\n",
      "Epoch 610 val accuracy: 80.42763157894737\n",
      "Saved model to .\\test_models/MLP_610.pth\n",
      "Epoch 611 train loss: 0.6337572303845694\n",
      "Epoch 611 train accuracy: 78.94159583219084\n",
      "Epoch 611 val loss: 0.6242913695934572\n",
      "Epoch 611 val accuracy: 80.42763157894737\n",
      "Saved model to .\\test_models/MLP_611.pth\n",
      "Epoch 612 train loss: 0.633609065867699\n",
      "Epoch 612 train accuracy: 78.96901562928434\n",
      "Epoch 612 val loss: 0.6241907032549774\n",
      "Epoch 612 val accuracy: 80.42763157894737\n",
      "Saved model to .\\test_models/MLP_612.pth\n",
      "Epoch 613 train loss: 0.6335987158511814\n",
      "Epoch 613 train accuracy: 78.96901562928434\n",
      "Epoch 613 val loss: 0.6240604441416892\n",
      "Epoch 613 val accuracy: 80.34539473684211\n",
      "Saved model to .\\test_models/MLP_613.pth\n",
      "Epoch 614 train loss: 0.6335260589982856\n",
      "Epoch 614 train accuracy: 78.96901562928434\n",
      "Epoch 614 val loss: 0.6239934030332064\n",
      "Epoch 614 val accuracy: 80.42763157894737\n",
      "Saved model to .\\test_models/MLP_614.pth\n",
      "Epoch 615 train loss: 0.6334176566451788\n",
      "Epoch 615 train accuracy: 78.99643542637784\n",
      "Epoch 615 val loss: 0.6239237394183874\n",
      "Epoch 615 val accuracy: 80.42763157894737\n",
      "Saved model to .\\test_models/MLP_615.pth\n",
      "Epoch 616 train loss: 0.6332973795697877\n",
      "Epoch 616 train accuracy: 78.99643542637784\n",
      "Epoch 616 val loss: 0.6238700580832205\n",
      "Epoch 616 val accuracy: 80.42763157894737\n",
      "Saved model to .\\test_models/MLP_616.pth\n",
      "Epoch 617 train loss: 0.633294401396262\n",
      "Epoch 617 train accuracy: 79.05127502056484\n",
      "Epoch 617 val loss: 0.6238104326552466\n",
      "Epoch 617 val accuracy: 80.42763157894737\n",
      "Saved model to .\\test_models/MLP_617.pth\n",
      "Epoch 618 train loss: 0.6331370744462076\n",
      "Epoch 618 train accuracy: 79.02385522347134\n",
      "Epoch 618 val loss: 0.6237318200108252\n",
      "Epoch 618 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_618.pth\n",
      "Epoch 619 train loss: 0.6330723203718662\n",
      "Epoch 619 train accuracy: 79.07869481765835\n",
      "Epoch 619 val loss: 0.6236764304339886\n",
      "Epoch 619 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_619.pth\n",
      "Epoch 620 train loss: 0.633006755916173\n",
      "Epoch 620 train accuracy: 79.02385522347134\n",
      "Epoch 620 val loss: 0.623589029927787\n",
      "Epoch 620 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_620.pth\n",
      "Epoch 621 train loss: 0.6329290526020422\n",
      "Epoch 621 train accuracy: 78.99643542637784\n",
      "Epoch 621 val loss: 0.6234864324429318\n",
      "Epoch 621 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_621.pth\n",
      "Epoch 622 train loss: 0.6328935008986216\n",
      "Epoch 622 train accuracy: 79.05127502056484\n",
      "Epoch 622 val loss: 0.6234160231328324\n",
      "Epoch 622 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_622.pth\n",
      "Epoch 623 train loss: 0.6328233021981361\n",
      "Epoch 623 train accuracy: 79.02385522347134\n",
      "Epoch 623 val loss: 0.6233398168298759\n",
      "Epoch 623 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_623.pth\n",
      "Epoch 624 train loss: 0.6327773487489474\n",
      "Epoch 624 train accuracy: 79.10611461475185\n",
      "Epoch 624 val loss: 0.6232336648788891\n",
      "Epoch 624 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_624.pth\n",
      "Epoch 625 train loss: 0.6326738698081228\n",
      "Epoch 625 train accuracy: 79.07869481765835\n",
      "Epoch 625 val loss: 0.6231573018686551\n",
      "Epoch 625 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_625.pth\n",
      "Epoch 626 train loss: 0.6325187012389825\n",
      "Epoch 626 train accuracy: 79.16095420893885\n",
      "Epoch 626 val loss: 0.6230942168224015\n",
      "Epoch 626 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_626.pth\n",
      "Epoch 627 train loss: 0.6324902256101108\n",
      "Epoch 627 train accuracy: 79.05127502056484\n",
      "Epoch 627 val loss: 0.6229990823684555\n",
      "Epoch 627 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_627.pth\n",
      "Epoch 628 train loss: 0.6324531076508656\n",
      "Epoch 628 train accuracy: 79.13353441184535\n",
      "Epoch 628 val loss: 0.6229055894440726\n",
      "Epoch 628 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_628.pth\n",
      "Epoch 629 train loss: 0.6324119339451978\n",
      "Epoch 629 train accuracy: 79.16095420893885\n",
      "Epoch 629 val loss: 0.6228366102042951\n",
      "Epoch 629 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_629.pth\n",
      "Epoch 630 train loss: 0.6322955523797295\n",
      "Epoch 630 train accuracy: 79.10611461475185\n",
      "Epoch 630 val loss: 0.622742933956416\n",
      "Epoch 630 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_630.pth\n",
      "Epoch 631 train loss: 0.632208153981258\n",
      "Epoch 631 train accuracy: 79.13353441184535\n",
      "Epoch 631 val loss: 0.6227339117934829\n",
      "Epoch 631 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_631.pth\n",
      "Epoch 632 train loss: 0.6321621212062606\n",
      "Epoch 632 train accuracy: 79.16095420893885\n",
      "Epoch 632 val loss: 0.6226121065647978\n",
      "Epoch 632 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_632.pth\n",
      "Epoch 633 train loss: 0.6321414670857944\n",
      "Epoch 633 train accuracy: 79.16095420893885\n",
      "Epoch 633 val loss: 0.6225483539073091\n",
      "Epoch 633 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_633.pth\n",
      "Epoch 634 train loss: 0.6319660097360611\n",
      "Epoch 634 train accuracy: 79.18837400603236\n",
      "Epoch 634 val loss: 0.6224583260911075\n",
      "Epoch 634 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_634.pth\n",
      "Epoch 635 train loss: 0.6319177806246699\n",
      "Epoch 635 train accuracy: 79.10611461475185\n",
      "Epoch 635 val loss: 0.622368646491515\n",
      "Epoch 635 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_635.pth\n",
      "Epoch 636 train loss: 0.6318306838603396\n",
      "Epoch 636 train accuracy: 79.21579380312586\n",
      "Epoch 636 val loss: 0.6223165841871187\n",
      "Epoch 636 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_636.pth\n",
      "Epoch 637 train loss: 0.6317429812298271\n",
      "Epoch 637 train accuracy: 79.16095420893885\n",
      "Epoch 637 val loss: 0.6222232654690742\n",
      "Epoch 637 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_637.pth\n",
      "Epoch 638 train loss: 0.6316953759248319\n",
      "Epoch 638 train accuracy: 79.32547299149986\n",
      "Epoch 638 val loss: 0.6221537210635448\n",
      "Epoch 638 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_638.pth\n",
      "Epoch 639 train loss: 0.631644225564965\n",
      "Epoch 639 train accuracy: 79.18837400603236\n",
      "Epoch 639 val loss: 0.6220555581936711\n",
      "Epoch 639 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_639.pth\n",
      "Epoch 640 train loss: 0.631574332289267\n",
      "Epoch 640 train accuracy: 79.21579380312586\n",
      "Epoch 640 val loss: 0.6219915427561653\n",
      "Epoch 640 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_640.pth\n",
      "Epoch 641 train loss: 0.6314087749311799\n",
      "Epoch 641 train accuracy: 79.24321360021936\n",
      "Epoch 641 val loss: 0.6218853865407015\n",
      "Epoch 641 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_641.pth\n",
      "Epoch 642 train loss: 0.6314443002144495\n",
      "Epoch 642 train accuracy: 79.29805319440636\n",
      "Epoch 642 val loss: 0.6218078545245685\n",
      "Epoch 642 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_642.pth\n",
      "Epoch 643 train loss: 0.6313378989957926\n",
      "Epoch 643 train accuracy: 79.32547299149986\n",
      "Epoch 643 val loss: 0.6217273693335684\n",
      "Epoch 643 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_643.pth\n",
      "Epoch 644 train loss: 0.6312615087321192\n",
      "Epoch 644 train accuracy: 79.46257197696737\n",
      "Epoch 644 val loss: 0.6216771155595779\n",
      "Epoch 644 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_644.pth\n",
      "Epoch 645 train loss: 0.6311662192864899\n",
      "Epoch 645 train accuracy: 79.35289278859337\n",
      "Epoch 645 val loss: 0.6216140735502306\n",
      "Epoch 645 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_645.pth\n",
      "Epoch 646 train loss: 0.6310762552250373\n",
      "Epoch 646 train accuracy: 79.38031258568687\n",
      "Epoch 646 val loss: 0.6215468589216471\n",
      "Epoch 646 val accuracy: 80.50986842105263\n",
      "Saved model to .\\test_models/MLP_646.pth\n",
      "Epoch 647 train loss: 0.6310274310638768\n",
      "Epoch 647 train accuracy: 79.32547299149986\n",
      "Epoch 647 val loss: 0.6214770842343569\n",
      "Epoch 647 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_647.pth\n",
      "Epoch 648 train loss: 0.6309497046300716\n",
      "Epoch 648 train accuracy: 79.35289278859337\n",
      "Epoch 648 val loss: 0.6214114485406562\n",
      "Epoch 648 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_648.pth\n",
      "Epoch 649 train loss: 0.6308709974809174\n",
      "Epoch 649 train accuracy: 79.43515217987387\n",
      "Epoch 649 val loss: 0.6213177448432696\n",
      "Epoch 649 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_649.pth\n",
      "Epoch 650 train loss: 0.6308413518494681\n",
      "Epoch 650 train accuracy: 79.43515217987387\n",
      "Epoch 650 val loss: 0.6212642955054578\n",
      "Epoch 650 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_650.pth\n",
      "Epoch 651 train loss: 0.6306237771518921\n",
      "Epoch 651 train accuracy: 79.46257197696737\n",
      "Epoch 651 val loss: 0.6212000286108569\n",
      "Epoch 651 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_651.pth\n",
      "Epoch 652 train loss: 0.630578965520519\n",
      "Epoch 652 train accuracy: 79.43515217987387\n",
      "Epoch 652 val loss: 0.6211085066591439\n",
      "Epoch 652 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_652.pth\n",
      "Epoch 653 train loss: 0.6305097388430384\n",
      "Epoch 653 train accuracy: 79.46257197696737\n",
      "Epoch 653 val loss: 0.6210276909956807\n",
      "Epoch 653 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_653.pth\n",
      "Epoch 654 train loss: 0.630480636434074\n",
      "Epoch 654 train accuracy: 79.51741157115437\n",
      "Epoch 654 val loss: 0.6209548862749025\n",
      "Epoch 654 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_654.pth\n",
      "Epoch 655 train loss: 0.6303331862252793\n",
      "Epoch 655 train accuracy: 79.57225116534137\n",
      "Epoch 655 val loss: 0.6209385280840491\n",
      "Epoch 655 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_655.pth\n",
      "Epoch 656 train loss: 0.630301631758349\n",
      "Epoch 656 train accuracy: 79.48999177406087\n",
      "Epoch 656 val loss: 0.6208708169624994\n",
      "Epoch 656 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_656.pth\n",
      "Epoch 657 train loss: 0.6302603240729424\n",
      "Epoch 657 train accuracy: 79.57225116534137\n",
      "Epoch 657 val loss: 0.6208094752540714\n",
      "Epoch 657 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_657.pth\n",
      "Epoch 658 train loss: 0.6301855243938533\n",
      "Epoch 658 train accuracy: 79.48999177406087\n",
      "Epoch 658 val loss: 0.6207321943028977\n",
      "Epoch 658 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_658.pth\n",
      "Epoch 659 train loss: 0.630012563086654\n",
      "Epoch 659 train accuracy: 79.48999177406087\n",
      "Epoch 659 val loss: 0.6206690771995407\n",
      "Epoch 659 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_659.pth\n",
      "Epoch 660 train loss: 0.629995433450268\n",
      "Epoch 660 train accuracy: 79.32547299149986\n",
      "Epoch 660 val loss: 0.620551746093521\n",
      "Epoch 660 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_660.pth\n",
      "Epoch 661 train loss: 0.6299267830653933\n",
      "Epoch 661 train accuracy: 79.57225116534137\n",
      "Epoch 661 val loss: 0.6205058358609676\n",
      "Epoch 661 val accuracy: 80.59210526315789\n",
      "Saved model to .\\test_models/MLP_661.pth\n",
      "Epoch 662 train loss: 0.6298769896098396\n",
      "Epoch 662 train accuracy: 79.57225116534137\n",
      "Epoch 662 val loss: 0.6204074769722003\n",
      "Epoch 662 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_662.pth\n",
      "Epoch 663 train loss: 0.6297861134404676\n",
      "Epoch 663 train accuracy: 79.57225116534137\n",
      "Epoch 663 val loss: 0.6203280156968456\n",
      "Epoch 663 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_663.pth\n",
      "Epoch 664 train loss: 0.629766970905557\n",
      "Epoch 664 train accuracy: 79.59967096243487\n",
      "Epoch 664 val loss: 0.6202779523047962\n",
      "Epoch 664 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_664.pth\n",
      "Epoch 665 train loss: 0.62965342373048\n",
      "Epoch 665 train accuracy: 79.62709075952839\n",
      "Epoch 665 val loss: 0.6202123720983141\n",
      "Epoch 665 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_665.pth\n",
      "Epoch 666 train loss: 0.6295474425873213\n",
      "Epoch 666 train accuracy: 79.54483136824787\n",
      "Epoch 666 val loss: 0.6201451868799172\n",
      "Epoch 666 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_666.pth\n",
      "Epoch 667 train loss: 0.6295065814955977\n",
      "Epoch 667 train accuracy: 79.54483136824787\n",
      "Epoch 667 val loss: 0.6200753239620673\n",
      "Epoch 667 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_667.pth\n",
      "Epoch 668 train loss: 0.629379527332882\n",
      "Epoch 668 train accuracy: 79.57225116534137\n",
      "Epoch 668 val loss: 0.6200004002373469\n",
      "Epoch 668 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_668.pth\n",
      "Epoch 669 train loss: 0.6293378827864664\n",
      "Epoch 669 train accuracy: 79.62709075952839\n",
      "Epoch 669 val loss: 0.6199092316000085\n",
      "Epoch 669 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_669.pth\n",
      "Epoch 670 train loss: 0.6292562668554877\n",
      "Epoch 670 train accuracy: 79.62709075952839\n",
      "Epoch 670 val loss: 0.6198314545480045\n",
      "Epoch 670 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_670.pth\n",
      "Epoch 671 train loss: 0.6291941651714998\n",
      "Epoch 671 train accuracy: 79.73676994790239\n",
      "Epoch 671 val loss: 0.619739939899821\n",
      "Epoch 671 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_671.pth\n",
      "Epoch 672 train loss: 0.6290940611639566\n",
      "Epoch 672 train accuracy: 79.59967096243487\n",
      "Epoch 672 val loss: 0.6197071998919311\n",
      "Epoch 672 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_672.pth\n",
      "Epoch 673 train loss: 0.6290178298296636\n",
      "Epoch 673 train accuracy: 79.59967096243487\n",
      "Epoch 673 val loss: 0.6196182458416412\n",
      "Epoch 673 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_673.pth\n",
      "Epoch 674 train loss: 0.6289504713525897\n",
      "Epoch 674 train accuracy: 79.68193035371539\n",
      "Epoch 674 val loss: 0.6195398223047194\n",
      "Epoch 674 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_674.pth\n",
      "Epoch 675 train loss: 0.6288610770808238\n",
      "Epoch 675 train accuracy: 79.73676994790239\n",
      "Epoch 675 val loss: 0.6194579173369628\n",
      "Epoch 675 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_675.pth\n",
      "Epoch 676 train loss: 0.6287972944576228\n",
      "Epoch 676 train accuracy: 79.65451055662189\n",
      "Epoch 676 val loss: 0.6194010595545957\n",
      "Epoch 676 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_676.pth\n",
      "Epoch 677 train loss: 0.6287638927205351\n",
      "Epoch 677 train accuracy: 79.70935015080889\n",
      "Epoch 677 val loss: 0.6193097489640901\n",
      "Epoch 677 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_677.pth\n",
      "Epoch 678 train loss: 0.6286074173097548\n",
      "Epoch 678 train accuracy: 79.68193035371539\n",
      "Epoch 678 val loss: 0.6192656901517981\n",
      "Epoch 678 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_678.pth\n",
      "Epoch 679 train loss: 0.6285597196077568\n",
      "Epoch 679 train accuracy: 79.73676994790239\n",
      "Epoch 679 val loss: 0.6191793189040924\n",
      "Epoch 679 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_679.pth\n",
      "Epoch 680 train loss: 0.6285131545083826\n",
      "Epoch 680 train accuracy: 79.65451055662189\n",
      "Epoch 680 val loss: 0.6190929270692562\n",
      "Epoch 680 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_680.pth\n",
      "Epoch 681 train loss: 0.6284108548343443\n",
      "Epoch 681 train accuracy: 79.73676994790239\n",
      "Epoch 681 val loss: 0.6190380693266266\n",
      "Epoch 681 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_681.pth\n",
      "Epoch 682 train loss: 0.6283636492301237\n",
      "Epoch 682 train accuracy: 79.73676994790239\n",
      "Epoch 682 val loss: 0.6189550366252661\n",
      "Epoch 682 val accuracy: 81.0032894736842\n",
      "Saved model to .\\test_models/MLP_682.pth\n",
      "Epoch 683 train loss: 0.628335296192713\n",
      "Epoch 683 train accuracy: 79.70935015080889\n",
      "Epoch 683 val loss: 0.6188895350420162\n",
      "Epoch 683 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_683.pth\n",
      "Epoch 684 train loss: 0.6281694890767858\n",
      "Epoch 684 train accuracy: 79.65451055662189\n",
      "Epoch 684 val loss: 0.6188173469548163\n",
      "Epoch 684 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_684.pth\n",
      "Epoch 685 train loss: 0.6281259569029013\n",
      "Epoch 685 train accuracy: 79.76418974499589\n",
      "Epoch 685 val loss: 0.6188025202994284\n",
      "Epoch 685 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_685.pth\n",
      "Epoch 686 train loss: 0.6280466378584766\n",
      "Epoch 686 train accuracy: 79.79160954208939\n",
      "Epoch 686 val loss: 0.6186819545140392\n",
      "Epoch 686 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_686.pth\n",
      "Epoch 687 train loss: 0.6279681992570036\n",
      "Epoch 687 train accuracy: 79.70935015080889\n",
      "Epoch 687 val loss: 0.6185915879905224\n",
      "Epoch 687 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_687.pth\n",
      "Epoch 688 train loss: 0.6278946690849567\n",
      "Epoch 688 train accuracy: 79.68193035371539\n",
      "Epoch 688 val loss: 0.6185572414021743\n",
      "Epoch 688 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_688.pth\n",
      "Epoch 689 train loss: 0.6278174989448305\n",
      "Epoch 689 train accuracy: 79.76418974499589\n",
      "Epoch 689 val loss: 0.6184415343756738\n",
      "Epoch 689 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_689.pth\n",
      "Epoch 690 train loss: 0.6277845409094241\n",
      "Epoch 690 train accuracy: 79.70935015080889\n",
      "Epoch 690 val loss: 0.6183878714708906\n",
      "Epoch 690 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_690.pth\n",
      "Epoch 691 train loss: 0.6277201594294686\n",
      "Epoch 691 train accuracy: 79.76418974499589\n",
      "Epoch 691 val loss: 0.6183381760002751\n",
      "Epoch 691 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_691.pth\n",
      "Epoch 692 train loss: 0.627673746233708\n",
      "Epoch 692 train accuracy: 79.65451055662189\n",
      "Epoch 692 val loss: 0.618232929196797\n",
      "Epoch 692 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_692.pth\n",
      "Epoch 693 train loss: 0.6275013652221676\n",
      "Epoch 693 train accuracy: 79.70935015080889\n",
      "Epoch 693 val loss: 0.6181885343241064\n",
      "Epoch 693 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_693.pth\n",
      "Epoch 694 train loss: 0.6274528900782267\n",
      "Epoch 694 train accuracy: 79.76418974499589\n",
      "Epoch 694 val loss: 0.6181368439605361\n",
      "Epoch 694 val accuracy: 80.67434210526316\n",
      "Saved model to .\\test_models/MLP_694.pth\n",
      "Epoch 695 train loss: 0.6274131443351507\n",
      "Epoch 695 train accuracy: 79.76418974499589\n",
      "Epoch 695 val loss: 0.6181019666163545\n",
      "Epoch 695 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_695.pth\n",
      "Epoch 696 train loss: 0.6273550696082806\n",
      "Epoch 696 train accuracy: 79.79160954208939\n",
      "Epoch 696 val loss: 0.6180332658910438\n",
      "Epoch 696 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_696.pth\n",
      "Epoch 697 train loss: 0.6272860284763992\n",
      "Epoch 697 train accuracy: 79.73676994790239\n",
      "Epoch 697 val loss: 0.6179170842331491\n",
      "Epoch 697 val accuracy: 80.75657894736842\n",
      "Saved model to .\\test_models/MLP_697.pth\n",
      "Epoch 698 train loss: 0.6271992322678367\n",
      "Epoch 698 train accuracy: 79.73676994790239\n",
      "Epoch 698 val loss: 0.6178561682371717\n",
      "Epoch 698 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_698.pth\n",
      "Epoch 699 train loss: 0.6271506765399847\n",
      "Epoch 699 train accuracy: 79.79160954208939\n",
      "Epoch 699 val loss: 0.6177383207372928\n",
      "Epoch 699 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_699.pth\n",
      "Epoch 700 train loss: 0.6270801227605134\n",
      "Epoch 700 train accuracy: 79.81902933918289\n",
      "Epoch 700 val loss: 0.6176646094965307\n",
      "Epoch 700 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_700.pth\n",
      "Epoch 701 train loss: 0.6270336180827335\n",
      "Epoch 701 train accuracy: 79.76418974499589\n",
      "Epoch 701 val loss: 0.6176154023330462\n",
      "Epoch 701 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_701.pth\n",
      "Epoch 702 train loss: 0.6269138157694486\n",
      "Epoch 702 train accuracy: 79.84644913627639\n",
      "Epoch 702 val loss: 0.6176261776372006\n",
      "Epoch 702 val accuracy: 80.83881578947368\n",
      "Saved model to .\\test_models/MLP_702.pth\n",
      "Epoch 703 train loss: 0.6268329624772856\n",
      "Epoch 703 train accuracy: 79.81902933918289\n",
      "Epoch 703 val loss: 0.6175410635769367\n",
      "Epoch 703 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_703.pth\n",
      "Epoch 704 train loss: 0.6267615667822068\n",
      "Epoch 704 train accuracy: 79.79160954208939\n",
      "Epoch 704 val loss: 0.6174475248706969\n",
      "Epoch 704 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_704.pth\n",
      "Epoch 705 train loss: 0.6267008899400631\n",
      "Epoch 705 train accuracy: 79.81902933918289\n",
      "Epoch 705 val loss: 0.6173512254302439\n",
      "Epoch 705 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_705.pth\n",
      "Epoch 706 train loss: 0.6266684467463117\n",
      "Epoch 706 train accuracy: 79.81902933918289\n",
      "Epoch 706 val loss: 0.61727674726985\n",
      "Epoch 706 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_706.pth\n",
      "Epoch 707 train loss: 0.6265909804782847\n",
      "Epoch 707 train accuracy: 79.84644913627639\n",
      "Epoch 707 val loss: 0.6172111015766859\n",
      "Epoch 707 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_707.pth\n",
      "Epoch 708 train loss: 0.626507779550657\n",
      "Epoch 708 train accuracy: 79.90128873046339\n",
      "Epoch 708 val loss: 0.61717271295033\n",
      "Epoch 708 val accuracy: 81.0032894736842\n",
      "Saved model to .\\test_models/MLP_708.pth\n",
      "Epoch 709 train loss: 0.6265020602987262\n",
      "Epoch 709 train accuracy: 79.84644913627639\n",
      "Epoch 709 val loss: 0.6170606084756161\n",
      "Epoch 709 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_709.pth\n",
      "Epoch 710 train loss: 0.6264081119902825\n",
      "Epoch 710 train accuracy: 79.81902933918289\n",
      "Epoch 710 val loss: 0.6170184058382323\n",
      "Epoch 710 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_710.pth\n",
      "Epoch 711 train loss: 0.6263210530343809\n",
      "Epoch 711 train accuracy: 79.81902933918289\n",
      "Epoch 711 val loss: 0.6169572350029883\n",
      "Epoch 711 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_711.pth\n",
      "Epoch 712 train loss: 0.6262286575511098\n",
      "Epoch 712 train accuracy: 79.90128873046339\n",
      "Epoch 712 val loss: 0.6168611362380417\n",
      "Epoch 712 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_712.pth\n",
      "Epoch 713 train loss: 0.6261992439006766\n",
      "Epoch 713 train accuracy: 79.87386893336989\n",
      "Epoch 713 val loss: 0.6168464795245152\n",
      "Epoch 713 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_713.pth\n",
      "Epoch 714 train loss: 0.6261639409094003\n",
      "Epoch 714 train accuracy: 79.87386893336989\n",
      "Epoch 714 val loss: 0.6167906884496149\n",
      "Epoch 714 val accuracy: 81.16776315789474\n",
      "Saved model to .\\test_models/MLP_714.pth\n",
      "Epoch 715 train loss: 0.6260147816583252\n",
      "Epoch 715 train accuracy: 79.84644913627639\n",
      "Epoch 715 val loss: 0.6166873628175572\n",
      "Epoch 715 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_715.pth\n",
      "Epoch 716 train loss: 0.625923910521363\n",
      "Epoch 716 train accuracy: 79.84644913627639\n",
      "Epoch 716 val loss: 0.6166106569825819\n",
      "Epoch 716 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_716.pth\n",
      "Epoch 717 train loss: 0.6259188926533649\n",
      "Epoch 717 train accuracy: 79.84644913627639\n",
      "Epoch 717 val loss: 0.6165494055144096\n",
      "Epoch 717 val accuracy: 81.0032894736842\n",
      "Saved model to .\\test_models/MLP_717.pth\n",
      "Epoch 718 train loss: 0.625876946325757\n",
      "Epoch 718 train accuracy: 79.84644913627639\n",
      "Epoch 718 val loss: 0.6164748323591132\n",
      "Epoch 718 val accuracy: 81.0032894736842\n",
      "Saved model to .\\test_models/MLP_718.pth\n",
      "Epoch 719 train loss: 0.6258187192051035\n",
      "Epoch 719 train accuracy: 79.92870852755689\n",
      "Epoch 719 val loss: 0.6164255813254338\n",
      "Epoch 719 val accuracy: 81.16776315789474\n",
      "Saved model to .\\test_models/MLP_719.pth\n",
      "Epoch 720 train loss: 0.6257117380012285\n",
      "Epoch 720 train accuracy: 79.90128873046339\n",
      "Epoch 720 val loss: 0.6163956165117653\n",
      "Epoch 720 val accuracy: 81.16776315789474\n",
      "Saved model to .\\test_models/MLP_720.pth\n",
      "Epoch 721 train loss: 0.6256253573259241\n",
      "Epoch 721 train accuracy: 79.79160954208939\n",
      "Epoch 721 val loss: 0.6162905612666356\n",
      "Epoch 721 val accuracy: 81.16776315789474\n",
      "Saved model to .\\test_models/MLP_721.pth\n",
      "Epoch 722 train loss: 0.6256112963320655\n",
      "Epoch 722 train accuracy: 79.9561283246504\n",
      "Epoch 722 val loss: 0.6162025201575536\n",
      "Epoch 722 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_722.pth\n",
      "Epoch 723 train loss: 0.6255453852446455\n",
      "Epoch 723 train accuracy: 79.92870852755689\n",
      "Epoch 723 val loss: 0.616155588117085\n",
      "Epoch 723 val accuracy: 81.16776315789474\n",
      "Saved model to .\\test_models/MLP_723.pth\n",
      "Epoch 724 train loss: 0.6254112716241363\n",
      "Epoch 724 train accuracy: 79.87386893336989\n",
      "Epoch 724 val loss: 0.6160768986630597\n",
      "Epoch 724 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_724.pth\n",
      "Epoch 725 train loss: 0.6254043947219065\n",
      "Epoch 725 train accuracy: 79.9561283246504\n",
      "Epoch 725 val loss: 0.6160419022076224\n",
      "Epoch 725 val accuracy: 81.16776315789474\n",
      "Saved model to .\\test_models/MLP_725.pth\n",
      "Epoch 726 train loss: 0.6253159378671593\n",
      "Epoch 726 train accuracy: 79.9835481217439\n",
      "Epoch 726 val loss: 0.6159489267554722\n",
      "Epoch 726 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_726.pth\n",
      "Epoch 727 train loss: 0.6252614397457555\n",
      "Epoch 727 train accuracy: 79.9835481217439\n",
      "Epoch 727 val loss: 0.6159722268287289\n",
      "Epoch 727 val accuracy: 80.92105263157895\n",
      "Saved model to .\\test_models/MLP_727.pth\n",
      "Epoch 728 train loss: 0.6252264468848967\n",
      "Epoch 728 train accuracy: 79.90128873046339\n",
      "Epoch 728 val loss: 0.6158680560949602\n",
      "Epoch 728 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_728.pth\n",
      "Epoch 729 train loss: 0.6251397797053582\n",
      "Epoch 729 train accuracy: 79.87386893336989\n",
      "Epoch 729 val loss: 0.6157765590438717\n",
      "Epoch 729 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_729.pth\n",
      "Epoch 730 train loss: 0.6250324385534776\n",
      "Epoch 730 train accuracy: 79.92870852755689\n",
      "Epoch 730 val loss: 0.6156599517715605\n",
      "Epoch 730 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_730.pth\n",
      "Epoch 731 train loss: 0.6249622719754514\n",
      "Epoch 731 train accuracy: 79.9561283246504\n",
      "Epoch 731 val loss: 0.6155644604250005\n",
      "Epoch 731 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_731.pth\n",
      "Epoch 732 train loss: 0.6249498207971715\n",
      "Epoch 732 train accuracy: 79.92870852755689\n",
      "Epoch 732 val loss: 0.61550768249129\n",
      "Epoch 732 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_732.pth\n",
      "Epoch 733 train loss: 0.6248712834428277\n",
      "Epoch 733 train accuracy: 79.87386893336989\n",
      "Epoch 733 val loss: 0.615471973917202\n",
      "Epoch 733 val accuracy: 81.0032894736842\n",
      "Saved model to .\\test_models/MLP_733.pth\n",
      "Epoch 734 train loss: 0.6247696412008321\n",
      "Epoch 734 train accuracy: 79.84644913627639\n",
      "Epoch 734 val loss: 0.6153912468764343\n",
      "Epoch 734 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_734.pth\n",
      "Epoch 735 train loss: 0.6247528978999246\n",
      "Epoch 735 train accuracy: 79.92870852755689\n",
      "Epoch 735 val loss: 0.6153641247043484\n",
      "Epoch 735 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_735.pth\n",
      "Epoch 736 train loss: 0.624712332527627\n",
      "Epoch 736 train accuracy: 79.92870852755689\n",
      "Epoch 736 val loss: 0.6152603545863378\n",
      "Epoch 736 val accuracy: 81.0032894736842\n",
      "Saved model to .\\test_models/MLP_736.pth\n",
      "Epoch 737 train loss: 0.6246404825595387\n",
      "Epoch 737 train accuracy: 79.9835481217439\n",
      "Epoch 737 val loss: 0.6152147204664192\n",
      "Epoch 737 val accuracy: 81.0032894736842\n",
      "Saved model to .\\test_models/MLP_737.pth\n",
      "Epoch 738 train loss: 0.6245323419570923\n",
      "Epoch 738 train accuracy: 79.9561283246504\n",
      "Epoch 738 val loss: 0.6151100039286049\n",
      "Epoch 738 val accuracy: 81.25\n",
      "Saved model to .\\test_models/MLP_738.pth\n",
      "Epoch 739 train loss: 0.624436796463111\n",
      "Epoch 739 train accuracy: 79.9561283246504\n",
      "Epoch 739 val loss: 0.6150863849999089\n",
      "Epoch 739 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_739.pth\n",
      "Epoch 740 train loss: 0.624415244400632\n",
      "Epoch 740 train accuracy: 80.0109679188374\n",
      "Epoch 740 val loss: 0.6150608592617669\n",
      "Epoch 740 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_740.pth\n",
      "Epoch 741 train loss: 0.6242141177583682\n",
      "Epoch 741 train accuracy: 79.9561283246504\n",
      "Epoch 741 val loss: 0.6149879103330406\n",
      "Epoch 741 val accuracy: 81.08552631578948\n",
      "Saved model to .\\test_models/MLP_741.pth\n",
      "Epoch 742 train loss: 0.6243074929929877\n",
      "Epoch 742 train accuracy: 79.90128873046339\n",
      "Epoch 742 val loss: 0.6149090705929618\n",
      "Epoch 742 val accuracy: 81.33223684210526\n",
      "Saved model to .\\test_models/MLP_742.pth\n",
      "Epoch 743 train loss: 0.624233568463017\n",
      "Epoch 743 train accuracy: 79.92870852755689\n",
      "Epoch 743 val loss: 0.6148205223052126\n",
      "Epoch 743 val accuracy: 81.25\n",
      "Saved model to .\\test_models/MLP_743.pth\n",
      "Epoch 744 train loss: 0.6241302601993084\n",
      "Epoch 744 train accuracy: 79.9561283246504\n",
      "Epoch 744 val loss: 0.61474883928895\n",
      "Epoch 744 val accuracy: 81.25\n",
      "Saved model to .\\test_models/MLP_744.pth\n",
      "Epoch 745 train loss: 0.6241037139276925\n",
      "Epoch 745 train accuracy: 80.0383877159309\n",
      "Epoch 745 val loss: 0.6147228364685648\n",
      "Epoch 745 val accuracy: 81.33223684210526\n",
      "Saved model to .\\test_models/MLP_745.pth\n",
      "Epoch 746 train loss: 0.6240455658224068\n",
      "Epoch 746 train accuracy: 79.9561283246504\n",
      "Epoch 746 val loss: 0.61466035815446\n",
      "Epoch 746 val accuracy: 81.33223684210526\n",
      "Saved model to .\\test_models/MLP_746.pth\n",
      "Epoch 747 train loss: 0.6239423186501913\n",
      "Epoch 747 train accuracy: 79.92870852755689\n",
      "Epoch 747 val loss: 0.6145808829092666\n",
      "Epoch 747 val accuracy: 81.33223684210526\n",
      "Saved model to .\\test_models/MLP_747.pth\n",
      "Epoch 748 train loss: 0.6239061226512779\n",
      "Epoch 748 train accuracy: 79.9835481217439\n",
      "Epoch 748 val loss: 0.6145075502756395\n",
      "Epoch 748 val accuracy: 81.33223684210526\n",
      "Saved model to .\\test_models/MLP_748.pth\n",
      "Epoch 749 train loss: 0.6238005463229982\n",
      "Epoch 749 train accuracy: 80.06580751302441\n",
      "Epoch 749 val loss: 0.6144467967709428\n",
      "Epoch 749 val accuracy: 81.41447368421052\n",
      "Saved model to .\\test_models/MLP_749.pth\n",
      "Epoch 750 train loss: 0.6237725527270844\n",
      "Epoch 750 train accuracy: 80.0383877159309\n",
      "Epoch 750 val loss: 0.6143740692028874\n",
      "Epoch 750 val accuracy: 81.33223684210526\n",
      "Saved model to .\\test_models/MLP_750.pth\n",
      "Epoch 751 train loss: 0.6236575384902066\n",
      "Epoch 751 train accuracy: 79.9561283246504\n",
      "Epoch 751 val loss: 0.6142901700774306\n",
      "Epoch 751 val accuracy: 81.41447368421052\n",
      "Saved model to .\\test_models/MLP_751.pth\n",
      "Epoch 752 train loss: 0.6236252474941706\n",
      "Epoch 752 train accuracy: 80.06580751302441\n",
      "Epoch 752 val loss: 0.6143364950426315\n",
      "Epoch 752 val accuracy: 81.33223684210526\n",
      "Saved model to .\\test_models/MLP_752.pth\n",
      "Epoch 753 train loss: 0.6236019901882269\n",
      "Epoch 753 train accuracy: 79.9835481217439\n",
      "Epoch 753 val loss: 0.614261422698435\n",
      "Epoch 753 val accuracy: 81.41447368421052\n",
      "Saved model to .\\test_models/MLP_753.pth\n",
      "Epoch 754 train loss: 0.623543591712389\n",
      "Epoch 754 train accuracy: 79.90128873046339\n",
      "Epoch 754 val loss: 0.6141466093004534\n",
      "Epoch 754 val accuracy: 81.4967105263158\n",
      "Saved model to .\\test_models/MLP_754.pth\n",
      "Epoch 755 train loss: 0.6234499937282842\n",
      "Epoch 755 train accuracy: 79.9835481217439\n",
      "Epoch 755 val loss: 0.6140819155169945\n",
      "Epoch 755 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_755.pth\n",
      "Epoch 756 train loss: 0.6233795411035157\n",
      "Epoch 756 train accuracy: 79.92870852755689\n",
      "Epoch 756 val loss: 0.6140220417199951\n",
      "Epoch 756 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_756.pth\n",
      "Epoch 757 train loss: 0.6232637600287011\n",
      "Epoch 757 train accuracy: 80.06580751302441\n",
      "Epoch 757 val loss: 0.6140018852525636\n",
      "Epoch 757 val accuracy: 81.57894736842105\n",
      "Saved model to .\\test_models/MLP_757.pth\n",
      "Epoch 758 train loss: 0.6232421595701262\n",
      "Epoch 758 train accuracy: 79.9561283246504\n",
      "Epoch 758 val loss: 0.6139248631110317\n",
      "Epoch 758 val accuracy: 81.57894736842105\n",
      "Saved model to .\\test_models/MLP_758.pth\n",
      "Epoch 759 train loss: 0.6231711999627582\n",
      "Epoch 759 train accuracy: 79.9561283246504\n",
      "Epoch 759 val loss: 0.6138724973915439\n",
      "Epoch 759 val accuracy: 81.57894736842105\n",
      "Saved model to .\\test_models/MLP_759.pth\n",
      "Epoch 760 train loss: 0.6231196923018024\n",
      "Epoch 760 train accuracy: 80.0383877159309\n",
      "Epoch 760 val loss: 0.6138105821844778\n",
      "Epoch 760 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_760.pth\n",
      "Epoch 761 train loss: 0.6230557140028268\n",
      "Epoch 761 train accuracy: 80.0109679188374\n",
      "Epoch 761 val loss: 0.6137243963189816\n",
      "Epoch 761 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_761.pth\n",
      "Epoch 762 train loss: 0.62295679996411\n",
      "Epoch 762 train accuracy: 80.06580751302441\n",
      "Epoch 762 val loss: 0.613650950750238\n",
      "Epoch 762 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_762.pth\n",
      "Epoch 763 train loss: 0.622875121438451\n",
      "Epoch 763 train accuracy: 80.09322731011791\n",
      "Epoch 763 val loss: 0.6137056275221863\n",
      "Epoch 763 val accuracy: 81.33223684210526\n",
      "Saved model to .\\test_models/MLP_763.pth\n",
      "Epoch 764 train loss: 0.6228675628571134\n",
      "Epoch 764 train accuracy: 80.17548670139841\n",
      "Epoch 764 val loss: 0.6135747582700691\n",
      "Epoch 764 val accuracy: 81.57894736842105\n",
      "Saved model to .\\test_models/MLP_764.pth\n",
      "Epoch 765 train loss: 0.6227072987607435\n",
      "Epoch 765 train accuracy: 80.12064710721141\n",
      "Epoch 765 val loss: 0.6135025963824439\n",
      "Epoch 765 val accuracy: 81.57894736842105\n",
      "Saved model to .\\test_models/MLP_765.pth\n",
      "Epoch 766 train loss: 0.6227298597723507\n",
      "Epoch 766 train accuracy: 80.12064710721141\n",
      "Epoch 766 val loss: 0.6134403777357779\n",
      "Epoch 766 val accuracy: 81.57894736842105\n",
      "Saved model to .\\test_models/MLP_766.pth\n",
      "Epoch 767 train loss: 0.6226251868024599\n",
      "Epoch 767 train accuracy: 80.09322731011791\n",
      "Epoch 767 val loss: 0.6134084787611899\n",
      "Epoch 767 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_767.pth\n",
      "Epoch 768 train loss: 0.6225536865296594\n",
      "Epoch 768 train accuracy: 80.09322731011791\n",
      "Epoch 768 val loss: 0.61330704709613\n",
      "Epoch 768 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_768.pth\n",
      "Epoch 769 train loss: 0.6224895355602106\n",
      "Epoch 769 train accuracy: 80.12064710721141\n",
      "Epoch 769 val loss: 0.6132102404770098\n",
      "Epoch 769 val accuracy: 81.57894736842105\n",
      "Saved model to .\\test_models/MLP_769.pth\n",
      "Epoch 770 train loss: 0.6224691980894197\n",
      "Epoch 770 train accuracy: 80.17548670139841\n",
      "Epoch 770 val loss: 0.6131904515388765\n",
      "Epoch 770 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_770.pth\n",
      "Epoch 771 train loss: 0.6224046714211765\n",
      "Epoch 771 train accuracy: 80.20290649849191\n",
      "Epoch 771 val loss: 0.6131394289335922\n",
      "Epoch 771 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_771.pth\n",
      "Epoch 772 train loss: 0.6223516278132274\n",
      "Epoch 772 train accuracy: 80.23032629558541\n",
      "Epoch 772 val loss: 0.6130634288940775\n",
      "Epoch 772 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_772.pth\n",
      "Epoch 773 train loss: 0.6222737676120902\n",
      "Epoch 773 train accuracy: 80.28516588977241\n",
      "Epoch 773 val loss: 0.6131190023335972\n",
      "Epoch 773 val accuracy: 81.41447368421052\n",
      "Saved model to .\\test_models/MLP_773.pth\n",
      "Epoch 774 train loss: 0.6221910561843399\n",
      "Epoch 774 train accuracy: 80.23032629558541\n",
      "Epoch 774 val loss: 0.6130236686256371\n",
      "Epoch 774 val accuracy: 81.57894736842105\n",
      "Saved model to .\\test_models/MLP_774.pth\n",
      "Epoch 775 train loss: 0.6221939792627829\n",
      "Epoch 775 train accuracy: 80.23032629558541\n",
      "Epoch 775 val loss: 0.6128801880894523\n",
      "Epoch 775 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_775.pth\n",
      "Epoch 776 train loss: 0.6220826311853894\n",
      "Epoch 776 train accuracy: 80.20290649849191\n",
      "Epoch 776 val loss: 0.6128556143100324\n",
      "Epoch 776 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_776.pth\n",
      "Epoch 777 train loss: 0.6220338035930406\n",
      "Epoch 777 train accuracy: 80.25774609267891\n",
      "Epoch 777 val loss: 0.6128294585566771\n",
      "Epoch 777 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_777.pth\n",
      "Epoch 778 train loss: 0.6219074285115328\n",
      "Epoch 778 train accuracy: 80.28516588977241\n",
      "Epoch 778 val loss: 0.6127115315022437\n",
      "Epoch 778 val accuracy: 81.66118421052632\n",
      "Saved model to .\\test_models/MLP_778.pth\n",
      "Epoch 779 train loss: 0.6218960483868917\n",
      "Epoch 779 train accuracy: 80.28516588977241\n",
      "Epoch 779 val loss: 0.612597493503831\n",
      "Epoch 779 val accuracy: 81.74342105263158\n",
      "Saved model to .\\test_models/MLP_779.pth\n",
      "Epoch 780 train loss: 0.6218294503592086\n",
      "Epoch 780 train accuracy: 80.31258568686592\n",
      "Epoch 780 val loss: 0.6125414660690647\n",
      "Epoch 780 val accuracy: 81.74342105263158\n",
      "Saved model to .\\test_models/MLP_780.pth\n",
      "Epoch 781 train loss: 0.6217755028128362\n",
      "Epoch 781 train accuracy: 80.28516588977241\n",
      "Epoch 781 val loss: 0.6124721842965013\n",
      "Epoch 781 val accuracy: 81.74342105263158\n",
      "Saved model to .\\test_models/MLP_781.pth\n",
      "Epoch 782 train loss: 0.621727422647701\n",
      "Epoch 782 train accuracy: 80.25774609267891\n",
      "Epoch 782 val loss: 0.6125031700847965\n",
      "Epoch 782 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_782.pth\n",
      "Epoch 783 train loss: 0.6216131154970642\n",
      "Epoch 783 train accuracy: 80.28516588977241\n",
      "Epoch 783 val loss: 0.6124289694585299\n",
      "Epoch 783 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_783.pth\n",
      "Epoch 784 train loss: 0.6215799253499299\n",
      "Epoch 784 train accuracy: 80.25774609267891\n",
      "Epoch 784 val loss: 0.6123562367927087\n",
      "Epoch 784 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_784.pth\n",
      "Epoch 785 train loss: 0.621465702402291\n",
      "Epoch 785 train accuracy: 80.39484507814642\n",
      "Epoch 785 val loss: 0.612319936583701\n",
      "Epoch 785 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_785.pth\n",
      "Epoch 786 train loss: 0.6214625801760376\n",
      "Epoch 786 train accuracy: 80.36742528105292\n",
      "Epoch 786 val loss: 0.6122222743242195\n",
      "Epoch 786 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_786.pth\n",
      "Epoch 787 train loss: 0.6213326652517968\n",
      "Epoch 787 train accuracy: 80.36742528105292\n",
      "Epoch 787 val loss: 0.612153327680732\n",
      "Epoch 787 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_787.pth\n",
      "Epoch 788 train loss: 0.6213258142305309\n",
      "Epoch 788 train accuracy: 80.36742528105292\n",
      "Epoch 788 val loss: 0.6121137897042852\n",
      "Epoch 788 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_788.pth\n",
      "Epoch 789 train loss: 0.621246968510381\n",
      "Epoch 789 train accuracy: 80.31258568686592\n",
      "Epoch 789 val loss: 0.6120129885936254\n",
      "Epoch 789 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_789.pth\n",
      "Epoch 790 train loss: 0.621084427640757\n",
      "Epoch 790 train accuracy: 80.42226487523992\n",
      "Epoch 790 val loss: 0.6119653111029613\n",
      "Epoch 790 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_790.pth\n",
      "Epoch 791 train loss: 0.6211232272091142\n",
      "Epoch 791 train accuracy: 80.36742528105292\n",
      "Epoch 791 val loss: 0.6119060231078612\n",
      "Epoch 791 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_791.pth\n",
      "Epoch 792 train loss: 0.6210687372572067\n",
      "Epoch 792 train accuracy: 80.34000548395942\n",
      "Epoch 792 val loss: 0.6118980129494479\n",
      "Epoch 792 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_792.pth\n",
      "Epoch 793 train loss: 0.621026689742218\n",
      "Epoch 793 train accuracy: 80.34000548395942\n",
      "Epoch 793 val loss: 0.6118527227816614\n",
      "Epoch 793 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_793.pth\n",
      "Epoch 794 train loss: 0.6209633400941497\n",
      "Epoch 794 train accuracy: 80.42226487523992\n",
      "Epoch 794 val loss: 0.6117750786637005\n",
      "Epoch 794 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_794.pth\n",
      "Epoch 795 train loss: 0.6209038437850642\n",
      "Epoch 795 train accuracy: 80.34000548395942\n",
      "Epoch 795 val loss: 0.6116594536426035\n",
      "Epoch 795 val accuracy: 82.07236842105263\n",
      "Saved model to .\\test_models/MLP_795.pth\n",
      "Epoch 796 train loss: 0.6207778303181393\n",
      "Epoch 796 train accuracy: 80.36742528105292\n",
      "Epoch 796 val loss: 0.6115678374312425\n",
      "Epoch 796 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_796.pth\n",
      "Epoch 797 train loss: 0.6207354352727794\n",
      "Epoch 797 train accuracy: 80.42226487523992\n",
      "Epoch 797 val loss: 0.6115864479522172\n",
      "Epoch 797 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_797.pth\n",
      "Epoch 798 train loss: 0.62071087364957\n",
      "Epoch 798 train accuracy: 80.42226487523992\n",
      "Epoch 798 val loss: 0.611438970424627\n",
      "Epoch 798 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_798.pth\n",
      "Epoch 799 train loss: 0.6206398188185535\n",
      "Epoch 799 train accuracy: 80.34000548395942\n",
      "Epoch 799 val loss: 0.6114761266661318\n",
      "Epoch 799 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_799.pth\n",
      "Epoch 800 train loss: 0.6205495650504242\n",
      "Epoch 800 train accuracy: 80.42226487523992\n",
      "Epoch 800 val loss: 0.6114302924098937\n",
      "Epoch 800 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_800.pth\n",
      "Epoch 801 train loss: 0.6205028712651447\n",
      "Epoch 801 train accuracy: 80.39484507814642\n",
      "Epoch 801 val loss: 0.611324646265099\n",
      "Epoch 801 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_801.pth\n",
      "Epoch 802 train loss: 0.6204722187922973\n",
      "Epoch 802 train accuracy: 80.39484507814642\n",
      "Epoch 802 val loss: 0.6112256097656331\n",
      "Epoch 802 val accuracy: 82.07236842105263\n",
      "Saved model to .\\test_models/MLP_802.pth\n",
      "Epoch 803 train loss: 0.6203775437254655\n",
      "Epoch 803 train accuracy: 80.39484507814642\n",
      "Epoch 803 val loss: 0.6111557207462427\n",
      "Epoch 803 val accuracy: 82.07236842105263\n",
      "Saved model to .\\test_models/MLP_803.pth\n",
      "Epoch 804 train loss: 0.6202785640203378\n",
      "Epoch 804 train accuracy: 80.44968467233342\n",
      "Epoch 804 val loss: 0.6110733019090012\n",
      "Epoch 804 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_804.pth\n",
      "Epoch 805 train loss: 0.62029106705858\n",
      "Epoch 805 train accuracy: 80.42226487523992\n",
      "Epoch 805 val loss: 0.6110827879195935\n",
      "Epoch 805 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_805.pth\n",
      "Epoch 806 train loss: 0.6202766211834132\n",
      "Epoch 806 train accuracy: 80.39484507814642\n",
      "Epoch 806 val loss: 0.6109853089836083\n",
      "Epoch 806 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_806.pth\n",
      "Epoch 807 train loss: 0.6200931094129357\n",
      "Epoch 807 train accuracy: 80.44968467233342\n",
      "Epoch 807 val loss: 0.6109706666320562\n",
      "Epoch 807 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_807.pth\n",
      "Epoch 808 train loss: 0.6200625162506312\n",
      "Epoch 808 train accuracy: 80.44968467233342\n",
      "Epoch 808 val loss: 0.6109607907404241\n",
      "Epoch 808 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_808.pth\n",
      "Epoch 809 train loss: 0.6200235140624276\n",
      "Epoch 809 train accuracy: 80.42226487523992\n",
      "Epoch 809 val loss: 0.6108650425449014\n",
      "Epoch 809 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_809.pth\n",
      "Epoch 810 train loss: 0.619973665658842\n",
      "Epoch 810 train accuracy: 80.39484507814642\n",
      "Epoch 810 val loss: 0.6108272191823313\n",
      "Epoch 810 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_810.pth\n",
      "Epoch 811 train loss: 0.6199079488583824\n",
      "Epoch 811 train accuracy: 80.44968467233342\n",
      "Epoch 811 val loss: 0.6106960413683402\n",
      "Epoch 811 val accuracy: 82.07236842105263\n",
      "Saved model to .\\test_models/MLP_811.pth\n",
      "Epoch 812 train loss: 0.6197716953690376\n",
      "Epoch 812 train accuracy: 80.53194406361393\n",
      "Epoch 812 val loss: 0.6107639128734407\n",
      "Epoch 812 val accuracy: 81.90789473684211\n",
      "Saved model to .\\test_models/MLP_812.pth\n",
      "Epoch 813 train loss: 0.6198208060507712\n",
      "Epoch 813 train accuracy: 80.36742528105292\n",
      "Epoch 813 val loss: 0.6106039476826003\n",
      "Epoch 813 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_813.pth\n",
      "Epoch 814 train loss: 0.6197407684828106\n",
      "Epoch 814 train accuracy: 80.44968467233342\n",
      "Epoch 814 val loss: 0.610545201031001\n",
      "Epoch 814 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_814.pth\n",
      "Epoch 815 train loss: 0.6196430033040151\n",
      "Epoch 815 train accuracy: 80.50452426652043\n",
      "Epoch 815 val loss: 0.6105170558745924\n",
      "Epoch 815 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_815.pth\n",
      "Epoch 816 train loss: 0.6196090023016982\n",
      "Epoch 816 train accuracy: 80.44968467233342\n",
      "Epoch 816 val loss: 0.6104978917068556\n",
      "Epoch 816 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_816.pth\n",
      "Epoch 817 train loss: 0.6195067652713573\n",
      "Epoch 817 train accuracy: 80.42226487523992\n",
      "Epoch 817 val loss: 0.6103998853972084\n",
      "Epoch 817 val accuracy: 81.99013157894737\n",
      "Saved model to .\\test_models/MLP_817.pth\n",
      "Epoch 818 train loss: 0.6194315015975582\n",
      "Epoch 818 train accuracy: 80.39484507814642\n",
      "Epoch 818 val loss: 0.6102542777202631\n",
      "Epoch 818 val accuracy: 82.23684210526316\n",
      "Saved model to .\\test_models/MLP_818.pth\n",
      "Epoch 819 train loss: 0.6193675624794865\n",
      "Epoch 819 train accuracy: 80.53194406361393\n",
      "Epoch 819 val loss: 0.6102001792015997\n",
      "Epoch 819 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_819.pth\n",
      "Epoch 820 train loss: 0.619338874378356\n",
      "Epoch 820 train accuracy: 80.53194406361393\n",
      "Epoch 820 val loss: 0.6101749207040197\n",
      "Epoch 820 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_820.pth\n",
      "Epoch 821 train loss: 0.6193182779998895\n",
      "Epoch 821 train accuracy: 80.47710446942692\n",
      "Epoch 821 val loss: 0.6101285761810447\n",
      "Epoch 821 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_821.pth\n",
      "Epoch 822 train loss: 0.6191810005458823\n",
      "Epoch 822 train accuracy: 80.53194406361393\n",
      "Epoch 822 val loss: 0.6101405786252335\n",
      "Epoch 822 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_822.pth\n",
      "Epoch 823 train loss: 0.6192042390211371\n",
      "Epoch 823 train accuracy: 80.55936386070744\n",
      "Epoch 823 val loss: 0.6100538641606507\n",
      "Epoch 823 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_823.pth\n",
      "Epoch 824 train loss: 0.6191445246600268\n",
      "Epoch 824 train accuracy: 80.58678365780094\n",
      "Epoch 824 val loss: 0.6099908883242231\n",
      "Epoch 824 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_824.pth\n",
      "Epoch 825 train loss: 0.6191199259799823\n",
      "Epoch 825 train accuracy: 80.53194406361393\n",
      "Epoch 825 val loss: 0.6098934997755446\n",
      "Epoch 825 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_825.pth\n",
      "Epoch 826 train loss: 0.6190292880004435\n",
      "Epoch 826 train accuracy: 80.61420345489444\n",
      "Epoch 826 val loss: 0.6098484190082863\n",
      "Epoch 826 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_826.pth\n",
      "Epoch 827 train loss: 0.6189521395911773\n",
      "Epoch 827 train accuracy: 80.61420345489444\n",
      "Epoch 827 val loss: 0.6098544292740131\n",
      "Epoch 827 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_827.pth\n",
      "Epoch 828 train loss: 0.6189050990761372\n",
      "Epoch 828 train accuracy: 80.55936386070744\n",
      "Epoch 828 val loss: 0.6097495943601978\n",
      "Epoch 828 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_828.pth\n",
      "Epoch 829 train loss: 0.6188585269019792\n",
      "Epoch 829 train accuracy: 80.53194406361393\n",
      "Epoch 829 val loss: 0.6096738130834541\n",
      "Epoch 829 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_829.pth\n",
      "Epoch 830 train loss: 0.618733337165363\n",
      "Epoch 830 train accuracy: 80.58678365780094\n",
      "Epoch 830 val loss: 0.6096781454000034\n",
      "Epoch 830 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_830.pth\n",
      "Epoch 831 train loss: 0.6187330983383091\n",
      "Epoch 831 train accuracy: 80.61420345489444\n",
      "Epoch 831 val loss: 0.6096060061827302\n",
      "Epoch 831 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_831.pth\n",
      "Epoch 832 train loss: 0.6186697636976054\n",
      "Epoch 832 train accuracy: 80.58678365780094\n",
      "Epoch 832 val loss: 0.6095823772055539\n",
      "Epoch 832 val accuracy: 82.23684210526316\n",
      "Saved model to .\\test_models/MLP_832.pth\n",
      "Epoch 833 train loss: 0.6186172149977401\n",
      "Epoch 833 train accuracy: 80.66904304908144\n",
      "Epoch 833 val loss: 0.6095043507551676\n",
      "Epoch 833 val accuracy: 82.15460526315789\n",
      "Saved model to .\\test_models/MLP_833.pth\n",
      "Epoch 834 train loss: 0.6185316759276024\n",
      "Epoch 834 train accuracy: 80.64162325198794\n",
      "Epoch 834 val loss: 0.609491710698134\n",
      "Epoch 834 val accuracy: 82.31907894736842\n",
      "Saved model to .\\test_models/MLP_834.pth\n",
      "Epoch 835 train loss: 0.6184784859549581\n",
      "Epoch 835 train accuracy: 80.64162325198794\n",
      "Epoch 835 val loss: 0.6093964977680069\n",
      "Epoch 835 val accuracy: 82.23684210526316\n",
      "Saved model to .\\test_models/MLP_835.pth\n",
      "Epoch 836 train loss: 0.6184449726388904\n",
      "Epoch 836 train accuracy: 80.64162325198794\n",
      "Epoch 836 val loss: 0.6093017431466203\n",
      "Epoch 836 val accuracy: 82.23684210526316\n",
      "Saved model to .\\test_models/MLP_836.pth\n",
      "Epoch 837 train loss: 0.6183393918827438\n",
      "Epoch 837 train accuracy: 80.61420345489444\n",
      "Epoch 837 val loss: 0.6092969721771384\n",
      "Epoch 837 val accuracy: 82.31907894736842\n",
      "Saved model to .\\test_models/MLP_837.pth\n",
      "Epoch 838 train loss: 0.6183028535982757\n",
      "Epoch 838 train accuracy: 80.66904304908144\n",
      "Epoch 838 val loss: 0.6092475840919896\n",
      "Epoch 838 val accuracy: 82.31907894736842\n",
      "Saved model to .\\test_models/MLP_838.pth\n",
      "Epoch 839 train loss: 0.6182703488065224\n",
      "Epoch 839 train accuracy: 80.64162325198794\n",
      "Epoch 839 val loss: 0.6091464599104304\n",
      "Epoch 839 val accuracy: 82.31907894736842\n",
      "Saved model to .\\test_models/MLP_839.pth\n",
      "Epoch 840 train loss: 0.6181779253182181\n",
      "Epoch 840 train accuracy: 80.69646284617494\n",
      "Epoch 840 val loss: 0.6090465918379394\n",
      "Epoch 840 val accuracy: 82.23684210526316\n",
      "Saved model to .\\test_models/MLP_840.pth\n",
      "Epoch 841 train loss: 0.6180625857556599\n",
      "Epoch 841 train accuracy: 80.69646284617494\n",
      "Epoch 841 val loss: 0.6091298146271392\n",
      "Epoch 841 val accuracy: 82.31907894736842\n",
      "Saved model to .\\test_models/MLP_841.pth\n",
      "Epoch 842 train loss: 0.6180767588840242\n",
      "Epoch 842 train accuracy: 80.72388264326844\n",
      "Epoch 842 val loss: 0.6090754119581298\n",
      "Epoch 842 val accuracy: 82.31907894736842\n",
      "Saved model to .\\test_models/MLP_842.pth\n",
      "Epoch 843 train loss: 0.6180410812233101\n",
      "Epoch 843 train accuracy: 80.69646284617494\n",
      "Epoch 843 val loss: 0.6089868252410701\n",
      "Epoch 843 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_843.pth\n",
      "Epoch 844 train loss: 0.617985983738643\n",
      "Epoch 844 train accuracy: 80.69646284617494\n",
      "Epoch 844 val loss: 0.6089063539218745\n",
      "Epoch 844 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_844.pth\n",
      "Epoch 845 train loss: 0.6179200538041952\n",
      "Epoch 845 train accuracy: 80.75130244036194\n",
      "Epoch 845 val loss: 0.6088269571038453\n",
      "Epoch 845 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_845.pth\n",
      "Epoch 846 train loss: 0.6178518395968958\n",
      "Epoch 846 train accuracy: 80.64162325198794\n",
      "Epoch 846 val loss: 0.6087937968734064\n",
      "Epoch 846 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_846.pth\n",
      "Epoch 847 train loss: 0.6177546337181539\n",
      "Epoch 847 train accuracy: 80.80614203454894\n",
      "Epoch 847 val loss: 0.6087979490525628\n",
      "Epoch 847 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_847.pth\n",
      "Epoch 848 train loss: 0.6177041967513791\n",
      "Epoch 848 train accuracy: 80.69646284617494\n",
      "Epoch 848 val loss: 0.6087081200002056\n",
      "Epoch 848 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_848.pth\n",
      "Epoch 849 train loss: 0.6177000601432825\n",
      "Epoch 849 train accuracy: 80.75130244036194\n",
      "Epoch 849 val loss: 0.6086355727656108\n",
      "Epoch 849 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_849.pth\n",
      "Epoch 850 train loss: 0.6176411033722392\n",
      "Epoch 850 train accuracy: 80.72388264326844\n",
      "Epoch 850 val loss: 0.6085982065353739\n",
      "Epoch 850 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_850.pth\n",
      "Epoch 851 train loss: 0.6176348957478216\n",
      "Epoch 851 train accuracy: 80.83356183164244\n",
      "Epoch 851 val loss: 0.608495943052204\n",
      "Epoch 851 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_851.pth\n",
      "Epoch 852 train loss: 0.6175408887497166\n",
      "Epoch 852 train accuracy: 80.77872223745544\n",
      "Epoch 852 val loss: 0.6084595286336384\n",
      "Epoch 852 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_852.pth\n",
      "Epoch 853 train loss: 0.6173595104105117\n",
      "Epoch 853 train accuracy: 80.77872223745544\n",
      "Epoch 853 val loss: 0.6084443604769675\n",
      "Epoch 853 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_853.pth\n",
      "Epoch 854 train loss: 0.6173773248467529\n",
      "Epoch 854 train accuracy: 80.75130244036194\n",
      "Epoch 854 val loss: 0.6084148045139093\n",
      "Epoch 854 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_854.pth\n",
      "Epoch 855 train loss: 0.6174054439097905\n",
      "Epoch 855 train accuracy: 80.83356183164244\n",
      "Epoch 855 val loss: 0.6083474370013726\n",
      "Epoch 855 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_855.pth\n",
      "Epoch 856 train loss: 0.6172361794140255\n",
      "Epoch 856 train accuracy: 80.77872223745544\n",
      "Epoch 856 val loss: 0.6082379167507354\n",
      "Epoch 856 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_856.pth\n",
      "Epoch 857 train loss: 0.6172290429015431\n",
      "Epoch 857 train accuracy: 80.86098162873594\n",
      "Epoch 857 val loss: 0.6082083153489389\n",
      "Epoch 857 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_857.pth\n",
      "Epoch 858 train loss: 0.6171939933443802\n",
      "Epoch 858 train accuracy: 80.86098162873594\n",
      "Epoch 858 val loss: 0.6081413210026527\n",
      "Epoch 858 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_858.pth\n",
      "Epoch 859 train loss: 0.6171313610434401\n",
      "Epoch 859 train accuracy: 80.86098162873594\n",
      "Epoch 859 val loss: 0.6080876172177101\n",
      "Epoch 859 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_859.pth\n",
      "Epoch 860 train loss: 0.6170860324218347\n",
      "Epoch 860 train accuracy: 80.88840142582944\n",
      "Epoch 860 val loss: 0.6080330176475016\n",
      "Epoch 860 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_860.pth\n",
      "Epoch 861 train loss: 0.6170261166499633\n",
      "Epoch 861 train accuracy: 80.91582122292294\n",
      "Epoch 861 val loss: 0.6079438871851093\n",
      "Epoch 861 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_861.pth\n",
      "Epoch 862 train loss: 0.6169688307696528\n",
      "Epoch 862 train accuracy: 80.94324102001646\n",
      "Epoch 862 val loss: 0.6079103801595537\n",
      "Epoch 862 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_862.pth\n",
      "Epoch 863 train loss: 0.616895037931962\n",
      "Epoch 863 train accuracy: 80.97066081710996\n",
      "Epoch 863 val loss: 0.6078504183770794\n",
      "Epoch 863 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_863.pth\n",
      "Epoch 864 train loss: 0.616876774140748\n",
      "Epoch 864 train accuracy: 80.97066081710996\n",
      "Epoch 864 val loss: 0.6078356617179356\n",
      "Epoch 864 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_864.pth\n",
      "Epoch 865 train loss: 0.6168030987150575\n",
      "Epoch 865 train accuracy: 80.88840142582944\n",
      "Epoch 865 val loss: 0.6078012097430857\n",
      "Epoch 865 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_865.pth\n",
      "Epoch 866 train loss: 0.6167594060269103\n",
      "Epoch 866 train accuracy: 80.97066081710996\n",
      "Epoch 866 val loss: 0.6077349321230462\n",
      "Epoch 866 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_866.pth\n",
      "Epoch 867 train loss: 0.6167090451835018\n",
      "Epoch 867 train accuracy: 80.97066081710996\n",
      "Epoch 867 val loss: 0.6076778081784907\n",
      "Epoch 867 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_867.pth\n",
      "Epoch 868 train loss: 0.6166586873628068\n",
      "Epoch 868 train accuracy: 80.97066081710996\n",
      "Epoch 868 val loss: 0.607630046476659\n",
      "Epoch 868 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_868.pth\n",
      "Epoch 869 train loss: 0.6166641890120349\n",
      "Epoch 869 train accuracy: 80.99808061420346\n",
      "Epoch 869 val loss: 0.6076216535936845\n",
      "Epoch 869 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_869.pth\n",
      "Epoch 870 train loss: 0.6165171891385526\n",
      "Epoch 870 train accuracy: 80.99808061420346\n",
      "Epoch 870 val loss: 0.6075809296024474\n",
      "Epoch 870 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_870.pth\n",
      "Epoch 871 train loss: 0.61647553772976\n",
      "Epoch 871 train accuracy: 81.02550041129696\n",
      "Epoch 871 val loss: 0.6075141129427051\n",
      "Epoch 871 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_871.pth\n",
      "Epoch 872 train loss: 0.6164180396876314\n",
      "Epoch 872 train accuracy: 80.99808061420346\n",
      "Epoch 872 val loss: 0.6075372289572107\n",
      "Epoch 872 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_872.pth\n",
      "Epoch 873 train loss: 0.6163683050197729\n",
      "Epoch 873 train accuracy: 81.02550041129696\n",
      "Epoch 873 val loss: 0.6074814379803444\n",
      "Epoch 873 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_873.pth\n",
      "Epoch 874 train loss: 0.6163097815424726\n",
      "Epoch 874 train accuracy: 80.97066081710996\n",
      "Epoch 874 val loss: 0.607417697675134\n",
      "Epoch 874 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_874.pth\n",
      "Epoch 875 train loss: 0.616164606146253\n",
      "Epoch 875 train accuracy: 80.94324102001646\n",
      "Epoch 875 val loss: 0.6073277447568742\n",
      "Epoch 875 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_875.pth\n",
      "Epoch 876 train loss: 0.6161967345529742\n",
      "Epoch 876 train accuracy: 80.91582122292294\n",
      "Epoch 876 val loss: 0.6072763612395838\n",
      "Epoch 876 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_876.pth\n",
      "Epoch 877 train loss: 0.6160309796237893\n",
      "Epoch 877 train accuracy: 81.02550041129696\n",
      "Epoch 877 val loss: 0.6072550346878799\n",
      "Epoch 877 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_877.pth\n",
      "Epoch 878 train loss: 0.6160964680541503\n",
      "Epoch 878 train accuracy: 80.94324102001646\n",
      "Epoch 878 val loss: 0.6071976934020457\n",
      "Epoch 878 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_878.pth\n",
      "Epoch 879 train loss: 0.6160334750291026\n",
      "Epoch 879 train accuracy: 81.02550041129696\n",
      "Epoch 879 val loss: 0.607146908235001\n",
      "Epoch 879 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_879.pth\n",
      "Epoch 880 train loss: 0.6159337748070819\n",
      "Epoch 880 train accuracy: 81.10775980257746\n",
      "Epoch 880 val loss: 0.6071517305742753\n",
      "Epoch 880 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_880.pth\n",
      "Epoch 881 train loss: 0.6159026377197159\n",
      "Epoch 881 train accuracy: 81.02550041129696\n",
      "Epoch 881 val loss: 0.6070555122079033\n",
      "Epoch 881 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_881.pth\n",
      "Epoch 882 train loss: 0.6158194339654425\n",
      "Epoch 882 train accuracy: 81.08034000548396\n",
      "Epoch 882 val loss: 0.606971294570126\n",
      "Epoch 882 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_882.pth\n",
      "Epoch 883 train loss: 0.6157953729362864\n",
      "Epoch 883 train accuracy: 81.05292020839046\n",
      "Epoch 883 val loss: 0.6069713895650286\n",
      "Epoch 883 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_883.pth\n",
      "Epoch 884 train loss: 0.6157408755664763\n",
      "Epoch 884 train accuracy: 80.99808061420346\n",
      "Epoch 884 val loss: 0.6069692273281122\n",
      "Epoch 884 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_884.pth\n",
      "Epoch 885 train loss: 0.6156503640752482\n",
      "Epoch 885 train accuracy: 81.08034000548396\n",
      "Epoch 885 val loss: 0.6068727080465147\n",
      "Epoch 885 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_885.pth\n",
      "Epoch 886 train loss: 0.6156591242832834\n",
      "Epoch 886 train accuracy: 81.05292020839046\n",
      "Epoch 886 val loss: 0.6068820064201167\n",
      "Epoch 886 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_886.pth\n",
      "Epoch 887 train loss: 0.6155613707215116\n",
      "Epoch 887 train accuracy: 81.08034000548396\n",
      "Epoch 887 val loss: 0.6067847742355967\n",
      "Epoch 887 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_887.pth\n",
      "Epoch 888 train loss: 0.6155565669596718\n",
      "Epoch 888 train accuracy: 81.19001919385796\n",
      "Epoch 888 val loss: 0.6067959136868778\n",
      "Epoch 888 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_888.pth\n",
      "Epoch 889 train loss: 0.6154367220996503\n",
      "Epoch 889 train accuracy: 81.13517959967096\n",
      "Epoch 889 val loss: 0.6066510644006101\n",
      "Epoch 889 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_889.pth\n",
      "Epoch 890 train loss: 0.6154410745458383\n",
      "Epoch 890 train accuracy: 81.16259939676446\n",
      "Epoch 890 val loss: 0.6065895437802139\n",
      "Epoch 890 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_890.pth\n",
      "Epoch 891 train loss: 0.615329627601201\n",
      "Epoch 891 train accuracy: 81.19001919385796\n",
      "Epoch 891 val loss: 0.6065344470308015\n",
      "Epoch 891 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_891.pth\n",
      "Epoch 892 train loss: 0.6152989967938578\n",
      "Epoch 892 train accuracy: 81.27227858513847\n",
      "Epoch 892 val loss: 0.6064891627450523\n",
      "Epoch 892 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_892.pth\n",
      "Epoch 893 train loss: 0.6152177394057313\n",
      "Epoch 893 train accuracy: 81.10775980257746\n",
      "Epoch 893 val loss: 0.6064203306052246\n",
      "Epoch 893 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_893.pth\n",
      "Epoch 894 train loss: 0.615229549605334\n",
      "Epoch 894 train accuracy: 81.13517959967096\n",
      "Epoch 894 val loss: 0.6064052879810333\n",
      "Epoch 894 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_894.pth\n",
      "Epoch 895 train loss: 0.6151742977662045\n",
      "Epoch 895 train accuracy: 81.13517959967096\n",
      "Epoch 895 val loss: 0.6063614440101542\n",
      "Epoch 895 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_895.pth\n",
      "Epoch 896 train loss: 0.6150630963149301\n",
      "Epoch 896 train accuracy: 81.19001919385796\n",
      "Epoch 896 val loss: 0.6063470859080553\n",
      "Epoch 896 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_896.pth\n",
      "Epoch 897 train loss: 0.6150383295720083\n",
      "Epoch 897 train accuracy: 81.21743899095146\n",
      "Epoch 897 val loss: 0.6062190733163765\n",
      "Epoch 897 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_897.pth\n",
      "Epoch 898 train loss: 0.6150169303281265\n",
      "Epoch 898 train accuracy: 81.24485878804497\n",
      "Epoch 898 val loss: 0.6062398089193984\n",
      "Epoch 898 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_898.pth\n",
      "Epoch 899 train loss: 0.6148818866921621\n",
      "Epoch 899 train accuracy: 81.19001919385796\n",
      "Epoch 899 val loss: 0.6060869676109991\n",
      "Epoch 899 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_899.pth\n",
      "Epoch 900 train loss: 0.6148787983774877\n",
      "Epoch 900 train accuracy: 81.21743899095146\n",
      "Epoch 900 val loss: 0.6060921910562014\n",
      "Epoch 900 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_900.pth\n",
      "Epoch 901 train loss: 0.6148648088177046\n",
      "Epoch 901 train accuracy: 81.21743899095146\n",
      "Epoch 901 val loss: 0.6059656843641087\n",
      "Epoch 901 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_901.pth\n",
      "Epoch 902 train loss: 0.6148738075995392\n",
      "Epoch 902 train accuracy: 81.24485878804497\n",
      "Epoch 902 val loss: 0.6060112766725453\n",
      "Epoch 902 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_902.pth\n",
      "Epoch 903 train loss: 0.6147506572469547\n",
      "Epoch 903 train accuracy: 81.29969838223197\n",
      "Epoch 903 val loss: 0.6060156494281009\n",
      "Epoch 903 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_903.pth\n",
      "Epoch 904 train loss: 0.6147012147856387\n",
      "Epoch 904 train accuracy: 81.29969838223197\n",
      "Epoch 904 val loss: 0.605921701332064\n",
      "Epoch 904 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_904.pth\n",
      "Epoch 905 train loss: 0.6146185934020761\n",
      "Epoch 905 train accuracy: 81.35453797641897\n",
      "Epoch 905 val loss: 0.6059365855824006\n",
      "Epoch 905 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_905.pth\n",
      "Epoch 906 train loss: 0.6146139123297313\n",
      "Epoch 906 train accuracy: 81.29969838223197\n",
      "Epoch 906 val loss: 0.6058708319048348\n",
      "Epoch 906 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_906.pth\n",
      "Epoch 907 train loss: 0.6145225414728517\n",
      "Epoch 907 train accuracy: 81.29969838223197\n",
      "Epoch 907 val loss: 0.6058701969879238\n",
      "Epoch 907 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_907.pth\n",
      "Epoch 908 train loss: 0.6144928572895495\n",
      "Epoch 908 train accuracy: 81.29969838223197\n",
      "Epoch 908 val loss: 0.6058018568315005\n",
      "Epoch 908 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_908.pth\n",
      "Epoch 909 train loss: 0.6144340012810732\n",
      "Epoch 909 train accuracy: 81.38195777351248\n",
      "Epoch 909 val loss: 0.605684408709701\n",
      "Epoch 909 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_909.pth\n",
      "Epoch 910 train loss: 0.6143692925637751\n",
      "Epoch 910 train accuracy: 81.29969838223197\n",
      "Epoch 910 val loss: 0.6056366620683357\n",
      "Epoch 910 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_910.pth\n",
      "Epoch 911 train loss: 0.6143532099953869\n",
      "Epoch 911 train accuracy: 81.24485878804497\n",
      "Epoch 911 val loss: 0.6056498513606033\n",
      "Epoch 911 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_911.pth\n",
      "Epoch 912 train loss: 0.6142733258832442\n",
      "Epoch 912 train accuracy: 81.35453797641897\n",
      "Epoch 912 val loss: 0.6055958661201754\n",
      "Epoch 912 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_912.pth\n",
      "Epoch 913 train loss: 0.6141913141891883\n",
      "Epoch 913 train accuracy: 81.29969838223197\n",
      "Epoch 913 val loss: 0.6055662985891104\n",
      "Epoch 913 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_913.pth\n",
      "Epoch 914 train loss: 0.6140996913605353\n",
      "Epoch 914 train accuracy: 81.27227858513847\n",
      "Epoch 914 val loss: 0.6055153777920886\n",
      "Epoch 914 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_914.pth\n",
      "Epoch 915 train loss: 0.6140330758991471\n",
      "Epoch 915 train accuracy: 81.16259939676446\n",
      "Epoch 915 val loss: 0.6053828000042\n",
      "Epoch 915 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_915.pth\n",
      "Epoch 916 train loss: 0.6141045617364478\n",
      "Epoch 916 train accuracy: 81.24485878804497\n",
      "Epoch 916 val loss: 0.6053956075522461\n",
      "Epoch 916 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_916.pth\n",
      "Epoch 917 train loss: 0.6139827715559748\n",
      "Epoch 917 train accuracy: 81.32711817932547\n",
      "Epoch 917 val loss: 0.6053258401684856\n",
      "Epoch 917 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_917.pth\n",
      "Epoch 918 train loss: 0.61397913556644\n",
      "Epoch 918 train accuracy: 81.24485878804497\n",
      "Epoch 918 val loss: 0.6052717801281496\n",
      "Epoch 918 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_918.pth\n",
      "Epoch 919 train loss: 0.6138055828775753\n",
      "Epoch 919 train accuracy: 81.38195777351248\n",
      "Epoch 919 val loss: 0.6052611020246619\n",
      "Epoch 919 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_919.pth\n",
      "Epoch 920 train loss: 0.6138238613902215\n",
      "Epoch 920 train accuracy: 81.38195777351248\n",
      "Epoch 920 val loss: 0.6052309273693123\n",
      "Epoch 920 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_920.pth\n",
      "Epoch 921 train loss: 0.613838113060123\n",
      "Epoch 921 train accuracy: 81.35453797641897\n",
      "Epoch 921 val loss: 0.605171644079842\n",
      "Epoch 921 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_921.pth\n",
      "Epoch 922 train loss: 0.6137429475130742\n",
      "Epoch 922 train accuracy: 81.35453797641897\n",
      "Epoch 922 val loss: 0.6051722255682475\n",
      "Epoch 922 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_922.pth\n",
      "Epoch 923 train loss: 0.6136159488375772\n",
      "Epoch 923 train accuracy: 81.32711817932547\n",
      "Epoch 923 val loss: 0.6051117771942365\n",
      "Epoch 923 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_923.pth\n",
      "Epoch 924 train loss: 0.6136787464646133\n",
      "Epoch 924 train accuracy: 81.38195777351248\n",
      "Epoch 924 val loss: 0.605140785049451\n",
      "Epoch 924 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_924.pth\n",
      "Epoch 925 train loss: 0.6136132648476121\n",
      "Epoch 925 train accuracy: 81.43679736769948\n",
      "Epoch 925 val loss: 0.6051956685750108\n",
      "Epoch 925 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_925.pth\n",
      "Epoch 926 train loss: 0.6135598807023805\n",
      "Epoch 926 train accuracy: 81.35453797641897\n",
      "Epoch 926 val loss: 0.6051359450640647\n",
      "Epoch 926 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_926.pth\n",
      "Epoch 927 train loss: 0.6135324971554311\n",
      "Epoch 927 train accuracy: 81.35453797641897\n",
      "Epoch 927 val loss: 0.6050645335528412\n",
      "Epoch 927 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_927.pth\n",
      "Epoch 928 train loss: 0.6134665356785581\n",
      "Epoch 928 train accuracy: 81.32711817932547\n",
      "Epoch 928 val loss: 0.6050000976477015\n",
      "Epoch 928 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_928.pth\n",
      "Epoch 929 train loss: 0.6134588647503079\n",
      "Epoch 929 train accuracy: 81.32711817932547\n",
      "Epoch 929 val loss: 0.6048803372112544\n",
      "Epoch 929 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_929.pth\n",
      "Epoch 930 train loss: 0.6133538471012\n",
      "Epoch 930 train accuracy: 81.29969838223197\n",
      "Epoch 930 val loss: 0.6048162622671378\n",
      "Epoch 930 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_930.pth\n",
      "Epoch 931 train loss: 0.613327756442391\n",
      "Epoch 931 train accuracy: 81.35453797641897\n",
      "Epoch 931 val loss: 0.6048009029932713\n",
      "Epoch 931 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_931.pth\n",
      "Epoch 932 train loss: 0.6132754101663044\n",
      "Epoch 932 train accuracy: 81.32711817932547\n",
      "Epoch 932 val loss: 0.6047603129899424\n",
      "Epoch 932 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_932.pth\n",
      "Epoch 933 train loss: 0.6132227730071336\n",
      "Epoch 933 train accuracy: 81.38195777351248\n",
      "Epoch 933 val loss: 0.6047265966373839\n",
      "Epoch 933 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_933.pth\n",
      "Epoch 934 train loss: 0.6131257433771041\n",
      "Epoch 934 train accuracy: 81.32711817932547\n",
      "Epoch 934 val loss: 0.604675875388478\n",
      "Epoch 934 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_934.pth\n",
      "Epoch 935 train loss: 0.6130694925229538\n",
      "Epoch 935 train accuracy: 81.38195777351248\n",
      "Epoch 935 val loss: 0.6046540786169077\n",
      "Epoch 935 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_935.pth\n",
      "Epoch 936 train loss: 0.6130674377966084\n",
      "Epoch 936 train accuracy: 81.46421716479298\n",
      "Epoch 936 val loss: 0.6046441096420351\n",
      "Epoch 936 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_936.pth\n",
      "Epoch 937 train loss: 0.6130102642141936\n",
      "Epoch 937 train accuracy: 81.49163696188648\n",
      "Epoch 937 val loss: 0.6045992681266446\n",
      "Epoch 937 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_937.pth\n",
      "Epoch 938 train loss: 0.6128974706097915\n",
      "Epoch 938 train accuracy: 81.38195777351248\n",
      "Epoch 938 val loss: 0.6045216989066255\n",
      "Epoch 938 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_938.pth\n",
      "Epoch 939 train loss: 0.6128612801824745\n",
      "Epoch 939 train accuracy: 81.40937757060598\n",
      "Epoch 939 val loss: 0.6044575443099204\n",
      "Epoch 939 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_939.pth\n",
      "Epoch 940 train loss: 0.6128251139695445\n",
      "Epoch 940 train accuracy: 81.40937757060598\n",
      "Epoch 940 val loss: 0.6043930887979897\n",
      "Epoch 940 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_940.pth\n",
      "Epoch 941 train loss: 0.6127982381404492\n",
      "Epoch 941 train accuracy: 81.35453797641897\n",
      "Epoch 941 val loss: 0.6042438161216284\n",
      "Epoch 941 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_941.pth\n",
      "Epoch 942 train loss: 0.6127919206363067\n",
      "Epoch 942 train accuracy: 81.35453797641897\n",
      "Epoch 942 val loss: 0.604383774591904\n",
      "Epoch 942 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_942.pth\n",
      "Epoch 943 train loss: 0.6126727472762006\n",
      "Epoch 943 train accuracy: 81.49163696188648\n",
      "Epoch 943 val loss: 0.6043468787285843\n",
      "Epoch 943 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_943.pth\n",
      "Epoch 944 train loss: 0.6126277850973502\n",
      "Epoch 944 train accuracy: 81.32711817932547\n",
      "Epoch 944 val loss: 0.6043233869499282\n",
      "Epoch 944 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_944.pth\n",
      "Epoch 945 train loss: 0.6126734814034742\n",
      "Epoch 945 train accuracy: 81.43679736769948\n",
      "Epoch 945 val loss: 0.60421661841438\n",
      "Epoch 945 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_945.pth\n",
      "Epoch 946 train loss: 0.612571997960147\n",
      "Epoch 946 train accuracy: 81.46421716479298\n",
      "Epoch 946 val loss: 0.6041070938992658\n",
      "Epoch 946 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_946.pth\n",
      "Epoch 947 train loss: 0.612583218746933\n",
      "Epoch 947 train accuracy: 81.40937757060598\n",
      "Epoch 947 val loss: 0.6040726267291527\n",
      "Epoch 947 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_947.pth\n",
      "Epoch 948 train loss: 0.6125414372307428\n",
      "Epoch 948 train accuracy: 81.43679736769948\n",
      "Epoch 948 val loss: 0.6040220094452563\n",
      "Epoch 948 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_948.pth\n",
      "Epoch 949 train loss: 0.6123799606177368\n",
      "Epoch 949 train accuracy: 81.40937757060598\n",
      "Epoch 949 val loss: 0.6040801173566204\n",
      "Epoch 949 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_949.pth\n",
      "Epoch 950 train loss: 0.6123382732141436\n",
      "Epoch 950 train accuracy: 81.40937757060598\n",
      "Epoch 950 val loss: 0.6040385136576859\n",
      "Epoch 950 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_950.pth\n",
      "Epoch 951 train loss: 0.6123392884374449\n",
      "Epoch 951 train accuracy: 81.40937757060598\n",
      "Epoch 951 val loss: 0.6040591444133928\n",
      "Epoch 951 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_951.pth\n",
      "Epoch 952 train loss: 0.612294901211403\n",
      "Epoch 952 train accuracy: 81.46421716479298\n",
      "Epoch 952 val loss: 0.6040034369614563\n",
      "Epoch 952 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_952.pth\n",
      "Epoch 953 train loss: 0.612241872406581\n",
      "Epoch 953 train accuracy: 81.35453797641897\n",
      "Epoch 953 val loss: 0.6038905302748868\n",
      "Epoch 953 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_953.pth\n",
      "Epoch 954 train loss: 0.6121924207627512\n",
      "Epoch 954 train accuracy: 81.32711817932547\n",
      "Epoch 954 val loss: 0.6037962606274768\n",
      "Epoch 954 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_954.pth\n",
      "Epoch 955 train loss: 0.6121306676384911\n",
      "Epoch 955 train accuracy: 81.32711817932547\n",
      "Epoch 955 val loss: 0.6038453499541471\n",
      "Epoch 955 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_955.pth\n",
      "Epoch 956 train loss: 0.6120079650396579\n",
      "Epoch 956 train accuracy: 81.35453797641897\n",
      "Epoch 956 val loss: 0.6037737506588823\n",
      "Epoch 956 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_956.pth\n",
      "Epoch 957 train loss: 0.6120557022820178\n",
      "Epoch 957 train accuracy: 81.40937757060598\n",
      "Epoch 957 val loss: 0.6037333732666937\n",
      "Epoch 957 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_957.pth\n",
      "Epoch 958 train loss: 0.6119330826362497\n",
      "Epoch 958 train accuracy: 81.46421716479298\n",
      "Epoch 958 val loss: 0.6037597562627572\n",
      "Epoch 958 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_958.pth\n",
      "Epoch 959 train loss: 0.6119256319249409\n",
      "Epoch 959 train accuracy: 81.38195777351248\n",
      "Epoch 959 val loss: 0.60358782573358\n",
      "Epoch 959 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_959.pth\n",
      "Epoch 960 train loss: 0.6118973341133249\n",
      "Epoch 960 train accuracy: 81.40937757060598\n",
      "Epoch 960 val loss: 0.6036869266413545\n",
      "Epoch 960 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_960.pth\n",
      "Epoch 961 train loss: 0.611868797817774\n",
      "Epoch 961 train accuracy: 81.38195777351248\n",
      "Epoch 961 val loss: 0.6036111619323492\n",
      "Epoch 961 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_961.pth\n",
      "Epoch 962 train loss: 0.6118016567800129\n",
      "Epoch 962 train accuracy: 81.35453797641897\n",
      "Epoch 962 val loss: 0.6035020097501969\n",
      "Epoch 962 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_962.pth\n",
      "Epoch 963 train loss: 0.6117848228140358\n",
      "Epoch 963 train accuracy: 81.40937757060598\n",
      "Epoch 963 val loss: 0.6034751168795323\n",
      "Epoch 963 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_963.pth\n",
      "Epoch 964 train loss: 0.6117135391881069\n",
      "Epoch 964 train accuracy: 81.40937757060598\n",
      "Epoch 964 val loss: 0.6034546433702895\n",
      "Epoch 964 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_964.pth\n",
      "Epoch 965 train loss: 0.6116802958167044\n",
      "Epoch 965 train accuracy: 81.38195777351248\n",
      "Epoch 965 val loss: 0.6034070595020526\n",
      "Epoch 965 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_965.pth\n",
      "Epoch 966 train loss: 0.6115377454511952\n",
      "Epoch 966 train accuracy: 81.38195777351248\n",
      "Epoch 966 val loss: 0.6032447303694329\n",
      "Epoch 966 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_966.pth\n",
      "Epoch 967 train loss: 0.6115264981462244\n",
      "Epoch 967 train accuracy: 81.46421716479298\n",
      "Epoch 967 val loss: 0.6032070175401474\n",
      "Epoch 967 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_967.pth\n",
      "Epoch 968 train loss: 0.611534825183059\n",
      "Epoch 968 train accuracy: 81.46421716479298\n",
      "Epoch 968 val loss: 0.6032923633526814\n",
      "Epoch 968 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_968.pth\n",
      "Epoch 969 train loss: 0.6114352023098291\n",
      "Epoch 969 train accuracy: 81.40937757060598\n",
      "Epoch 969 val loss: 0.6032528428262786\n",
      "Epoch 969 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_969.pth\n",
      "Epoch 970 train loss: 0.6114484162903145\n",
      "Epoch 970 train accuracy: 81.40937757060598\n",
      "Epoch 970 val loss: 0.6031725244400533\n",
      "Epoch 970 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_970.pth\n",
      "Epoch 971 train loss: 0.6114020110598128\n",
      "Epoch 971 train accuracy: 81.43679736769948\n",
      "Epoch 971 val loss: 0.6031118864193559\n",
      "Epoch 971 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_971.pth\n",
      "Epoch 972 train loss: 0.6113466045149324\n",
      "Epoch 972 train accuracy: 81.38195777351248\n",
      "Epoch 972 val loss: 0.6030786322233709\n",
      "Epoch 972 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_972.pth\n",
      "Epoch 973 train loss: 0.6112435864480702\n",
      "Epoch 973 train accuracy: 81.40937757060598\n",
      "Epoch 973 val loss: 0.6030790821992253\n",
      "Epoch 973 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_973.pth\n",
      "Epoch 974 train loss: 0.6112236559652445\n",
      "Epoch 974 train accuracy: 81.38195777351248\n",
      "Epoch 974 val loss: 0.6030698683308927\n",
      "Epoch 974 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_974.pth\n",
      "Epoch 975 train loss: 0.6111964485526347\n",
      "Epoch 975 train accuracy: 81.27227858513847\n",
      "Epoch 975 val loss: 0.6029556628904844\n",
      "Epoch 975 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_975.pth\n",
      "Epoch 976 train loss: 0.6111202800417679\n",
      "Epoch 976 train accuracy: 81.43679736769948\n",
      "Epoch 976 val loss: 0.602972692859016\n",
      "Epoch 976 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_976.pth\n",
      "Epoch 977 train loss: 0.6110759670601079\n",
      "Epoch 977 train accuracy: 81.40937757060598\n",
      "Epoch 977 val loss: 0.6029426966254648\n",
      "Epoch 977 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_977.pth\n",
      "Epoch 978 train loss: 0.6109792213527518\n",
      "Epoch 978 train accuracy: 81.40937757060598\n",
      "Epoch 978 val loss: 0.6029040919322717\n",
      "Epoch 978 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_978.pth\n",
      "Epoch 979 train loss: 0.6110314302505893\n",
      "Epoch 979 train accuracy: 81.40937757060598\n",
      "Epoch 979 val loss: 0.6028142940056952\n",
      "Epoch 979 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_979.pth\n",
      "Epoch 980 train loss: 0.6109812541848474\n",
      "Epoch 980 train accuracy: 81.43679736769948\n",
      "Epoch 980 val loss: 0.6027807479626254\n",
      "Epoch 980 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_980.pth\n",
      "Epoch 981 train loss: 0.6109360064984414\n",
      "Epoch 981 train accuracy: 81.43679736769948\n",
      "Epoch 981 val loss: 0.602732087975662\n",
      "Epoch 981 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_981.pth\n",
      "Epoch 982 train loss: 0.6108685148259004\n",
      "Epoch 982 train accuracy: 81.43679736769948\n",
      "Epoch 982 val loss: 0.6027002088039329\n",
      "Epoch 982 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_982.pth\n",
      "Epoch 983 train loss: 0.6107252161263635\n",
      "Epoch 983 train accuracy: 81.38195777351248\n",
      "Epoch 983 val loss: 0.6026631823103679\n",
      "Epoch 983 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_983.pth\n",
      "Epoch 984 train loss: 0.610738484826135\n",
      "Epoch 984 train accuracy: 81.40937757060598\n",
      "Epoch 984 val loss: 0.6026085575944499\n",
      "Epoch 984 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_984.pth\n",
      "Epoch 985 train loss: 0.6106965235810269\n",
      "Epoch 985 train accuracy: 81.46421716479298\n",
      "Epoch 985 val loss: 0.6025302359638246\n",
      "Epoch 985 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_985.pth\n",
      "Epoch 986 train loss: 0.610706708393991\n",
      "Epoch 986 train accuracy: 81.46421716479298\n",
      "Epoch 986 val loss: 0.6024985595753318\n",
      "Epoch 986 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_986.pth\n",
      "Epoch 987 train loss: 0.6106920612551141\n",
      "Epoch 987 train accuracy: 81.51905675897999\n",
      "Epoch 987 val loss: 0.6024861277914361\n",
      "Epoch 987 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_987.pth\n",
      "Epoch 988 train loss: 0.6105705936553708\n",
      "Epoch 988 train accuracy: 81.38195777351248\n",
      "Epoch 988 val loss: 0.6024243277742675\n",
      "Epoch 988 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_988.pth\n",
      "Epoch 989 train loss: 0.6105706699176185\n",
      "Epoch 989 train accuracy: 81.46421716479298\n",
      "Epoch 989 val loss: 0.6024100465798065\n",
      "Epoch 989 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_989.pth\n",
      "Epoch 990 train loss: 0.6104757597081756\n",
      "Epoch 990 train accuracy: 81.43679736769948\n",
      "Epoch 990 val loss: 0.6023729037689535\n",
      "Epoch 990 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_990.pth\n",
      "Epoch 991 train loss: 0.6104880460096818\n",
      "Epoch 991 train accuracy: 81.43679736769948\n",
      "Epoch 991 val loss: 0.6023308899939844\n",
      "Epoch 991 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_991.pth\n",
      "Epoch 992 train loss: 0.6103901461322319\n",
      "Epoch 992 train accuracy: 81.51905675897999\n",
      "Epoch 992 val loss: 0.6023576011587131\n",
      "Epoch 992 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_992.pth\n",
      "Epoch 993 train loss: 0.6103595986700895\n",
      "Epoch 993 train accuracy: 81.32711817932547\n",
      "Epoch 993 val loss: 0.6022726635105515\n",
      "Epoch 993 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_993.pth\n",
      "Epoch 994 train loss: 0.6102741582221106\n",
      "Epoch 994 train accuracy: 81.40937757060598\n",
      "Epoch 994 val loss: 0.6021158215344736\n",
      "Epoch 994 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_994.pth\n",
      "Epoch 995 train loss: 0.6102904208543661\n",
      "Epoch 995 train accuracy: 81.43679736769948\n",
      "Epoch 995 val loss: 0.6021295621697056\n",
      "Epoch 995 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_995.pth\n",
      "Epoch 996 train loss: 0.6102070388498536\n",
      "Epoch 996 train accuracy: 81.43679736769948\n",
      "Epoch 996 val loss: 0.6021457829169536\n",
      "Epoch 996 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_996.pth\n",
      "Epoch 997 train loss: 0.6101188914883032\n",
      "Epoch 997 train accuracy: 81.38195777351248\n",
      "Epoch 997 val loss: 0.6021037775729048\n",
      "Epoch 997 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_997.pth\n",
      "Epoch 998 train loss: 0.6101672939400662\n",
      "Epoch 998 train accuracy: 81.43679736769948\n",
      "Epoch 998 val loss: 0.6020676838724237\n",
      "Epoch 998 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_998.pth\n",
      "Epoch 999 train loss: 0.6100993651341189\n",
      "Epoch 999 train accuracy: 81.38195777351248\n",
      "Epoch 999 val loss: 0.6019799331766799\n",
      "Epoch 999 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_999.pth\n",
      "Epoch 1000 train loss: 0.6100308410006395\n",
      "Epoch 1000 train accuracy: 81.49163696188648\n",
      "Epoch 1000 val loss: 0.6020431039168647\n",
      "Epoch 1000 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1000.pth\n",
      "Epoch 1001 train loss: 0.6099948693524327\n",
      "Epoch 1001 train accuracy: 81.43679736769948\n",
      "Epoch 1001 val loss: 0.6020344236963674\n",
      "Epoch 1001 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1001.pth\n",
      "Epoch 1002 train loss: 0.609943604717652\n",
      "Epoch 1002 train accuracy: 81.40937757060598\n",
      "Epoch 1002 val loss: 0.6018130162632779\n",
      "Epoch 1002 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1002.pth\n",
      "Epoch 1003 train loss: 0.6098959031433129\n",
      "Epoch 1003 train accuracy: 81.43679736769948\n",
      "Epoch 1003 val loss: 0.6018809753127004\n",
      "Epoch 1003 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1003.pth\n",
      "Epoch 1004 train loss: 0.6098717938487729\n",
      "Epoch 1004 train accuracy: 81.40937757060598\n",
      "Epoch 1004 val loss: 0.6018551852259981\n",
      "Epoch 1004 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1004.pth\n",
      "Epoch 1005 train loss: 0.6097929646636833\n",
      "Epoch 1005 train accuracy: 81.43679736769948\n",
      "Epoch 1005 val loss: 0.6017632873140668\n",
      "Epoch 1005 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1005.pth\n",
      "Epoch 1006 train loss: 0.609793171286583\n",
      "Epoch 1006 train accuracy: 81.40937757060598\n",
      "Epoch 1006 val loss: 0.6017446301534379\n",
      "Epoch 1006 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1006.pth\n",
      "Epoch 1007 train loss: 0.6097356029050914\n",
      "Epoch 1007 train accuracy: 81.40937757060598\n",
      "Epoch 1007 val loss: 0.6017892852327541\n",
      "Epoch 1007 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1007.pth\n",
      "Epoch 1008 train loss: 0.6096669955734622\n",
      "Epoch 1008 train accuracy: 81.38195777351248\n",
      "Epoch 1008 val loss: 0.6016970925817364\n",
      "Epoch 1008 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1008.pth\n",
      "Epoch 1009 train loss: 0.6095563183914412\n",
      "Epoch 1009 train accuracy: 81.40937757060598\n",
      "Epoch 1009 val loss: 0.6016641322425321\n",
      "Epoch 1009 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1009.pth\n",
      "Epoch 1010 train loss: 0.6096032127868711\n",
      "Epoch 1010 train accuracy: 81.43679736769948\n",
      "Epoch 1010 val loss: 0.6015611225248951\n",
      "Epoch 1010 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1010.pth\n",
      "Epoch 1011 train loss: 0.609526134161442\n",
      "Epoch 1011 train accuracy: 81.40937757060598\n",
      "Epoch 1011 val loss: 0.6015582296899274\n",
      "Epoch 1011 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1011.pth\n",
      "Epoch 1012 train loss: 0.6094472498485917\n",
      "Epoch 1012 train accuracy: 81.43679736769948\n",
      "Epoch 1012 val loss: 0.6014595422893763\n",
      "Epoch 1012 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1012.pth\n",
      "Epoch 1013 train loss: 0.6095098887423152\n",
      "Epoch 1013 train accuracy: 81.43679736769948\n",
      "Epoch 1013 val loss: 0.6014229161174673\n",
      "Epoch 1013 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1013.pth\n",
      "Epoch 1014 train loss: 0.609438434635338\n",
      "Epoch 1014 train accuracy: 81.40937757060598\n",
      "Epoch 1014 val loss: 0.6014307743722671\n",
      "Epoch 1014 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1014.pth\n",
      "Epoch 1015 train loss: 0.6094124559313059\n",
      "Epoch 1015 train accuracy: 81.40937757060598\n",
      "Epoch 1015 val loss: 0.6014717841324838\n",
      "Epoch 1015 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1015.pth\n",
      "Epoch 1016 train loss: 0.6093402726314309\n",
      "Epoch 1016 train accuracy: 81.32711817932547\n",
      "Epoch 1016 val loss: 0.6013256370727169\n",
      "Epoch 1016 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1016.pth\n",
      "Epoch 1017 train loss: 0.6093070764878863\n",
      "Epoch 1017 train accuracy: 81.38195777351248\n",
      "Epoch 1017 val loss: 0.6013114288645355\n",
      "Epoch 1017 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1017.pth\n",
      "Epoch 1018 train loss: 0.6092517762526608\n",
      "Epoch 1018 train accuracy: 81.43679736769948\n",
      "Epoch 1018 val loss: 0.6012788026740676\n",
      "Epoch 1018 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1018.pth\n",
      "Epoch 1019 train loss: 0.6091629605119427\n",
      "Epoch 1019 train accuracy: 81.40937757060598\n",
      "Epoch 1019 val loss: 0.6012180378954661\n",
      "Epoch 1019 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1019.pth\n",
      "Epoch 1020 train loss: 0.6091187154351357\n",
      "Epoch 1020 train accuracy: 81.38195777351248\n",
      "Epoch 1020 val loss: 0.6011360550397321\n",
      "Epoch 1020 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1020.pth\n",
      "Epoch 1021 train loss: 0.6090494520276001\n",
      "Epoch 1021 train accuracy: 81.40937757060598\n",
      "Epoch 1021 val loss: 0.6011502805509066\n",
      "Epoch 1021 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1021.pth\n",
      "Epoch 1022 train loss: 0.6090802165695972\n",
      "Epoch 1022 train accuracy: 81.38195777351248\n",
      "Epoch 1022 val loss: 0.6011463097345672\n",
      "Epoch 1022 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1022.pth\n",
      "Epoch 1023 train loss: 0.6089442250433198\n",
      "Epoch 1023 train accuracy: 81.38195777351248\n",
      "Epoch 1023 val loss: 0.6010958636669737\n",
      "Epoch 1023 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1023.pth\n",
      "Epoch 1024 train loss: 0.6089184941364485\n",
      "Epoch 1024 train accuracy: 81.38195777351248\n",
      "Epoch 1024 val loss: 0.6010210791504697\n",
      "Epoch 1024 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1024.pth\n",
      "Epoch 1025 train loss: 0.6089286709351367\n",
      "Epoch 1025 train accuracy: 81.43679736769948\n",
      "Epoch 1025 val loss: 0.6010396269297129\n",
      "Epoch 1025 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1025.pth\n",
      "Epoch 1026 train loss: 0.6088946843683197\n",
      "Epoch 1026 train accuracy: 81.38195777351248\n",
      "Epoch 1026 val loss: 0.600899999765189\n",
      "Epoch 1026 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1026.pth\n",
      "Epoch 1027 train loss: 0.608804087628398\n",
      "Epoch 1027 train accuracy: 81.43679736769948\n",
      "Epoch 1027 val loss: 0.6008741580145923\n",
      "Epoch 1027 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1027.pth\n",
      "Epoch 1028 train loss: 0.6087741054953975\n",
      "Epoch 1028 train accuracy: 81.40937757060598\n",
      "Epoch 1028 val loss: 0.6008259939323914\n",
      "Epoch 1028 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1028.pth\n",
      "Epoch 1029 train loss: 0.6087682637173617\n",
      "Epoch 1029 train accuracy: 81.38195777351248\n",
      "Epoch 1029 val loss: 0.6008610932254478\n",
      "Epoch 1029 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1029.pth\n",
      "Epoch 1030 train loss: 0.6087409512450298\n",
      "Epoch 1030 train accuracy: 81.43679736769948\n",
      "Epoch 1030 val loss: 0.6007671020434875\n",
      "Epoch 1030 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1030.pth\n",
      "Epoch 1031 train loss: 0.6086555497165311\n",
      "Epoch 1031 train accuracy: 81.40937757060598\n",
      "Epoch 1031 val loss: 0.6008134887210632\n",
      "Epoch 1031 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1031.pth\n",
      "Epoch 1032 train loss: 0.6086576211249881\n",
      "Epoch 1032 train accuracy: 81.38195777351248\n",
      "Epoch 1032 val loss: 0.600741025452551\n",
      "Epoch 1032 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1032.pth\n",
      "Epoch 1033 train loss: 0.608523082625317\n",
      "Epoch 1033 train accuracy: 81.54647655607349\n",
      "Epoch 1033 val loss: 0.6007696263198006\n",
      "Epoch 1033 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1033.pth\n",
      "Epoch 1034 train loss: 0.6085411661811042\n",
      "Epoch 1034 train accuracy: 81.38195777351248\n",
      "Epoch 1034 val loss: 0.6006375492403382\n",
      "Epoch 1034 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1034.pth\n",
      "Epoch 1035 train loss: 0.6084717854024156\n",
      "Epoch 1035 train accuracy: 81.40937757060598\n",
      "Epoch 1035 val loss: 0.6005761309183741\n",
      "Epoch 1035 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1035.pth\n",
      "Epoch 1036 train loss: 0.6083999345601913\n",
      "Epoch 1036 train accuracy: 81.46421716479298\n",
      "Epoch 1036 val loss: 0.600515043510026\n",
      "Epoch 1036 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1036.pth\n",
      "Epoch 1037 train loss: 0.6083920308176363\n",
      "Epoch 1037 train accuracy: 81.46421716479298\n",
      "Epoch 1037 val loss: 0.6004669724130317\n",
      "Epoch 1037 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1037.pth\n",
      "Epoch 1038 train loss: 0.6083861320982116\n",
      "Epoch 1038 train accuracy: 81.54647655607349\n",
      "Epoch 1038 val loss: 0.6005327721175394\n",
      "Epoch 1038 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1038.pth\n",
      "Epoch 1039 train loss: 0.6083023722953441\n",
      "Epoch 1039 train accuracy: 81.38195777351248\n",
      "Epoch 1039 val loss: 0.6004568631515691\n",
      "Epoch 1039 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1039.pth\n",
      "Epoch 1040 train loss: 0.6082441106177213\n",
      "Epoch 1040 train accuracy: 81.46421716479298\n",
      "Epoch 1040 val loss: 0.6004169212262097\n",
      "Epoch 1040 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1040.pth\n",
      "Epoch 1041 train loss: 0.6082325696520376\n",
      "Epoch 1041 train accuracy: 81.51905675897999\n",
      "Epoch 1041 val loss: 0.6004601493477821\n",
      "Epoch 1041 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1041.pth\n",
      "Epoch 1042 train loss: 0.6081956348692378\n",
      "Epoch 1042 train accuracy: 81.46421716479298\n",
      "Epoch 1042 val loss: 0.6004352714180162\n",
      "Epoch 1042 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1042.pth\n",
      "Epoch 1043 train loss: 0.6081727994279119\n",
      "Epoch 1043 train accuracy: 81.40937757060598\n",
      "Epoch 1043 val loss: 0.6002911143985233\n",
      "Epoch 1043 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1043.pth\n",
      "Epoch 1044 train loss: 0.6081368860772305\n",
      "Epoch 1044 train accuracy: 81.51905675897999\n",
      "Epoch 1044 val loss: 0.6003015636417427\n",
      "Epoch 1044 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1044.pth\n",
      "Epoch 1045 train loss: 0.6080947793374786\n",
      "Epoch 1045 train accuracy: 81.51905675897999\n",
      "Epoch 1045 val loss: 0.600301935190433\n",
      "Epoch 1045 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1045.pth\n",
      "Epoch 1046 train loss: 0.6080168653279543\n",
      "Epoch 1046 train accuracy: 81.46421716479298\n",
      "Epoch 1046 val loss: 0.600203273572812\n",
      "Epoch 1046 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1046.pth\n",
      "Epoch 1047 train loss: 0.6079694014696175\n",
      "Epoch 1047 train accuracy: 81.38195777351248\n",
      "Epoch 1047 val loss: 0.600128786834447\n",
      "Epoch 1047 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1047.pth\n",
      "Epoch 1048 train loss: 0.6079809415203176\n",
      "Epoch 1048 train accuracy: 81.62873594735399\n",
      "Epoch 1048 val loss: 0.6002106263645386\n",
      "Epoch 1048 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1048.pth\n",
      "Epoch 1049 train loss: 0.6079317908243913\n",
      "Epoch 1049 train accuracy: 81.46421716479298\n",
      "Epoch 1049 val loss: 0.6000879251545197\n",
      "Epoch 1049 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1049.pth\n",
      "Epoch 1050 train loss: 0.6078766506622758\n",
      "Epoch 1050 train accuracy: 81.40937757060598\n",
      "Epoch 1050 val loss: 0.6000566496268699\n",
      "Epoch 1050 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1050.pth\n",
      "Epoch 1051 train loss: 0.6078478913721547\n",
      "Epoch 1051 train accuracy: 81.60131615026049\n",
      "Epoch 1051 val loss: 0.6000657802153575\n",
      "Epoch 1051 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1051.pth\n",
      "Epoch 1052 train loss: 0.6078046229096097\n",
      "Epoch 1052 train accuracy: 81.49163696188648\n",
      "Epoch 1052 val loss: 0.6000457652354318\n",
      "Epoch 1052 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1052.pth\n",
      "Epoch 1053 train loss: 0.6076962720406683\n",
      "Epoch 1053 train accuracy: 81.49163696188648\n",
      "Epoch 1053 val loss: 0.5999548874893471\n",
      "Epoch 1053 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1053.pth\n",
      "Epoch 1054 train loss: 0.6077146267093587\n",
      "Epoch 1054 train accuracy: 81.57389635316699\n",
      "Epoch 1054 val loss: 0.5999398605015717\n",
      "Epoch 1054 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1054.pth\n",
      "Epoch 1055 train loss: 0.6076795512385536\n",
      "Epoch 1055 train accuracy: 81.49163696188648\n",
      "Epoch 1055 val loss: 0.5998859899608713\n",
      "Epoch 1055 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1055.pth\n",
      "Epoch 1056 train loss: 0.6075960607513001\n",
      "Epoch 1056 train accuracy: 81.51905675897999\n",
      "Epoch 1056 val loss: 0.5998316682188919\n",
      "Epoch 1056 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1056.pth\n",
      "Epoch 1057 train loss: 0.6075945496967617\n",
      "Epoch 1057 train accuracy: 81.57389635316699\n",
      "Epoch 1057 val loss: 0.5998625661197462\n",
      "Epoch 1057 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1057.pth\n",
      "Epoch 1058 train loss: 0.6075512417183634\n",
      "Epoch 1058 train accuracy: 81.43679736769948\n",
      "Epoch 1058 val loss: 0.5997841124864001\n",
      "Epoch 1058 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1058.pth\n",
      "Epoch 1059 train loss: 0.6075215117940516\n",
      "Epoch 1059 train accuracy: 81.46421716479298\n",
      "Epoch 1059 val loss: 0.5997306014362135\n",
      "Epoch 1059 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1059.pth\n",
      "Epoch 1060 train loss: 0.6074690958485007\n",
      "Epoch 1060 train accuracy: 81.60131615026049\n",
      "Epoch 1060 val loss: 0.5996965319898567\n",
      "Epoch 1060 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1060.pth\n",
      "Epoch 1061 train loss: 0.6074238326727298\n",
      "Epoch 1061 train accuracy: 81.60131615026049\n",
      "Epoch 1061 val loss: 0.5996987382440191\n",
      "Epoch 1061 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1061.pth\n",
      "Epoch 1062 train loss: 0.6073928391070742\n",
      "Epoch 1062 train accuracy: 81.57389635316699\n",
      "Epoch 1062 val loss: 0.5996098098296084\n",
      "Epoch 1062 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1062.pth\n",
      "Epoch 1063 train loss: 0.6073581718496586\n",
      "Epoch 1063 train accuracy: 81.60131615026049\n",
      "Epoch 1063 val loss: 0.5995687576206891\n",
      "Epoch 1063 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1063.pth\n",
      "Epoch 1064 train loss: 0.6072996258817351\n",
      "Epoch 1064 train accuracy: 81.43679736769948\n",
      "Epoch 1064 val loss: 0.5995187152079061\n",
      "Epoch 1064 val accuracy: 82.31907894736842\n",
      "Saved model to .\\test_models/MLP_1064.pth\n",
      "Epoch 1065 train loss: 0.6072084169442716\n",
      "Epoch 1065 train accuracy: 81.68357554154099\n",
      "Epoch 1065 val loss: 0.5995353301987052\n",
      "Epoch 1065 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1065.pth\n",
      "Epoch 1066 train loss: 0.6071666304120108\n",
      "Epoch 1066 train accuracy: 81.60131615026049\n",
      "Epoch 1066 val loss: 0.5994871488135112\n",
      "Epoch 1066 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1066.pth\n",
      "Epoch 1067 train loss: 0.6072158290955582\n",
      "Epoch 1067 train accuracy: 81.62873594735399\n",
      "Epoch 1067 val loss: 0.5995491638191437\n",
      "Epoch 1067 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1067.pth\n",
      "Epoch 1068 train loss: 0.6071326520718765\n",
      "Epoch 1068 train accuracy: 81.60131615026049\n",
      "Epoch 1068 val loss: 0.5995554460800792\n",
      "Epoch 1068 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1068.pth\n",
      "Epoch 1069 train loss: 0.6070950424396678\n",
      "Epoch 1069 train accuracy: 81.57389635316699\n",
      "Epoch 1069 val loss: 0.5994975008070469\n",
      "Epoch 1069 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1069.pth\n",
      "Epoch 1070 train loss: 0.6070060411696894\n",
      "Epoch 1070 train accuracy: 81.57389635316699\n",
      "Epoch 1070 val loss: 0.5994431332341934\n",
      "Epoch 1070 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1070.pth\n",
      "Epoch 1071 train loss: 0.607010729496547\n",
      "Epoch 1071 train accuracy: 81.49163696188648\n",
      "Epoch 1071 val loss: 0.5993112473699608\n",
      "Epoch 1071 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1071.pth\n",
      "Epoch 1072 train loss: 0.6069187543828759\n",
      "Epoch 1072 train accuracy: 81.60131615026049\n",
      "Epoch 1072 val loss: 0.5992469767010525\n",
      "Epoch 1072 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1072.pth\n",
      "Epoch 1073 train loss: 0.6069336871926984\n",
      "Epoch 1073 train accuracy: 81.65615574444749\n",
      "Epoch 1073 val loss: 0.5992785597612199\n",
      "Epoch 1073 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1073.pth\n",
      "Epoch 1074 train loss: 0.6068384469601146\n",
      "Epoch 1074 train accuracy: 81.51905675897999\n",
      "Epoch 1074 val loss: 0.5992273612891471\n",
      "Epoch 1074 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1074.pth\n",
      "Epoch 1075 train loss: 0.6068726423474258\n",
      "Epoch 1075 train accuracy: 81.43679736769948\n",
      "Epoch 1075 val loss: 0.5992109178516426\n",
      "Epoch 1075 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1075.pth\n",
      "Epoch 1076 train loss: 0.6068004694881669\n",
      "Epoch 1076 train accuracy: 81.62873594735399\n",
      "Epoch 1076 val loss: 0.5992129105388334\n",
      "Epoch 1076 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1076.pth\n",
      "Epoch 1077 train loss: 0.6067208925337662\n",
      "Epoch 1077 train accuracy: 81.57389635316699\n",
      "Epoch 1077 val loss: 0.59916350176852\n",
      "Epoch 1077 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1077.pth\n",
      "Epoch 1078 train loss: 0.6066885473402707\n",
      "Epoch 1078 train accuracy: 81.57389635316699\n",
      "Epoch 1078 val loss: 0.5991516402481418\n",
      "Epoch 1078 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1078.pth\n",
      "Epoch 1079 train loss: 0.6066796586505676\n",
      "Epoch 1079 train accuracy: 81.60131615026049\n",
      "Epoch 1079 val loss: 0.5991972963766832\n",
      "Epoch 1079 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1079.pth\n",
      "Epoch 1080 train loss: 0.6066642676300386\n",
      "Epoch 1080 train accuracy: 81.51905675897999\n",
      "Epoch 1080 val loss: 0.5990971156248921\n",
      "Epoch 1080 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1080.pth\n",
      "Epoch 1081 train loss: 0.6065846406119434\n",
      "Epoch 1081 train accuracy: 81.60131615026049\n",
      "Epoch 1081 val loss: 0.599136979711291\n",
      "Epoch 1081 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1081.pth\n",
      "Epoch 1082 train loss: 0.6065701882706204\n",
      "Epoch 1082 train accuracy: 81.51905675897999\n",
      "Epoch 1082 val loss: 0.5989998555987289\n",
      "Epoch 1082 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1082.pth\n",
      "Epoch 1083 train loss: 0.6064989575462645\n",
      "Epoch 1083 train accuracy: 81.51905675897999\n",
      "Epoch 1083 val loss: 0.5990278148337415\n",
      "Epoch 1083 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1083.pth\n",
      "Epoch 1084 train loss: 0.606497878976689\n",
      "Epoch 1084 train accuracy: 81.43679736769948\n",
      "Epoch 1084 val loss: 0.5989578708908275\n",
      "Epoch 1084 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1084.pth\n",
      "Epoch 1085 train loss: 0.6064093162289315\n",
      "Epoch 1085 train accuracy: 81.46421716479298\n",
      "Epoch 1085 val loss: 0.598837962668193\n",
      "Epoch 1085 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1085.pth\n",
      "Epoch 1086 train loss: 0.6063998010042205\n",
      "Epoch 1086 train accuracy: 81.73841513572799\n",
      "Epoch 1086 val loss: 0.598952035272592\n",
      "Epoch 1086 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1086.pth\n",
      "Epoch 1087 train loss: 0.6063678696294102\n",
      "Epoch 1087 train accuracy: 81.49163696188648\n",
      "Epoch 1087 val loss: 0.5988517827109286\n",
      "Epoch 1087 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1087.pth\n",
      "Epoch 1088 train loss: 0.6062684733616678\n",
      "Epoch 1088 train accuracy: 81.49163696188648\n",
      "Epoch 1088 val loss: 0.598695934112919\n",
      "Epoch 1088 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1088.pth\n",
      "Epoch 1089 train loss: 0.606257563391537\n",
      "Epoch 1089 train accuracy: 81.54647655607349\n",
      "Epoch 1089 val loss: 0.5987870327049964\n",
      "Epoch 1089 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1089.pth\n",
      "Epoch 1090 train loss: 0.6061941777159902\n",
      "Epoch 1090 train accuracy: 81.54647655607349\n",
      "Epoch 1090 val loss: 0.5986683581906714\n",
      "Epoch 1090 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1090.pth\n",
      "Epoch 1091 train loss: 0.6062083558685947\n",
      "Epoch 1091 train accuracy: 81.51905675897999\n",
      "Epoch 1091 val loss: 0.598576259921844\n",
      "Epoch 1091 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1091.pth\n",
      "Epoch 1092 train loss: 0.6061976695139157\n",
      "Epoch 1092 train accuracy: 81.51905675897999\n",
      "Epoch 1092 val loss: 0.5985630857022969\n",
      "Epoch 1092 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1092.pth\n",
      "Epoch 1093 train loss: 0.6061393008975867\n",
      "Epoch 1093 train accuracy: 81.46421716479298\n",
      "Epoch 1093 val loss: 0.5985357403559121\n",
      "Epoch 1093 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1093.pth\n",
      "Epoch 1094 train loss: 0.6060804123908543\n",
      "Epoch 1094 train accuracy: 81.54647655607349\n",
      "Epoch 1094 val loss: 0.5985186955842533\n",
      "Epoch 1094 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1094.pth\n",
      "Epoch 1095 train loss: 0.6060541268405423\n",
      "Epoch 1095 train accuracy: 81.54647655607349\n",
      "Epoch 1095 val loss: 0.5984212153248096\n",
      "Epoch 1095 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1095.pth\n",
      "Epoch 1096 train loss: 0.6059696408184735\n",
      "Epoch 1096 train accuracy: 81.68357554154099\n",
      "Epoch 1096 val loss: 0.5985704391802612\n",
      "Epoch 1096 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1096.pth\n",
      "Epoch 1097 train loss: 0.6060004586419254\n",
      "Epoch 1097 train accuracy: 81.54647655607349\n",
      "Epoch 1097 val loss: 0.5984492855342595\n",
      "Epoch 1097 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1097.pth\n",
      "Epoch 1098 train loss: 0.6059252417303229\n",
      "Epoch 1098 train accuracy: 81.49163696188648\n",
      "Epoch 1098 val loss: 0.5984281463254439\n",
      "Epoch 1098 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1098.pth\n",
      "Epoch 1099 train loss: 0.6058898421429229\n",
      "Epoch 1099 train accuracy: 81.54647655607349\n",
      "Epoch 1099 val loss: 0.5985245229676366\n",
      "Epoch 1099 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1099.pth\n",
      "Epoch 1100 train loss: 0.6057989354849908\n",
      "Epoch 1100 train accuracy: 81.49163696188648\n",
      "Epoch 1100 val loss: 0.5984322385568368\n",
      "Epoch 1100 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1100.pth\n",
      "Epoch 1101 train loss: 0.6057990787125993\n",
      "Epoch 1101 train accuracy: 81.51905675897999\n",
      "Epoch 1101 val loss: 0.5982512630718319\n",
      "Epoch 1101 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1101.pth\n",
      "Epoch 1102 train loss: 0.6057599523807304\n",
      "Epoch 1102 train accuracy: 81.51905675897999\n",
      "Epoch 1102 val loss: 0.5982412108661312\n",
      "Epoch 1102 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1102.pth\n",
      "Epoch 1103 train loss: 0.6056971671549898\n",
      "Epoch 1103 train accuracy: 81.54647655607349\n",
      "Epoch 1103 val loss: 0.5982224463828301\n",
      "Epoch 1103 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1103.pth\n",
      "Epoch 1104 train loss: 0.6057236593935573\n",
      "Epoch 1104 train accuracy: 81.57389635316699\n",
      "Epoch 1104 val loss: 0.5981778198068863\n",
      "Epoch 1104 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1104.pth\n",
      "Epoch 1105 train loss: 0.6056638861303789\n",
      "Epoch 1105 train accuracy: 81.54647655607349\n",
      "Epoch 1105 val loss: 0.5981599173851704\n",
      "Epoch 1105 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1105.pth\n",
      "Epoch 1106 train loss: 0.605560158297681\n",
      "Epoch 1106 train accuracy: 81.54647655607349\n",
      "Epoch 1106 val loss: 0.5982199711234946\n",
      "Epoch 1106 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1106.pth\n",
      "Epoch 1107 train loss: 0.6055466418007487\n",
      "Epoch 1107 train accuracy: 81.51905675897999\n",
      "Epoch 1107 val loss: 0.5980507640756274\n",
      "Epoch 1107 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1107.pth\n",
      "Epoch 1108 train loss: 0.6055415230884886\n",
      "Epoch 1108 train accuracy: 81.62873594735399\n",
      "Epoch 1108 val loss: 0.598059242493228\n",
      "Epoch 1108 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1108.pth\n",
      "Epoch 1109 train loss: 0.6054652878164983\n",
      "Epoch 1109 train accuracy: 81.68357554154099\n",
      "Epoch 1109 val loss: 0.5981499854671327\n",
      "Epoch 1109 val accuracy: 82.31907894736842\n",
      "Saved model to .\\test_models/MLP_1109.pth\n",
      "Epoch 1110 train loss: 0.6054781280588686\n",
      "Epoch 1110 train accuracy: 81.60131615026049\n",
      "Epoch 1110 val loss: 0.5980914407164643\n",
      "Epoch 1110 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1110.pth\n",
      "Epoch 1111 train loss: 0.6054534870771724\n",
      "Epoch 1111 train accuracy: 81.51905675897999\n",
      "Epoch 1111 val loss: 0.5980543072678541\n",
      "Epoch 1111 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1111.pth\n",
      "Epoch 1112 train loss: 0.6053936676563401\n",
      "Epoch 1112 train accuracy: 81.60131615026049\n",
      "Epoch 1112 val loss: 0.5979424522405392\n",
      "Epoch 1112 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1112.pth\n",
      "Epoch 1113 train loss: 0.6053780865152938\n",
      "Epoch 1113 train accuracy: 81.49163696188648\n",
      "Epoch 1113 val loss: 0.5979167220525836\n",
      "Epoch 1113 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1113.pth\n",
      "Epoch 1114 train loss: 0.6052924318141059\n",
      "Epoch 1114 train accuracy: 81.57389635316699\n",
      "Epoch 1114 val loss: 0.5979422026951062\n",
      "Epoch 1114 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1114.pth\n",
      "Epoch 1115 train loss: 0.6052856414105025\n",
      "Epoch 1115 train accuracy: 81.60131615026049\n",
      "Epoch 1115 val loss: 0.5979168895435961\n",
      "Epoch 1115 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1115.pth\n",
      "Epoch 1116 train loss: 0.6052513455547262\n",
      "Epoch 1116 train accuracy: 81.51905675897999\n",
      "Epoch 1116 val loss: 0.5978814334559598\n",
      "Epoch 1116 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1116.pth\n",
      "Epoch 1117 train loss: 0.6051533926572454\n",
      "Epoch 1117 train accuracy: 81.60131615026049\n",
      "Epoch 1117 val loss: 0.5977824206807112\n",
      "Epoch 1117 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1117.pth\n",
      "Epoch 1118 train loss: 0.6051040780322071\n",
      "Epoch 1118 train accuracy: 81.65615574444749\n",
      "Epoch 1118 val loss: 0.5978010416668105\n",
      "Epoch 1118 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1118.pth\n",
      "Epoch 1119 train loss: 0.6051006121070761\n",
      "Epoch 1119 train accuracy: 81.60131615026049\n",
      "Epoch 1119 val loss: 0.5977969879382535\n",
      "Epoch 1119 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1119.pth\n",
      "Epoch 1120 train loss: 0.6050063949241712\n",
      "Epoch 1120 train accuracy: 81.57389635316699\n",
      "Epoch 1120 val loss: 0.597750620426316\n",
      "Epoch 1120 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1120.pth\n",
      "Epoch 1121 train loss: 0.6050624219177846\n",
      "Epoch 1121 train accuracy: 81.57389635316699\n",
      "Epoch 1121 val loss: 0.5977396212126079\n",
      "Epoch 1121 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1121.pth\n",
      "Epoch 1122 train loss: 0.6049573952658919\n",
      "Epoch 1122 train accuracy: 81.57389635316699\n",
      "Epoch 1122 val loss: 0.597756072143583\n",
      "Epoch 1122 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1122.pth\n",
      "Epoch 1123 train loss: 0.6049590440499678\n",
      "Epoch 1123 train accuracy: 81.49163696188648\n",
      "Epoch 1123 val loss: 0.5976388342188377\n",
      "Epoch 1123 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1123.pth\n",
      "Epoch 1124 train loss: 0.6049684437089845\n",
      "Epoch 1124 train accuracy: 81.62873594735399\n",
      "Epoch 1124 val loss: 0.5977083925451887\n",
      "Epoch 1124 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1124.pth\n",
      "Epoch 1125 train loss: 0.6048580354831198\n",
      "Epoch 1125 train accuracy: 81.54647655607349\n",
      "Epoch 1125 val loss: 0.5975663881062677\n",
      "Epoch 1125 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1125.pth\n",
      "Epoch 1126 train loss: 0.6048607763654569\n",
      "Epoch 1126 train accuracy: 81.60131615026049\n",
      "Epoch 1126 val loss: 0.5975126437352676\n",
      "Epoch 1126 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1126.pth\n",
      "Epoch 1127 train loss: 0.604842081094128\n",
      "Epoch 1127 train accuracy: 81.49163696188648\n",
      "Epoch 1127 val loss: 0.5974082508565564\n",
      "Epoch 1127 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1127.pth\n",
      "Epoch 1128 train loss: 0.6048219510305085\n",
      "Epoch 1128 train accuracy: 81.65615574444749\n",
      "Epoch 1128 val loss: 0.5974004468635509\n",
      "Epoch 1128 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1128.pth\n",
      "Epoch 1129 train loss: 0.604665565712933\n",
      "Epoch 1129 train accuracy: 81.60131615026049\n",
      "Epoch 1129 val loss: 0.5973828802571485\n",
      "Epoch 1129 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1129.pth\n",
      "Epoch 1130 train loss: 0.6047133260994757\n",
      "Epoch 1130 train accuracy: 81.57389635316699\n",
      "Epoch 1130 val loss: 0.597356871505709\n",
      "Epoch 1130 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1130.pth\n",
      "Epoch 1131 train loss: 0.6046117965393422\n",
      "Epoch 1131 train accuracy: 81.68357554154099\n",
      "Epoch 1131 val loss: 0.5974451725028063\n",
      "Epoch 1131 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1131.pth\n",
      "Epoch 1132 train loss: 0.6046838224620411\n",
      "Epoch 1132 train accuracy: 81.60131615026049\n",
      "Epoch 1132 val loss: 0.597337351180613\n",
      "Epoch 1132 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1132.pth\n",
      "Epoch 1133 train loss: 0.6046100580541972\n",
      "Epoch 1133 train accuracy: 81.57389635316699\n",
      "Epoch 1133 val loss: 0.5973183862423819\n",
      "Epoch 1133 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1133.pth\n",
      "Epoch 1134 train loss: 0.6045388583453339\n",
      "Epoch 1134 train accuracy: 81.60131615026049\n",
      "Epoch 1134 val loss: 0.5972605360377776\n",
      "Epoch 1134 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1134.pth\n",
      "Epoch 1135 train loss: 0.6044850043560329\n",
      "Epoch 1135 train accuracy: 81.60131615026049\n",
      "Epoch 1135 val loss: 0.5971955257026773\n",
      "Epoch 1135 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1135.pth\n",
      "Epoch 1136 train loss: 0.6045123868817953\n",
      "Epoch 1136 train accuracy: 81.62873594735399\n",
      "Epoch 1136 val loss: 0.5972879215290672\n",
      "Epoch 1136 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1136.pth\n",
      "Epoch 1137 train loss: 0.6044037594508967\n",
      "Epoch 1137 train accuracy: 81.60131615026049\n",
      "Epoch 1137 val loss: 0.5972588387636566\n",
      "Epoch 1137 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1137.pth\n",
      "Epoch 1138 train loss: 0.6044503303669524\n",
      "Epoch 1138 train accuracy: 81.60131615026049\n",
      "Epoch 1138 val loss: 0.5971885743599973\n",
      "Epoch 1138 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1138.pth\n",
      "Epoch 1139 train loss: 0.6044255063558618\n",
      "Epoch 1139 train accuracy: 81.57389635316699\n",
      "Epoch 1139 val loss: 0.5971512504314122\n",
      "Epoch 1139 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1139.pth\n",
      "Epoch 1140 train loss: 0.6043542214554914\n",
      "Epoch 1140 train accuracy: 81.71099533863449\n",
      "Epoch 1140 val loss: 0.5971199322099748\n",
      "Epoch 1140 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1140.pth\n",
      "Epoch 1141 train loss: 0.604337613866256\n",
      "Epoch 1141 train accuracy: 81.62873594735399\n",
      "Epoch 1141 val loss: 0.5971205829103526\n",
      "Epoch 1141 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1141.pth\n",
      "Epoch 1142 train loss: 0.6042663397659597\n",
      "Epoch 1142 train accuracy: 81.68357554154099\n",
      "Epoch 1142 val loss: 0.5971728078530807\n",
      "Epoch 1142 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1142.pth\n",
      "Epoch 1143 train loss: 0.6042687218930376\n",
      "Epoch 1143 train accuracy: 81.60131615026049\n",
      "Epoch 1143 val loss: 0.5970496062287375\n",
      "Epoch 1143 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1143.pth\n",
      "Epoch 1144 train loss: 0.6041885091874161\n",
      "Epoch 1144 train accuracy: 81.57389635316699\n",
      "Epoch 1144 val loss: 0.5970509654695266\n",
      "Epoch 1144 val accuracy: 82.48355263157895\n",
      "Saved model to .\\test_models/MLP_1144.pth\n",
      "Epoch 1145 train loss: 0.6041481474316434\n",
      "Epoch 1145 train accuracy: 81.57389635316699\n",
      "Epoch 1145 val loss: 0.5970842851031768\n",
      "Epoch 1145 val accuracy: 82.40131578947368\n",
      "Saved model to .\\test_models/MLP_1145.pth\n",
      "Epoch 1146 train loss: 0.6041738592218935\n",
      "Epoch 1146 train accuracy: 81.60131615026049\n",
      "Epoch 1146 val loss: 0.5969273511712488\n",
      "Epoch 1146 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1146.pth\n",
      "Epoch 1147 train loss: 0.6040053376029327\n",
      "Epoch 1147 train accuracy: 81.57389635316699\n",
      "Epoch 1147 val loss: 0.5968614161798829\n",
      "Epoch 1147 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1147.pth\n",
      "Epoch 1148 train loss: 0.6040602128364538\n",
      "Epoch 1148 train accuracy: 81.60131615026049\n",
      "Epoch 1148 val loss: 0.5968343029779039\n",
      "Epoch 1148 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1148.pth\n",
      "Epoch 1149 train loss: 0.6040328692220021\n",
      "Epoch 1149 train accuracy: 81.62873594735399\n",
      "Epoch 1149 val loss: 0.5968277624220049\n",
      "Epoch 1149 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1149.pth\n",
      "Epoch 1150 train loss: 0.6039859457921825\n",
      "Epoch 1150 train accuracy: 81.62873594735399\n",
      "Epoch 1150 val loss: 0.5968000223664077\n",
      "Epoch 1150 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1150.pth\n",
      "Epoch 1151 train loss: 0.6039902828633785\n",
      "Epoch 1151 train accuracy: 81.68357554154099\n",
      "Epoch 1151 val loss: 0.5967249591638776\n",
      "Epoch 1151 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1151.pth\n",
      "Epoch 1152 train loss: 0.6039532761440792\n",
      "Epoch 1152 train accuracy: 81.68357554154099\n",
      "Epoch 1152 val loss: 0.5966322296053955\n",
      "Epoch 1152 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1152.pth\n",
      "Epoch 1153 train loss: 0.6039216964946765\n",
      "Epoch 1153 train accuracy: 81.60131615026049\n",
      "Epoch 1153 val loss: 0.5966733204396931\n",
      "Epoch 1153 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1153.pth\n",
      "Epoch 1154 train loss: 0.6038778882816827\n",
      "Epoch 1154 train accuracy: 81.76583493282149\n",
      "Epoch 1154 val loss: 0.5966844485190353\n",
      "Epoch 1154 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1154.pth\n",
      "Epoch 1155 train loss: 0.6038475660443828\n",
      "Epoch 1155 train accuracy: 81.62873594735399\n",
      "Epoch 1155 val loss: 0.5966506503816498\n",
      "Epoch 1155 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1155.pth\n",
      "Epoch 1156 train loss: 0.603782797591728\n",
      "Epoch 1156 train accuracy: 81.65615574444749\n",
      "Epoch 1156 val loss: 0.5967396538410532\n",
      "Epoch 1156 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1156.pth\n",
      "Epoch 1157 train loss: 0.6037653415349492\n",
      "Epoch 1157 train accuracy: 81.68357554154099\n",
      "Epoch 1157 val loss: 0.5965157965884397\n",
      "Epoch 1157 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1157.pth\n",
      "Epoch 1158 train loss: 0.6037275479747015\n",
      "Epoch 1158 train accuracy: 81.79325472991499\n",
      "Epoch 1158 val loss: 0.5965383438589541\n",
      "Epoch 1158 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1158.pth\n",
      "Epoch 1159 train loss: 0.6036407390544027\n",
      "Epoch 1159 train accuracy: 81.73841513572799\n",
      "Epoch 1159 val loss: 0.5963974874956828\n",
      "Epoch 1159 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1159.pth\n",
      "Epoch 1160 train loss: 0.6036897952619352\n",
      "Epoch 1160 train accuracy: 81.73841513572799\n",
      "Epoch 1160 val loss: 0.5964612627990151\n",
      "Epoch 1160 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1160.pth\n",
      "Epoch 1161 train loss: 0.603637130375494\n",
      "Epoch 1161 train accuracy: 81.71099533863449\n",
      "Epoch 1161 val loss: 0.5963604806089088\n",
      "Epoch 1161 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1161.pth\n",
      "Epoch 1162 train loss: 0.6035952073963065\n",
      "Epoch 1162 train accuracy: 81.57389635316699\n",
      "Epoch 1162 val loss: 0.5963843454557815\n",
      "Epoch 1162 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1162.pth\n",
      "Epoch 1163 train loss: 0.6035169143752571\n",
      "Epoch 1163 train accuracy: 81.68357554154099\n",
      "Epoch 1163 val loss: 0.596358389299559\n",
      "Epoch 1163 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1163.pth\n",
      "Epoch 1164 train loss: 0.6035370717740112\n",
      "Epoch 1164 train accuracy: 81.76583493282149\n",
      "Epoch 1164 val loss: 0.5963836293667555\n",
      "Epoch 1164 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1164.pth\n",
      "Epoch 1165 train loss: 0.6034325565652627\n",
      "Epoch 1165 train accuracy: 81.60131615026049\n",
      "Epoch 1165 val loss: 0.596270718121607\n",
      "Epoch 1165 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1165.pth\n",
      "Epoch 1166 train loss: 0.6034808076934464\n",
      "Epoch 1166 train accuracy: 81.68357554154099\n",
      "Epoch 1166 val loss: 0.5962494506843781\n",
      "Epoch 1166 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1166.pth\n",
      "Epoch 1167 train loss: 0.6034464004465885\n",
      "Epoch 1167 train accuracy: 81.71099533863449\n",
      "Epoch 1167 val loss: 0.5962794290757493\n",
      "Epoch 1167 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1167.pth\n",
      "Epoch 1168 train loss: 0.6033474695133535\n",
      "Epoch 1168 train accuracy: 81.68357554154099\n",
      "Epoch 1168 val loss: 0.5961901423472323\n",
      "Epoch 1168 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1168.pth\n",
      "Epoch 1169 train loss: 0.6033701720206361\n",
      "Epoch 1169 train accuracy: 81.76583493282149\n",
      "Epoch 1169 val loss: 0.5962409894227197\n",
      "Epoch 1169 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1169.pth\n",
      "Epoch 1170 train loss: 0.6033164603766381\n",
      "Epoch 1170 train accuracy: 81.73841513572799\n",
      "Epoch 1170 val loss: 0.5961423670186808\n",
      "Epoch 1170 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1170.pth\n",
      "Epoch 1171 train loss: 0.603223935717292\n",
      "Epoch 1171 train accuracy: 81.65615574444749\n",
      "Epoch 1171 val loss: 0.5960817129694318\n",
      "Epoch 1171 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1171.pth\n",
      "Epoch 1172 train loss: 0.6032797599603471\n",
      "Epoch 1172 train accuracy: 81.73841513572799\n",
      "Epoch 1172 val loss: 0.5961021046203218\n",
      "Epoch 1172 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1172.pth\n",
      "Epoch 1173 train loss: 0.6031980191545332\n",
      "Epoch 1173 train accuracy: 81.73841513572799\n",
      "Epoch 1173 val loss: 0.5960143208993893\n",
      "Epoch 1173 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1173.pth\n",
      "Epoch 1174 train loss: 0.603179465227744\n",
      "Epoch 1174 train accuracy: 81.76583493282149\n",
      "Epoch 1174 val loss: 0.5959523529500553\n",
      "Epoch 1174 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1174.pth\n",
      "Epoch 1175 train loss: 0.6032106108113862\n",
      "Epoch 1175 train accuracy: 81.76583493282149\n",
      "Epoch 1175 val loss: 0.5960209461321172\n",
      "Epoch 1175 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1175.pth\n",
      "Epoch 1176 train loss: 0.6030920390039682\n",
      "Epoch 1176 train accuracy: 81.79325472991499\n",
      "Epoch 1176 val loss: 0.5960147122999555\n",
      "Epoch 1176 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1176.pth\n",
      "Epoch 1177 train loss: 0.6030502857542351\n",
      "Epoch 1177 train accuracy: 81.79325472991499\n",
      "Epoch 1177 val loss: 0.5961229633049745\n",
      "Epoch 1177 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1177.pth\n",
      "Epoch 1178 train loss: 0.6030344473557514\n",
      "Epoch 1178 train accuracy: 81.71099533863449\n",
      "Epoch 1178 val loss: 0.5960072818163195\n",
      "Epoch 1178 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1178.pth\n",
      "Epoch 1179 train loss: 0.6031022033441746\n",
      "Epoch 1179 train accuracy: 81.73841513572799\n",
      "Epoch 1179 val loss: 0.5959158115285007\n",
      "Epoch 1179 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1179.pth\n",
      "Epoch 1180 train loss: 0.6029897773997825\n",
      "Epoch 1180 train accuracy: 81.73841513572799\n",
      "Epoch 1180 val loss: 0.5957634521550254\n",
      "Epoch 1180 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1180.pth\n",
      "Epoch 1181 train loss: 0.6029142153269628\n",
      "Epoch 1181 train accuracy: 81.8206745270085\n",
      "Epoch 1181 val loss: 0.5958587649327359\n",
      "Epoch 1181 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1181.pth\n",
      "Epoch 1182 train loss: 0.6029407028435615\n",
      "Epoch 1182 train accuracy: 81.84809432410201\n",
      "Epoch 1182 val loss: 0.5957882397955185\n",
      "Epoch 1182 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1182.pth\n",
      "Epoch 1183 train loss: 0.6028220108301755\n",
      "Epoch 1183 train accuracy: 81.8206745270085\n",
      "Epoch 1183 val loss: 0.595771102773908\n",
      "Epoch 1183 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1183.pth\n",
      "Epoch 1184 train loss: 0.6028747346350237\n",
      "Epoch 1184 train accuracy: 81.8206745270085\n",
      "Epoch 1184 val loss: 0.5957503812387586\n",
      "Epoch 1184 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1184.pth\n",
      "Epoch 1185 train loss: 0.6027461681188199\n",
      "Epoch 1185 train accuracy: 81.95777351247601\n",
      "Epoch 1185 val loss: 0.5957558726597774\n",
      "Epoch 1185 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1185.pth\n",
      "Epoch 1186 train loss: 0.6028096740575213\n",
      "Epoch 1186 train accuracy: 81.79325472991499\n",
      "Epoch 1186 val loss: 0.5956781009016069\n",
      "Epoch 1186 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1186.pth\n",
      "Epoch 1187 train loss: 0.6027623980322427\n",
      "Epoch 1187 train accuracy: 81.90293391828901\n",
      "Epoch 1187 val loss: 0.5956096330069398\n",
      "Epoch 1187 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1187.pth\n",
      "Epoch 1188 train loss: 0.6027444764612275\n",
      "Epoch 1188 train accuracy: 81.87551412119551\n",
      "Epoch 1188 val loss: 0.595730214085626\n",
      "Epoch 1188 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1188.pth\n",
      "Epoch 1189 train loss: 0.6027026866121512\n",
      "Epoch 1189 train accuracy: 81.87551412119551\n",
      "Epoch 1189 val loss: 0.5956700557450715\n",
      "Epoch 1189 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1189.pth\n",
      "Epoch 1190 train loss: 0.6025914480060077\n",
      "Epoch 1190 train accuracy: 81.93035371538251\n",
      "Epoch 1190 val loss: 0.5956257067032551\n",
      "Epoch 1190 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1190.pth\n",
      "Epoch 1191 train loss: 0.602604065768486\n",
      "Epoch 1191 train accuracy: 81.84809432410201\n",
      "Epoch 1191 val loss: 0.5955984102758137\n",
      "Epoch 1191 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1191.pth\n",
      "Epoch 1192 train loss: 0.6025556866079569\n",
      "Epoch 1192 train accuracy: 81.79325472991499\n",
      "Epoch 1192 val loss: 0.5956180174099771\n",
      "Epoch 1192 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1192.pth\n",
      "Epoch 1193 train loss: 0.6025972482666635\n",
      "Epoch 1193 train accuracy: 81.90293391828901\n",
      "Epoch 1193 val loss: 0.5955199825234319\n",
      "Epoch 1193 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1193.pth\n",
      "Epoch 1194 train loss: 0.6025516029524928\n",
      "Epoch 1194 train accuracy: 81.90293391828901\n",
      "Epoch 1194 val loss: 0.595482765157756\n",
      "Epoch 1194 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1194.pth\n",
      "Epoch 1195 train loss: 0.6024596314027644\n",
      "Epoch 1195 train accuracy: 81.93035371538251\n",
      "Epoch 1195 val loss: 0.5954830182814285\n",
      "Epoch 1195 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1195.pth\n",
      "Epoch 1196 train loss: 0.6024350429100818\n",
      "Epoch 1196 train accuracy: 81.98519330956951\n",
      "Epoch 1196 val loss: 0.5954209446514908\n",
      "Epoch 1196 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1196.pth\n",
      "Epoch 1197 train loss: 0.6023893662679353\n",
      "Epoch 1197 train accuracy: 81.93035371538251\n",
      "Epoch 1197 val loss: 0.5953174163832476\n",
      "Epoch 1197 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1197.pth\n",
      "Epoch 1198 train loss: 0.6024085386215072\n",
      "Epoch 1198 train accuracy: 81.87551412119551\n",
      "Epoch 1198 val loss: 0.5952718950513947\n",
      "Epoch 1198 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1198.pth\n",
      "Epoch 1199 train loss: 0.602346163831259\n",
      "Epoch 1199 train accuracy: 81.90293391828901\n",
      "Epoch 1199 val loss: 0.5952710029424021\n",
      "Epoch 1199 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1199.pth\n",
      "Epoch 1200 train loss: 0.6023040139688212\n",
      "Epoch 1200 train accuracy: 81.93035371538251\n",
      "Epoch 1200 val loss: 0.5952895982681137\n",
      "Epoch 1200 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1200.pth\n",
      "Epoch 1201 train loss: 0.6023326995128995\n",
      "Epoch 1201 train accuracy: 81.87551412119551\n",
      "Epoch 1201 val loss: 0.5952791204970134\n",
      "Epoch 1201 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1201.pth\n",
      "Epoch 1202 train loss: 0.6023056863790803\n",
      "Epoch 1202 train accuracy: 81.90293391828901\n",
      "Epoch 1202 val loss: 0.5953101653017496\n",
      "Epoch 1202 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1202.pth\n",
      "Epoch 1203 train loss: 0.6022713149881416\n",
      "Epoch 1203 train accuracy: 81.93035371538251\n",
      "Epoch 1203 val loss: 0.595187194302286\n",
      "Epoch 1203 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1203.pth\n",
      "Epoch 1204 train loss: 0.6022462752574173\n",
      "Epoch 1204 train accuracy: 81.84809432410201\n",
      "Epoch 1204 val loss: 0.5951665428614146\n",
      "Epoch 1204 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1204.pth\n",
      "Epoch 1205 train loss: 0.6022045772130552\n",
      "Epoch 1205 train accuracy: 81.90293391828901\n",
      "Epoch 1205 val loss: 0.5951777663768122\n",
      "Epoch 1205 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1205.pth\n",
      "Epoch 1206 train loss: 0.6021859659078089\n",
      "Epoch 1206 train accuracy: 81.87551412119551\n",
      "Epoch 1206 val loss: 0.5951410657971313\n",
      "Epoch 1206 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1206.pth\n",
      "Epoch 1207 train loss: 0.6020905565339745\n",
      "Epoch 1207 train accuracy: 82.04003290375651\n",
      "Epoch 1207 val loss: 0.5950600493111109\n",
      "Epoch 1207 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1207.pth\n",
      "Epoch 1208 train loss: 0.6021040650248005\n",
      "Epoch 1208 train accuracy: 81.90293391828901\n",
      "Epoch 1208 val loss: 0.5951223139111933\n",
      "Epoch 1208 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1208.pth\n",
      "Epoch 1209 train loss: 0.602017389169257\n",
      "Epoch 1209 train accuracy: 81.93035371538251\n",
      "Epoch 1209 val loss: 0.5950333862810543\n",
      "Epoch 1209 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1209.pth\n",
      "Epoch 1210 train loss: 0.60204205890758\n",
      "Epoch 1210 train accuracy: 81.98519330956951\n",
      "Epoch 1210 val loss: 0.5949236488852062\n",
      "Epoch 1210 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1210.pth\n",
      "Epoch 1211 train loss: 0.6020251282311061\n",
      "Epoch 1211 train accuracy: 82.01261310666301\n",
      "Epoch 1211 val loss: 0.5949227088376096\n",
      "Epoch 1211 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1211.pth\n",
      "Epoch 1212 train loss: 0.6019889956111448\n",
      "Epoch 1212 train accuracy: 81.95777351247601\n",
      "Epoch 1212 val loss: 0.5948588612832522\n",
      "Epoch 1212 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1212.pth\n",
      "Epoch 1213 train loss: 0.6019692788586805\n",
      "Epoch 1213 train accuracy: 82.06745270085001\n",
      "Epoch 1213 val loss: 0.5948446194984411\n",
      "Epoch 1213 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1213.pth\n",
      "Epoch 1214 train loss: 0.6019346197544221\n",
      "Epoch 1214 train accuracy: 82.01261310666301\n",
      "Epoch 1214 val loss: 0.5948041077997339\n",
      "Epoch 1214 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1214.pth\n",
      "Epoch 1215 train loss: 0.6018315610790363\n",
      "Epoch 1215 train accuracy: 81.87551412119551\n",
      "Epoch 1215 val loss: 0.5948315543661776\n",
      "Epoch 1215 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1215.pth\n",
      "Epoch 1216 train loss: 0.6018053436684504\n",
      "Epoch 1216 train accuracy: 82.04003290375651\n",
      "Epoch 1216 val loss: 0.5948785587066883\n",
      "Epoch 1216 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1216.pth\n",
      "Epoch 1217 train loss: 0.6018085933061676\n",
      "Epoch 1217 train accuracy: 82.04003290375651\n",
      "Epoch 1217 val loss: 0.5947275423493824\n",
      "Epoch 1217 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1217.pth\n",
      "Epoch 1218 train loss: 0.6018128592618986\n",
      "Epoch 1218 train accuracy: 81.98519330956951\n",
      "Epoch 1218 val loss: 0.5947389466393935\n",
      "Epoch 1218 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1218.pth\n",
      "Epoch 1219 train loss: 0.6017767835016313\n",
      "Epoch 1219 train accuracy: 82.01261310666301\n",
      "Epoch 1219 val loss: 0.5947686975429717\n",
      "Epoch 1219 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1219.pth\n",
      "Epoch 1220 train loss: 0.6017383410056171\n",
      "Epoch 1220 train accuracy: 81.95777351247601\n",
      "Epoch 1220 val loss: 0.5947479763509411\n",
      "Epoch 1220 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1220.pth\n",
      "Epoch 1221 train loss: 0.6017120213885057\n",
      "Epoch 1221 train accuracy: 82.06745270085001\n",
      "Epoch 1221 val loss: 0.5946926557409921\n",
      "Epoch 1221 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1221.pth\n",
      "Epoch 1222 train loss: 0.6016774524264691\n",
      "Epoch 1222 train accuracy: 81.98519330956951\n",
      "Epoch 1222 val loss: 0.5946869341362464\n",
      "Epoch 1222 val accuracy: 82.5657894736842\n",
      "Saved model to .\\test_models/MLP_1222.pth\n",
      "Epoch 1223 train loss: 0.6016341335009456\n",
      "Epoch 1223 train accuracy: 81.95777351247601\n",
      "Epoch 1223 val loss: 0.5945994335863936\n",
      "Epoch 1223 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1223.pth\n",
      "Epoch 1224 train loss: 0.6016143785805947\n",
      "Epoch 1224 train accuracy: 82.04003290375651\n",
      "Epoch 1224 val loss: 0.59455364418069\n",
      "Epoch 1224 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1224.pth\n",
      "Epoch 1225 train loss: 0.601602203122814\n",
      "Epoch 1225 train accuracy: 82.09487249794351\n",
      "Epoch 1225 val loss: 0.5945168746341216\n",
      "Epoch 1225 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1225.pth\n",
      "Epoch 1226 train loss: 0.6014803837609004\n",
      "Epoch 1226 train accuracy: 82.04003290375651\n",
      "Epoch 1226 val loss: 0.5945020609192158\n",
      "Epoch 1226 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1226.pth\n",
      "Epoch 1227 train loss: 0.6015229723661354\n",
      "Epoch 1227 train accuracy: 81.98519330956951\n",
      "Epoch 1227 val loss: 0.5943902034655606\n",
      "Epoch 1227 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1227.pth\n",
      "Epoch 1228 train loss: 0.6014806291970768\n",
      "Epoch 1228 train accuracy: 82.04003290375651\n",
      "Epoch 1228 val loss: 0.5944698155906639\n",
      "Epoch 1228 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1228.pth\n",
      "Epoch 1229 train loss: 0.6014592933484859\n",
      "Epoch 1229 train accuracy: 81.95777351247601\n",
      "Epoch 1229 val loss: 0.5943755473647463\n",
      "Epoch 1229 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1229.pth\n",
      "Epoch 1230 train loss: 0.6013854066351134\n",
      "Epoch 1230 train accuracy: 82.06745270085001\n",
      "Epoch 1230 val loss: 0.5943258295178806\n",
      "Epoch 1230 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1230.pth\n",
      "Epoch 1231 train loss: 0.6014185686383331\n",
      "Epoch 1231 train accuracy: 81.98519330956951\n",
      "Epoch 1231 val loss: 0.5943074901343176\n",
      "Epoch 1231 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1231.pth\n",
      "Epoch 1232 train loss: 0.6013931432706222\n",
      "Epoch 1232 train accuracy: 81.98519330956951\n",
      "Epoch 1232 val loss: 0.5943617498208034\n",
      "Epoch 1232 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1232.pth\n",
      "Epoch 1233 train loss: 0.6013061612877145\n",
      "Epoch 1233 train accuracy: 82.04003290375651\n",
      "Epoch 1233 val loss: 0.5943468049364654\n",
      "Epoch 1233 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1233.pth\n",
      "Epoch 1234 train loss: 0.6012729477921599\n",
      "Epoch 1234 train accuracy: 81.95777351247601\n",
      "Epoch 1234 val loss: 0.5943499853540408\n",
      "Epoch 1234 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1234.pth\n",
      "Epoch 1235 train loss: 0.6012777391853824\n",
      "Epoch 1235 train accuracy: 81.95777351247601\n",
      "Epoch 1235 val loss: 0.5942240463765828\n",
      "Epoch 1235 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1235.pth\n",
      "Epoch 1236 train loss: 0.6011788163726267\n",
      "Epoch 1236 train accuracy: 81.98519330956951\n",
      "Epoch 1236 val loss: 0.5942194924052608\n",
      "Epoch 1236 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1236.pth\n",
      "Epoch 1237 train loss: 0.6012320882199627\n",
      "Epoch 1237 train accuracy: 82.01261310666301\n",
      "Epoch 1237 val loss: 0.5941402822438824\n",
      "Epoch 1237 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1237.pth\n",
      "Epoch 1238 train loss: 0.6011256791422503\n",
      "Epoch 1238 train accuracy: 82.01261310666301\n",
      "Epoch 1238 val loss: 0.5941940567113067\n",
      "Epoch 1238 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1238.pth\n",
      "Epoch 1239 train loss: 0.6010710488792443\n",
      "Epoch 1239 train accuracy: 81.93035371538251\n",
      "Epoch 1239 val loss: 0.5941438075939292\n",
      "Epoch 1239 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1239.pth\n",
      "Epoch 1240 train loss: 0.601154445866613\n",
      "Epoch 1240 train accuracy: 82.04003290375651\n",
      "Epoch 1240 val loss: 0.5941444018757657\n",
      "Epoch 1240 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1240.pth\n",
      "Epoch 1241 train loss: 0.6010779075553281\n",
      "Epoch 1241 train accuracy: 82.01261310666301\n",
      "Epoch 1241 val loss: 0.5941028359689211\n",
      "Epoch 1241 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1241.pth\n",
      "Epoch 1242 train loss: 0.6010542737254709\n",
      "Epoch 1242 train accuracy: 81.95777351247601\n",
      "Epoch 1242 val loss: 0.5940778324086415\n",
      "Epoch 1242 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1242.pth\n",
      "Epoch 1243 train loss: 0.601022225657576\n",
      "Epoch 1243 train accuracy: 82.06745270085001\n",
      "Epoch 1243 val loss: 0.5940806850006706\n",
      "Epoch 1243 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1243.pth\n",
      "Epoch 1244 train loss: 0.6010648283715311\n",
      "Epoch 1244 train accuracy: 82.04003290375651\n",
      "Epoch 1244 val loss: 0.5940545221888706\n",
      "Epoch 1244 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1244.pth\n",
      "Epoch 1245 train loss: 0.600930471332711\n",
      "Epoch 1245 train accuracy: 82.01261310666301\n",
      "Epoch 1245 val loss: 0.5940566782496477\n",
      "Epoch 1245 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1245.pth\n",
      "Epoch 1246 train loss: 0.6009923420487004\n",
      "Epoch 1246 train accuracy: 82.01261310666301\n",
      "Epoch 1246 val loss: 0.5939862604596113\n",
      "Epoch 1246 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1246.pth\n",
      "Epoch 1247 train loss: 0.60093359249693\n",
      "Epoch 1247 train accuracy: 82.04003290375651\n",
      "Epoch 1247 val loss: 0.5939966018164629\n",
      "Epoch 1247 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1247.pth\n",
      "Epoch 1248 train loss: 0.6009285694576407\n",
      "Epoch 1248 train accuracy: 81.98519330956951\n",
      "Epoch 1248 val loss: 0.5939206862332005\n",
      "Epoch 1248 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1248.pth\n",
      "Epoch 1249 train loss: 0.6008344193299612\n",
      "Epoch 1249 train accuracy: 82.01261310666301\n",
      "Epoch 1249 val loss: 0.5938770075475699\n",
      "Epoch 1249 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1249.pth\n",
      "Epoch 1250 train loss: 0.6008784927166345\n",
      "Epoch 1250 train accuracy: 82.01261310666301\n",
      "Epoch 1250 val loss: 0.5938413805377326\n",
      "Epoch 1250 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1250.pth\n",
      "Epoch 1251 train loss: 0.6007671831175685\n",
      "Epoch 1251 train accuracy: 82.04003290375651\n",
      "Epoch 1251 val loss: 0.593862594791541\n",
      "Epoch 1251 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1251.pth\n",
      "Epoch 1252 train loss: 0.6007974147061376\n",
      "Epoch 1252 train accuracy: 81.93035371538251\n",
      "Epoch 1252 val loss: 0.593848024494946\n",
      "Epoch 1252 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1252.pth\n",
      "Epoch 1253 train loss: 0.6007769523860413\n",
      "Epoch 1253 train accuracy: 82.04003290375651\n",
      "Epoch 1253 val loss: 0.5937782614246795\n",
      "Epoch 1253 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1253.pth\n",
      "Epoch 1254 train loss: 0.6006803325001608\n",
      "Epoch 1254 train accuracy: 82.04003290375651\n",
      "Epoch 1254 val loss: 0.5936526966428286\n",
      "Epoch 1254 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1254.pth\n",
      "Epoch 1255 train loss: 0.6006721297050255\n",
      "Epoch 1255 train accuracy: 82.04003290375651\n",
      "Epoch 1255 val loss: 0.5936853648408463\n",
      "Epoch 1255 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1255.pth\n",
      "Epoch 1256 train loss: 0.6006855430865758\n",
      "Epoch 1256 train accuracy: 82.09487249794351\n",
      "Epoch 1256 val loss: 0.5937178321917983\n",
      "Epoch 1256 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1256.pth\n",
      "Epoch 1257 train loss: 0.6005908702908639\n",
      "Epoch 1257 train accuracy: 82.04003290375651\n",
      "Epoch 1257 val loss: 0.5937440826704627\n",
      "Epoch 1257 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1257.pth\n",
      "Epoch 1258 train loss: 0.6005768761479933\n",
      "Epoch 1258 train accuracy: 82.06745270085001\n",
      "Epoch 1258 val loss: 0.5937326432842958\n",
      "Epoch 1258 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1258.pth\n",
      "Epoch 1259 train loss: 0.6006042826267188\n",
      "Epoch 1259 train accuracy: 81.98519330956951\n",
      "Epoch 1259 val loss: 0.5936775811898866\n",
      "Epoch 1259 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1259.pth\n",
      "Epoch 1260 train loss: 0.6005808251109301\n",
      "Epoch 1260 train accuracy: 81.98519330956951\n",
      "Epoch 1260 val loss: 0.5936006838455796\n",
      "Epoch 1260 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1260.pth\n",
      "Epoch 1261 train loss: 0.6004620449160013\n",
      "Epoch 1261 train accuracy: 82.01261310666301\n",
      "Epoch 1261 val loss: 0.5935284269875601\n",
      "Epoch 1261 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1261.pth\n",
      "Epoch 1262 train loss: 0.6004569325677789\n",
      "Epoch 1262 train accuracy: 82.09487249794351\n",
      "Epoch 1262 val loss: 0.5934848967253378\n",
      "Epoch 1262 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1262.pth\n",
      "Epoch 1263 train loss: 0.6004624260883582\n",
      "Epoch 1263 train accuracy: 82.06745270085001\n",
      "Epoch 1263 val loss: 0.5934689059167316\n",
      "Epoch 1263 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1263.pth\n",
      "Epoch 1264 train loss: 0.6004659438571125\n",
      "Epoch 1264 train accuracy: 82.01261310666301\n",
      "Epoch 1264 val loss: 0.5934302205906102\n",
      "Epoch 1264 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1264.pth\n",
      "Epoch 1265 train loss: 0.6003461103690299\n",
      "Epoch 1265 train accuracy: 82.04003290375651\n",
      "Epoch 1265 val loss: 0.5934892256106985\n",
      "Epoch 1265 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1265.pth\n",
      "Epoch 1266 train loss: 0.6003743257667673\n",
      "Epoch 1266 train accuracy: 82.09487249794351\n",
      "Epoch 1266 val loss: 0.5934335828611725\n",
      "Epoch 1266 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1266.pth\n",
      "Epoch 1267 train loss: 0.6003812508526862\n",
      "Epoch 1267 train accuracy: 82.12229229503701\n",
      "Epoch 1267 val loss: 0.5933937313231198\n",
      "Epoch 1267 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1267.pth\n",
      "Epoch 1268 train loss: 0.6003048220289904\n",
      "Epoch 1268 train accuracy: 82.12229229503701\n",
      "Epoch 1268 val loss: 0.593482155254797\n",
      "Epoch 1268 val accuracy: 82.64802631578948\n",
      "Saved model to .\\test_models/MLP_1268.pth\n",
      "Epoch 1269 train loss: 0.6003369512690002\n",
      "Epoch 1269 train accuracy: 82.06745270085001\n",
      "Epoch 1269 val loss: 0.5934355045717797\n",
      "Epoch 1269 val accuracy: 82.73026315789474\n",
      "Saved model to .\\test_models/MLP_1269.pth\n",
      "Epoch 1270 train loss: 0.6003049941439378\n",
      "Epoch 1270 train accuracy: 82.01261310666301\n",
      "Epoch 1270 val loss: 0.5933144594983835\n",
      "Epoch 1270 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1270.pth\n",
      "Epoch 1271 train loss: 0.6002292272455075\n",
      "Epoch 1271 train accuracy: 82.06745270085001\n",
      "Epoch 1271 val loss: 0.5933172495447492\n",
      "Epoch 1271 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1271.pth\n",
      "Epoch 1272 train loss: 0.6001861382667956\n",
      "Epoch 1272 train accuracy: 82.06745270085001\n",
      "Epoch 1272 val loss: 0.5932267695469292\n",
      "Epoch 1272 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1272.pth\n",
      "Epoch 1273 train loss: 0.6001509847609621\n",
      "Epoch 1273 train accuracy: 82.12229229503701\n",
      "Epoch 1273 val loss: 0.593269197809461\n",
      "Epoch 1273 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1273.pth\n",
      "Epoch 1274 train loss: 0.6001700595217315\n",
      "Epoch 1274 train accuracy: 82.09487249794351\n",
      "Epoch 1274 val loss: 0.5932976682425329\n",
      "Epoch 1274 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1274.pth\n",
      "Epoch 1275 train loss: 0.6001118292639914\n",
      "Epoch 1275 train accuracy: 81.98519330956951\n",
      "Epoch 1275 val loss: 0.5931666818888564\n",
      "Epoch 1275 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1275.pth\n",
      "Epoch 1276 train loss: 0.6001381664618588\n",
      "Epoch 1276 train accuracy: 82.06745270085001\n",
      "Epoch 1276 val loss: 0.593159289295344\n",
      "Epoch 1276 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1276.pth\n",
      "Epoch 1277 train loss: 0.6000682941490882\n",
      "Epoch 1277 train accuracy: 82.12229229503701\n",
      "Epoch 1277 val loss: 0.5931687207010231\n",
      "Epoch 1277 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1277.pth\n",
      "Epoch 1278 train loss: 0.6000676475865603\n",
      "Epoch 1278 train accuracy: 82.12229229503701\n",
      "Epoch 1278 val loss: 0.5931923874702892\n",
      "Epoch 1278 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1278.pth\n",
      "Epoch 1279 train loss: 0.6000280127484809\n",
      "Epoch 1279 train accuracy: 82.09487249794351\n",
      "Epoch 1279 val loss: 0.59314592430172\n",
      "Epoch 1279 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1279.pth\n",
      "Epoch 1280 train loss: 0.6000376577211315\n",
      "Epoch 1280 train accuracy: 82.09487249794351\n",
      "Epoch 1280 val loss: 0.5930948049124134\n",
      "Epoch 1280 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1280.pth\n",
      "Epoch 1281 train loss: 0.6000129719215789\n",
      "Epoch 1281 train accuracy: 82.09487249794351\n",
      "Epoch 1281 val loss: 0.5930321284716851\n",
      "Epoch 1281 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1281.pth\n",
      "Epoch 1282 train loss: 0.5999192935496307\n",
      "Epoch 1282 train accuracy: 82.12229229503701\n",
      "Epoch 1282 val loss: 0.5930258441030195\n",
      "Epoch 1282 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1282.pth\n",
      "Epoch 1283 train loss: 0.5998841559906539\n",
      "Epoch 1283 train accuracy: 82.09487249794351\n",
      "Epoch 1283 val loss: 0.5929544693055121\n",
      "Epoch 1283 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1283.pth\n",
      "Epoch 1284 train loss: 0.5997932280756926\n",
      "Epoch 1284 train accuracy: 82.12229229503701\n",
      "Epoch 1284 val loss: 0.5929606476504552\n",
      "Epoch 1284 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1284.pth\n",
      "Epoch 1285 train loss: 0.5999069181842762\n",
      "Epoch 1285 train accuracy: 82.14971209213051\n",
      "Epoch 1285 val loss: 0.5929205459542572\n",
      "Epoch 1285 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1285.pth\n",
      "Epoch 1286 train loss: 0.5998630660929178\n",
      "Epoch 1286 train accuracy: 82.04003290375651\n",
      "Epoch 1286 val loss: 0.5929121711340389\n",
      "Epoch 1286 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1286.pth\n",
      "Epoch 1287 train loss: 0.5998335051464668\n",
      "Epoch 1287 train accuracy: 82.09487249794351\n",
      "Epoch 1287 val loss: 0.5929187720995455\n",
      "Epoch 1287 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1287.pth\n",
      "Epoch 1288 train loss: 0.5998156252888995\n",
      "Epoch 1288 train accuracy: 82.14971209213051\n",
      "Epoch 1288 val loss: 0.5928629538240401\n",
      "Epoch 1288 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1288.pth\n",
      "Epoch 1289 train loss: 0.5996881873626926\n",
      "Epoch 1289 train accuracy: 82.23197148341102\n",
      "Epoch 1289 val loss: 0.5928282214720783\n",
      "Epoch 1289 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1289.pth\n",
      "Epoch 1290 train loss: 0.5997104495763779\n",
      "Epoch 1290 train accuracy: 82.14971209213051\n",
      "Epoch 1290 val loss: 0.5928156147465894\n",
      "Epoch 1290 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1290.pth\n",
      "Epoch 1291 train loss: 0.599735426741015\n",
      "Epoch 1291 train accuracy: 82.14971209213051\n",
      "Epoch 1291 val loss: 0.5927869694209412\n",
      "Epoch 1291 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1291.pth\n",
      "Epoch 1292 train loss: 0.5997051722125003\n",
      "Epoch 1292 train accuracy: 82.20455168631752\n",
      "Epoch 1292 val loss: 0.5927621836921102\n",
      "Epoch 1292 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1292.pth\n",
      "Epoch 1293 train loss: 0.5996337593778184\n",
      "Epoch 1293 train accuracy: 82.01261310666301\n",
      "Epoch 1293 val loss: 0.5927044770827419\n",
      "Epoch 1293 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1293.pth\n",
      "Epoch 1294 train loss: 0.599645407543632\n",
      "Epoch 1294 train accuracy: 82.17713188922401\n",
      "Epoch 1294 val loss: 0.5927121642682898\n",
      "Epoch 1294 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1294.pth\n",
      "Epoch 1295 train loss: 0.5995214531328856\n",
      "Epoch 1295 train accuracy: 82.12229229503701\n",
      "Epoch 1295 val loss: 0.5926489723160079\n",
      "Epoch 1295 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1295.pth\n",
      "Epoch 1296 train loss: 0.5995158775497162\n",
      "Epoch 1296 train accuracy: 82.17713188922401\n",
      "Epoch 1296 val loss: 0.5926480714329764\n",
      "Epoch 1296 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1296.pth\n",
      "Epoch 1297 train loss: 0.599576606627619\n",
      "Epoch 1297 train accuracy: 82.09487249794351\n",
      "Epoch 1297 val loss: 0.5925993043929338\n",
      "Epoch 1297 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1297.pth\n",
      "Epoch 1298 train loss: 0.5995833240449429\n",
      "Epoch 1298 train accuracy: 82.12229229503701\n",
      "Epoch 1298 val loss: 0.5925615266130894\n",
      "Epoch 1298 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1298.pth\n",
      "Epoch 1299 train loss: 0.5995119059327663\n",
      "Epoch 1299 train accuracy: 82.12229229503701\n",
      "Epoch 1299 val loss: 0.59257015478062\n",
      "Epoch 1299 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1299.pth\n",
      "Epoch 1300 train loss: 0.5994650729882874\n",
      "Epoch 1300 train accuracy: 82.17713188922401\n",
      "Epoch 1300 val loss: 0.5926740772012732\n",
      "Epoch 1300 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1300.pth\n",
      "Epoch 1301 train loss: 0.5994035758143454\n",
      "Epoch 1301 train accuracy: 82.09487249794351\n",
      "Epoch 1301 val loss: 0.5926103081897294\n",
      "Epoch 1301 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1301.pth\n",
      "Epoch 1302 train loss: 0.5993939713950742\n",
      "Epoch 1302 train accuracy: 82.06745270085001\n",
      "Epoch 1302 val loss: 0.592560221784209\n",
      "Epoch 1302 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1302.pth\n",
      "Epoch 1303 train loss: 0.5994065915675539\n",
      "Epoch 1303 train accuracy: 82.12229229503701\n",
      "Epoch 1303 val loss: 0.5925323231341807\n",
      "Epoch 1303 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1303.pth\n",
      "Epoch 1304 train loss: 0.5994064119611785\n",
      "Epoch 1304 train accuracy: 82.06745270085001\n",
      "Epoch 1304 val loss: 0.5924335190732228\n",
      "Epoch 1304 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1304.pth\n",
      "Epoch 1305 train loss: 0.5993570579509986\n",
      "Epoch 1305 train accuracy: 82.14971209213051\n",
      "Epoch 1305 val loss: 0.5924338730738351\n",
      "Epoch 1305 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1305.pth\n",
      "Epoch 1306 train loss: 0.5993315478329334\n",
      "Epoch 1306 train accuracy: 82.12229229503701\n",
      "Epoch 1306 val loss: 0.5925629799695391\n",
      "Epoch 1306 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1306.pth\n",
      "Epoch 1307 train loss: 0.5992999468325523\n",
      "Epoch 1307 train accuracy: 82.12229229503701\n",
      "Epoch 1307 val loss: 0.5924103229404672\n",
      "Epoch 1307 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1307.pth\n",
      "Epoch 1308 train loss: 0.5991764800590381\n",
      "Epoch 1308 train accuracy: 82.14971209213051\n",
      "Epoch 1308 val loss: 0.5924125009853589\n",
      "Epoch 1308 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1308.pth\n",
      "Epoch 1309 train loss: 0.5992433767144879\n",
      "Epoch 1309 train accuracy: 82.12229229503701\n",
      "Epoch 1309 val loss: 0.5924202624071193\n",
      "Epoch 1309 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1309.pth\n",
      "Epoch 1310 train loss: 0.5991647701154936\n",
      "Epoch 1310 train accuracy: 82.14971209213051\n",
      "Epoch 1310 val loss: 0.5924152555434328\n",
      "Epoch 1310 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1310.pth\n",
      "Epoch 1311 train loss: 0.5991214009720767\n",
      "Epoch 1311 train accuracy: 82.12229229503701\n",
      "Epoch 1311 val loss: 0.5924534766297591\n",
      "Epoch 1311 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1311.pth\n",
      "Epoch 1312 train loss: 0.5991362592107371\n",
      "Epoch 1312 train accuracy: 82.14971209213051\n",
      "Epoch 1312 val loss: 0.5923550806351399\n",
      "Epoch 1312 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1312.pth\n",
      "Epoch 1313 train loss: 0.5991503439614909\n",
      "Epoch 1313 train accuracy: 82.14971209213051\n",
      "Epoch 1313 val loss: 0.5922940645464941\n",
      "Epoch 1313 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1313.pth\n",
      "Epoch 1314 train loss: 0.5990723130995768\n",
      "Epoch 1314 train accuracy: 82.12229229503701\n",
      "Epoch 1314 val loss: 0.5922600881343609\n",
      "Epoch 1314 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1314.pth\n",
      "Epoch 1315 train loss: 0.5990924472234359\n",
      "Epoch 1315 train accuracy: 82.09487249794351\n",
      "Epoch 1315 val loss: 0.592248505551221\n",
      "Epoch 1315 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1315.pth\n",
      "Epoch 1316 train loss: 0.5990584171458817\n",
      "Epoch 1316 train accuracy: 82.17713188922401\n",
      "Epoch 1316 val loss: 0.5921963208698129\n",
      "Epoch 1316 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1316.pth\n",
      "Epoch 1317 train loss: 0.5990443895979408\n",
      "Epoch 1317 train accuracy: 82.12229229503701\n",
      "Epoch 1317 val loss: 0.5921876383455176\n",
      "Epoch 1317 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1317.pth\n",
      "Epoch 1318 train loss: 0.598998449840828\n",
      "Epoch 1318 train accuracy: 82.12229229503701\n",
      "Epoch 1318 val loss: 0.5921487493783628\n",
      "Epoch 1318 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1318.pth\n",
      "Epoch 1319 train loss: 0.5989714852419862\n",
      "Epoch 1319 train accuracy: 82.25939128050453\n",
      "Epoch 1319 val loss: 0.5922687960494506\n",
      "Epoch 1319 val accuracy: 82.89473684210526\n",
      "Saved model to .\\test_models/MLP_1319.pth\n",
      "Epoch 1320 train loss: 0.5989808310313445\n",
      "Epoch 1320 train accuracy: 82.23197148341102\n",
      "Epoch 1320 val loss: 0.5921620132989789\n",
      "Epoch 1320 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1320.pth\n",
      "Epoch 1321 train loss: 0.5989321465113837\n",
      "Epoch 1321 train accuracy: 82.14971209213051\n",
      "Epoch 1321 val loss: 0.5921126334976993\n",
      "Epoch 1321 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1321.pth\n",
      "Epoch 1322 train loss: 0.5989143940734497\n",
      "Epoch 1322 train accuracy: 82.14971209213051\n",
      "Epoch 1322 val loss: 0.5920669080101346\n",
      "Epoch 1322 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1322.pth\n",
      "Epoch 1323 train loss: 0.5988743503561669\n",
      "Epoch 1323 train accuracy: 82.17713188922401\n",
      "Epoch 1323 val loss: 0.5920090129795043\n",
      "Epoch 1323 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1323.pth\n",
      "Epoch 1324 train loss: 0.5988638530436315\n",
      "Epoch 1324 train accuracy: 82.14971209213051\n",
      "Epoch 1324 val loss: 0.592016790258257\n",
      "Epoch 1324 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1324.pth\n",
      "Epoch 1325 train loss: 0.5987802611402514\n",
      "Epoch 1325 train accuracy: 82.25939128050453\n",
      "Epoch 1325 val loss: 0.5920446821929592\n",
      "Epoch 1325 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1325.pth\n",
      "Epoch 1326 train loss: 0.5987708414332908\n",
      "Epoch 1326 train accuracy: 82.14971209213051\n",
      "Epoch 1326 val loss: 0.5920672955383596\n",
      "Epoch 1326 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1326.pth\n",
      "Epoch 1327 train loss: 0.5987832315854336\n",
      "Epoch 1327 train accuracy: 82.12229229503701\n",
      "Epoch 1327 val loss: 0.5919597330748251\n",
      "Epoch 1327 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1327.pth\n",
      "Epoch 1328 train loss: 0.5986948554616487\n",
      "Epoch 1328 train accuracy: 82.25939128050453\n",
      "Epoch 1328 val loss: 0.5919777460298256\n",
      "Epoch 1328 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1328.pth\n",
      "Epoch 1329 train loss: 0.5987272539519166\n",
      "Epoch 1329 train accuracy: 82.20455168631752\n",
      "Epoch 1329 val loss: 0.5919664083048701\n",
      "Epoch 1329 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1329.pth\n",
      "Epoch 1330 train loss: 0.5987105453223512\n",
      "Epoch 1330 train accuracy: 82.20455168631752\n",
      "Epoch 1330 val loss: 0.5919796905823445\n",
      "Epoch 1330 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1330.pth\n",
      "Epoch 1331 train loss: 0.5986303632850187\n",
      "Epoch 1331 train accuracy: 82.23197148341102\n",
      "Epoch 1331 val loss: 0.591890702514272\n",
      "Epoch 1331 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1331.pth\n",
      "Epoch 1332 train loss: 0.5986718070905721\n",
      "Epoch 1332 train accuracy: 82.14971209213051\n",
      "Epoch 1332 val loss: 0.5918662671587969\n",
      "Epoch 1332 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1332.pth\n",
      "Epoch 1333 train loss: 0.5985792335286214\n",
      "Epoch 1333 train accuracy: 82.09487249794351\n",
      "Epoch 1333 val loss: 0.5918828205842721\n",
      "Epoch 1333 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1333.pth\n",
      "Epoch 1334 train loss: 0.5986260300044689\n",
      "Epoch 1334 train accuracy: 82.17713188922401\n",
      "Epoch 1334 val loss: 0.5918877152726054\n",
      "Epoch 1334 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1334.pth\n",
      "Epoch 1335 train loss: 0.5985928442361846\n",
      "Epoch 1335 train accuracy: 82.23197148341102\n",
      "Epoch 1335 val loss: 0.5919793173180599\n",
      "Epoch 1335 val accuracy: 82.8125\n",
      "Saved model to .\\test_models/MLP_1335.pth\n",
      "Epoch 1336 train loss: 0.5985820658766386\n",
      "Epoch 1336 train accuracy: 82.14971209213051\n",
      "Epoch 1336 val loss: 0.5918095395165054\n",
      "Epoch 1336 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1336.pth\n",
      "Epoch 1337 train loss: 0.598480901043666\n",
      "Epoch 1337 train accuracy: 82.25939128050453\n",
      "Epoch 1337 val loss: 0.5918749562023502\n",
      "Epoch 1337 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1337.pth\n",
      "Epoch 1338 train loss: 0.5984247326728349\n",
      "Epoch 1338 train accuracy: 82.23197148341102\n",
      "Epoch 1338 val loss: 0.5918671727474583\n",
      "Epoch 1338 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1338.pth\n",
      "Epoch 1339 train loss: 0.5984811812818965\n",
      "Epoch 1339 train accuracy: 82.09487249794351\n",
      "Epoch 1339 val loss: 0.5917573865307005\n",
      "Epoch 1339 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1339.pth\n",
      "Epoch 1340 train loss: 0.5984319025781333\n",
      "Epoch 1340 train accuracy: 82.17713188922401\n",
      "Epoch 1340 val loss: 0.5916963944603738\n",
      "Epoch 1340 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1340.pth\n",
      "Epoch 1341 train loss: 0.5984086941012687\n",
      "Epoch 1341 train accuracy: 82.25939128050453\n",
      "Epoch 1341 val loss: 0.591806107543801\n",
      "Epoch 1341 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1341.pth\n",
      "Epoch 1342 train loss: 0.598304210492132\n",
      "Epoch 1342 train accuracy: 82.09487249794351\n",
      "Epoch 1342 val loss: 0.5916596333937425\n",
      "Epoch 1342 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1342.pth\n",
      "Epoch 1343 train loss: 0.5983606656163669\n",
      "Epoch 1343 train accuracy: 82.20455168631752\n",
      "Epoch 1343 val loss: 0.5916845102451349\n",
      "Epoch 1343 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1343.pth\n",
      "Epoch 1344 train loss: 0.5982890528250944\n",
      "Epoch 1344 train accuracy: 82.17713188922401\n",
      "Epoch 1344 val loss: 0.5916362037195971\n",
      "Epoch 1344 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1344.pth\n",
      "Epoch 1345 train loss: 0.5983080781767505\n",
      "Epoch 1345 train accuracy: 82.20455168631752\n",
      "Epoch 1345 val loss: 0.5917174051466741\n",
      "Epoch 1345 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1345.pth\n",
      "Epoch 1346 train loss: 0.5982439571893529\n",
      "Epoch 1346 train accuracy: 82.17713188922401\n",
      "Epoch 1346 val loss: 0.5915750331294379\n",
      "Epoch 1346 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1346.pth\n",
      "Epoch 1347 train loss: 0.5982795677785027\n",
      "Epoch 1347 train accuracy: 82.23197148341102\n",
      "Epoch 1347 val loss: 0.5915674681922323\n",
      "Epoch 1347 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1347.pth\n",
      "Epoch 1348 train loss: 0.5982754808817908\n",
      "Epoch 1348 train accuracy: 82.12229229503701\n",
      "Epoch 1348 val loss: 0.5915105355119235\n",
      "Epoch 1348 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1348.pth\n",
      "Epoch 1349 train loss: 0.5981089330621456\n",
      "Epoch 1349 train accuracy: 82.28681107759803\n",
      "Epoch 1349 val loss: 0.5915888405748104\n",
      "Epoch 1349 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1349.pth\n",
      "Epoch 1350 train loss: 0.5982088039449432\n",
      "Epoch 1350 train accuracy: 82.25939128050453\n",
      "Epoch 1350 val loss: 0.5914862949009004\n",
      "Epoch 1350 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1350.pth\n",
      "Epoch 1351 train loss: 0.5981696787077868\n",
      "Epoch 1351 train accuracy: 82.28681107759803\n",
      "Epoch 1351 val loss: 0.5915230260671753\n",
      "Epoch 1351 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1351.pth\n",
      "Epoch 1352 train loss: 0.5981138569809366\n",
      "Epoch 1352 train accuracy: 82.14971209213051\n",
      "Epoch 1352 val loss: 0.591496277159374\n",
      "Epoch 1352 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1352.pth\n",
      "Epoch 1353 train loss: 0.5981069381038348\n",
      "Epoch 1353 train accuracy: 82.20455168631752\n",
      "Epoch 1353 val loss: 0.5914824840514675\n",
      "Epoch 1353 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1353.pth\n",
      "Epoch 1354 train loss: 0.5980446126736831\n",
      "Epoch 1354 train accuracy: 82.23197148341102\n",
      "Epoch 1354 val loss: 0.5915276540541335\n",
      "Epoch 1354 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1354.pth\n",
      "Epoch 1355 train loss: 0.598079024185018\n",
      "Epoch 1355 train accuracy: 82.17713188922401\n",
      "Epoch 1355 val loss: 0.5914370548960409\n",
      "Epoch 1355 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1355.pth\n",
      "Epoch 1356 train loss: 0.598050572272194\n",
      "Epoch 1356 train accuracy: 82.14971209213051\n",
      "Epoch 1356 val loss: 0.5913396686511604\n",
      "Epoch 1356 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1356.pth\n",
      "Epoch 1357 train loss: 0.5980312899572023\n",
      "Epoch 1357 train accuracy: 82.20455168631752\n",
      "Epoch 1357 val loss: 0.5913469118409251\n",
      "Epoch 1357 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1357.pth\n",
      "Epoch 1358 train loss: 0.597971446681441\n",
      "Epoch 1358 train accuracy: 82.25939128050453\n",
      "Epoch 1358 val loss: 0.5913964097486123\n",
      "Epoch 1358 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1358.pth\n",
      "Epoch 1359 train loss: 0.5979537653753109\n",
      "Epoch 1359 train accuracy: 82.28681107759803\n",
      "Epoch 1359 val loss: 0.5913870066012207\n",
      "Epoch 1359 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1359.pth\n",
      "Epoch 1360 train loss: 0.5978991866373179\n",
      "Epoch 1360 train accuracy: 82.20455168631752\n",
      "Epoch 1360 val loss: 0.5913525074230213\n",
      "Epoch 1360 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1360.pth\n",
      "Epoch 1361 train loss: 0.5978945595653433\n",
      "Epoch 1361 train accuracy: 82.25939128050453\n",
      "Epoch 1361 val loss: 0.5913527148138535\n",
      "Epoch 1361 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1361.pth\n",
      "Epoch 1362 train loss: 0.5978591853850767\n",
      "Epoch 1362 train accuracy: 82.28681107759803\n",
      "Epoch 1362 val loss: 0.5913929651050192\n",
      "Epoch 1362 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1362.pth\n",
      "Epoch 1363 train loss: 0.597882709204497\n",
      "Epoch 1363 train accuracy: 82.17713188922401\n",
      "Epoch 1363 val loss: 0.5912068054374111\n",
      "Epoch 1363 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1363.pth\n",
      "Epoch 1364 train loss: 0.5978933708219413\n",
      "Epoch 1364 train accuracy: 82.23197148341102\n",
      "Epoch 1364 val loss: 0.591179073003954\n",
      "Epoch 1364 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1364.pth\n",
      "Epoch 1365 train loss: 0.5978113528863903\n",
      "Epoch 1365 train accuracy: 82.31423087469153\n",
      "Epoch 1365 val loss: 0.5912692470868167\n",
      "Epoch 1365 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1365.pth\n",
      "Epoch 1366 train loss: 0.5976832437312656\n",
      "Epoch 1366 train accuracy: 82.20455168631752\n",
      "Epoch 1366 val loss: 0.5911577442955029\n",
      "Epoch 1366 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1366.pth\n",
      "Epoch 1367 train loss: 0.5977854539493197\n",
      "Epoch 1367 train accuracy: 82.25939128050453\n",
      "Epoch 1367 val loss: 0.5911965977008405\n",
      "Epoch 1367 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1367.pth\n",
      "Epoch 1368 train loss: 0.5977185069697729\n",
      "Epoch 1368 train accuracy: 82.17713188922401\n",
      "Epoch 1368 val loss: 0.5911534554570129\n",
      "Epoch 1368 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1368.pth\n",
      "Epoch 1369 train loss: 0.5977466765039584\n",
      "Epoch 1369 train accuracy: 82.28681107759803\n",
      "Epoch 1369 val loss: 0.5911226976466807\n",
      "Epoch 1369 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1369.pth\n",
      "Epoch 1370 train loss: 0.5976534745280158\n",
      "Epoch 1370 train accuracy: 82.31423087469153\n",
      "Epoch 1370 val loss: 0.5911352624136367\n",
      "Epoch 1370 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1370.pth\n",
      "Epoch 1371 train loss: 0.5976457070036415\n",
      "Epoch 1371 train accuracy: 82.28681107759803\n",
      "Epoch 1371 val loss: 0.5910978576560554\n",
      "Epoch 1371 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1371.pth\n",
      "Epoch 1372 train loss: 0.5976102478606137\n",
      "Epoch 1372 train accuracy: 82.23197148341102\n",
      "Epoch 1372 val loss: 0.5910903831061564\n",
      "Epoch 1372 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1372.pth\n",
      "Epoch 1373 train loss: 0.5976329002071891\n",
      "Epoch 1373 train accuracy: 82.25939128050453\n",
      "Epoch 1373 val loss: 0.5909580030037385\n",
      "Epoch 1373 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1373.pth\n",
      "Epoch 1374 train loss: 0.5976257819943783\n",
      "Epoch 1374 train accuracy: 82.31423087469153\n",
      "Epoch 1374 val loss: 0.5910886298669012\n",
      "Epoch 1374 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1374.pth\n",
      "Epoch 1375 train loss: 0.5975882743236103\n",
      "Epoch 1375 train accuracy: 82.36907046887853\n",
      "Epoch 1375 val loss: 0.5911514109588767\n",
      "Epoch 1375 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1375.pth\n",
      "Epoch 1376 train loss: 0.597455018641133\n",
      "Epoch 1376 train accuracy: 82.25939128050453\n",
      "Epoch 1376 val loss: 0.5910755271876329\n",
      "Epoch 1376 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1376.pth\n",
      "Epoch 1377 train loss: 0.5975553194436718\n",
      "Epoch 1377 train accuracy: 82.17713188922401\n",
      "Epoch 1377 val loss: 0.5909710530387727\n",
      "Epoch 1377 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1377.pth\n",
      "Epoch 1378 train loss: 0.597482230514288\n",
      "Epoch 1378 train accuracy: 82.25939128050453\n",
      "Epoch 1378 val loss: 0.5909751158109621\n",
      "Epoch 1378 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1378.pth\n",
      "Epoch 1379 train loss: 0.5975136873960429\n",
      "Epoch 1379 train accuracy: 82.25939128050453\n",
      "Epoch 1379 val loss: 0.590950229450276\n",
      "Epoch 1379 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1379.pth\n",
      "Epoch 1380 train loss: 0.5974857102622065\n",
      "Epoch 1380 train accuracy: 82.28681107759803\n",
      "Epoch 1380 val loss: 0.5909545145144588\n",
      "Epoch 1380 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1380.pth\n",
      "Epoch 1381 train loss: 0.5974269486114121\n",
      "Epoch 1381 train accuracy: 82.25939128050453\n",
      "Epoch 1381 val loss: 0.5908932695165277\n",
      "Epoch 1381 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1381.pth\n",
      "Epoch 1382 train loss: 0.5974380786841115\n",
      "Epoch 1382 train accuracy: 82.28681107759803\n",
      "Epoch 1382 val loss: 0.5908791249323833\n",
      "Epoch 1382 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1382.pth\n",
      "Epoch 1383 train loss: 0.5974001644930819\n",
      "Epoch 1383 train accuracy: 82.25939128050453\n",
      "Epoch 1383 val loss: 0.5908224339547911\n",
      "Epoch 1383 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1383.pth\n",
      "Epoch 1384 train loss: 0.5973889362066984\n",
      "Epoch 1384 train accuracy: 82.23197148341102\n",
      "Epoch 1384 val loss: 0.5908478729083741\n",
      "Epoch 1384 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1384.pth\n",
      "Epoch 1385 train loss: 0.5973691481917182\n",
      "Epoch 1385 train accuracy: 82.31423087469153\n",
      "Epoch 1385 val loss: 0.5908798186206504\n",
      "Epoch 1385 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1385.pth\n",
      "Epoch 1386 train loss: 0.5973372048322569\n",
      "Epoch 1386 train accuracy: 82.31423087469153\n",
      "Epoch 1386 val loss: 0.5908018675093588\n",
      "Epoch 1386 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1386.pth\n",
      "Epoch 1387 train loss: 0.5973167413551557\n",
      "Epoch 1387 train accuracy: 82.23197148341102\n",
      "Epoch 1387 val loss: 0.5907466631186636\n",
      "Epoch 1387 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1387.pth\n",
      "Epoch 1388 train loss: 0.597237432980093\n",
      "Epoch 1388 train accuracy: 82.31423087469153\n",
      "Epoch 1388 val loss: 0.5907702531273428\n",
      "Epoch 1388 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1388.pth\n",
      "Epoch 1389 train loss: 0.597133589091531\n",
      "Epoch 1389 train accuracy: 82.34165067178503\n",
      "Epoch 1389 val loss: 0.5907609714440217\n",
      "Epoch 1389 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1389.pth\n",
      "Epoch 1390 train loss: 0.5971765586648855\n",
      "Epoch 1390 train accuracy: 82.09487249794351\n",
      "Epoch 1390 val loss: 0.5906552193980468\n",
      "Epoch 1390 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1390.pth\n",
      "Epoch 1391 train loss: 0.5972241248379935\n",
      "Epoch 1391 train accuracy: 82.34165067178503\n",
      "Epoch 1391 val loss: 0.590736908544051\n",
      "Epoch 1391 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1391.pth\n",
      "Epoch 1392 train loss: 0.5971543397264261\n",
      "Epoch 1392 train accuracy: 82.14971209213051\n",
      "Epoch 1392 val loss: 0.5907126578845476\n",
      "Epoch 1392 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1392.pth\n",
      "Epoch 1393 train loss: 0.5971678037751924\n",
      "Epoch 1393 train accuracy: 82.23197148341102\n",
      "Epoch 1393 val loss: 0.5906869750469923\n",
      "Epoch 1393 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1393.pth\n",
      "Epoch 1394 train loss: 0.5971536345355082\n",
      "Epoch 1394 train accuracy: 82.25939128050453\n",
      "Epoch 1394 val loss: 0.590641203655028\n",
      "Epoch 1394 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1394.pth\n",
      "Epoch 1395 train loss: 0.597142135875561\n",
      "Epoch 1395 train accuracy: 82.34165067178503\n",
      "Epoch 1395 val loss: 0.5905552978112706\n",
      "Epoch 1395 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1395.pth\n",
      "Epoch 1396 train loss: 0.5971134501394996\n",
      "Epoch 1396 train accuracy: 82.34165067178503\n",
      "Epoch 1396 val loss: 0.5906052896507868\n",
      "Epoch 1396 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1396.pth\n",
      "Epoch 1397 train loss: 0.5970148783373205\n",
      "Epoch 1397 train accuracy: 82.28681107759803\n",
      "Epoch 1397 val loss: 0.5906868177515111\n",
      "Epoch 1397 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1397.pth\n",
      "Epoch 1398 train loss: 0.597052726992651\n",
      "Epoch 1398 train accuracy: 82.34165067178503\n",
      "Epoch 1398 val loss: 0.5907127660160002\n",
      "Epoch 1398 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1398.pth\n",
      "Epoch 1399 train loss: 0.5970052948156208\n",
      "Epoch 1399 train accuracy: 82.14971209213051\n",
      "Epoch 1399 val loss: 0.5906059674820617\n",
      "Epoch 1399 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1399.pth\n",
      "Epoch 1400 train loss: 0.5970367346808576\n",
      "Epoch 1400 train accuracy: 82.39649026597203\n",
      "Epoch 1400 val loss: 0.5906218979017515\n",
      "Epoch 1400 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1400.pth\n",
      "Epoch 1401 train loss: 0.5969440177850948\n",
      "Epoch 1401 train accuracy: 82.25939128050453\n",
      "Epoch 1401 val loss: 0.5905660607508922\n",
      "Epoch 1401 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1401.pth\n",
      "Epoch 1402 train loss: 0.5969148939475417\n",
      "Epoch 1402 train accuracy: 82.31423087469153\n",
      "Epoch 1402 val loss: 0.5906323029316569\n",
      "Epoch 1402 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1402.pth\n",
      "Epoch 1403 train loss: 0.596945123992076\n",
      "Epoch 1403 train accuracy: 82.28681107759803\n",
      "Epoch 1403 val loss: 0.5906215124812565\n",
      "Epoch 1403 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1403.pth\n",
      "Epoch 1404 train loss: 0.596937706465261\n",
      "Epoch 1404 train accuracy: 82.12229229503701\n",
      "Epoch 1404 val loss: 0.5904723490637384\n",
      "Epoch 1404 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1404.pth\n",
      "Epoch 1405 train loss: 0.5969087877147422\n",
      "Epoch 1405 train accuracy: 82.23197148341102\n",
      "Epoch 1405 val loss: 0.590404639461715\n",
      "Epoch 1405 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1405.pth\n",
      "Epoch 1406 train loss: 0.5969317551016023\n",
      "Epoch 1406 train accuracy: 82.36907046887853\n",
      "Epoch 1406 val loss: 0.5904429186576683\n",
      "Epoch 1406 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1406.pth\n",
      "Epoch 1407 train loss: 0.5968223346495315\n",
      "Epoch 1407 train accuracy: 82.06745270085001\n",
      "Epoch 1407 val loss: 0.5903828440626201\n",
      "Epoch 1407 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1407.pth\n",
      "Epoch 1408 train loss: 0.5967898143357352\n",
      "Epoch 1408 train accuracy: 82.17713188922401\n",
      "Epoch 1408 val loss: 0.5903199689070645\n",
      "Epoch 1408 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1408.pth\n",
      "Epoch 1409 train loss: 0.5968571175543362\n",
      "Epoch 1409 train accuracy: 82.39649026597203\n",
      "Epoch 1409 val loss: 0.5903940674309668\n",
      "Epoch 1409 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1409.pth\n",
      "Epoch 1410 train loss: 0.5967746467264206\n",
      "Epoch 1410 train accuracy: 82.20455168631752\n",
      "Epoch 1410 val loss: 0.5902925792493319\n",
      "Epoch 1410 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1410.pth\n",
      "Epoch 1411 train loss: 0.5967206495176804\n",
      "Epoch 1411 train accuracy: 82.39649026597203\n",
      "Epoch 1411 val loss: 0.590377314016223\n",
      "Epoch 1411 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1411.pth\n",
      "Epoch 1412 train loss: 0.5966986899770665\n",
      "Epoch 1412 train accuracy: 82.20455168631752\n",
      "Epoch 1412 val loss: 0.5903006786186444\n",
      "Epoch 1412 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1412.pth\n",
      "Epoch 1413 train loss: 0.5967322539603501\n",
      "Epoch 1413 train accuracy: 82.39649026597203\n",
      "Epoch 1413 val loss: 0.5903568140868294\n",
      "Epoch 1413 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1413.pth\n",
      "Epoch 1414 train loss: 0.5966058185552818\n",
      "Epoch 1414 train accuracy: 82.23197148341102\n",
      "Epoch 1414 val loss: 0.5902605623398957\n",
      "Epoch 1414 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1414.pth\n",
      "Epoch 1415 train loss: 0.5966340975770563\n",
      "Epoch 1415 train accuracy: 82.23197148341102\n",
      "Epoch 1415 val loss: 0.5902346313783997\n",
      "Epoch 1415 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1415.pth\n",
      "Epoch 1416 train loss: 0.5965516793525272\n",
      "Epoch 1416 train accuracy: 82.28681107759803\n",
      "Epoch 1416 val loss: 0.5902479704175341\n",
      "Epoch 1416 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1416.pth\n",
      "Epoch 1417 train loss: 0.5966027875169458\n",
      "Epoch 1417 train accuracy: 82.34165067178503\n",
      "Epoch 1417 val loss: 0.5902405540017706\n",
      "Epoch 1417 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1417.pth\n",
      "Epoch 1418 train loss: 0.5966625747581323\n",
      "Epoch 1418 train accuracy: 82.34165067178503\n",
      "Epoch 1418 val loss: 0.5902456186319652\n",
      "Epoch 1418 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1418.pth\n",
      "Epoch 1419 train loss: 0.5966055422302401\n",
      "Epoch 1419 train accuracy: 82.20455168631752\n",
      "Epoch 1419 val loss: 0.5902383900982769\n",
      "Epoch 1419 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1419.pth\n",
      "Epoch 1420 train loss: 0.5965823193587232\n",
      "Epoch 1420 train accuracy: 82.23197148341102\n",
      "Epoch 1420 val loss: 0.590245012880156\n",
      "Epoch 1420 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1420.pth\n",
      "Epoch 1421 train loss: 0.596557715711625\n",
      "Epoch 1421 train accuracy: 82.17713188922401\n",
      "Epoch 1421 val loss: 0.59018833866637\n",
      "Epoch 1421 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1421.pth\n",
      "Epoch 1422 train loss: 0.5965445358632949\n",
      "Epoch 1422 train accuracy: 82.28681107759803\n",
      "Epoch 1422 val loss: 0.590195073059907\n",
      "Epoch 1422 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1422.pth\n",
      "Epoch 1423 train loss: 0.5964265605761555\n",
      "Epoch 1423 train accuracy: 82.25939128050453\n",
      "Epoch 1423 val loss: 0.5901700613628093\n",
      "Epoch 1423 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1423.pth\n",
      "Epoch 1424 train loss: 0.5964419912187415\n",
      "Epoch 1424 train accuracy: 82.34165067178503\n",
      "Epoch 1424 val loss: 0.5901604885921666\n",
      "Epoch 1424 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1424.pth\n",
      "Epoch 1425 train loss: 0.5964028192847445\n",
      "Epoch 1425 train accuracy: 82.23197148341102\n",
      "Epoch 1425 val loss: 0.5901418291522484\n",
      "Epoch 1425 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1425.pth\n",
      "Epoch 1426 train loss: 0.5964460583534419\n",
      "Epoch 1426 train accuracy: 82.28681107759803\n",
      "Epoch 1426 val loss: 0.5901305456890872\n",
      "Epoch 1426 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1426.pth\n",
      "Epoch 1427 train loss: 0.5964205801127511\n",
      "Epoch 1427 train accuracy: 82.20455168631752\n",
      "Epoch 1427 val loss: 0.5900281141267011\n",
      "Epoch 1427 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1427.pth\n",
      "Epoch 1428 train loss: 0.5963622497296647\n",
      "Epoch 1428 train accuracy: 82.20455168631752\n",
      "Epoch 1428 val loss: 0.5899795568303058\n",
      "Epoch 1428 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1428.pth\n",
      "Epoch 1429 train loss: 0.5963707660210499\n",
      "Epoch 1429 train accuracy: 82.34165067178503\n",
      "Epoch 1429 val loss: 0.5900018686232599\n",
      "Epoch 1429 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1429.pth\n",
      "Epoch 1430 train loss: 0.5963527396844145\n",
      "Epoch 1430 train accuracy: 82.25939128050453\n",
      "Epoch 1430 val loss: 0.5899392438954428\n",
      "Epoch 1430 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1430.pth\n",
      "Epoch 1431 train loss: 0.596310943463131\n",
      "Epoch 1431 train accuracy: 82.34165067178503\n",
      "Epoch 1431 val loss: 0.5899345054732341\n",
      "Epoch 1431 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1431.pth\n",
      "Epoch 1432 train loss: 0.5963210152102667\n",
      "Epoch 1432 train accuracy: 82.36907046887853\n",
      "Epoch 1432 val loss: 0.5899918619543314\n",
      "Epoch 1432 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1432.pth\n",
      "Epoch 1433 train loss: 0.5962985020392296\n",
      "Epoch 1433 train accuracy: 82.25939128050453\n",
      "Epoch 1433 val loss: 0.5900396998775633\n",
      "Epoch 1433 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1433.pth\n",
      "Epoch 1434 train loss: 0.5962396563733356\n",
      "Epoch 1434 train accuracy: 82.23197148341102\n",
      "Epoch 1434 val loss: 0.5899595877547797\n",
      "Epoch 1434 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1434.pth\n",
      "Epoch 1435 train loss: 0.5962428394419125\n",
      "Epoch 1435 train accuracy: 82.12229229503701\n",
      "Epoch 1435 val loss: 0.5898307477075019\n",
      "Epoch 1435 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1435.pth\n",
      "Epoch 1436 train loss: 0.5961844908040866\n",
      "Epoch 1436 train accuracy: 82.42391006306553\n",
      "Epoch 1436 val loss: 0.5898476263606235\n",
      "Epoch 1436 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1436.pth\n",
      "Epoch 1437 train loss: 0.5961523251771405\n",
      "Epoch 1437 train accuracy: 82.36907046887853\n",
      "Epoch 1437 val loss: 0.5899022198527267\n",
      "Epoch 1437 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1437.pth\n",
      "Epoch 1438 train loss: 0.5961858716940409\n",
      "Epoch 1438 train accuracy: 82.14971209213051\n",
      "Epoch 1438 val loss: 0.5899189580722075\n",
      "Epoch 1438 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1438.pth\n",
      "Epoch 1439 train loss: 0.596157111930089\n",
      "Epoch 1439 train accuracy: 82.14971209213051\n",
      "Epoch 1439 val loss: 0.5897991200418848\n",
      "Epoch 1439 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1439.pth\n",
      "Epoch 1440 train loss: 0.5961340694900668\n",
      "Epoch 1440 train accuracy: 82.34165067178503\n",
      "Epoch 1440 val loss: 0.5898067163499562\n",
      "Epoch 1440 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1440.pth\n",
      "Epoch 1441 train loss: 0.5961177848001713\n",
      "Epoch 1441 train accuracy: 82.20455168631752\n",
      "Epoch 1441 val loss: 0.5897716157824585\n",
      "Epoch 1441 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1441.pth\n",
      "Epoch 1442 train loss: 0.5960417868969798\n",
      "Epoch 1442 train accuracy: 82.23197148341102\n",
      "Epoch 1442 val loss: 0.5897355902155763\n",
      "Epoch 1442 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1442.pth\n",
      "Epoch 1443 train loss: 0.5960811114167435\n",
      "Epoch 1443 train accuracy: 82.36907046887853\n",
      "Epoch 1443 val loss: 0.5897912572285062\n",
      "Epoch 1443 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1443.pth\n",
      "Epoch 1444 train loss: 0.5960527429063069\n",
      "Epoch 1444 train accuracy: 82.25939128050453\n",
      "Epoch 1444 val loss: 0.5897589678336915\n",
      "Epoch 1444 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1444.pth\n",
      "Epoch 1445 train loss: 0.5959638062652135\n",
      "Epoch 1445 train accuracy: 82.17713188922401\n",
      "Epoch 1445 val loss: 0.5896856359843361\n",
      "Epoch 1445 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1445.pth\n",
      "Epoch 1446 train loss: 0.5960047542885468\n",
      "Epoch 1446 train accuracy: 82.34165067178503\n",
      "Epoch 1446 val loss: 0.5896390681400111\n",
      "Epoch 1446 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1446.pth\n",
      "Epoch 1447 train loss: 0.5959475091821923\n",
      "Epoch 1447 train accuracy: 82.31423087469153\n",
      "Epoch 1447 val loss: 0.589687376773279\n",
      "Epoch 1447 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1447.pth\n",
      "Epoch 1448 train loss: 0.5958844827847523\n",
      "Epoch 1448 train accuracy: 82.28681107759803\n",
      "Epoch 1448 val loss: 0.5896468130675586\n",
      "Epoch 1448 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1448.pth\n",
      "Epoch 1449 train loss: 0.5958885932667998\n",
      "Epoch 1449 train accuracy: 82.31423087469153\n",
      "Epoch 1449 val loss: 0.5896331969354498\n",
      "Epoch 1449 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1449.pth\n",
      "Epoch 1450 train loss: 0.5958600688170184\n",
      "Epoch 1450 train accuracy: 82.34165067178503\n",
      "Epoch 1450 val loss: 0.5897600469424537\n",
      "Epoch 1450 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1450.pth\n",
      "Epoch 1451 train loss: 0.5958996656138384\n",
      "Epoch 1451 train accuracy: 82.17713188922401\n",
      "Epoch 1451 val loss: 0.589625853260881\n",
      "Epoch 1451 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1451.pth\n",
      "Epoch 1452 train loss: 0.5958683967361587\n",
      "Epoch 1452 train accuracy: 82.25939128050453\n",
      "Epoch 1452 val loss: 0.5895620122257816\n",
      "Epoch 1452 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1452.pth\n",
      "Epoch 1453 train loss: 0.5958517616157207\n",
      "Epoch 1453 train accuracy: 82.34165067178503\n",
      "Epoch 1453 val loss: 0.5896024479481735\n",
      "Epoch 1453 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1453.pth\n",
      "Epoch 1454 train loss: 0.5957878177593413\n",
      "Epoch 1454 train accuracy: 82.25939128050453\n",
      "Epoch 1454 val loss: 0.5896043796092272\n",
      "Epoch 1454 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1454.pth\n",
      "Epoch 1455 train loss: 0.5957142917700765\n",
      "Epoch 1455 train accuracy: 82.14971209213051\n",
      "Epoch 1455 val loss: 0.5895742419616956\n",
      "Epoch 1455 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1455.pth\n",
      "Epoch 1456 train loss: 0.5958126696610921\n",
      "Epoch 1456 train accuracy: 82.31423087469153\n",
      "Epoch 1456 val loss: 0.5896438275905032\n",
      "Epoch 1456 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1456.pth\n",
      "Epoch 1457 train loss: 0.5957704861730075\n",
      "Epoch 1457 train accuracy: 82.17713188922401\n",
      "Epoch 1457 val loss: 0.589577820985333\n",
      "Epoch 1457 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1457.pth\n",
      "Epoch 1458 train loss: 0.595753526592856\n",
      "Epoch 1458 train accuracy: 82.20455168631752\n",
      "Epoch 1458 val loss: 0.5895237276624692\n",
      "Epoch 1458 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1458.pth\n",
      "Epoch 1459 train loss: 0.5956824469755877\n",
      "Epoch 1459 train accuracy: 82.28681107759803\n",
      "Epoch 1459 val loss: 0.5895211694173907\n",
      "Epoch 1459 val accuracy: 82.97697368421052\n",
      "Saved model to .\\test_models/MLP_1459.pth\n",
      "Epoch 1460 train loss: 0.5956913679470554\n",
      "Epoch 1460 train accuracy: 82.31423087469153\n",
      "Epoch 1460 val loss: 0.5895592076213736\n",
      "Epoch 1460 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1460.pth\n",
      "Epoch 1461 train loss: 0.5956255331831543\n",
      "Epoch 1461 train accuracy: 82.12229229503701\n",
      "Epoch 1461 val loss: 0.5894583975896239\n",
      "Epoch 1461 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1461.pth\n",
      "Epoch 1462 train loss: 0.5956274785117752\n",
      "Epoch 1462 train accuracy: 82.23197148341102\n",
      "Epoch 1462 val loss: 0.5894633186981082\n",
      "Epoch 1462 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1462.pth\n",
      "Epoch 1463 train loss: 0.5955484225169608\n",
      "Epoch 1463 train accuracy: 82.23197148341102\n",
      "Epoch 1463 val loss: 0.5894355264149214\n",
      "Epoch 1463 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1463.pth\n",
      "Epoch 1464 train loss: 0.5955696781574372\n",
      "Epoch 1464 train accuracy: 82.17713188922401\n",
      "Epoch 1464 val loss: 0.589421143314164\n",
      "Epoch 1464 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1464.pth\n",
      "Epoch 1465 train loss: 0.5955655158072579\n",
      "Epoch 1465 train accuracy: 82.23197148341102\n",
      "Epoch 1465 val loss: 0.5894414476658169\n",
      "Epoch 1465 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1465.pth\n",
      "Epoch 1466 train loss: 0.5955008391225547\n",
      "Epoch 1466 train accuracy: 82.14971209213051\n",
      "Epoch 1466 val loss: 0.5894335574029308\n",
      "Epoch 1466 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1466.pth\n",
      "Epoch 1467 train loss: 0.595505035318957\n",
      "Epoch 1467 train accuracy: 82.23197148341102\n",
      "Epoch 1467 val loss: 0.5893683764887484\n",
      "Epoch 1467 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1467.pth\n",
      "Epoch 1468 train loss: 0.5955195825694031\n",
      "Epoch 1468 train accuracy: 82.17713188922401\n",
      "Epoch 1468 val loss: 0.5894231168847335\n",
      "Epoch 1468 val accuracy: 83.0592105263158\n",
      "Saved model to .\\test_models/MLP_1468.pth\n",
      "Epoch 1469 train loss: 0.5954861924248306\n",
      "Epoch 1469 train accuracy: 82.17713188922401\n",
      "Epoch 1469 val loss: 0.5893569788650462\n",
      "Epoch 1469 val accuracy: 83.14144736842105\n",
      "Saved model to .\\test_models/MLP_1469.pth\n",
      "Epoch 1470 train loss: 0.5954200742896973\n",
      "Epoch 1470 train accuracy: 82.25939128050453\n",
      "Epoch 1470 val loss: 0.589387049837234\n",
      "Epoch 1470 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1470.pth\n",
      "Epoch 1471 train loss: 0.5954738264870748\n",
      "Epoch 1471 train accuracy: 82.09487249794351\n",
      "Epoch 1471 val loss: 0.5893533400406963\n",
      "Epoch 1471 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1471.pth\n",
      "Epoch 1472 train loss: 0.5953826877010757\n",
      "Epoch 1472 train accuracy: 82.20455168631752\n",
      "Epoch 1472 val loss: 0.5893781617970059\n",
      "Epoch 1472 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1472.pth\n",
      "Epoch 1473 train loss: 0.595415269400467\n",
      "Epoch 1473 train accuracy: 82.23197148341102\n",
      "Epoch 1473 val loss: 0.5893940777566872\n",
      "Epoch 1473 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1473.pth\n",
      "Epoch 1474 train loss: 0.5952977885965977\n",
      "Epoch 1474 train accuracy: 82.23197148341102\n",
      "Epoch 1474 val loss: 0.5892634062880748\n",
      "Epoch 1474 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1474.pth\n",
      "Epoch 1475 train loss: 0.5952763115137554\n",
      "Epoch 1475 train accuracy: 82.28681107759803\n",
      "Epoch 1475 val loss: 0.5892164248875097\n",
      "Epoch 1475 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1475.pth\n",
      "Epoch 1476 train loss: 0.5952447384693905\n",
      "Epoch 1476 train accuracy: 82.14971209213051\n",
      "Epoch 1476 val loss: 0.5891865453633823\n",
      "Epoch 1476 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1476.pth\n",
      "Epoch 1477 train loss: 0.5952492936824759\n",
      "Epoch 1477 train accuracy: 82.17713188922401\n",
      "Epoch 1477 val loss: 0.5892760868821489\n",
      "Epoch 1477 val accuracy: 83.22368421052632\n",
      "Saved model to .\\test_models/MLP_1477.pth\n",
      "Epoch 1478 train loss: 0.5953105024731996\n",
      "Epoch 1478 train accuracy: 82.14971209213051\n",
      "Epoch 1478 val loss: 0.5891644825766745\n",
      "Epoch 1478 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1478.pth\n",
      "Epoch 1479 train loss: 0.5953015781726623\n",
      "Epoch 1479 train accuracy: 82.17713188922401\n",
      "Epoch 1479 val loss: 0.5891634703760869\n",
      "Epoch 1479 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1479.pth\n",
      "Epoch 1480 train loss: 0.595234442959752\n",
      "Epoch 1480 train accuracy: 82.28681107759803\n",
      "Epoch 1480 val loss: 0.5890413767192513\n",
      "Epoch 1480 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1480.pth\n",
      "Epoch 1481 train loss: 0.5952502879428497\n",
      "Epoch 1481 train accuracy: 82.34165067178503\n",
      "Epoch 1481 val loss: 0.5891374979952448\n",
      "Epoch 1481 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1481.pth\n",
      "Epoch 1482 train loss: 0.5951600118801651\n",
      "Epoch 1482 train accuracy: 82.25939128050453\n",
      "Epoch 1482 val loss: 0.5890230868305815\n",
      "Epoch 1482 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1482.pth\n",
      "Epoch 1483 train loss: 0.5952249646529948\n",
      "Epoch 1483 train accuracy: 82.34165067178503\n",
      "Epoch 1483 val loss: 0.5890815799173555\n",
      "Epoch 1483 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1483.pth\n",
      "Epoch 1484 train loss: 0.5951803323175562\n",
      "Epoch 1484 train accuracy: 82.20455168631752\n",
      "Epoch 1484 val loss: 0.5889724401855155\n",
      "Epoch 1484 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1484.pth\n",
      "Epoch 1485 train loss: 0.5951329331943079\n",
      "Epoch 1485 train accuracy: 82.28681107759803\n",
      "Epoch 1485 val loss: 0.5890110679657051\n",
      "Epoch 1485 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1485.pth\n",
      "Epoch 1486 train loss: 0.5951033891505447\n",
      "Epoch 1486 train accuracy: 82.20455168631752\n",
      "Epoch 1486 val loss: 0.5890204807449329\n",
      "Epoch 1486 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1486.pth\n",
      "Epoch 1487 train loss: 0.5951226803621179\n",
      "Epoch 1487 train accuracy: 82.28681107759803\n",
      "Epoch 1487 val loss: 0.5891217200918809\n",
      "Epoch 1487 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1487.pth\n",
      "Epoch 1488 train loss: 0.5951082649918502\n",
      "Epoch 1488 train accuracy: 82.17713188922401\n",
      "Epoch 1488 val loss: 0.5889577345530453\n",
      "Epoch 1488 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1488.pth\n",
      "Epoch 1489 train loss: 0.5950656064965746\n",
      "Epoch 1489 train accuracy: 82.34165067178503\n",
      "Epoch 1489 val loss: 0.5890131244239839\n",
      "Epoch 1489 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1489.pth\n",
      "Epoch 1490 train loss: 0.5950630161290368\n",
      "Epoch 1490 train accuracy: 82.36907046887853\n",
      "Epoch 1490 val loss: 0.5890127120931682\n",
      "Epoch 1490 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1490.pth\n",
      "Epoch 1491 train loss: 0.5950499596237614\n",
      "Epoch 1491 train accuracy: 82.20455168631752\n",
      "Epoch 1491 val loss: 0.5889265152233604\n",
      "Epoch 1491 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1491.pth\n",
      "Epoch 1492 train loss: 0.5949666250921917\n",
      "Epoch 1492 train accuracy: 82.31423087469153\n",
      "Epoch 1492 val loss: 0.5889777266665509\n",
      "Epoch 1492 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1492.pth\n",
      "Epoch 1493 train loss: 0.595043611173567\n",
      "Epoch 1493 train accuracy: 82.23197148341102\n",
      "Epoch 1493 val loss: 0.5889230186707879\n",
      "Epoch 1493 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1493.pth\n",
      "Epoch 1494 train loss: 0.5949290649017744\n",
      "Epoch 1494 train accuracy: 82.25939128050453\n",
      "Epoch 1494 val loss: 0.5888715234928226\n",
      "Epoch 1494 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1494.pth\n",
      "Epoch 1495 train loss: 0.5949104344962459\n",
      "Epoch 1495 train accuracy: 82.28681107759803\n",
      "Epoch 1495 val loss: 0.588924903618662\n",
      "Epoch 1495 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1495.pth\n",
      "Epoch 1496 train loss: 0.5948948941945115\n",
      "Epoch 1496 train accuracy: 82.34165067178503\n",
      "Epoch 1496 val loss: 0.588898966088891\n",
      "Epoch 1496 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1496.pth\n",
      "Epoch 1497 train loss: 0.5949325629166866\n",
      "Epoch 1497 train accuracy: 82.31423087469153\n",
      "Epoch 1497 val loss: 0.5888593980650368\n",
      "Epoch 1497 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1497.pth\n",
      "Epoch 1498 train loss: 0.5949107678076089\n",
      "Epoch 1498 train accuracy: 82.28681107759803\n",
      "Epoch 1498 val loss: 0.588747387555869\n",
      "Epoch 1498 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1498.pth\n",
      "Epoch 1499 train loss: 0.5948375852762215\n",
      "Epoch 1499 train accuracy: 82.42391006306553\n",
      "Epoch 1499 val loss: 0.5888312010976829\n",
      "Epoch 1499 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1499.pth\n",
      "Epoch 1500 train loss: 0.5948679258131928\n",
      "Epoch 1500 train accuracy: 82.28681107759803\n",
      "Epoch 1500 val loss: 0.5888137261530286\n",
      "Epoch 1500 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1500.pth\n",
      "Epoch 1501 train loss: 0.5948508820218736\n",
      "Epoch 1501 train accuracy: 82.28681107759803\n",
      "Epoch 1501 val loss: 0.5887200287788322\n",
      "Epoch 1501 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1501.pth\n",
      "Epoch 1502 train loss: 0.5948315857697213\n",
      "Epoch 1502 train accuracy: 82.23197148341102\n",
      "Epoch 1502 val loss: 0.5886751440794844\n",
      "Epoch 1502 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1502.pth\n",
      "Epoch 1503 train loss: 0.594771831933605\n",
      "Epoch 1503 train accuracy: 82.45132986015903\n",
      "Epoch 1503 val loss: 0.5888683699365509\n",
      "Epoch 1503 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1503.pth\n",
      "Epoch 1504 train loss: 0.5948371106039798\n",
      "Epoch 1504 train accuracy: 82.28681107759803\n",
      "Epoch 1504 val loss: 0.5886659732970753\n",
      "Epoch 1504 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1504.pth\n",
      "Epoch 1505 train loss: 0.5947154860191962\n",
      "Epoch 1505 train accuracy: 82.36907046887853\n",
      "Epoch 1505 val loss: 0.5887408741063586\n",
      "Epoch 1505 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1505.pth\n",
      "Epoch 1506 train loss: 0.5947060214453622\n",
      "Epoch 1506 train accuracy: 82.28681107759803\n",
      "Epoch 1506 val loss: 0.5886448205105568\n",
      "Epoch 1506 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1506.pth\n",
      "Epoch 1507 train loss: 0.5946809188381099\n",
      "Epoch 1507 train accuracy: 82.39649026597203\n",
      "Epoch 1507 val loss: 0.5887742780737186\n",
      "Epoch 1507 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1507.pth\n",
      "Epoch 1508 train loss: 0.5946679851693804\n",
      "Epoch 1508 train accuracy: 82.25939128050453\n",
      "Epoch 1508 val loss: 0.5886635511231265\n",
      "Epoch 1508 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1508.pth\n",
      "Epoch 1509 train loss: 0.5947223717444822\n",
      "Epoch 1509 train accuracy: 82.39649026597203\n",
      "Epoch 1509 val loss: 0.5885914765102299\n",
      "Epoch 1509 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1509.pth\n",
      "Epoch 1510 train loss: 0.5946306662160185\n",
      "Epoch 1510 train accuracy: 82.34165067178503\n",
      "Epoch 1510 val loss: 0.5885492462272707\n",
      "Epoch 1510 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1510.pth\n",
      "Epoch 1511 train loss: 0.5946680725829905\n",
      "Epoch 1511 train accuracy: 82.42391006306553\n",
      "Epoch 1511 val loss: 0.5886145202737105\n",
      "Epoch 1511 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1511.pth\n",
      "Epoch 1512 train loss: 0.5946176410897782\n",
      "Epoch 1512 train accuracy: 82.36907046887853\n",
      "Epoch 1512 val loss: 0.5885344101606231\n",
      "Epoch 1512 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1512.pth\n",
      "Epoch 1513 train loss: 0.594618613570275\n",
      "Epoch 1513 train accuracy: 82.34165067178503\n",
      "Epoch 1513 val loss: 0.5885267548851276\n",
      "Epoch 1513 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1513.pth\n",
      "Epoch 1514 train loss: 0.5946047052479627\n",
      "Epoch 1514 train accuracy: 82.39649026597203\n",
      "Epoch 1514 val loss: 0.5885889128732839\n",
      "Epoch 1514 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1514.pth\n",
      "Epoch 1515 train loss: 0.5945422285024011\n",
      "Epoch 1515 train accuracy: 82.31423087469153\n",
      "Epoch 1515 val loss: 0.5885335265805847\n",
      "Epoch 1515 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1515.pth\n",
      "Epoch 1516 train loss: 0.5945723927988295\n",
      "Epoch 1516 train accuracy: 82.39649026597203\n",
      "Epoch 1516 val loss: 0.5885091163708192\n",
      "Epoch 1516 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1516.pth\n",
      "Epoch 1517 train loss: 0.5945422710001207\n",
      "Epoch 1517 train accuracy: 82.47874965725254\n",
      "Epoch 1517 val loss: 0.5885357995958704\n",
      "Epoch 1517 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1517.pth\n",
      "Epoch 1518 train loss: 0.5944905805058385\n",
      "Epoch 1518 train accuracy: 82.34165067178503\n",
      "Epoch 1518 val loss: 0.5885057477280498\n",
      "Epoch 1518 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1518.pth\n",
      "Epoch 1519 train loss: 0.5944902914853996\n",
      "Epoch 1519 train accuracy: 82.34165067178503\n",
      "Epoch 1519 val loss: 0.5884523801383024\n",
      "Epoch 1519 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1519.pth\n",
      "Epoch 1520 train loss: 0.5944925836009676\n",
      "Epoch 1520 train accuracy: 82.42391006306553\n",
      "Epoch 1520 val loss: 0.588471124340829\n",
      "Epoch 1520 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1520.pth\n",
      "Epoch 1521 train loss: 0.5944021818015659\n",
      "Epoch 1521 train accuracy: 82.28681107759803\n",
      "Epoch 1521 val loss: 0.5883820317685604\n",
      "Epoch 1521 val accuracy: 83.30592105263158\n",
      "Saved model to .\\test_models/MLP_1521.pth\n",
      "Epoch 1522 train loss: 0.5943983557323614\n",
      "Epoch 1522 train accuracy: 82.36907046887853\n",
      "Epoch 1522 val loss: 0.5883302112894231\n",
      "Epoch 1522 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1522.pth\n",
      "Epoch 1523 train loss: 0.5944363477133345\n",
      "Epoch 1523 train accuracy: 82.28681107759803\n",
      "Epoch 1523 val loss: 0.5882968689854208\n",
      "Epoch 1523 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1523.pth\n",
      "Epoch 1524 train loss: 0.5943536184679129\n",
      "Epoch 1524 train accuracy: 82.28681107759803\n",
      "Epoch 1524 val loss: 0.5883006899568596\n",
      "Epoch 1524 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1524.pth\n",
      "Epoch 1525 train loss: 0.5943983069768077\n",
      "Epoch 1525 train accuracy: 82.39649026597203\n",
      "Epoch 1525 val loss: 0.5882632426035247\n",
      "Epoch 1525 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1525.pth\n",
      "Epoch 1526 train loss: 0.5943247349769399\n",
      "Epoch 1526 train accuracy: 82.42391006306553\n",
      "Epoch 1526 val loss: 0.5883815101789016\n",
      "Epoch 1526 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1526.pth\n",
      "Epoch 1527 train loss: 0.5943735266888612\n",
      "Epoch 1527 train accuracy: 82.34165067178503\n",
      "Epoch 1527 val loss: 0.5883252778531689\n",
      "Epoch 1527 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1527.pth\n",
      "Epoch 1528 train loss: 0.5942884383625106\n",
      "Epoch 1528 train accuracy: 82.36907046887853\n",
      "Epoch 1528 val loss: 0.588331199839319\n",
      "Epoch 1528 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1528.pth\n",
      "Epoch 1529 train loss: 0.5943228989316706\n",
      "Epoch 1529 train accuracy: 82.28681107759803\n",
      "Epoch 1529 val loss: 0.5882306637634572\n",
      "Epoch 1529 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1529.pth\n",
      "Epoch 1530 train loss: 0.5942666154322133\n",
      "Epoch 1530 train accuracy: 82.47874965725254\n",
      "Epoch 1530 val loss: 0.5883166555217222\n",
      "Epoch 1530 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1530.pth\n",
      "Epoch 1531 train loss: 0.5942934765235374\n",
      "Epoch 1531 train accuracy: 82.34165067178503\n",
      "Epoch 1531 val loss: 0.5882564467917147\n",
      "Epoch 1531 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1531.pth\n",
      "Epoch 1532 train loss: 0.5942100660646694\n",
      "Epoch 1532 train accuracy: 82.34165067178503\n",
      "Epoch 1532 val loss: 0.5882889052460852\n",
      "Epoch 1532 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1532.pth\n",
      "Epoch 1533 train loss: 0.5942396883313593\n",
      "Epoch 1533 train accuracy: 82.34165067178503\n",
      "Epoch 1533 val loss: 0.5882613004528379\n",
      "Epoch 1533 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1533.pth\n",
      "Epoch 1534 train loss: 0.5942356220953036\n",
      "Epoch 1534 train accuracy: 82.36907046887853\n",
      "Epoch 1534 val loss: 0.5881338295293972\n",
      "Epoch 1534 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1534.pth\n",
      "Epoch 1535 train loss: 0.5942416030815557\n",
      "Epoch 1535 train accuracy: 82.34165067178503\n",
      "Epoch 1535 val loss: 0.5881957100018075\n",
      "Epoch 1535 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1535.pth\n",
      "Epoch 1536 train loss: 0.5942084060393666\n",
      "Epoch 1536 train accuracy: 82.31423087469153\n",
      "Epoch 1536 val loss: 0.5881492968550638\n",
      "Epoch 1536 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1536.pth\n",
      "Epoch 1537 train loss: 0.5941848073710214\n",
      "Epoch 1537 train accuracy: 82.31423087469153\n",
      "Epoch 1537 val loss: 0.5880984141932506\n",
      "Epoch 1537 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1537.pth\n",
      "Epoch 1538 train loss: 0.5941963379124278\n",
      "Epoch 1538 train accuracy: 82.36907046887853\n",
      "Epoch 1538 val loss: 0.5881012493842527\n",
      "Epoch 1538 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1538.pth\n",
      "Epoch 1539 train loss: 0.5941520074725544\n",
      "Epoch 1539 train accuracy: 82.39649026597203\n",
      "Epoch 1539 val loss: 0.588099289195318\n",
      "Epoch 1539 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1539.pth\n",
      "Epoch 1540 train loss: 0.594082978635765\n",
      "Epoch 1540 train accuracy: 82.45132986015903\n",
      "Epoch 1540 val loss: 0.5880882892463553\n",
      "Epoch 1540 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1540.pth\n",
      "Epoch 1541 train loss: 0.5941224481763416\n",
      "Epoch 1541 train accuracy: 82.42391006306553\n",
      "Epoch 1541 val loss: 0.5880538680541673\n",
      "Epoch 1541 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1541.pth\n",
      "Epoch 1542 train loss: 0.5940999827233323\n",
      "Epoch 1542 train accuracy: 82.45132986015903\n",
      "Epoch 1542 val loss: 0.588045680258227\n",
      "Epoch 1542 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1542.pth\n",
      "Epoch 1543 train loss: 0.5940160112324775\n",
      "Epoch 1543 train accuracy: 82.31423087469153\n",
      "Epoch 1543 val loss: 0.5880292524142485\n",
      "Epoch 1543 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1543.pth\n",
      "Epoch 1544 train loss: 0.5940553063951564\n",
      "Epoch 1544 train accuracy: 82.36907046887853\n",
      "Epoch 1544 val loss: 0.5879598787348521\n",
      "Epoch 1544 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1544.pth\n",
      "Epoch 1545 train loss: 0.5940298609386542\n",
      "Epoch 1545 train accuracy: 82.47874965725254\n",
      "Epoch 1545 val loss: 0.5880604840226864\n",
      "Epoch 1545 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1545.pth\n",
      "Epoch 1546 train loss: 0.5940414723744126\n",
      "Epoch 1546 train accuracy: 82.42391006306553\n",
      "Epoch 1546 val loss: 0.587984165568885\n",
      "Epoch 1546 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1546.pth\n",
      "Epoch 1547 train loss: 0.5940172948237312\n",
      "Epoch 1547 train accuracy: 82.42391006306553\n",
      "Epoch 1547 val loss: 0.5879824081631867\n",
      "Epoch 1547 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1547.pth\n",
      "Epoch 1548 train loss: 0.5939611978828907\n",
      "Epoch 1548 train accuracy: 82.36907046887853\n",
      "Epoch 1548 val loss: 0.5879226948967889\n",
      "Epoch 1548 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1548.pth\n",
      "Epoch 1549 train loss: 0.5939629099642237\n",
      "Epoch 1549 train accuracy: 82.53358925143954\n",
      "Epoch 1549 val loss: 0.5879282902338003\n",
      "Epoch 1549 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1549.pth\n",
      "Epoch 1550 train loss: 0.5938978372958669\n",
      "Epoch 1550 train accuracy: 82.39649026597203\n",
      "Epoch 1550 val loss: 0.5878935036690611\n",
      "Epoch 1550 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1550.pth\n",
      "Epoch 1551 train loss: 0.5939213357490014\n",
      "Epoch 1551 train accuracy: 82.42391006306553\n",
      "Epoch 1551 val loss: 0.5879061713716701\n",
      "Epoch 1551 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1551.pth\n",
      "Epoch 1552 train loss: 0.5939218746988397\n",
      "Epoch 1552 train accuracy: 82.34165067178503\n",
      "Epoch 1552 val loss: 0.5877935539833025\n",
      "Epoch 1552 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1552.pth\n",
      "Epoch 1553 train loss: 0.5937976743699166\n",
      "Epoch 1553 train accuracy: 82.47874965725254\n",
      "Epoch 1553 val loss: 0.5878301541762132\n",
      "Epoch 1553 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1553.pth\n",
      "Epoch 1554 train loss: 0.5938771022320316\n",
      "Epoch 1554 train accuracy: 82.42391006306553\n",
      "Epoch 1554 val loss: 0.5877566691488028\n",
      "Epoch 1554 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1554.pth\n",
      "Epoch 1555 train loss: 0.5938660352441826\n",
      "Epoch 1555 train accuracy: 82.42391006306553\n",
      "Epoch 1555 val loss: 0.5878176456317306\n",
      "Epoch 1555 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1555.pth\n",
      "Epoch 1556 train loss: 0.5937985534240541\n",
      "Epoch 1556 train accuracy: 82.42391006306553\n",
      "Epoch 1556 val loss: 0.5877758748829365\n",
      "Epoch 1556 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1556.pth\n",
      "Epoch 1557 train loss: 0.5937670467323378\n",
      "Epoch 1557 train accuracy: 82.39649026597203\n",
      "Epoch 1557 val loss: 0.5877150803265211\n",
      "Epoch 1557 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1557.pth\n",
      "Epoch 1558 train loss: 0.593844648029884\n",
      "Epoch 1558 train accuracy: 82.47874965725254\n",
      "Epoch 1558 val loss: 0.5877427525916382\n",
      "Epoch 1558 val accuracy: 83.38815789473684\n",
      "Saved model to .\\test_models/MLP_1558.pth\n",
      "Epoch 1559 train loss: 0.593795122889181\n",
      "Epoch 1559 train accuracy: 82.45132986015903\n",
      "Epoch 1559 val loss: 0.5877611312132917\n",
      "Epoch 1559 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1559.pth\n",
      "Epoch 1560 train loss: 0.593766329491413\n",
      "Epoch 1560 train accuracy: 82.39649026597203\n",
      "Epoch 1560 val loss: 0.5876377561178646\n",
      "Epoch 1560 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1560.pth\n",
      "Epoch 1561 train loss: 0.5937015247580252\n",
      "Epoch 1561 train accuracy: 82.42391006306553\n",
      "Epoch 1561 val loss: 0.5876427399680803\n",
      "Epoch 1561 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1561.pth\n",
      "Epoch 1562 train loss: 0.5937546265327878\n",
      "Epoch 1562 train accuracy: 82.47874965725254\n",
      "Epoch 1562 val loss: 0.5876445959959375\n",
      "Epoch 1562 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1562.pth\n",
      "Epoch 1563 train loss: 0.5937468134389635\n",
      "Epoch 1563 train accuracy: 82.47874965725254\n",
      "Epoch 1563 val loss: 0.5876679177346983\n",
      "Epoch 1563 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1563.pth\n",
      "Epoch 1564 train loss: 0.5937042957204476\n",
      "Epoch 1564 train accuracy: 82.36907046887853\n",
      "Epoch 1564 val loss: 0.5875909456395005\n",
      "Epoch 1564 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1564.pth\n",
      "Epoch 1565 train loss: 0.5937213782025011\n",
      "Epoch 1565 train accuracy: 82.50616945434604\n",
      "Epoch 1565 val loss: 0.5876826012114945\n",
      "Epoch 1565 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1565.pth\n",
      "Epoch 1566 train loss: 0.5936976506195047\n",
      "Epoch 1566 train accuracy: 82.45132986015903\n",
      "Epoch 1566 val loss: 0.5876258844019551\n",
      "Epoch 1566 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1566.pth\n",
      "Epoch 1567 train loss: 0.593600536451528\n",
      "Epoch 1567 train accuracy: 82.42391006306553\n",
      "Epoch 1567 val loss: 0.5876294533771119\n",
      "Epoch 1567 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1567.pth\n",
      "Epoch 1568 train loss: 0.5936391830133895\n",
      "Epoch 1568 train accuracy: 82.53358925143954\n",
      "Epoch 1568 val loss: 0.5876718660522449\n",
      "Epoch 1568 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1568.pth\n",
      "Epoch 1569 train loss: 0.5936261585325395\n",
      "Epoch 1569 train accuracy: 82.34165067178503\n",
      "Epoch 1569 val loss: 0.5875877856620049\n",
      "Epoch 1569 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1569.pth\n",
      "Epoch 1570 train loss: 0.5935529276744969\n",
      "Epoch 1570 train accuracy: 82.50616945434604\n",
      "Epoch 1570 val loss: 0.587597562980495\n",
      "Epoch 1570 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1570.pth\n",
      "Epoch 1571 train loss: 0.593596947853241\n",
      "Epoch 1571 train accuracy: 82.56100904853304\n",
      "Epoch 1571 val loss: 0.5876322765099374\n",
      "Epoch 1571 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1571.pth\n",
      "Epoch 1572 train loss: 0.5934637344785427\n",
      "Epoch 1572 train accuracy: 82.39649026597203\n",
      "Epoch 1572 val loss: 0.5875350705004836\n",
      "Epoch 1572 val accuracy: 83.47039473684211\n",
      "Saved model to .\\test_models/MLP_1572.pth\n",
      "Epoch 1573 train loss: 0.5935620859003904\n",
      "Epoch 1573 train accuracy: 82.39649026597203\n",
      "Epoch 1573 val loss: 0.587525598361696\n",
      "Epoch 1573 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1573.pth\n",
      "Epoch 1574 train loss: 0.5935451060006591\n",
      "Epoch 1574 train accuracy: 82.50616945434604\n",
      "Epoch 1574 val loss: 0.5875222098670507\n",
      "Epoch 1574 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1574.pth\n",
      "Epoch 1575 train loss: 0.5935247165616602\n",
      "Epoch 1575 train accuracy: 82.50616945434604\n",
      "Epoch 1575 val loss: 0.5874971785631619\n",
      "Epoch 1575 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1575.pth\n",
      "Epoch 1576 train loss: 0.5935068286040373\n",
      "Epoch 1576 train accuracy: 82.50616945434604\n",
      "Epoch 1576 val loss: 0.5875063262095577\n",
      "Epoch 1576 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1576.pth\n",
      "Epoch 1577 train loss: 0.593461402120036\n",
      "Epoch 1577 train accuracy: 82.45132986015903\n",
      "Epoch 1577 val loss: 0.5875865028386837\n",
      "Epoch 1577 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1577.pth\n",
      "Epoch 1578 train loss: 0.5934267391597754\n",
      "Epoch 1578 train accuracy: 82.42391006306553\n",
      "Epoch 1578 val loss: 0.587547310431929\n",
      "Epoch 1578 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1578.pth\n",
      "Epoch 1579 train loss: 0.5934593626216316\n",
      "Epoch 1579 train accuracy: 82.36907046887853\n",
      "Epoch 1579 val loss: 0.587464539334178\n",
      "Epoch 1579 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1579.pth\n",
      "Epoch 1580 train loss: 0.5934820126317311\n",
      "Epoch 1580 train accuracy: 82.47874965725254\n",
      "Epoch 1580 val loss: 0.5874619192664364\n",
      "Epoch 1580 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1580.pth\n",
      "Epoch 1581 train loss: 0.5934244249375504\n",
      "Epoch 1581 train accuracy: 82.47874965725254\n",
      "Epoch 1581 val loss: 0.5874381854051822\n",
      "Epoch 1581 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1581.pth\n",
      "Epoch 1582 train loss: 0.5932942306655541\n",
      "Epoch 1582 train accuracy: 82.45132986015903\n",
      "Epoch 1582 val loss: 0.5874560238107255\n",
      "Epoch 1582 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1582.pth\n",
      "Epoch 1583 train loss: 0.5934059228584693\n",
      "Epoch 1583 train accuracy: 82.45132986015903\n",
      "Epoch 1583 val loss: 0.5873675797085621\n",
      "Epoch 1583 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1583.pth\n",
      "Epoch 1584 train loss: 0.5933737690772927\n",
      "Epoch 1584 train accuracy: 82.45132986015903\n",
      "Epoch 1584 val loss: 0.587371007343264\n",
      "Epoch 1584 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1584.pth\n",
      "Epoch 1585 train loss: 0.5932933215721788\n",
      "Epoch 1585 train accuracy: 82.42391006306553\n",
      "Epoch 1585 val loss: 0.5873355135738262\n",
      "Epoch 1585 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1585.pth\n",
      "Epoch 1586 train loss: 0.5932836840256003\n",
      "Epoch 1586 train accuracy: 82.53358925143954\n",
      "Epoch 1586 val loss: 0.5873889653502327\n",
      "Epoch 1586 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1586.pth\n",
      "Epoch 1587 train loss: 0.593319605627473\n",
      "Epoch 1587 train accuracy: 82.45132986015903\n",
      "Epoch 1587 val loss: 0.5873686812100412\n",
      "Epoch 1587 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1587.pth\n",
      "Epoch 1588 train loss: 0.5933111652307081\n",
      "Epoch 1588 train accuracy: 82.47874965725254\n",
      "Epoch 1588 val loss: 0.5873083232068702\n",
      "Epoch 1588 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1588.pth\n",
      "Epoch 1589 train loss: 0.5932185270480419\n",
      "Epoch 1589 train accuracy: 82.28681107759803\n",
      "Epoch 1589 val loss: 0.5872621835258446\n",
      "Epoch 1589 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1589.pth\n",
      "Epoch 1590 train loss: 0.5931781093475589\n",
      "Epoch 1590 train accuracy: 82.50616945434604\n",
      "Epoch 1590 val loss: 0.5872883962614364\n",
      "Epoch 1590 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1590.pth\n",
      "Epoch 1591 train loss: 0.5932131315287399\n",
      "Epoch 1591 train accuracy: 82.47874965725254\n",
      "Epoch 1591 val loss: 0.5873202499198286\n",
      "Epoch 1591 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1591.pth\n",
      "Epoch 1592 train loss: 0.5931983123321021\n",
      "Epoch 1592 train accuracy: 82.36907046887853\n",
      "Epoch 1592 val loss: 0.587257171196765\n",
      "Epoch 1592 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1592.pth\n",
      "Epoch 1593 train loss: 0.5932059675095636\n",
      "Epoch 1593 train accuracy: 82.34165067178503\n",
      "Epoch 1593 val loss: 0.5871536840537661\n",
      "Epoch 1593 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1593.pth\n",
      "Epoch 1594 train loss: 0.5932402889767107\n",
      "Epoch 1594 train accuracy: 82.47874965725254\n",
      "Epoch 1594 val loss: 0.5872088152130968\n",
      "Epoch 1594 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1594.pth\n",
      "Epoch 1595 train loss: 0.5931871335240175\n",
      "Epoch 1595 train accuracy: 82.50616945434604\n",
      "Epoch 1595 val loss: 0.587209674970884\n",
      "Epoch 1595 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1595.pth\n",
      "Epoch 1596 train loss: 0.5931658043215672\n",
      "Epoch 1596 train accuracy: 82.42391006306553\n",
      "Epoch 1596 val loss: 0.5871752913869721\n",
      "Epoch 1596 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1596.pth\n",
      "Epoch 1597 train loss: 0.5931640529694656\n",
      "Epoch 1597 train accuracy: 82.50616945434604\n",
      "Epoch 1597 val loss: 0.5871858619839737\n",
      "Epoch 1597 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1597.pth\n",
      "Epoch 1598 train loss: 0.5931418742330974\n",
      "Epoch 1598 train accuracy: 82.45132986015903\n",
      "Epoch 1598 val loss: 0.5871823056551971\n",
      "Epoch 1598 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1598.pth\n",
      "Epoch 1599 train loss: 0.5931399476698094\n",
      "Epoch 1599 train accuracy: 82.56100904853304\n",
      "Epoch 1599 val loss: 0.5871479486752498\n",
      "Epoch 1599 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1599.pth\n",
      "Epoch 1600 train loss: 0.5930072971734038\n",
      "Epoch 1600 train accuracy: 82.53358925143954\n",
      "Epoch 1600 val loss: 0.5871242426433846\n",
      "Epoch 1600 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1600.pth\n",
      "Epoch 1601 train loss: 0.5929814461259204\n",
      "Epoch 1601 train accuracy: 82.50616945434604\n",
      "Epoch 1601 val loss: 0.5871193318039571\n",
      "Epoch 1601 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1601.pth\n",
      "Epoch 1602 train loss: 0.5929616256045145\n",
      "Epoch 1602 train accuracy: 82.42391006306553\n",
      "Epoch 1602 val loss: 0.5871069789619038\n",
      "Epoch 1602 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1602.pth\n",
      "Epoch 1603 train loss: 0.5930318302442238\n",
      "Epoch 1603 train accuracy: 82.39649026597203\n",
      "Epoch 1603 val loss: 0.5871056804041329\n",
      "Epoch 1603 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1603.pth\n",
      "Epoch 1604 train loss: 0.5930400916064779\n",
      "Epoch 1604 train accuracy: 82.42391006306553\n",
      "Epoch 1604 val loss: 0.5870915969441596\n",
      "Epoch 1604 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1604.pth\n",
      "Epoch 1605 train loss: 0.5930058445797808\n",
      "Epoch 1605 train accuracy: 82.47874965725254\n",
      "Epoch 1605 val loss: 0.5870242522735345\n",
      "Epoch 1605 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1605.pth\n",
      "Epoch 1606 train loss: 0.5929633230297712\n",
      "Epoch 1606 train accuracy: 82.45132986015903\n",
      "Epoch 1606 val loss: 0.586993195018486\n",
      "Epoch 1606 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1606.pth\n",
      "Epoch 1607 train loss: 0.5930128679855874\n",
      "Epoch 1607 train accuracy: 82.47874965725254\n",
      "Epoch 1607 val loss: 0.5870326915755868\n",
      "Epoch 1607 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1607.pth\n",
      "Epoch 1608 train loss: 0.5929702521466983\n",
      "Epoch 1608 train accuracy: 82.53358925143954\n",
      "Epoch 1608 val loss: 0.5869682481218326\n",
      "Epoch 1608 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1608.pth\n",
      "Epoch 1609 train loss: 0.5930195498329244\n",
      "Epoch 1609 train accuracy: 82.50616945434604\n",
      "Epoch 1609 val loss: 0.5869960349151179\n",
      "Epoch 1609 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1609.pth\n",
      "Epoch 1610 train loss: 0.5929438560555705\n",
      "Epoch 1610 train accuracy: 82.53358925143954\n",
      "Epoch 1610 val loss: 0.5869711980615792\n",
      "Epoch 1610 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1610.pth\n",
      "Epoch 1611 train loss: 0.5929380636989025\n",
      "Epoch 1611 train accuracy: 82.47874965725254\n",
      "Epoch 1611 val loss: 0.5869917315676024\n",
      "Epoch 1611 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1611.pth\n",
      "Epoch 1612 train loss: 0.5929122844612912\n",
      "Epoch 1612 train accuracy: 82.50616945434604\n",
      "Epoch 1612 val loss: 0.5870145876940928\n",
      "Epoch 1612 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1612.pth\n",
      "Epoch 1613 train loss: 0.5929040816988338\n",
      "Epoch 1613 train accuracy: 82.58842884562654\n",
      "Epoch 1613 val loss: 0.5869616775920516\n",
      "Epoch 1613 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1613.pth\n",
      "Epoch 1614 train loss: 0.5928447531013373\n",
      "Epoch 1614 train accuracy: 82.45132986015903\n",
      "Epoch 1614 val loss: 0.5869519000774935\n",
      "Epoch 1614 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1614.pth\n",
      "Epoch 1615 train loss: 0.5928070099142037\n",
      "Epoch 1615 train accuracy: 82.47874965725254\n",
      "Epoch 1615 val loss: 0.5868990678634298\n",
      "Epoch 1615 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1615.pth\n",
      "Epoch 1616 train loss: 0.5928563524789193\n",
      "Epoch 1616 train accuracy: 82.56100904853304\n",
      "Epoch 1616 val loss: 0.5868956860841105\n",
      "Epoch 1616 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1616.pth\n",
      "Epoch 1617 train loss: 0.5928012196795622\n",
      "Epoch 1617 train accuracy: 82.42391006306553\n",
      "Epoch 1617 val loss: 0.5869131709301942\n",
      "Epoch 1617 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1617.pth\n",
      "Epoch 1618 train loss: 0.5928200589688984\n",
      "Epoch 1618 train accuracy: 82.47874965725254\n",
      "Epoch 1618 val loss: 0.5869081335044221\n",
      "Epoch 1618 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1618.pth\n",
      "Epoch 1619 train loss: 0.5927857446010437\n",
      "Epoch 1619 train accuracy: 82.47874965725254\n",
      "Epoch 1619 val loss: 0.586867974188767\n",
      "Epoch 1619 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1619.pth\n",
      "Epoch 1620 train loss: 0.592779804119154\n",
      "Epoch 1620 train accuracy: 82.53358925143954\n",
      "Epoch 1620 val loss: 0.5868480297197637\n",
      "Epoch 1620 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1620.pth\n",
      "Epoch 1621 train loss: 0.592800456475009\n",
      "Epoch 1621 train accuracy: 82.45132986015903\n",
      "Epoch 1621 val loss: 0.5867945582752949\n",
      "Epoch 1621 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1621.pth\n",
      "Epoch 1622 train loss: 0.5927525440704796\n",
      "Epoch 1622 train accuracy: 82.47874965725254\n",
      "Epoch 1622 val loss: 0.5868804852331155\n",
      "Epoch 1622 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1622.pth\n",
      "Epoch 1623 train loss: 0.5926419022460386\n",
      "Epoch 1623 train accuracy: 82.45132986015903\n",
      "Epoch 1623 val loss: 0.5867806185943711\n",
      "Epoch 1623 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1623.pth\n",
      "Epoch 1624 train loss: 0.592695546385489\n",
      "Epoch 1624 train accuracy: 82.50616945434604\n",
      "Epoch 1624 val loss: 0.5868620244099906\n",
      "Epoch 1624 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1624.pth\n",
      "Epoch 1625 train loss: 0.5926839439034984\n",
      "Epoch 1625 train accuracy: 82.50616945434604\n",
      "Epoch 1625 val loss: 0.5867682112331846\n",
      "Epoch 1625 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1625.pth\n",
      "Epoch 1626 train loss: 0.5926715056493617\n",
      "Epoch 1626 train accuracy: 82.53358925143954\n",
      "Epoch 1626 val loss: 0.586807039713389\n",
      "Epoch 1626 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1626.pth\n",
      "Epoch 1627 train loss: 0.592651027777608\n",
      "Epoch 1627 train accuracy: 82.47874965725254\n",
      "Epoch 1627 val loss: 0.5868119407616752\n",
      "Epoch 1627 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1627.pth\n",
      "Epoch 1628 train loss: 0.5926660995015449\n",
      "Epoch 1628 train accuracy: 82.45132986015903\n",
      "Epoch 1628 val loss: 0.5867817117587516\n",
      "Epoch 1628 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1628.pth\n",
      "Epoch 1629 train loss: 0.5926101249560976\n",
      "Epoch 1629 train accuracy: 82.53358925143954\n",
      "Epoch 1629 val loss: 0.5868002618417928\n",
      "Epoch 1629 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1629.pth\n",
      "Epoch 1630 train loss: 0.5925304744425312\n",
      "Epoch 1630 train accuracy: 82.39649026597203\n",
      "Epoch 1630 val loss: 0.5866995707252308\n",
      "Epoch 1630 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1630.pth\n",
      "Epoch 1631 train loss: 0.5926123414711472\n",
      "Epoch 1631 train accuracy: 82.56100904853304\n",
      "Epoch 1631 val loss: 0.5867614451501715\n",
      "Epoch 1631 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1631.pth\n",
      "Epoch 1632 train loss: 0.5925423955021981\n",
      "Epoch 1632 train accuracy: 82.47874965725254\n",
      "Epoch 1632 val loss: 0.5866583055865607\n",
      "Epoch 1632 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1632.pth\n",
      "Epoch 1633 train loss: 0.5925641222530159\n",
      "Epoch 1633 train accuracy: 82.34165067178503\n",
      "Epoch 1633 val loss: 0.5866319145762214\n",
      "Epoch 1633 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1633.pth\n",
      "Epoch 1634 train loss: 0.5925034587843376\n",
      "Epoch 1634 train accuracy: 82.53358925143954\n",
      "Epoch 1634 val loss: 0.5867128840794689\n",
      "Epoch 1634 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1634.pth\n",
      "Epoch 1635 train loss: 0.5925598927904248\n",
      "Epoch 1635 train accuracy: 82.50616945434604\n",
      "Epoch 1635 val loss: 0.5867143617207674\n",
      "Epoch 1635 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1635.pth\n",
      "Epoch 1636 train loss: 0.5924958801713952\n",
      "Epoch 1636 train accuracy: 82.47874965725254\n",
      "Epoch 1636 val loss: 0.5866934098303318\n",
      "Epoch 1636 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1636.pth\n",
      "Epoch 1637 train loss: 0.5924587594181822\n",
      "Epoch 1637 train accuracy: 82.56100904853304\n",
      "Epoch 1637 val loss: 0.5866804610153562\n",
      "Epoch 1637 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1637.pth\n",
      "Epoch 1638 train loss: 0.5924425054047453\n",
      "Epoch 1638 train accuracy: 82.53358925143954\n",
      "Epoch 1638 val loss: 0.5865720626162855\n",
      "Epoch 1638 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1638.pth\n",
      "Epoch 1639 train loss: 0.5924649008533411\n",
      "Epoch 1639 train accuracy: 82.58842884562654\n",
      "Epoch 1639 val loss: 0.5865981775384984\n",
      "Epoch 1639 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1639.pth\n",
      "Epoch 1640 train loss: 0.5924501405914494\n",
      "Epoch 1640 train accuracy: 82.45132986015903\n",
      "Epoch 1640 val loss: 0.5866159156553055\n",
      "Epoch 1640 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1640.pth\n",
      "Epoch 1641 train loss: 0.5924108763707376\n",
      "Epoch 1641 train accuracy: 82.53358925143954\n",
      "Epoch 1641 val loss: 0.5866241534975799\n",
      "Epoch 1641 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1641.pth\n",
      "Epoch 1642 train loss: 0.5923213131006873\n",
      "Epoch 1642 train accuracy: 82.39649026597203\n",
      "Epoch 1642 val loss: 0.5865571346918219\n",
      "Epoch 1642 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1642.pth\n",
      "Epoch 1643 train loss: 0.5922776354280742\n",
      "Epoch 1643 train accuracy: 82.47874965725254\n",
      "Epoch 1643 val loss: 0.5865259357777081\n",
      "Epoch 1643 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1643.pth\n",
      "Epoch 1644 train loss: 0.5923767031350157\n",
      "Epoch 1644 train accuracy: 82.50616945434604\n",
      "Epoch 1644 val loss: 0.5865109560422992\n",
      "Epoch 1644 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1644.pth\n",
      "Epoch 1645 train loss: 0.592359058428229\n",
      "Epoch 1645 train accuracy: 82.50616945434604\n",
      "Epoch 1645 val loss: 0.5865210446185971\n",
      "Epoch 1645 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1645.pth\n",
      "Epoch 1646 train loss: 0.5923960324695432\n",
      "Epoch 1646 train accuracy: 82.50616945434604\n",
      "Epoch 1646 val loss: 0.586512372878037\n",
      "Epoch 1646 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1646.pth\n",
      "Epoch 1647 train loss: 0.5922474621125219\n",
      "Epoch 1647 train accuracy: 82.58842884562654\n",
      "Epoch 1647 val loss: 0.5865549938753247\n",
      "Epoch 1647 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1647.pth\n",
      "Epoch 1648 train loss: 0.5923498741007949\n",
      "Epoch 1648 train accuracy: 82.61584864272004\n",
      "Epoch 1648 val loss: 0.5865249545558503\n",
      "Epoch 1648 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1648.pth\n",
      "Epoch 1649 train loss: 0.5922759362790537\n",
      "Epoch 1649 train accuracy: 82.47874965725254\n",
      "Epoch 1649 val loss: 0.5864687860992394\n",
      "Epoch 1649 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1649.pth\n",
      "Epoch 1650 train loss: 0.5922708253359847\n",
      "Epoch 1650 train accuracy: 82.53358925143954\n",
      "Epoch 1650 val loss: 0.5864147203239171\n",
      "Epoch 1650 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1650.pth\n",
      "Epoch 1651 train loss: 0.5923095422127006\n",
      "Epoch 1651 train accuracy: 82.53358925143954\n",
      "Epoch 1651 val loss: 0.5863545307472936\n",
      "Epoch 1651 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1651.pth\n",
      "Epoch 1652 train loss: 0.5923162275484126\n",
      "Epoch 1652 train accuracy: 82.56100904853304\n",
      "Epoch 1652 val loss: 0.5863549467666369\n",
      "Epoch 1652 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1652.pth\n",
      "Epoch 1653 train loss: 0.5922228960001743\n",
      "Epoch 1653 train accuracy: 82.72552783109406\n",
      "Epoch 1653 val loss: 0.5864284727722406\n",
      "Epoch 1653 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1653.pth\n",
      "Epoch 1654 train loss: 0.5922658216747406\n",
      "Epoch 1654 train accuracy: 82.53358925143954\n",
      "Epoch 1654 val loss: 0.5863791238516569\n",
      "Epoch 1654 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1654.pth\n",
      "Epoch 1655 train loss: 0.5922649637305815\n",
      "Epoch 1655 train accuracy: 82.56100904853304\n",
      "Epoch 1655 val loss: 0.5864342062145864\n",
      "Epoch 1655 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1655.pth\n",
      "Epoch 1656 train loss: 0.5922376541502512\n",
      "Epoch 1656 train accuracy: 82.61584864272004\n",
      "Epoch 1656 val loss: 0.5864170163771824\n",
      "Epoch 1656 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1656.pth\n",
      "Epoch 1657 train loss: 0.592230746195766\n",
      "Epoch 1657 train accuracy: 82.45132986015903\n",
      "Epoch 1657 val loss: 0.5863475775787312\n",
      "Epoch 1657 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1657.pth\n",
      "Epoch 1658 train loss: 0.5921139063460654\n",
      "Epoch 1658 train accuracy: 82.47874965725254\n",
      "Epoch 1658 val loss: 0.5863637984485218\n",
      "Epoch 1658 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1658.pth\n",
      "Epoch 1659 train loss: 0.5921798111348037\n",
      "Epoch 1659 train accuracy: 82.61584864272004\n",
      "Epoch 1659 val loss: 0.5862661927546325\n",
      "Epoch 1659 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1659.pth\n",
      "Epoch 1660 train loss: 0.592140045180394\n",
      "Epoch 1660 train accuracy: 82.64326843981354\n",
      "Epoch 1660 val loss: 0.5862585892900825\n",
      "Epoch 1660 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1660.pth\n",
      "Epoch 1661 train loss: 0.5921211549358671\n",
      "Epoch 1661 train accuracy: 82.61584864272004\n",
      "Epoch 1661 val loss: 0.5863010503939892\n",
      "Epoch 1661 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1661.pth\n",
      "Epoch 1662 train loss: 0.5921514353943629\n",
      "Epoch 1662 train accuracy: 82.45132986015903\n",
      "Epoch 1662 val loss: 0.5862834434956312\n",
      "Epoch 1662 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1662.pth\n",
      "Epoch 1663 train loss: 0.5920506912496006\n",
      "Epoch 1663 train accuracy: 82.56100904853304\n",
      "Epoch 1663 val loss: 0.5863404230851876\n",
      "Epoch 1663 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1663.pth\n",
      "Epoch 1664 train loss: 0.5919998411963318\n",
      "Epoch 1664 train accuracy: 82.61584864272004\n",
      "Epoch 1664 val loss: 0.5862717144191265\n",
      "Epoch 1664 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1664.pth\n",
      "Epoch 1665 train loss: 0.59201172420657\n",
      "Epoch 1665 train accuracy: 82.67068823690704\n",
      "Epoch 1665 val loss: 0.5862588296693406\n",
      "Epoch 1665 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1665.pth\n",
      "Epoch 1666 train loss: 0.5920923309269965\n",
      "Epoch 1666 train accuracy: 82.64326843981354\n",
      "Epoch 1666 val loss: 0.5862926804019433\n",
      "Epoch 1666 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1666.pth\n",
      "Epoch 1667 train loss: 0.5920612003425496\n",
      "Epoch 1667 train accuracy: 82.56100904853304\n",
      "Epoch 1667 val loss: 0.5862655077423704\n",
      "Epoch 1667 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1667.pth\n",
      "Epoch 1668 train loss: 0.5920638716697955\n",
      "Epoch 1668 train accuracy: 82.53358925143954\n",
      "Epoch 1668 val loss: 0.5861957475150886\n",
      "Epoch 1668 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1668.pth\n",
      "Epoch 1669 train loss: 0.5920503326659009\n",
      "Epoch 1669 train accuracy: 82.64326843981354\n",
      "Epoch 1669 val loss: 0.5861787451921325\n",
      "Epoch 1669 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1669.pth\n",
      "Epoch 1670 train loss: 0.5920362155118614\n",
      "Epoch 1670 train accuracy: 82.58842884562654\n",
      "Epoch 1670 val loss: 0.5861603437653301\n",
      "Epoch 1670 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1670.pth\n",
      "Epoch 1671 train loss: 0.5920309344012487\n",
      "Epoch 1671 train accuracy: 82.69810803400055\n",
      "Epoch 1671 val loss: 0.5861442357693848\n",
      "Epoch 1671 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1671.pth\n",
      "Epoch 1672 train loss: 0.5920136362281546\n",
      "Epoch 1672 train accuracy: 82.61584864272004\n",
      "Epoch 1672 val loss: 0.5861307069365131\n",
      "Epoch 1672 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1672.pth\n",
      "Epoch 1673 train loss: 0.5919657928476992\n",
      "Epoch 1673 train accuracy: 82.61584864272004\n",
      "Epoch 1673 val loss: 0.5861486589634105\n",
      "Epoch 1673 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1673.pth\n",
      "Epoch 1674 train loss: 0.5919227596176299\n",
      "Epoch 1674 train accuracy: 82.56100904853304\n",
      "Epoch 1674 val loss: 0.5861126500132837\n",
      "Epoch 1674 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1674.pth\n",
      "Epoch 1675 train loss: 0.5919416280005846\n",
      "Epoch 1675 train accuracy: 82.67068823690704\n",
      "Epoch 1675 val loss: 0.5861141898969532\n",
      "Epoch 1675 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1675.pth\n",
      "Epoch 1676 train loss: 0.5919596154830957\n",
      "Epoch 1676 train accuracy: 82.67068823690704\n",
      "Epoch 1676 val loss: 0.5861175663671211\n",
      "Epoch 1676 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1676.pth\n",
      "Epoch 1677 train loss: 0.5919220612073938\n",
      "Epoch 1677 train accuracy: 82.61584864272004\n",
      "Epoch 1677 val loss: 0.5860830332201562\n",
      "Epoch 1677 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1677.pth\n",
      "Epoch 1678 train loss: 0.5918890104318658\n",
      "Epoch 1678 train accuracy: 82.64326843981354\n",
      "Epoch 1678 val loss: 0.5860859146341681\n",
      "Epoch 1678 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1678.pth\n",
      "Epoch 1679 train loss: 0.5918721477746179\n",
      "Epoch 1679 train accuracy: 82.53358925143954\n",
      "Epoch 1679 val loss: 0.5860745076972403\n",
      "Epoch 1679 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1679.pth\n",
      "Epoch 1680 train loss: 0.5918031062506008\n",
      "Epoch 1680 train accuracy: 82.58842884562654\n",
      "Epoch 1680 val loss: 0.5859779805239094\n",
      "Epoch 1680 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1680.pth\n",
      "Epoch 1681 train loss: 0.5918125027235139\n",
      "Epoch 1681 train accuracy: 82.69810803400055\n",
      "Epoch 1681 val loss: 0.5859713613202697\n",
      "Epoch 1681 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1681.pth\n",
      "Epoch 1682 train loss: 0.5918556468626648\n",
      "Epoch 1682 train accuracy: 82.69810803400055\n",
      "Epoch 1682 val loss: 0.5860205046636494\n",
      "Epoch 1682 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1682.pth\n",
      "Epoch 1683 train loss: 0.5918408655479812\n",
      "Epoch 1683 train accuracy: 82.69810803400055\n",
      "Epoch 1683 val loss: 0.586031377756674\n",
      "Epoch 1683 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1683.pth\n",
      "Epoch 1684 train loss: 0.5917803919792437\n",
      "Epoch 1684 train accuracy: 82.67068823690704\n",
      "Epoch 1684 val loss: 0.5860120596266106\n",
      "Epoch 1684 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1684.pth\n",
      "Epoch 1685 train loss: 0.5916836701227319\n",
      "Epoch 1685 train accuracy: 82.80778722237456\n",
      "Epoch 1685 val loss: 0.5860728633737093\n",
      "Epoch 1685 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1685.pth\n",
      "Epoch 1686 train loss: 0.5918166395930344\n",
      "Epoch 1686 train accuracy: 82.50616945434604\n",
      "Epoch 1686 val loss: 0.5860187762269848\n",
      "Epoch 1686 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1686.pth\n",
      "Epoch 1687 train loss: 0.5917949249902577\n",
      "Epoch 1687 train accuracy: 82.56100904853304\n",
      "Epoch 1687 val loss: 0.5859754572769529\n",
      "Epoch 1687 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1687.pth\n",
      "Epoch 1688 train loss: 0.5917895147250148\n",
      "Epoch 1688 train accuracy: 82.47874965725254\n",
      "Epoch 1688 val loss: 0.5859401484608258\n",
      "Epoch 1688 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1688.pth\n",
      "Epoch 1689 train loss: 0.5917858081592018\n",
      "Epoch 1689 train accuracy: 82.58842884562654\n",
      "Epoch 1689 val loss: 0.5859136494660848\n",
      "Epoch 1689 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1689.pth\n",
      "Epoch 1690 train loss: 0.5917283402134975\n",
      "Epoch 1690 train accuracy: 82.45132986015903\n",
      "Epoch 1690 val loss: 0.5859062003069803\n",
      "Epoch 1690 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1690.pth\n",
      "Epoch 1691 train loss: 0.5916821350294509\n",
      "Epoch 1691 train accuracy: 82.69810803400055\n",
      "Epoch 1691 val loss: 0.5859182477977715\n",
      "Epoch 1691 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1691.pth\n",
      "Epoch 1692 train loss: 0.5917078644167959\n",
      "Epoch 1692 train accuracy: 82.58842884562654\n",
      "Epoch 1692 val loss: 0.5859337595144385\n",
      "Epoch 1692 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1692.pth\n",
      "Epoch 1693 train loss: 0.591718506754229\n",
      "Epoch 1693 train accuracy: 82.67068823690704\n",
      "Epoch 1693 val loss: 0.5859551559153356\n",
      "Epoch 1693 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1693.pth\n",
      "Epoch 1694 train loss: 0.5916325715452171\n",
      "Epoch 1694 train accuracy: 82.61584864272004\n",
      "Epoch 1694 val loss: 0.5859101194104082\n",
      "Epoch 1694 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1694.pth\n",
      "Epoch 1695 train loss: 0.5916202147001106\n",
      "Epoch 1695 train accuracy: 82.58842884562654\n",
      "Epoch 1695 val loss: 0.5859090087837294\n",
      "Epoch 1695 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1695.pth\n",
      "Epoch 1696 train loss: 0.5915884468214292\n",
      "Epoch 1696 train accuracy: 82.64326843981354\n",
      "Epoch 1696 val loss: 0.5858119056364032\n",
      "Epoch 1696 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1696.pth\n",
      "Epoch 1697 train loss: 0.591648913184671\n",
      "Epoch 1697 train accuracy: 82.67068823690704\n",
      "Epoch 1697 val loss: 0.5857400813287026\n",
      "Epoch 1697 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1697.pth\n",
      "Epoch 1698 train loss: 0.5916298087318673\n",
      "Epoch 1698 train accuracy: 82.72552783109406\n",
      "Epoch 1698 val loss: 0.5858025657209126\n",
      "Epoch 1698 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1698.pth\n",
      "Epoch 1699 train loss: 0.5916093655600491\n",
      "Epoch 1699 train accuracy: 82.47874965725254\n",
      "Epoch 1699 val loss: 0.5857411177436772\n",
      "Epoch 1699 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1699.pth\n",
      "Epoch 1700 train loss: 0.5916130433079639\n",
      "Epoch 1700 train accuracy: 82.75294762818756\n",
      "Epoch 1700 val loss: 0.5857615234624398\n",
      "Epoch 1700 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1700.pth\n",
      "Epoch 1701 train loss: 0.591595700598861\n",
      "Epoch 1701 train accuracy: 82.75294762818756\n",
      "Epoch 1701 val loss: 0.585778258642868\n",
      "Epoch 1701 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1701.pth\n",
      "Epoch 1702 train loss: 0.5915784942794984\n",
      "Epoch 1702 train accuracy: 82.64326843981354\n",
      "Epoch 1702 val loss: 0.5857808858793425\n",
      "Epoch 1702 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1702.pth\n",
      "Epoch 1703 train loss: 0.5914973609567887\n",
      "Epoch 1703 train accuracy: 82.61584864272004\n",
      "Epoch 1703 val loss: 0.5857696147684596\n",
      "Epoch 1703 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1703.pth\n",
      "Epoch 1704 train loss: 0.5915567236544009\n",
      "Epoch 1704 train accuracy: 82.50616945434604\n",
      "Epoch 1704 val loss: 0.585767283202394\n",
      "Epoch 1704 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1704.pth\n",
      "Epoch 1705 train loss: 0.5915493526937146\n",
      "Epoch 1705 train accuracy: 82.61584864272004\n",
      "Epoch 1705 val loss: 0.5857574335348449\n",
      "Epoch 1705 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1705.pth\n",
      "Epoch 1706 train loss: 0.5913723093669927\n",
      "Epoch 1706 train accuracy: 82.61584864272004\n",
      "Epoch 1706 val loss: 0.5857101675417078\n",
      "Epoch 1706 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1706.pth\n",
      "Epoch 1707 train loss: 0.5914621976073504\n",
      "Epoch 1707 train accuracy: 82.64326843981354\n",
      "Epoch 1707 val loss: 0.5857040612762304\n",
      "Epoch 1707 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1707.pth\n",
      "Epoch 1708 train loss: 0.5914515479255402\n",
      "Epoch 1708 train accuracy: 82.75294762818756\n",
      "Epoch 1708 val loss: 0.58569187283712\n",
      "Epoch 1708 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1708.pth\n",
      "Epoch 1709 train loss: 0.5914478523068523\n",
      "Epoch 1709 train accuracy: 82.64326843981354\n",
      "Epoch 1709 val loss: 0.5857051829562375\n",
      "Epoch 1709 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1709.pth\n",
      "Epoch 1710 train loss: 0.5914002747618055\n",
      "Epoch 1710 train accuracy: 82.56100904853304\n",
      "Epoch 1710 val loss: 0.5856367761612331\n",
      "Epoch 1710 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1710.pth\n",
      "Epoch 1711 train loss: 0.5914579926287395\n",
      "Epoch 1711 train accuracy: 82.69810803400055\n",
      "Epoch 1711 val loss: 0.5856302582511776\n",
      "Epoch 1711 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1711.pth\n",
      "Epoch 1712 train loss: 0.5914427140694961\n",
      "Epoch 1712 train accuracy: 82.61584864272004\n",
      "Epoch 1712 val loss: 0.5856378484811438\n",
      "Epoch 1712 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1712.pth\n",
      "Epoch 1713 train loss: 0.591440373622167\n",
      "Epoch 1713 train accuracy: 82.72552783109406\n",
      "Epoch 1713 val loss: 0.5856225186664807\n",
      "Epoch 1713 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1713.pth\n",
      "Epoch 1714 train loss: 0.5913128046024787\n",
      "Epoch 1714 train accuracy: 82.61584864272004\n",
      "Epoch 1714 val loss: 0.5856213308870792\n",
      "Epoch 1714 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1714.pth\n",
      "Epoch 1715 train loss: 0.5914151878831418\n",
      "Epoch 1715 train accuracy: 82.64326843981354\n",
      "Epoch 1715 val loss: 0.5856379826773742\n",
      "Epoch 1715 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1715.pth\n",
      "Epoch 1716 train loss: 0.591334601341371\n",
      "Epoch 1716 train accuracy: 82.72552783109406\n",
      "Epoch 1716 val loss: 0.5856796046228785\n",
      "Epoch 1716 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1716.pth\n",
      "Epoch 1717 train loss: 0.5913572011254075\n",
      "Epoch 1717 train accuracy: 82.64326843981354\n",
      "Epoch 1717 val loss: 0.5856191802181696\n",
      "Epoch 1717 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1717.pth\n",
      "Epoch 1718 train loss: 0.591357626821519\n",
      "Epoch 1718 train accuracy: 82.58842884562654\n",
      "Epoch 1718 val loss: 0.585544850432167\n",
      "Epoch 1718 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1718.pth\n",
      "Epoch 1719 train loss: 0.5912566628601206\n",
      "Epoch 1719 train accuracy: 82.69810803400055\n",
      "Epoch 1719 val loss: 0.5855679606136522\n",
      "Epoch 1719 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1719.pth\n",
      "Epoch 1720 train loss: 0.5912910856045129\n",
      "Epoch 1720 train accuracy: 82.64326843981354\n",
      "Epoch 1720 val loss: 0.5855563787351313\n",
      "Epoch 1720 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1720.pth\n",
      "Epoch 1721 train loss: 0.5912670742458942\n",
      "Epoch 1721 train accuracy: 82.72552783109406\n",
      "Epoch 1721 val loss: 0.5855562071266928\n",
      "Epoch 1721 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1721.pth\n",
      "Epoch 1722 train loss: 0.5912417519608872\n",
      "Epoch 1722 train accuracy: 82.67068823690704\n",
      "Epoch 1722 val loss: 0.5855163296831674\n",
      "Epoch 1722 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1722.pth\n",
      "Epoch 1723 train loss: 0.5912443414787975\n",
      "Epoch 1723 train accuracy: 82.78036742528106\n",
      "Epoch 1723 val loss: 0.5854851955449895\n",
      "Epoch 1723 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1723.pth\n",
      "Epoch 1724 train loss: 0.5912911083320516\n",
      "Epoch 1724 train accuracy: 82.78036742528106\n",
      "Epoch 1724 val loss: 0.5855076217925862\n",
      "Epoch 1724 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1724.pth\n",
      "Epoch 1725 train loss: 0.5913201471986739\n",
      "Epoch 1725 train accuracy: 82.53358925143954\n",
      "Epoch 1725 val loss: 0.5854480353821265\n",
      "Epoch 1725 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1725.pth\n",
      "Epoch 1726 train loss: 0.5912968754899084\n",
      "Epoch 1726 train accuracy: 82.67068823690704\n",
      "Epoch 1726 val loss: 0.5854558373654359\n",
      "Epoch 1726 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1726.pth\n",
      "Epoch 1727 train loss: 0.5911994060632169\n",
      "Epoch 1727 train accuracy: 82.72552783109406\n",
      "Epoch 1727 val loss: 0.5854878033952493\n",
      "Epoch 1727 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1727.pth\n",
      "Epoch 1728 train loss: 0.5911932695951116\n",
      "Epoch 1728 train accuracy: 82.69810803400055\n",
      "Epoch 1728 val loss: 0.5854557884955093\n",
      "Epoch 1728 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1728.pth\n",
      "Epoch 1729 train loss: 0.5911524266886868\n",
      "Epoch 1729 train accuracy: 82.61584864272004\n",
      "Epoch 1729 val loss: 0.585434553139892\n",
      "Epoch 1729 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1729.pth\n",
      "Epoch 1730 train loss: 0.5911621227533671\n",
      "Epoch 1730 train accuracy: 82.61584864272004\n",
      "Epoch 1730 val loss: 0.5854618506702153\n",
      "Epoch 1730 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1730.pth\n",
      "Epoch 1731 train loss: 0.5911904266921052\n",
      "Epoch 1731 train accuracy: 82.69810803400055\n",
      "Epoch 1731 val loss: 0.5854169464621105\n",
      "Epoch 1731 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1731.pth\n",
      "Epoch 1732 train loss: 0.5910834614024089\n",
      "Epoch 1732 train accuracy: 82.58842884562654\n",
      "Epoch 1732 val loss: 0.5854942135414795\n",
      "Epoch 1732 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1732.pth\n",
      "Epoch 1733 train loss: 0.5911702289033616\n",
      "Epoch 1733 train accuracy: 82.61584864272004\n",
      "Epoch 1733 val loss: 0.5854008821280379\n",
      "Epoch 1733 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1733.pth\n",
      "Epoch 1734 train loss: 0.5911009687493277\n",
      "Epoch 1734 train accuracy: 82.72552783109406\n",
      "Epoch 1734 val loss: 0.5854056537347404\n",
      "Epoch 1734 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1734.pth\n",
      "Epoch 1735 train loss: 0.5910642585112599\n",
      "Epoch 1735 train accuracy: 82.67068823690704\n",
      "Epoch 1735 val loss: 0.5853915230714177\n",
      "Epoch 1735 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1735.pth\n",
      "Epoch 1736 train loss: 0.5911226092037141\n",
      "Epoch 1736 train accuracy: 82.69810803400055\n",
      "Epoch 1736 val loss: 0.5853125197126677\n",
      "Epoch 1736 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1736.pth\n",
      "Epoch 1737 train loss: 0.5911180278155626\n",
      "Epoch 1737 train accuracy: 82.72552783109406\n",
      "Epoch 1737 val loss: 0.5853783099078819\n",
      "Epoch 1737 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1737.pth\n",
      "Epoch 1738 train loss: 0.5910466636138919\n",
      "Epoch 1738 train accuracy: 82.75294762818756\n",
      "Epoch 1738 val loss: 0.5853840079844782\n",
      "Epoch 1738 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1738.pth\n",
      "Epoch 1739 train loss: 0.5910888031174085\n",
      "Epoch 1739 train accuracy: 82.72552783109406\n",
      "Epoch 1739 val loss: 0.585375831621748\n",
      "Epoch 1739 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1739.pth\n",
      "Epoch 1740 train loss: 0.5910139789380002\n",
      "Epoch 1740 train accuracy: 82.72552783109406\n",
      "Epoch 1740 val loss: 0.5853291705348774\n",
      "Epoch 1740 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1740.pth\n",
      "Epoch 1741 train loss: 0.5910894997548639\n",
      "Epoch 1741 train accuracy: 82.67068823690704\n",
      "Epoch 1741 val loss: 0.5852807585738207\n",
      "Epoch 1741 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1741.pth\n",
      "Epoch 1742 train loss: 0.5910576232954076\n",
      "Epoch 1742 train accuracy: 82.75294762818756\n",
      "Epoch 1742 val loss: 0.5853014285921266\n",
      "Epoch 1742 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1742.pth\n",
      "Epoch 1743 train loss: 0.5910227622738794\n",
      "Epoch 1743 train accuracy: 82.69810803400055\n",
      "Epoch 1743 val loss: 0.585278049797604\n",
      "Epoch 1743 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1743.pth\n",
      "Epoch 1744 train loss: 0.5910100929046932\n",
      "Epoch 1744 train accuracy: 82.78036742528106\n",
      "Epoch 1744 val loss: 0.5852589501607183\n",
      "Epoch 1744 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1744.pth\n",
      "Epoch 1745 train loss: 0.5910221598225466\n",
      "Epoch 1745 train accuracy: 82.67068823690704\n",
      "Epoch 1745 val loss: 0.585255175436798\n",
      "Epoch 1745 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1745.pth\n",
      "Epoch 1746 train loss: 0.5909279051416537\n",
      "Epoch 1746 train accuracy: 82.69810803400055\n",
      "Epoch 1746 val loss: 0.5852109858472097\n",
      "Epoch 1746 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1746.pth\n",
      "Epoch 1747 train loss: 0.5909921465637652\n",
      "Epoch 1747 train accuracy: 82.67068823690704\n",
      "Epoch 1747 val loss: 0.5852018646699818\n",
      "Epoch 1747 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1747.pth\n",
      "Epoch 1748 train loss: 0.5909983781493154\n",
      "Epoch 1748 train accuracy: 82.75294762818756\n",
      "Epoch 1748 val loss: 0.585207569559938\n",
      "Epoch 1748 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1748.pth\n",
      "Epoch 1749 train loss: 0.5909418917277403\n",
      "Epoch 1749 train accuracy: 82.75294762818756\n",
      "Epoch 1749 val loss: 0.5851585100846071\n",
      "Epoch 1749 val accuracy: 83.88157894736842\n",
      "Saved model to .\\test_models/MLP_1749.pth\n",
      "Epoch 1750 train loss: 0.5908218342729175\n",
      "Epoch 1750 train accuracy: 82.69810803400055\n",
      "Epoch 1750 val loss: 0.58515561156367\n",
      "Epoch 1750 val accuracy: 83.88157894736842\n",
      "Saved model to .\\test_models/MLP_1750.pth\n",
      "Epoch 1751 train loss: 0.5909264137240314\n",
      "Epoch 1751 train accuracy: 82.78036742528106\n",
      "Epoch 1751 val loss: 0.585090631079909\n",
      "Epoch 1751 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1751.pth\n",
      "Epoch 1752 train loss: 0.5909233146526834\n",
      "Epoch 1752 train accuracy: 82.78036742528106\n",
      "Epoch 1752 val loss: 0.5851146229297707\n",
      "Epoch 1752 val accuracy: 83.88157894736842\n",
      "Saved model to .\\test_models/MLP_1752.pth\n",
      "Epoch 1753 train loss: 0.5908707959838865\n",
      "Epoch 1753 train accuracy: 82.72552783109406\n",
      "Epoch 1753 val loss: 0.5851515288293165\n",
      "Epoch 1753 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1753.pth\n",
      "Epoch 1754 train loss: 0.590893636637351\n",
      "Epoch 1754 train accuracy: 82.83520701946806\n",
      "Epoch 1754 val loss: 0.5851909744118242\n",
      "Epoch 1754 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1754.pth\n",
      "Epoch 1755 train loss: 0.5908979114978329\n",
      "Epoch 1755 train accuracy: 82.69810803400055\n",
      "Epoch 1755 val loss: 0.5851511962123608\n",
      "Epoch 1755 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1755.pth\n",
      "Epoch 1756 train loss: 0.5908229438293922\n",
      "Epoch 1756 train accuracy: 82.78036742528106\n",
      "Epoch 1756 val loss: 0.5851360446234283\n",
      "Epoch 1756 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1756.pth\n",
      "Epoch 1757 train loss: 0.5908710037627699\n",
      "Epoch 1757 train accuracy: 82.78036742528106\n",
      "Epoch 1757 val loss: 0.5851052949254058\n",
      "Epoch 1757 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1757.pth\n",
      "Epoch 1758 train loss: 0.5908535838805204\n",
      "Epoch 1758 train accuracy: 82.67068823690704\n",
      "Epoch 1758 val loss: 0.585081952525989\n",
      "Epoch 1758 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1758.pth\n",
      "Epoch 1759 train loss: 0.5907816848505223\n",
      "Epoch 1759 train accuracy: 82.86262681656156\n",
      "Epoch 1759 val loss: 0.5850891978725007\n",
      "Epoch 1759 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1759.pth\n",
      "Epoch 1760 train loss: 0.5907583617066082\n",
      "Epoch 1760 train accuracy: 82.78036742528106\n",
      "Epoch 1760 val loss: 0.5851201829255411\n",
      "Epoch 1760 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1760.pth\n",
      "Epoch 1761 train loss: 0.5908283124056956\n",
      "Epoch 1761 train accuracy: 82.75294762818756\n",
      "Epoch 1761 val loss: 0.585104912568472\n",
      "Epoch 1761 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1761.pth\n",
      "Epoch 1762 train loss: 0.5908032185234652\n",
      "Epoch 1762 train accuracy: 82.69810803400055\n",
      "Epoch 1762 val loss: 0.5850167512697609\n",
      "Epoch 1762 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1762.pth\n",
      "Epoch 1763 train loss: 0.5907693375555569\n",
      "Epoch 1763 train accuracy: 82.72552783109406\n",
      "Epoch 1763 val loss: 0.5850701572275475\n",
      "Epoch 1763 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1763.pth\n",
      "Epoch 1764 train loss: 0.5907749688710299\n",
      "Epoch 1764 train accuracy: 82.69810803400055\n",
      "Epoch 1764 val loss: 0.5850040827828803\n",
      "Epoch 1764 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1764.pth\n",
      "Epoch 1765 train loss: 0.5907220843047917\n",
      "Epoch 1765 train accuracy: 82.69810803400055\n",
      "Epoch 1765 val loss: 0.584970154799521\n",
      "Epoch 1765 val accuracy: 83.88157894736842\n",
      "Saved model to .\\test_models/MLP_1765.pth\n",
      "Epoch 1766 train loss: 0.5906877657071802\n",
      "Epoch 1766 train accuracy: 82.80778722237456\n",
      "Epoch 1766 val loss: 0.5850418799703843\n",
      "Epoch 1766 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1766.pth\n",
      "Epoch 1767 train loss: 0.590670194231758\n",
      "Epoch 1767 train accuracy: 82.78036742528106\n",
      "Epoch 1767 val loss: 0.5850715834745451\n",
      "Epoch 1767 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1767.pth\n",
      "Epoch 1768 train loss: 0.590710842099629\n",
      "Epoch 1768 train accuracy: 82.67068823690704\n",
      "Epoch 1768 val loss: 0.5850131799417891\n",
      "Epoch 1768 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1768.pth\n",
      "Epoch 1769 train loss: 0.5906965850950464\n",
      "Epoch 1769 train accuracy: 82.67068823690704\n",
      "Epoch 1769 val loss: 0.5849072698405698\n",
      "Epoch 1769 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1769.pth\n",
      "Epoch 1770 train loss: 0.5906511623118269\n",
      "Epoch 1770 train accuracy: 82.75294762818756\n",
      "Epoch 1770 val loss: 0.584938776826388\n",
      "Epoch 1770 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1770.pth\n",
      "Epoch 1771 train loss: 0.5907130524058614\n",
      "Epoch 1771 train accuracy: 82.80778722237456\n",
      "Epoch 1771 val loss: 0.5849488789803887\n",
      "Epoch 1771 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1771.pth\n",
      "Epoch 1772 train loss: 0.5906790692457243\n",
      "Epoch 1772 train accuracy: 82.64326843981354\n",
      "Epoch 1772 val loss: 0.5849413177868548\n",
      "Epoch 1772 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1772.pth\n",
      "Epoch 1773 train loss: 0.5906669754175502\n",
      "Epoch 1773 train accuracy: 82.78036742528106\n",
      "Epoch 1773 val loss: 0.5849165361264328\n",
      "Epoch 1773 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1773.pth\n",
      "Epoch 1774 train loss: 0.5906520777855787\n",
      "Epoch 1774 train accuracy: 82.80778722237456\n",
      "Epoch 1774 val loss: 0.5849550110042879\n",
      "Epoch 1774 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1774.pth\n",
      "Epoch 1775 train loss: 0.5906388623999399\n",
      "Epoch 1775 train accuracy: 82.78036742528106\n",
      "Epoch 1775 val loss: 0.5848844893472759\n",
      "Epoch 1775 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1775.pth\n",
      "Epoch 1776 train loss: 0.590631771857213\n",
      "Epoch 1776 train accuracy: 82.75294762818756\n",
      "Epoch 1776 val loss: 0.5849036912580854\n",
      "Epoch 1776 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1776.pth\n",
      "Epoch 1777 train loss: 0.5905663799821285\n",
      "Epoch 1777 train accuracy: 82.67068823690704\n",
      "Epoch 1777 val loss: 0.584841415531149\n",
      "Epoch 1777 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1777.pth\n",
      "Epoch 1778 train loss: 0.5905569302931166\n",
      "Epoch 1778 train accuracy: 82.78036742528106\n",
      "Epoch 1778 val loss: 0.5848349734748665\n",
      "Epoch 1778 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1778.pth\n",
      "Epoch 1779 train loss: 0.5905541303473639\n",
      "Epoch 1779 train accuracy: 82.83520701946806\n",
      "Epoch 1779 val loss: 0.5848280492875921\n",
      "Epoch 1779 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1779.pth\n",
      "Epoch 1780 train loss: 0.590587959396081\n",
      "Epoch 1780 train accuracy: 82.72552783109406\n",
      "Epoch 1780 val loss: 0.5847857517533397\n",
      "Epoch 1780 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1780.pth\n",
      "Epoch 1781 train loss: 0.5905286622674841\n",
      "Epoch 1781 train accuracy: 82.83520701946806\n",
      "Epoch 1781 val loss: 0.5848193319612428\n",
      "Epoch 1781 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1781.pth\n",
      "Epoch 1782 train loss: 0.5904959172925406\n",
      "Epoch 1782 train accuracy: 82.75294762818756\n",
      "Epoch 1782 val loss: 0.58483464824722\n",
      "Epoch 1782 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1782.pth\n",
      "Epoch 1783 train loss: 0.5905439374445561\n",
      "Epoch 1783 train accuracy: 82.78036742528106\n",
      "Epoch 1783 val loss: 0.5848590666918378\n",
      "Epoch 1783 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1783.pth\n",
      "Epoch 1784 train loss: 0.5905716670513675\n",
      "Epoch 1784 train accuracy: 82.75294762818756\n",
      "Epoch 1784 val loss: 0.584797936981838\n",
      "Epoch 1784 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1784.pth\n",
      "Epoch 1785 train loss: 0.590380727166408\n",
      "Epoch 1785 train accuracy: 82.69810803400055\n",
      "Epoch 1785 val loss: 0.5847779072232937\n",
      "Epoch 1785 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1785.pth\n",
      "Epoch 1786 train loss: 0.5904878224409594\n",
      "Epoch 1786 train accuracy: 82.72552783109406\n",
      "Epoch 1786 val loss: 0.5847279361792301\n",
      "Epoch 1786 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1786.pth\n",
      "Epoch 1787 train loss: 0.5904421377927065\n",
      "Epoch 1787 train accuracy: 82.80778722237456\n",
      "Epoch 1787 val loss: 0.5847976558204544\n",
      "Epoch 1787 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1787.pth\n",
      "Epoch 1788 train loss: 0.5904875295931113\n",
      "Epoch 1788 train accuracy: 82.78036742528106\n",
      "Epoch 1788 val loss: 0.5847253171530994\n",
      "Epoch 1788 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1788.pth\n",
      "Epoch 1789 train loss: 0.5904737986428173\n",
      "Epoch 1789 train accuracy: 82.75294762818756\n",
      "Epoch 1789 val loss: 0.5847391467051286\n",
      "Epoch 1789 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1789.pth\n",
      "Epoch 1790 train loss: 0.5904617920485243\n",
      "Epoch 1790 train accuracy: 82.64326843981354\n",
      "Epoch 1790 val loss: 0.5846754349768162\n",
      "Epoch 1790 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1790.pth\n",
      "Epoch 1791 train loss: 0.5903900837599251\n",
      "Epoch 1791 train accuracy: 82.75294762818756\n",
      "Epoch 1791 val loss: 0.58465487054108\n",
      "Epoch 1791 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1791.pth\n",
      "Epoch 1792 train loss: 0.5903778544774181\n",
      "Epoch 1792 train accuracy: 82.83520701946806\n",
      "Epoch 1792 val loss: 0.5847141248615164\n",
      "Epoch 1792 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1792.pth\n",
      "Epoch 1793 train loss: 0.5904119455892789\n",
      "Epoch 1793 train accuracy: 82.75294762818756\n",
      "Epoch 1793 val loss: 0.5846333715476488\n",
      "Epoch 1793 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1793.pth\n",
      "Epoch 1794 train loss: 0.5904224026261976\n",
      "Epoch 1794 train accuracy: 82.83520701946806\n",
      "Epoch 1794 val loss: 0.5846766604992905\n",
      "Epoch 1794 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1794.pth\n",
      "Epoch 1795 train loss: 0.5904897714335994\n",
      "Epoch 1795 train accuracy: 82.80778722237456\n",
      "Epoch 1795 val loss: 0.58469781083496\n",
      "Epoch 1795 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1795.pth\n",
      "Epoch 1796 train loss: 0.5903908345488864\n",
      "Epoch 1796 train accuracy: 82.80778722237456\n",
      "Epoch 1796 val loss: 0.5847191956188333\n",
      "Epoch 1796 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1796.pth\n",
      "Epoch 1797 train loss: 0.5903044629090449\n",
      "Epoch 1797 train accuracy: 82.75294762818756\n",
      "Epoch 1797 val loss: 0.5846791074758297\n",
      "Epoch 1797 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1797.pth\n",
      "Epoch 1798 train loss: 0.5903768161017644\n",
      "Epoch 1798 train accuracy: 82.89004661365506\n",
      "Epoch 1798 val loss: 0.5846582544771465\n",
      "Epoch 1798 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1798.pth\n",
      "Epoch 1799 train loss: 0.5903462290502431\n",
      "Epoch 1799 train accuracy: 82.75294762818756\n",
      "Epoch 1799 val loss: 0.584568609581574\n",
      "Epoch 1799 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1799.pth\n",
      "Epoch 1800 train loss: 0.590289743649855\n",
      "Epoch 1800 train accuracy: 82.80778722237456\n",
      "Epoch 1800 val loss: 0.5846279096838675\n",
      "Epoch 1800 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1800.pth\n",
      "Epoch 1801 train loss: 0.5902818431750986\n",
      "Epoch 1801 train accuracy: 82.69810803400055\n",
      "Epoch 1801 val loss: 0.5845889611365763\n",
      "Epoch 1801 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1801.pth\n",
      "Epoch 1802 train loss: 0.5902730011985752\n",
      "Epoch 1802 train accuracy: 82.72552783109406\n",
      "Epoch 1802 val loss: 0.5846092834284431\n",
      "Epoch 1802 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1802.pth\n",
      "Epoch 1803 train loss: 0.590271556488516\n",
      "Epoch 1803 train accuracy: 82.78036742528106\n",
      "Epoch 1803 val loss: 0.5846247871063257\n",
      "Epoch 1803 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1803.pth\n",
      "Epoch 1804 train loss: 0.5902292821964804\n",
      "Epoch 1804 train accuracy: 82.72552783109406\n",
      "Epoch 1804 val loss: 0.5846040130862477\n",
      "Epoch 1804 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1804.pth\n",
      "Epoch 1805 train loss: 0.5902461851865315\n",
      "Epoch 1805 train accuracy: 82.78036742528106\n",
      "Epoch 1805 val loss: 0.5845366278173107\n",
      "Epoch 1805 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1805.pth\n",
      "Epoch 1806 train loss: 0.5902066568408995\n",
      "Epoch 1806 train accuracy: 82.89004661365506\n",
      "Epoch 1806 val loss: 0.5845320955605099\n",
      "Epoch 1806 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1806.pth\n",
      "Epoch 1807 train loss: 0.5902261646350094\n",
      "Epoch 1807 train accuracy: 82.67068823690704\n",
      "Epoch 1807 val loss: 0.5845514858068016\n",
      "Epoch 1807 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1807.pth\n",
      "Epoch 1808 train loss: 0.5901889076554462\n",
      "Epoch 1808 train accuracy: 82.75294762818756\n",
      "Epoch 1808 val loss: 0.5845153540078747\n",
      "Epoch 1808 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1808.pth\n",
      "Epoch 1809 train loss: 0.5902331403554663\n",
      "Epoch 1809 train accuracy: 82.80778722237456\n",
      "Epoch 1809 val loss: 0.5844446095686994\n",
      "Epoch 1809 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1809.pth\n",
      "Epoch 1810 train loss: 0.5901939921865338\n",
      "Epoch 1810 train accuracy: 82.78036742528106\n",
      "Epoch 1810 val loss: 0.5844621043162126\n",
      "Epoch 1810 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1810.pth\n",
      "Epoch 1811 train loss: 0.5901637935046956\n",
      "Epoch 1811 train accuracy: 82.72552783109406\n",
      "Epoch 1811 val loss: 0.584449398625446\n",
      "Epoch 1811 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1811.pth\n",
      "Epoch 1812 train loss: 0.5901579422173662\n",
      "Epoch 1812 train accuracy: 82.83520701946806\n",
      "Epoch 1812 val loss: 0.5845237556158712\n",
      "Epoch 1812 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1812.pth\n",
      "Epoch 1813 train loss: 0.5900906990527323\n",
      "Epoch 1813 train accuracy: 82.78036742528106\n",
      "Epoch 1813 val loss: 0.5844631864150104\n",
      "Epoch 1813 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1813.pth\n",
      "Epoch 1814 train loss: 0.5901155587481824\n",
      "Epoch 1814 train accuracy: 82.78036742528106\n",
      "Epoch 1814 val loss: 0.58442051664583\n",
      "Epoch 1814 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1814.pth\n",
      "Epoch 1815 train loss: 0.5901758996443006\n",
      "Epoch 1815 train accuracy: 82.78036742528106\n",
      "Epoch 1815 val loss: 0.5844606141020593\n",
      "Epoch 1815 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1815.pth\n",
      "Epoch 1816 train loss: 0.5899768096533718\n",
      "Epoch 1816 train accuracy: 82.83520701946806\n",
      "Epoch 1816 val loss: 0.5843801616544002\n",
      "Epoch 1816 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1816.pth\n",
      "Epoch 1817 train loss: 0.5901598906503958\n",
      "Epoch 1817 train accuracy: 82.83520701946806\n",
      "Epoch 1817 val loss: 0.5843602841916052\n",
      "Epoch 1817 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1817.pth\n",
      "Epoch 1818 train loss: 0.5900746961205936\n",
      "Epoch 1818 train accuracy: 82.86262681656156\n",
      "Epoch 1818 val loss: 0.5844319859323533\n",
      "Epoch 1818 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1818.pth\n",
      "Epoch 1819 train loss: 0.5901181253179777\n",
      "Epoch 1819 train accuracy: 82.72552783109406\n",
      "Epoch 1819 val loss: 0.5843620949767923\n",
      "Epoch 1819 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1819.pth\n",
      "Epoch 1820 train loss: 0.5901375029669061\n",
      "Epoch 1820 train accuracy: 82.75294762818756\n",
      "Epoch 1820 val loss: 0.5843726338230466\n",
      "Epoch 1820 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1820.pth\n",
      "Epoch 1821 train loss: 0.5901093076947227\n",
      "Epoch 1821 train accuracy: 82.80778722237456\n",
      "Epoch 1821 val loss: 0.584336278518956\n",
      "Epoch 1821 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1821.pth\n",
      "Epoch 1822 train loss: 0.5900884235865975\n",
      "Epoch 1822 train accuracy: 82.80778722237456\n",
      "Epoch 1822 val loss: 0.5843792513601089\n",
      "Epoch 1822 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1822.pth\n",
      "Epoch 1823 train loss: 0.59002214836839\n",
      "Epoch 1823 train accuracy: 82.78036742528106\n",
      "Epoch 1823 val loss: 0.5843569192741263\n",
      "Epoch 1823 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1823.pth\n",
      "Epoch 1824 train loss: 0.590051113595173\n",
      "Epoch 1824 train accuracy: 82.67068823690704\n",
      "Epoch 1824 val loss: 0.5842671526203814\n",
      "Epoch 1824 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1824.pth\n",
      "Epoch 1825 train loss: 0.590059886376063\n",
      "Epoch 1825 train accuracy: 82.80778722237456\n",
      "Epoch 1825 val loss: 0.5843273930643734\n",
      "Epoch 1825 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1825.pth\n",
      "Epoch 1826 train loss: 0.5900582256890311\n",
      "Epoch 1826 train accuracy: 82.80778722237456\n",
      "Epoch 1826 val loss: 0.5842867998504325\n",
      "Epoch 1826 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1826.pth\n",
      "Epoch 1827 train loss: 0.5900343635135836\n",
      "Epoch 1827 train accuracy: 82.83520701946806\n",
      "Epoch 1827 val loss: 0.5843339666822239\n",
      "Epoch 1827 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1827.pth\n",
      "Epoch 1828 train loss: 0.590027727930104\n",
      "Epoch 1828 train accuracy: 82.75294762818756\n",
      "Epoch 1828 val loss: 0.5842892106524423\n",
      "Epoch 1828 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1828.pth\n",
      "Epoch 1829 train loss: 0.5899498758739546\n",
      "Epoch 1829 train accuracy: 82.75294762818756\n",
      "Epoch 1829 val loss: 0.5842608410472933\n",
      "Epoch 1829 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1829.pth\n",
      "Epoch 1830 train loss: 0.5899994457467345\n",
      "Epoch 1830 train accuracy: 82.80778722237456\n",
      "Epoch 1830 val loss: 0.5842754174219934\n",
      "Epoch 1830 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1830.pth\n",
      "Epoch 1831 train loss: 0.5899948628502898\n",
      "Epoch 1831 train accuracy: 82.80778722237456\n",
      "Epoch 1831 val loss: 0.5842787867510005\n",
      "Epoch 1831 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1831.pth\n",
      "Epoch 1832 train loss: 0.5899529711694637\n",
      "Epoch 1832 train accuracy: 82.72552783109406\n",
      "Epoch 1832 val loss: 0.5842364770605376\n",
      "Epoch 1832 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1832.pth\n",
      "Epoch 1833 train loss: 0.5899658765104648\n",
      "Epoch 1833 train accuracy: 82.83520701946806\n",
      "Epoch 1833 val loss: 0.5842433481869337\n",
      "Epoch 1833 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1833.pth\n",
      "Epoch 1834 train loss: 0.5898601523959977\n",
      "Epoch 1834 train accuracy: 82.75294762818756\n",
      "Epoch 1834 val loss: 0.5841850599176005\n",
      "Epoch 1834 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1834.pth\n",
      "Epoch 1835 train loss: 0.5899452910137674\n",
      "Epoch 1835 train accuracy: 82.86262681656156\n",
      "Epoch 1835 val loss: 0.5842241999742231\n",
      "Epoch 1835 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1835.pth\n",
      "Epoch 1836 train loss: 0.5899008138252324\n",
      "Epoch 1836 train accuracy: 82.78036742528106\n",
      "Epoch 1836 val loss: 0.5841807494136063\n",
      "Epoch 1836 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1836.pth\n",
      "Epoch 1837 train loss: 0.5898693455342334\n",
      "Epoch 1837 train accuracy: 82.83520701946806\n",
      "Epoch 1837 val loss: 0.5841795195347482\n",
      "Epoch 1837 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1837.pth\n",
      "Epoch 1838 train loss: 0.5898692235513999\n",
      "Epoch 1838 train accuracy: 82.86262681656156\n",
      "Epoch 1838 val loss: 0.5841588425744129\n",
      "Epoch 1838 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1838.pth\n",
      "Epoch 1839 train loss: 0.589892047490075\n",
      "Epoch 1839 train accuracy: 82.78036742528106\n",
      "Epoch 1839 val loss: 0.5841947395452544\n",
      "Epoch 1839 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1839.pth\n",
      "Epoch 1840 train loss: 0.5898269226676539\n",
      "Epoch 1840 train accuracy: 82.78036742528106\n",
      "Epoch 1840 val loss: 0.5841423426509688\n",
      "Epoch 1840 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1840.pth\n",
      "Epoch 1841 train loss: 0.5898189217530256\n",
      "Epoch 1841 train accuracy: 82.86262681656156\n",
      "Epoch 1841 val loss: 0.5841788046160027\n",
      "Epoch 1841 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1841.pth\n",
      "Epoch 1842 train loss: 0.589868346182221\n",
      "Epoch 1842 train accuracy: 82.80778722237456\n",
      "Epoch 1842 val loss: 0.5841506614447817\n",
      "Epoch 1842 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1842.pth\n",
      "Epoch 1843 train loss: 0.5899269192789992\n",
      "Epoch 1843 train accuracy: 82.72552783109406\n",
      "Epoch 1843 val loss: 0.5841252813605886\n",
      "Epoch 1843 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1843.pth\n",
      "Epoch 1844 train loss: 0.5898454187094773\n",
      "Epoch 1844 train accuracy: 82.80778722237456\n",
      "Epoch 1844 val loss: 0.5841363224838125\n",
      "Epoch 1844 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1844.pth\n",
      "Epoch 1845 train loss: 0.5898400799845133\n",
      "Epoch 1845 train accuracy: 82.78036742528106\n",
      "Epoch 1845 val loss: 0.584144514103077\n",
      "Epoch 1845 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1845.pth\n",
      "Epoch 1846 train loss: 0.5898244713612816\n",
      "Epoch 1846 train accuracy: 82.75294762818756\n",
      "Epoch 1846 val loss: 0.5841379695522942\n",
      "Epoch 1846 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1846.pth\n",
      "Epoch 1847 train loss: 0.5898159485342994\n",
      "Epoch 1847 train accuracy: 82.72552783109406\n",
      "Epoch 1847 val loss: 0.5840778497881011\n",
      "Epoch 1847 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1847.pth\n",
      "Epoch 1848 train loss: 0.5898073677202327\n",
      "Epoch 1848 train accuracy: 82.72552783109406\n",
      "Epoch 1848 val loss: 0.5840497014946059\n",
      "Epoch 1848 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1848.pth\n",
      "Epoch 1849 train loss: 0.5897391251811203\n",
      "Epoch 1849 train accuracy: 82.86262681656156\n",
      "Epoch 1849 val loss: 0.5841102230999815\n",
      "Epoch 1849 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1849.pth\n",
      "Epoch 1850 train loss: 0.5897182364490602\n",
      "Epoch 1850 train accuracy: 82.78036742528106\n",
      "Epoch 1850 val loss: 0.5840688077732921\n",
      "Epoch 1850 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1850.pth\n",
      "Epoch 1851 train loss: 0.589779144005948\n",
      "Epoch 1851 train accuracy: 82.72552783109406\n",
      "Epoch 1851 val loss: 0.5840151026503392\n",
      "Epoch 1851 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1851.pth\n",
      "Epoch 1852 train loss: 0.5896866967444095\n",
      "Epoch 1852 train accuracy: 82.80778722237456\n",
      "Epoch 1852 val loss: 0.5840529459160998\n",
      "Epoch 1852 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1852.pth\n",
      "Epoch 1853 train loss: 0.5896988710298676\n",
      "Epoch 1853 train accuracy: 82.83520701946806\n",
      "Epoch 1853 val loss: 0.5840288756023112\n",
      "Epoch 1853 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1853.pth\n",
      "Epoch 1854 train loss: 0.589705276989231\n",
      "Epoch 1854 train accuracy: 82.78036742528106\n",
      "Epoch 1854 val loss: 0.5840193147427941\n",
      "Epoch 1854 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1854.pth\n",
      "Epoch 1855 train loss: 0.5895882625288019\n",
      "Epoch 1855 train accuracy: 82.78036742528106\n",
      "Epoch 1855 val loss: 0.5840398836880922\n",
      "Epoch 1855 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1855.pth\n",
      "Epoch 1856 train loss: 0.5897402056705272\n",
      "Epoch 1856 train accuracy: 82.94488620784206\n",
      "Epoch 1856 val loss: 0.5840030902334931\n",
      "Epoch 1856 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1856.pth\n",
      "Epoch 1857 train loss: 0.5896527322188935\n",
      "Epoch 1857 train accuracy: 82.78036742528106\n",
      "Epoch 1857 val loss: 0.5839864129788781\n",
      "Epoch 1857 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1857.pth\n",
      "Epoch 1858 train loss: 0.5896720474651247\n",
      "Epoch 1858 train accuracy: 82.83520701946806\n",
      "Epoch 1858 val loss: 0.5839807264702884\n",
      "Epoch 1858 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1858.pth\n",
      "Epoch 1859 train loss: 0.5896854831330609\n",
      "Epoch 1859 train accuracy: 82.83520701946806\n",
      "Epoch 1859 val loss: 0.5839889938207833\n",
      "Epoch 1859 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1859.pth\n",
      "Epoch 1860 train loss: 0.5896764580699566\n",
      "Epoch 1860 train accuracy: 82.83520701946806\n",
      "Epoch 1860 val loss: 0.5839883966469451\n",
      "Epoch 1860 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1860.pth\n",
      "Epoch 1861 train loss: 0.5896613635939726\n",
      "Epoch 1861 train accuracy: 82.75294762818756\n",
      "Epoch 1861 val loss: 0.5839427718892694\n",
      "Epoch 1861 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1861.pth\n",
      "Epoch 1862 train loss: 0.5896030185425556\n",
      "Epoch 1862 train accuracy: 82.80778722237456\n",
      "Epoch 1862 val loss: 0.583903937796621\n",
      "Epoch 1862 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1862.pth\n",
      "Epoch 1863 train loss: 0.5896362201392389\n",
      "Epoch 1863 train accuracy: 82.75294762818756\n",
      "Epoch 1863 val loss: 0.5838929129470336\n",
      "Epoch 1863 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1863.pth\n",
      "Epoch 1864 train loss: 0.5896100390277672\n",
      "Epoch 1864 train accuracy: 82.78036742528106\n",
      "Epoch 1864 val loss: 0.583942201282633\n",
      "Epoch 1864 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1864.pth\n",
      "Epoch 1865 train loss: 0.5896143068706519\n",
      "Epoch 1865 train accuracy: 82.80778722237456\n",
      "Epoch 1865 val loss: 0.583879204417922\n",
      "Epoch 1865 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1865.pth\n",
      "Epoch 1866 train loss: 0.5895488670059038\n",
      "Epoch 1866 train accuracy: 82.78036742528106\n",
      "Epoch 1866 val loss: 0.5838839150965214\n",
      "Epoch 1866 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1866.pth\n",
      "Epoch 1867 train loss: 0.589486694992765\n",
      "Epoch 1867 train accuracy: 82.75294762818756\n",
      "Epoch 1867 val loss: 0.5839191359026652\n",
      "Epoch 1867 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1867.pth\n",
      "Epoch 1868 train loss: 0.5895889893239528\n",
      "Epoch 1868 train accuracy: 82.69810803400055\n",
      "Epoch 1868 val loss: 0.5838978511134261\n",
      "Epoch 1868 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1868.pth\n",
      "Epoch 1869 train loss: 0.5895738747183299\n",
      "Epoch 1869 train accuracy: 82.78036742528106\n",
      "Epoch 1869 val loss: 0.5838576824845452\n",
      "Epoch 1869 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1869.pth\n",
      "Epoch 1870 train loss: 0.5895973688906484\n",
      "Epoch 1870 train accuracy: 82.78036742528106\n",
      "Epoch 1870 val loss: 0.5838437971144327\n",
      "Epoch 1870 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1870.pth\n",
      "Epoch 1871 train loss: 0.5895057903324956\n",
      "Epoch 1871 train accuracy: 82.83520701946806\n",
      "Epoch 1871 val loss: 0.583851598693352\n",
      "Epoch 1871 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1871.pth\n",
      "Epoch 1872 train loss: 0.5895425367236481\n",
      "Epoch 1872 train accuracy: 82.75294762818756\n",
      "Epoch 1872 val loss: 0.5838426290950003\n",
      "Epoch 1872 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1872.pth\n",
      "Epoch 1873 train loss: 0.5894878544403535\n",
      "Epoch 1873 train accuracy: 82.78036742528106\n",
      "Epoch 1873 val loss: 0.583823642497392\n",
      "Epoch 1873 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1873.pth\n",
      "Epoch 1874 train loss: 0.5894631174425676\n",
      "Epoch 1874 train accuracy: 82.78036742528106\n",
      "Epoch 1874 val loss: 0.5837909389091166\n",
      "Epoch 1874 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1874.pth\n",
      "Epoch 1875 train loss: 0.5895162269538432\n",
      "Epoch 1875 train accuracy: 82.78036742528106\n",
      "Epoch 1875 val loss: 0.5837947555180443\n",
      "Epoch 1875 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1875.pth\n",
      "Epoch 1876 train loss: 0.5895062358396357\n",
      "Epoch 1876 train accuracy: 82.78036742528106\n",
      "Epoch 1876 val loss: 0.5837597018597942\n",
      "Epoch 1876 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1876.pth\n",
      "Epoch 1877 train loss: 0.5894289212219679\n",
      "Epoch 1877 train accuracy: 82.75294762818756\n",
      "Epoch 1877 val loss: 0.5837429432982677\n",
      "Epoch 1877 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1877.pth\n",
      "Epoch 1878 train loss: 0.5894379088524402\n",
      "Epoch 1878 train accuracy: 82.86262681656156\n",
      "Epoch 1878 val loss: 0.5837874422340017\n",
      "Epoch 1878 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1878.pth\n",
      "Epoch 1879 train loss: 0.5894825511955117\n",
      "Epoch 1879 train accuracy: 82.78036742528106\n",
      "Epoch 1879 val loss: 0.5837533264666012\n",
      "Epoch 1879 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1879.pth\n",
      "Epoch 1880 train loss: 0.5894554095718552\n",
      "Epoch 1880 train accuracy: 82.80778722237456\n",
      "Epoch 1880 val loss: 0.5837426925274102\n",
      "Epoch 1880 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1880.pth\n",
      "Epoch 1881 train loss: 0.5893576932752407\n",
      "Epoch 1881 train accuracy: 82.78036742528106\n",
      "Epoch 1881 val loss: 0.5837079016491771\n",
      "Epoch 1881 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1881.pth\n",
      "Epoch 1882 train loss: 0.5894477163653886\n",
      "Epoch 1882 train accuracy: 82.78036742528106\n",
      "Epoch 1882 val loss: 0.5836950119976935\n",
      "Epoch 1882 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1882.pth\n",
      "Epoch 1883 train loss: 0.5894300876871535\n",
      "Epoch 1883 train accuracy: 82.83520701946806\n",
      "Epoch 1883 val loss: 0.5837441227938\n",
      "Epoch 1883 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1883.pth\n",
      "Epoch 1884 train loss: 0.5893649665736839\n",
      "Epoch 1884 train accuracy: 82.78036742528106\n",
      "Epoch 1884 val loss: 0.5837174507446194\n",
      "Epoch 1884 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1884.pth\n",
      "Epoch 1885 train loss: 0.5894162601448203\n",
      "Epoch 1885 train accuracy: 82.78036742528106\n",
      "Epoch 1885 val loss: 0.5837056712786618\n",
      "Epoch 1885 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1885.pth\n",
      "Epoch 1886 train loss: 0.5894123680620013\n",
      "Epoch 1886 train accuracy: 82.78036742528106\n",
      "Epoch 1886 val loss: 0.583665086593675\n",
      "Epoch 1886 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1886.pth\n",
      "Epoch 1887 train loss: 0.5893933371101555\n",
      "Epoch 1887 train accuracy: 82.78036742528106\n",
      "Epoch 1887 val loss: 0.5836684943519925\n",
      "Epoch 1887 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1887.pth\n",
      "Epoch 1888 train loss: 0.589382730849218\n",
      "Epoch 1888 train accuracy: 82.80778722237456\n",
      "Epoch 1888 val loss: 0.5836699689787469\n",
      "Epoch 1888 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1888.pth\n",
      "Epoch 1889 train loss: 0.5893723902684685\n",
      "Epoch 1889 train accuracy: 82.78036742528106\n",
      "Epoch 1889 val loss: 0.5836442956014684\n",
      "Epoch 1889 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1889.pth\n",
      "Epoch 1890 train loss: 0.5893544801265785\n",
      "Epoch 1890 train accuracy: 82.80778722237456\n",
      "Epoch 1890 val loss: 0.5836210055766922\n",
      "Epoch 1890 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1890.pth\n",
      "Epoch 1891 train loss: 0.5893471171965071\n",
      "Epoch 1891 train accuracy: 82.83520701946806\n",
      "Epoch 1891 val loss: 0.5836190211733705\n",
      "Epoch 1891 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1891.pth\n",
      "Epoch 1892 train loss: 0.5892719433299805\n",
      "Epoch 1892 train accuracy: 82.83520701946806\n",
      "Epoch 1892 val loss: 0.5836239744860091\n",
      "Epoch 1892 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1892.pth\n",
      "Epoch 1893 train loss: 0.5892769023122495\n",
      "Epoch 1893 train accuracy: 82.83520701946806\n",
      "Epoch 1893 val loss: 0.5836089497039977\n",
      "Epoch 1893 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1893.pth\n",
      "Epoch 1894 train loss: 0.5891900005864731\n",
      "Epoch 1894 train accuracy: 82.78036742528106\n",
      "Epoch 1894 val loss: 0.5836007330523755\n",
      "Epoch 1894 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1894.pth\n",
      "Epoch 1895 train loss: 0.5892975449259802\n",
      "Epoch 1895 train accuracy: 82.91746641074856\n",
      "Epoch 1895 val loss: 0.5836239217927581\n",
      "Epoch 1895 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1895.pth\n",
      "Epoch 1896 train loss: 0.589280174260861\n",
      "Epoch 1896 train accuracy: 82.83520701946806\n",
      "Epoch 1896 val loss: 0.5835869576487887\n",
      "Epoch 1896 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1896.pth\n",
      "Epoch 1897 train loss: 0.5892753644781024\n",
      "Epoch 1897 train accuracy: 82.80778722237456\n",
      "Epoch 1897 val loss: 0.58356792033699\n",
      "Epoch 1897 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1897.pth\n",
      "Epoch 1898 train loss: 0.5892042900811423\n",
      "Epoch 1898 train accuracy: 82.83520701946806\n",
      "Epoch 1898 val loss: 0.5835675942760549\n",
      "Epoch 1898 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1898.pth\n",
      "Epoch 1899 train loss: 0.5891998382612017\n",
      "Epoch 1899 train accuracy: 82.86262681656156\n",
      "Epoch 1899 val loss: 0.583561998203789\n",
      "Epoch 1899 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1899.pth\n",
      "Epoch 1900 train loss: 0.5891843561099417\n",
      "Epoch 1900 train accuracy: 82.83520701946806\n",
      "Epoch 1900 val loss: 0.5835631001544627\n",
      "Epoch 1900 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1900.pth\n",
      "Epoch 1901 train loss: 0.5891713953920101\n",
      "Epoch 1901 train accuracy: 82.80778722237456\n",
      "Epoch 1901 val loss: 0.5835632198539219\n",
      "Epoch 1901 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1901.pth\n",
      "Epoch 1902 train loss: 0.5891194558424646\n",
      "Epoch 1902 train accuracy: 82.80778722237456\n",
      "Epoch 1902 val loss: 0.5835292541765069\n",
      "Epoch 1902 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1902.pth\n",
      "Epoch 1903 train loss: 0.5891989216437203\n",
      "Epoch 1903 train accuracy: 82.83520701946806\n",
      "Epoch 1903 val loss: 0.5835622046142817\n",
      "Epoch 1903 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1903.pth\n",
      "Epoch 1904 train loss: 0.5891439889459625\n",
      "Epoch 1904 train accuracy: 82.86262681656156\n",
      "Epoch 1904 val loss: 0.583568104297707\n",
      "Epoch 1904 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1904.pth\n",
      "Epoch 1905 train loss: 0.5891872864510668\n",
      "Epoch 1905 train accuracy: 82.72552783109406\n",
      "Epoch 1905 val loss: 0.5834707008968842\n",
      "Epoch 1905 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1905.pth\n",
      "Epoch 1906 train loss: 0.5891310861497595\n",
      "Epoch 1906 train accuracy: 82.78036742528106\n",
      "Epoch 1906 val loss: 0.5834956008597816\n",
      "Epoch 1906 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1906.pth\n",
      "Epoch 1907 train loss: 0.5891705273666925\n",
      "Epoch 1907 train accuracy: 82.83520701946806\n",
      "Epoch 1907 val loss: 0.5835030785957841\n",
      "Epoch 1907 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1907.pth\n",
      "Epoch 1908 train loss: 0.5891695641994215\n",
      "Epoch 1908 train accuracy: 82.80778722237456\n",
      "Epoch 1908 val loss: 0.583464923755903\n",
      "Epoch 1908 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1908.pth\n",
      "Epoch 1909 train loss: 0.5891523145868345\n",
      "Epoch 1909 train accuracy: 82.80778722237456\n",
      "Epoch 1909 val loss: 0.5834438155748343\n",
      "Epoch 1909 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1909.pth\n",
      "Epoch 1910 train loss: 0.5890554394491279\n",
      "Epoch 1910 train accuracy: 82.80778722237456\n",
      "Epoch 1910 val loss: 0.5834800726979187\n",
      "Epoch 1910 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1910.pth\n",
      "Epoch 1911 train loss: 0.5891351394616721\n",
      "Epoch 1911 train accuracy: 82.80778722237456\n",
      "Epoch 1911 val loss: 0.5834156912506411\n",
      "Epoch 1911 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1911.pth\n",
      "Epoch 1912 train loss: 0.5889423293911182\n",
      "Epoch 1912 train accuracy: 82.83520701946806\n",
      "Epoch 1912 val loss: 0.5834375908353219\n",
      "Epoch 1912 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1912.pth\n",
      "Epoch 1913 train loss: 0.589049023249301\n",
      "Epoch 1913 train accuracy: 82.78036742528106\n",
      "Epoch 1913 val loss: 0.5834470480974567\n",
      "Epoch 1913 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1913.pth\n",
      "Epoch 1914 train loss: 0.5890865541806674\n",
      "Epoch 1914 train accuracy: 82.89004661365506\n",
      "Epoch 1914 val loss: 0.5834934363435758\n",
      "Epoch 1914 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1914.pth\n",
      "Epoch 1915 train loss: 0.5890474885256896\n",
      "Epoch 1915 train accuracy: 82.83520701946806\n",
      "Epoch 1915 val loss: 0.5834529006265496\n",
      "Epoch 1915 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1915.pth\n",
      "Epoch 1916 train loss: 0.5890798499611648\n",
      "Epoch 1916 train accuracy: 82.75294762818756\n",
      "Epoch 1916 val loss: 0.5833906308306676\n",
      "Epoch 1916 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1916.pth\n",
      "Epoch 1917 train loss: 0.589029134888398\n",
      "Epoch 1917 train accuracy: 82.80778722237456\n",
      "Epoch 1917 val loss: 0.583375308564619\n",
      "Epoch 1917 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1917.pth\n",
      "Epoch 1918 train loss: 0.5890297453131592\n",
      "Epoch 1918 train accuracy: 82.78036742528106\n",
      "Epoch 1918 val loss: 0.5833786417190966\n",
      "Epoch 1918 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1918.pth\n",
      "Epoch 1919 train loss: 0.5889578290577782\n",
      "Epoch 1919 train accuracy: 82.83520701946806\n",
      "Epoch 1919 val loss: 0.5833698695427493\n",
      "Epoch 1919 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1919.pth\n",
      "Epoch 1920 train loss: 0.5890397203007811\n",
      "Epoch 1920 train accuracy: 82.78036742528106\n",
      "Epoch 1920 val loss: 0.5833191240365666\n",
      "Epoch 1920 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1920.pth\n",
      "Epoch 1921 train loss: 0.5890340018321009\n",
      "Epoch 1921 train accuracy: 82.75294762818756\n",
      "Epoch 1921 val loss: 0.5833568279386351\n",
      "Epoch 1921 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1921.pth\n",
      "Epoch 1922 train loss: 0.5890206613071394\n",
      "Epoch 1922 train accuracy: 82.86262681656156\n",
      "Epoch 1922 val loss: 0.5833421202964688\n",
      "Epoch 1922 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1922.pth\n",
      "Epoch 1923 train loss: 0.5889909066455928\n",
      "Epoch 1923 train accuracy: 82.83520701946806\n",
      "Epoch 1923 val loss: 0.5833447245516398\n",
      "Epoch 1923 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1923.pth\n",
      "Epoch 1924 train loss: 0.588972719855966\n",
      "Epoch 1924 train accuracy: 82.80778722237456\n",
      "Epoch 1924 val loss: 0.5833326142379328\n",
      "Epoch 1924 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1924.pth\n",
      "Epoch 1925 train loss: 0.5889941359657729\n",
      "Epoch 1925 train accuracy: 82.83520701946806\n",
      "Epoch 1925 val loss: 0.5832921621928874\n",
      "Epoch 1925 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1925.pth\n",
      "Epoch 1926 train loss: 0.5889197355789835\n",
      "Epoch 1926 train accuracy: 82.75294762818756\n",
      "Epoch 1926 val loss: 0.5832874390639757\n",
      "Epoch 1926 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1926.pth\n",
      "Epoch 1927 train loss: 0.5889575034829282\n",
      "Epoch 1927 train accuracy: 82.86262681656156\n",
      "Epoch 1927 val loss: 0.5832517481850166\n",
      "Epoch 1927 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_1927.pth\n",
      "Epoch 1928 train loss: 0.5889653771331436\n",
      "Epoch 1928 train accuracy: 82.83520701946806\n",
      "Epoch 1928 val loss: 0.5832728038934109\n",
      "Epoch 1928 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1928.pth\n",
      "Epoch 1929 train loss: 0.5888970881749532\n",
      "Epoch 1929 train accuracy: 82.83520701946806\n",
      "Epoch 1929 val loss: 0.5832634365774299\n",
      "Epoch 1929 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1929.pth\n",
      "Epoch 1930 train loss: 0.5888597686946588\n",
      "Epoch 1930 train accuracy: 82.80778722237456\n",
      "Epoch 1930 val loss: 0.583306071936692\n",
      "Epoch 1930 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1930.pth\n",
      "Epoch 1931 train loss: 0.5889055912358392\n",
      "Epoch 1931 train accuracy: 82.83520701946806\n",
      "Epoch 1931 val loss: 0.5832627765638264\n",
      "Epoch 1931 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1931.pth\n",
      "Epoch 1932 train loss: 0.5889000404266673\n",
      "Epoch 1932 train accuracy: 82.80778722237456\n",
      "Epoch 1932 val loss: 0.5832295880996083\n",
      "Epoch 1932 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1932.pth\n",
      "Epoch 1933 train loss: 0.588856656790564\n",
      "Epoch 1933 train accuracy: 82.83520701946806\n",
      "Epoch 1933 val loss: 0.5832064823786679\n",
      "Epoch 1933 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1933.pth\n",
      "Epoch 1934 train loss: 0.5888914731698797\n",
      "Epoch 1934 train accuracy: 82.80778722237456\n",
      "Epoch 1934 val loss: 0.583209586672877\n",
      "Epoch 1934 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1934.pth\n",
      "Epoch 1935 train loss: 0.5888861469074822\n",
      "Epoch 1935 train accuracy: 82.83520701946806\n",
      "Epoch 1935 val loss: 0.5832402045397382\n",
      "Epoch 1935 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1935.pth\n",
      "Epoch 1936 train loss: 0.588861282686131\n",
      "Epoch 1936 train accuracy: 82.83520701946806\n",
      "Epoch 1936 val loss: 0.5832254009713468\n",
      "Epoch 1936 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1936.pth\n",
      "Epoch 1937 train loss: 0.5888710277596194\n",
      "Epoch 1937 train accuracy: 82.83520701946806\n",
      "Epoch 1937 val loss: 0.5832039013406948\n",
      "Epoch 1937 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1937.pth\n",
      "Epoch 1938 train loss: 0.5888008662875284\n",
      "Epoch 1938 train accuracy: 82.80778722237456\n",
      "Epoch 1938 val loss: 0.5831739248609856\n",
      "Epoch 1938 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1938.pth\n",
      "Epoch 1939 train loss: 0.5887937434181049\n",
      "Epoch 1939 train accuracy: 82.78036742528106\n",
      "Epoch 1939 val loss: 0.5831735042953178\n",
      "Epoch 1939 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1939.pth\n",
      "Epoch 1940 train loss: 0.5887860007943553\n",
      "Epoch 1940 train accuracy: 82.91746641074856\n",
      "Epoch 1940 val loss: 0.5832155297669631\n",
      "Epoch 1940 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1940.pth\n",
      "Epoch 1941 train loss: 0.5887415540290245\n",
      "Epoch 1941 train accuracy: 82.83520701946806\n",
      "Epoch 1941 val loss: 0.5831474308904848\n",
      "Epoch 1941 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1941.pth\n",
      "Epoch 1942 train loss: 0.5887356895888061\n",
      "Epoch 1942 train accuracy: 82.86262681656156\n",
      "Epoch 1942 val loss: 0.5831679300356069\n",
      "Epoch 1942 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1942.pth\n",
      "Epoch 1943 train loss: 0.5887876488758546\n",
      "Epoch 1943 train accuracy: 82.78036742528106\n",
      "Epoch 1943 val loss: 0.5831483045690938\n",
      "Epoch 1943 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1943.pth\n",
      "Epoch 1944 train loss: 0.5887960715121344\n",
      "Epoch 1944 train accuracy: 82.75294762818756\n",
      "Epoch 1944 val loss: 0.5831610630021283\n",
      "Epoch 1944 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1944.pth\n",
      "Epoch 1945 train loss: 0.5887137920955163\n",
      "Epoch 1945 train accuracy: 82.89004661365506\n",
      "Epoch 1945 val loss: 0.5831420925494871\n",
      "Epoch 1945 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1945.pth\n",
      "Epoch 1946 train loss: 0.5887882617800578\n",
      "Epoch 1946 train accuracy: 82.86262681656156\n",
      "Epoch 1946 val loss: 0.5831214507649604\n",
      "Epoch 1946 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1946.pth\n",
      "Epoch 1947 train loss: 0.588708816949899\n",
      "Epoch 1947 train accuracy: 82.86262681656156\n",
      "Epoch 1947 val loss: 0.5831152371277935\n",
      "Epoch 1947 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1947.pth\n",
      "Epoch 1948 train loss: 0.58870054601708\n",
      "Epoch 1948 train accuracy: 82.78036742528106\n",
      "Epoch 1948 val loss: 0.5830909375983634\n",
      "Epoch 1948 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1948.pth\n",
      "Epoch 1949 train loss: 0.5887492022460752\n",
      "Epoch 1949 train accuracy: 82.83520701946806\n",
      "Epoch 1949 val loss: 0.5830547337567336\n",
      "Epoch 1949 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1949.pth\n",
      "Epoch 1950 train loss: 0.5887457983682683\n",
      "Epoch 1950 train accuracy: 82.78036742528106\n",
      "Epoch 1950 val loss: 0.5830504955037644\n",
      "Epoch 1950 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1950.pth\n",
      "Epoch 1951 train loss: 0.5887532508686969\n",
      "Epoch 1951 train accuracy: 82.86262681656156\n",
      "Epoch 1951 val loss: 0.5830578859895468\n",
      "Epoch 1951 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1951.pth\n",
      "Epoch 1952 train loss: 0.5886048232450297\n",
      "Epoch 1952 train accuracy: 82.86262681656156\n",
      "Epoch 1952 val loss: 0.5830596752807891\n",
      "Epoch 1952 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1952.pth\n",
      "Epoch 1953 train loss: 0.5886366741911492\n",
      "Epoch 1953 train accuracy: 82.80778722237456\n",
      "Epoch 1953 val loss: 0.5830302631580516\n",
      "Epoch 1953 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1953.pth\n",
      "Epoch 1954 train loss: 0.5886503164738155\n",
      "Epoch 1954 train accuracy: 82.83520701946806\n",
      "Epoch 1954 val loss: 0.5830224433815793\n",
      "Epoch 1954 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1954.pth\n",
      "Epoch 1955 train loss: 0.5886922680227528\n",
      "Epoch 1955 train accuracy: 82.86262681656156\n",
      "Epoch 1955 val loss: 0.5830220500203339\n",
      "Epoch 1955 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1955.pth\n",
      "Epoch 1956 train loss: 0.5887018345917264\n",
      "Epoch 1956 train accuracy: 82.91746641074856\n",
      "Epoch 1956 val loss: 0.5830178846065935\n",
      "Epoch 1956 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1956.pth\n",
      "Epoch 1957 train loss: 0.5886703066715742\n",
      "Epoch 1957 train accuracy: 82.86262681656156\n",
      "Epoch 1957 val loss: 0.5829752123007845\n",
      "Epoch 1957 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1957.pth\n",
      "Epoch 1958 train loss: 0.5886482950626758\n",
      "Epoch 1958 train accuracy: 82.97230600493556\n",
      "Epoch 1958 val loss: 0.5829809887922908\n",
      "Epoch 1958 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1958.pth\n",
      "Epoch 1959 train loss: 0.5885981131802526\n",
      "Epoch 1959 train accuracy: 82.89004661365506\n",
      "Epoch 1959 val loss: 0.5829752566488949\n",
      "Epoch 1959 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1959.pth\n",
      "Epoch 1960 train loss: 0.5886337695675984\n",
      "Epoch 1960 train accuracy: 82.89004661365506\n",
      "Epoch 1960 val loss: 0.5829455323125187\n",
      "Epoch 1960 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1960.pth\n",
      "Epoch 1961 train loss: 0.5885640633325174\n",
      "Epoch 1961 train accuracy: 82.72552783109406\n",
      "Epoch 1961 val loss: 0.5829608599214178\n",
      "Epoch 1961 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1961.pth\n",
      "Epoch 1962 train loss: 0.5885191988853509\n",
      "Epoch 1962 train accuracy: 82.83520701946806\n",
      "Epoch 1962 val loss: 0.5829481060959791\n",
      "Epoch 1962 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1962.pth\n",
      "Epoch 1963 train loss: 0.5885281328830803\n",
      "Epoch 1963 train accuracy: 82.94488620784206\n",
      "Epoch 1963 val loss: 0.5829548070109204\n",
      "Epoch 1963 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1963.pth\n",
      "Epoch 1964 train loss: 0.5885392681679182\n",
      "Epoch 1964 train accuracy: 82.94488620784206\n",
      "Epoch 1964 val loss: 0.5829781145837746\n",
      "Epoch 1964 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1964.pth\n",
      "Epoch 1965 train loss: 0.5885041550520742\n",
      "Epoch 1965 train accuracy: 82.86262681656156\n",
      "Epoch 1965 val loss: 0.5829398980070102\n",
      "Epoch 1965 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1965.pth\n",
      "Epoch 1966 train loss: 0.5884837653700328\n",
      "Epoch 1966 train accuracy: 82.80778722237456\n",
      "Epoch 1966 val loss: 0.5829090775529805\n",
      "Epoch 1966 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1966.pth\n",
      "Epoch 1967 train loss: 0.5885083556600046\n",
      "Epoch 1967 train accuracy: 82.94488620784206\n",
      "Epoch 1967 val loss: 0.5829390934913566\n",
      "Epoch 1967 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1967.pth\n",
      "Epoch 1968 train loss: 0.5885508357498207\n",
      "Epoch 1968 train accuracy: 82.89004661365506\n",
      "Epoch 1968 val loss: 0.5829216774651095\n",
      "Epoch 1968 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1968.pth\n",
      "Epoch 1969 train loss: 0.588495209698745\n",
      "Epoch 1969 train accuracy: 82.89004661365506\n",
      "Epoch 1969 val loss: 0.5828697436954826\n",
      "Epoch 1969 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1969.pth\n",
      "Epoch 1970 train loss: 0.5885535993596964\n",
      "Epoch 1970 train accuracy: 82.99972580202906\n",
      "Epoch 1970 val loss: 0.5828897672166166\n",
      "Epoch 1970 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1970.pth\n",
      "Epoch 1971 train loss: 0.588545310609206\n",
      "Epoch 1971 train accuracy: 82.83520701946806\n",
      "Epoch 1971 val loss: 0.5828779653499001\n",
      "Epoch 1971 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1971.pth\n",
      "Epoch 1972 train loss: 0.5885643714777472\n",
      "Epoch 1972 train accuracy: 82.86262681656156\n",
      "Epoch 1972 val loss: 0.5828707141703681\n",
      "Epoch 1972 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1972.pth\n",
      "Epoch 1973 train loss: 0.5885250873929053\n",
      "Epoch 1973 train accuracy: 82.89004661365506\n",
      "Epoch 1973 val loss: 0.5828852751537373\n",
      "Epoch 1973 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1973.pth\n",
      "Epoch 1974 train loss: 0.5883956412833772\n",
      "Epoch 1974 train accuracy: 82.94488620784206\n",
      "Epoch 1974 val loss: 0.5828418696887399\n",
      "Epoch 1974 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1974.pth\n",
      "Epoch 1975 train loss: 0.5885149738261182\n",
      "Epoch 1975 train accuracy: 82.89004661365506\n",
      "Epoch 1975 val loss: 0.5828407495987209\n",
      "Epoch 1975 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1975.pth\n",
      "Epoch 1976 train loss: 0.5884477111037102\n",
      "Epoch 1976 train accuracy: 82.91746641074856\n",
      "Epoch 1976 val loss: 0.5828527000879771\n",
      "Epoch 1976 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1976.pth\n",
      "Epoch 1977 train loss: 0.5884830021920303\n",
      "Epoch 1977 train accuracy: 82.89004661365506\n",
      "Epoch 1977 val loss: 0.5828335996913282\n",
      "Epoch 1977 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1977.pth\n",
      "Epoch 1978 train loss: 0.588479869925466\n",
      "Epoch 1978 train accuracy: 82.91746641074856\n",
      "Epoch 1978 val loss: 0.5828466078658637\n",
      "Epoch 1978 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1978.pth\n",
      "Epoch 1979 train loss: 0.5883980449125693\n",
      "Epoch 1979 train accuracy: 82.86262681656156\n",
      "Epoch 1979 val loss: 0.582810463089692\n",
      "Epoch 1979 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1979.pth\n",
      "Epoch 1980 train loss: 0.5883812420560341\n",
      "Epoch 1980 train accuracy: 82.99972580202906\n",
      "Epoch 1980 val loss: 0.5828464637069326\n",
      "Epoch 1980 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1980.pth\n",
      "Epoch 1981 train loss: 0.5883623564681202\n",
      "Epoch 1981 train accuracy: 82.83520701946806\n",
      "Epoch 1981 val loss: 0.5828325969510173\n",
      "Epoch 1981 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1981.pth\n",
      "Epoch 1982 train loss: 0.5883399577844038\n",
      "Epoch 1982 train accuracy: 82.91746641074856\n",
      "Epoch 1982 val loss: 0.5827913223030535\n",
      "Epoch 1982 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1982.pth\n",
      "Epoch 1983 train loss: 0.5883714026003554\n",
      "Epoch 1983 train accuracy: 82.89004661365506\n",
      "Epoch 1983 val loss: 0.5827791148698643\n",
      "Epoch 1983 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1983.pth\n",
      "Epoch 1984 train loss: 0.588384022903547\n",
      "Epoch 1984 train accuracy: 82.89004661365506\n",
      "Epoch 1984 val loss: 0.5827748294625628\n",
      "Epoch 1984 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1984.pth\n",
      "Epoch 1985 train loss: 0.5884275225219888\n",
      "Epoch 1985 train accuracy: 82.89004661365506\n",
      "Epoch 1985 val loss: 0.5827540047589297\n",
      "Epoch 1985 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1985.pth\n",
      "Epoch 1986 train loss: 0.588300826730566\n",
      "Epoch 1986 train accuracy: 82.91746641074856\n",
      "Epoch 1986 val loss: 0.5827516381579795\n",
      "Epoch 1986 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1986.pth\n",
      "Epoch 1987 train loss: 0.5883777695462892\n",
      "Epoch 1987 train accuracy: 82.89004661365506\n",
      "Epoch 1987 val loss: 0.5827568035915887\n",
      "Epoch 1987 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1987.pth\n",
      "Epoch 1988 train loss: 0.5883427104471546\n",
      "Epoch 1988 train accuracy: 82.86262681656156\n",
      "Epoch 1988 val loss: 0.5827457757274571\n",
      "Epoch 1988 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1988.pth\n",
      "Epoch 1989 train loss: 0.5883075681580394\n",
      "Epoch 1989 train accuracy: 82.86262681656156\n",
      "Epoch 1989 val loss: 0.5827201320973568\n",
      "Epoch 1989 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1989.pth\n",
      "Epoch 1990 train loss: 0.5883770860617229\n",
      "Epoch 1990 train accuracy: 82.89004661365506\n",
      "Epoch 1990 val loss: 0.5827036471057095\n",
      "Epoch 1990 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_1990.pth\n",
      "Epoch 1991 train loss: 0.5882945423721123\n",
      "Epoch 1991 train accuracy: 82.89004661365506\n",
      "Epoch 1991 val loss: 0.5826894073060861\n",
      "Epoch 1991 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1991.pth\n",
      "Epoch 1992 train loss: 0.5884085977123233\n",
      "Epoch 1992 train accuracy: 82.89004661365506\n",
      "Epoch 1992 val loss: 0.582677197373031\n",
      "Epoch 1992 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1992.pth\n",
      "Epoch 1993 train loss: 0.5882833258886087\n",
      "Epoch 1993 train accuracy: 82.89004661365506\n",
      "Epoch 1993 val loss: 0.582664377497215\n",
      "Epoch 1993 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1993.pth\n",
      "Epoch 1994 train loss: 0.5883040053671912\n",
      "Epoch 1994 train accuracy: 82.91746641074856\n",
      "Epoch 1994 val loss: 0.5826448391828882\n",
      "Epoch 1994 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1994.pth\n",
      "Epoch 1995 train loss: 0.5882712102968964\n",
      "Epoch 1995 train accuracy: 82.89004661365506\n",
      "Epoch 1995 val loss: 0.5826534620902845\n",
      "Epoch 1995 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1995.pth\n",
      "Epoch 1996 train loss: 0.5883406235983497\n",
      "Epoch 1996 train accuracy: 82.91746641074856\n",
      "Epoch 1996 val loss: 0.5826289150373716\n",
      "Epoch 1996 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1996.pth\n",
      "Epoch 1997 train loss: 0.5883111680547396\n",
      "Epoch 1997 train accuracy: 82.89004661365506\n",
      "Epoch 1997 val loss: 0.5826220408474144\n",
      "Epoch 1997 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1997.pth\n",
      "Epoch 1998 train loss: 0.5882552642489604\n",
      "Epoch 1998 train accuracy: 82.86262681656156\n",
      "Epoch 1998 val loss: 0.5826119742797393\n",
      "Epoch 1998 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_1998.pth\n",
      "Epoch 1999 train loss: 0.5882754426024723\n",
      "Epoch 1999 train accuracy: 82.91746641074856\n",
      "Epoch 1999 val loss: 0.5826114379482246\n",
      "Epoch 1999 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_1999.pth\n",
      "Epoch 2000 train loss: 0.5882644876919425\n",
      "Epoch 2000 train accuracy: 82.91746641074856\n",
      "Epoch 2000 val loss: 0.5825878104293033\n",
      "Epoch 2000 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2000.pth\n",
      "Epoch 2001 train loss: 0.5881455818828392\n",
      "Epoch 2001 train accuracy: 82.91746641074856\n",
      "Epoch 2001 val loss: 0.5825862444349026\n",
      "Epoch 2001 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2001.pth\n",
      "Epoch 2002 train loss: 0.58825617757005\n",
      "Epoch 2002 train accuracy: 82.94488620784206\n",
      "Epoch 2002 val loss: 0.5826029664787807\n",
      "Epoch 2002 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2002.pth\n",
      "Epoch 2003 train loss: 0.5882402435026801\n",
      "Epoch 2003 train accuracy: 82.89004661365506\n",
      "Epoch 2003 val loss: 0.582599567531265\n",
      "Epoch 2003 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2003.pth\n",
      "Epoch 2004 train loss: 0.5881724604650548\n",
      "Epoch 2004 train accuracy: 82.91746641074856\n",
      "Epoch 2004 val loss: 0.5825704716415586\n",
      "Epoch 2004 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2004.pth\n",
      "Epoch 2005 train loss: 0.58813946623878\n",
      "Epoch 2005 train accuracy: 82.89004661365506\n",
      "Epoch 2005 val loss: 0.5825374282798484\n",
      "Epoch 2005 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2005.pth\n",
      "Epoch 2006 train loss: 0.5882225406823094\n",
      "Epoch 2006 train accuracy: 82.91746641074856\n",
      "Epoch 2006 val loss: 0.5825291073783055\n",
      "Epoch 2006 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2006.pth\n",
      "Epoch 2007 train loss: 0.5882184470446143\n",
      "Epoch 2007 train accuracy: 82.91746641074856\n",
      "Epoch 2007 val loss: 0.5825243659415528\n",
      "Epoch 2007 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2007.pth\n",
      "Epoch 2008 train loss: 0.5881985472025055\n",
      "Epoch 2008 train accuracy: 82.94488620784206\n",
      "Epoch 2008 val loss: 0.5825125298119689\n",
      "Epoch 2008 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2008.pth\n",
      "Epoch 2009 train loss: 0.5880968886705344\n",
      "Epoch 2009 train accuracy: 82.86262681656156\n",
      "Epoch 2009 val loss: 0.5825048059862303\n",
      "Epoch 2009 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2009.pth\n",
      "Epoch 2010 train loss: 0.5881265826654016\n",
      "Epoch 2010 train accuracy: 82.94488620784206\n",
      "Epoch 2010 val loss: 0.5824974565521667\n",
      "Epoch 2010 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2010.pth\n",
      "Epoch 2011 train loss: 0.5881738095879228\n",
      "Epoch 2011 train accuracy: 82.91746641074856\n",
      "Epoch 2011 val loss: 0.5824821016898281\n",
      "Epoch 2011 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2011.pth\n",
      "Epoch 2012 train loss: 0.5881766303556791\n",
      "Epoch 2012 train accuracy: 82.94488620784206\n",
      "Epoch 2012 val loss: 0.5824867054623993\n",
      "Epoch 2012 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2012.pth\n",
      "Epoch 2013 train loss: 0.5881784105420178\n",
      "Epoch 2013 train accuracy: 82.89004661365506\n",
      "Epoch 2013 val loss: 0.5824912721291184\n",
      "Epoch 2013 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2013.pth\n",
      "Epoch 2014 train loss: 0.5880304997451931\n",
      "Epoch 2014 train accuracy: 82.89004661365506\n",
      "Epoch 2014 val loss: 0.5824716267617125\n",
      "Epoch 2014 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2014.pth\n",
      "Epoch 2015 train loss: 0.588134844427961\n",
      "Epoch 2015 train accuracy: 82.86262681656156\n",
      "Epoch 2015 val loss: 0.5824455088984809\n",
      "Epoch 2015 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2015.pth\n",
      "Epoch 2016 train loss: 0.5880870947679668\n",
      "Epoch 2016 train accuracy: 82.89004661365506\n",
      "Epoch 2016 val loss: 0.5824383133532185\n",
      "Epoch 2016 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2016.pth\n",
      "Epoch 2017 train loss: 0.5880780125102192\n",
      "Epoch 2017 train accuracy: 82.94488620784206\n",
      "Epoch 2017 val loss: 0.5824696158402061\n",
      "Epoch 2017 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2017.pth\n",
      "Epoch 2018 train loss: 0.5881299099541808\n",
      "Epoch 2018 train accuracy: 82.91746641074856\n",
      "Epoch 2018 val loss: 0.5824478420575983\n",
      "Epoch 2018 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2018.pth\n",
      "Epoch 2019 train loss: 0.5880955294787622\n",
      "Epoch 2019 train accuracy: 82.86262681656156\n",
      "Epoch 2019 val loss: 0.5824168653619525\n",
      "Epoch 2019 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2019.pth\n",
      "Epoch 2020 train loss: 0.5880925758137253\n",
      "Epoch 2020 train accuracy: 82.97230600493556\n",
      "Epoch 2020 val loss: 0.5824096268533092\n",
      "Epoch 2020 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2020.pth\n",
      "Epoch 2021 train loss: 0.5880154965347365\n",
      "Epoch 2021 train accuracy: 82.91746641074856\n",
      "Epoch 2021 val loss: 0.5823966964687172\n",
      "Epoch 2021 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2021.pth\n",
      "Epoch 2022 train loss: 0.5880583158547157\n",
      "Epoch 2022 train accuracy: 82.89004661365506\n",
      "Epoch 2022 val loss: 0.5823830320548854\n",
      "Epoch 2022 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2022.pth\n",
      "Epoch 2023 train loss: 0.5880430493536487\n",
      "Epoch 2023 train accuracy: 82.94488620784206\n",
      "Epoch 2023 val loss: 0.5823796764996491\n",
      "Epoch 2023 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2023.pth\n",
      "Epoch 2024 train loss: 0.5880669783882535\n",
      "Epoch 2024 train accuracy: 82.91746641074856\n",
      "Epoch 2024 val loss: 0.5823762589869531\n",
      "Epoch 2024 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2024.pth\n",
      "Epoch 2025 train loss: 0.5880443116531527\n",
      "Epoch 2025 train accuracy: 82.86262681656156\n",
      "Epoch 2025 val loss: 0.58236296744527\n",
      "Epoch 2025 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2025.pth\n",
      "Epoch 2026 train loss: 0.5880516861287648\n",
      "Epoch 2026 train accuracy: 82.94488620784206\n",
      "Epoch 2026 val loss: 0.5823585922388654\n",
      "Epoch 2026 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2026.pth\n",
      "Epoch 2027 train loss: 0.5879748201348999\n",
      "Epoch 2027 train accuracy: 82.89004661365506\n",
      "Epoch 2027 val loss: 0.5823430890634068\n",
      "Epoch 2027 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2027.pth\n",
      "Epoch 2028 train loss: 0.5880084079281803\n",
      "Epoch 2028 train accuracy: 82.94488620784206\n",
      "Epoch 2028 val loss: 0.5823400219608295\n",
      "Epoch 2028 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2028.pth\n",
      "Epoch 2029 train loss: 0.5879628974454183\n",
      "Epoch 2029 train accuracy: 82.89004661365506\n",
      "Epoch 2029 val loss: 0.5823604467962133\n",
      "Epoch 2029 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2029.pth\n",
      "Epoch 2030 train loss: 0.5880172864795384\n",
      "Epoch 2030 train accuracy: 82.86262681656156\n",
      "Epoch 2030 val loss: 0.5823540769909558\n",
      "Epoch 2030 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2030.pth\n",
      "Epoch 2031 train loss: 0.5879294736343518\n",
      "Epoch 2031 train accuracy: 82.99972580202906\n",
      "Epoch 2031 val loss: 0.5823226170124192\n",
      "Epoch 2031 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2031.pth\n",
      "Epoch 2032 train loss: 0.5879882075088588\n",
      "Epoch 2032 train accuracy: 82.86262681656156\n",
      "Epoch 2032 val loss: 0.5823156161135749\n",
      "Epoch 2032 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2032.pth\n",
      "Epoch 2033 train loss: 0.5879201624999967\n",
      "Epoch 2033 train accuracy: 82.91746641074856\n",
      "Epoch 2033 val loss: 0.5823131259040613\n",
      "Epoch 2033 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2033.pth\n",
      "Epoch 2034 train loss: 0.5879114948176337\n",
      "Epoch 2034 train accuracy: 82.91746641074856\n",
      "Epoch 2034 val loss: 0.5823113921735632\n",
      "Epoch 2034 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2034.pth\n",
      "Epoch 2035 train loss: 0.5878982491905621\n",
      "Epoch 2035 train accuracy: 82.97230600493556\n",
      "Epoch 2035 val loss: 0.5822704080982428\n",
      "Epoch 2035 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2035.pth\n",
      "Epoch 2036 train loss: 0.5879626278091517\n",
      "Epoch 2036 train accuracy: 83.02714559912256\n",
      "Epoch 2036 val loss: 0.5822683221807605\n",
      "Epoch 2036 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2036.pth\n",
      "Epoch 2037 train loss: 0.5878634555265307\n",
      "Epoch 2037 train accuracy: 82.99972580202906\n",
      "Epoch 2037 val loss: 0.5822869158398948\n",
      "Epoch 2037 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2037.pth\n",
      "Epoch 2038 train loss: 0.5878935667825046\n",
      "Epoch 2038 train accuracy: 83.05456539621606\n",
      "Epoch 2038 val loss: 0.5823251977072734\n",
      "Epoch 2038 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2038.pth\n",
      "Epoch 2039 train loss: 0.5879304216226988\n",
      "Epoch 2039 train accuracy: 82.91746641074856\n",
      "Epoch 2039 val loss: 0.5822660767130161\n",
      "Epoch 2039 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2039.pth\n",
      "Epoch 2040 train loss: 0.5879210998026425\n",
      "Epoch 2040 train accuracy: 82.94488620784206\n",
      "Epoch 2040 val loss: 0.5822629079124645\n",
      "Epoch 2040 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2040.pth\n",
      "Epoch 2041 train loss: 0.5878853966694391\n",
      "Epoch 2041 train accuracy: 82.83520701946806\n",
      "Epoch 2041 val loss: 0.5822653775838645\n",
      "Epoch 2041 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2041.pth\n",
      "Epoch 2042 train loss: 0.5879204247163183\n",
      "Epoch 2042 train accuracy: 82.89004661365506\n",
      "Epoch 2042 val loss: 0.5822613518930188\n",
      "Epoch 2042 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2042.pth\n",
      "Epoch 2043 train loss: 0.5879006936263881\n",
      "Epoch 2043 train accuracy: 82.86262681656156\n",
      "Epoch 2043 val loss: 0.5822326215964398\n",
      "Epoch 2043 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2043.pth\n",
      "Epoch 2044 train loss: 0.5878877884258001\n",
      "Epoch 2044 train accuracy: 82.97230600493556\n",
      "Epoch 2044 val loss: 0.5822294101511177\n",
      "Epoch 2044 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2044.pth\n",
      "Epoch 2045 train loss: 0.5878275716759003\n",
      "Epoch 2045 train accuracy: 82.91746641074856\n",
      "Epoch 2045 val loss: 0.5822108097766575\n",
      "Epoch 2045 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2045.pth\n",
      "Epoch 2046 train loss: 0.5877734070425249\n",
      "Epoch 2046 train accuracy: 82.86262681656156\n",
      "Epoch 2046 val loss: 0.5821856044134811\n",
      "Epoch 2046 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2046.pth\n",
      "Epoch 2047 train loss: 0.587870692948631\n",
      "Epoch 2047 train accuracy: 82.99972580202906\n",
      "Epoch 2047 val loss: 0.5821993834290066\n",
      "Epoch 2047 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2047.pth\n",
      "Epoch 2048 train loss: 0.5877596798073091\n",
      "Epoch 2048 train accuracy: 82.91746641074856\n",
      "Epoch 2048 val loss: 0.5821955164306258\n",
      "Epoch 2048 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2048.pth\n",
      "Epoch 2049 train loss: 0.58790938253106\n",
      "Epoch 2049 train accuracy: 82.97230600493556\n",
      "Epoch 2049 val loss: 0.5821538487155187\n",
      "Epoch 2049 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2049.pth\n",
      "Epoch 2050 train loss: 0.5877929482478321\n",
      "Epoch 2050 train accuracy: 82.97230600493556\n",
      "Epoch 2050 val loss: 0.5821675140576094\n",
      "Epoch 2050 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2050.pth\n",
      "Epoch 2051 train loss: 0.5878216296336368\n",
      "Epoch 2051 train accuracy: 82.94488620784206\n",
      "Epoch 2051 val loss: 0.5821569720773321\n",
      "Epoch 2051 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2051.pth\n",
      "Epoch 2052 train loss: 0.5876962753797048\n",
      "Epoch 2052 train accuracy: 82.89004661365506\n",
      "Epoch 2052 val loss: 0.5821420332710994\n",
      "Epoch 2052 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2052.pth\n",
      "Epoch 2053 train loss: 0.5877132694678087\n",
      "Epoch 2053 train accuracy: 82.94488620784206\n",
      "Epoch 2053 val loss: 0.5821318878841243\n",
      "Epoch 2053 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2053.pth\n",
      "Epoch 2054 train loss: 0.5878017597357955\n",
      "Epoch 2054 train accuracy: 82.99972580202906\n",
      "Epoch 2054 val loss: 0.5821265211622966\n",
      "Epoch 2054 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2054.pth\n",
      "Epoch 2055 train loss: 0.5877233238139173\n",
      "Epoch 2055 train accuracy: 83.02714559912256\n",
      "Epoch 2055 val loss: 0.5821121949702501\n",
      "Epoch 2055 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2055.pth\n",
      "Epoch 2056 train loss: 0.587709349825194\n",
      "Epoch 2056 train accuracy: 82.94488620784206\n",
      "Epoch 2056 val loss: 0.5820925531810835\n",
      "Epoch 2056 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2056.pth\n",
      "Epoch 2057 train loss: 0.5877508910724142\n",
      "Epoch 2057 train accuracy: 83.08198519330956\n",
      "Epoch 2057 val loss: 0.5821055311611608\n",
      "Epoch 2057 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2057.pth\n",
      "Epoch 2058 train loss: 0.5877806959477695\n",
      "Epoch 2058 train accuracy: 82.99972580202906\n",
      "Epoch 2058 val loss: 0.5821052382847196\n",
      "Epoch 2058 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2058.pth\n",
      "Epoch 2059 train loss: 0.5877538839551179\n",
      "Epoch 2059 train accuracy: 82.97230600493556\n",
      "Epoch 2059 val loss: 0.5820983122838171\n",
      "Epoch 2059 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2059.pth\n",
      "Epoch 2060 train loss: 0.5877507145010066\n",
      "Epoch 2060 train accuracy: 82.91746641074856\n",
      "Epoch 2060 val loss: 0.582090643136517\n",
      "Epoch 2060 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2060.pth\n",
      "Epoch 2061 train loss: 0.5876932603209034\n",
      "Epoch 2061 train accuracy: 82.99972580202906\n",
      "Epoch 2061 val loss: 0.5821003305088532\n",
      "Epoch 2061 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2061.pth\n",
      "Epoch 2062 train loss: 0.5877786149452604\n",
      "Epoch 2062 train accuracy: 82.99972580202906\n",
      "Epoch 2062 val loss: 0.5820795764264307\n",
      "Epoch 2062 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2062.pth\n",
      "Epoch 2063 train loss: 0.5877345075928851\n",
      "Epoch 2063 train accuracy: 82.99972580202906\n",
      "Epoch 2063 val loss: 0.582042461947391\n",
      "Epoch 2063 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2063.pth\n",
      "Epoch 2064 train loss: 0.5876740768037149\n",
      "Epoch 2064 train accuracy: 82.97230600493556\n",
      "Epoch 2064 val loss: 0.5820280844590774\n",
      "Epoch 2064 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2064.pth\n",
      "Epoch 2065 train loss: 0.5876521158375239\n",
      "Epoch 2065 train accuracy: 83.05456539621606\n",
      "Epoch 2065 val loss: 0.5820356207336054\n",
      "Epoch 2065 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2065.pth\n",
      "Epoch 2066 train loss: 0.5877082397724224\n",
      "Epoch 2066 train accuracy: 83.02714559912256\n",
      "Epoch 2066 val loss: 0.5820313934726935\n",
      "Epoch 2066 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2066.pth\n",
      "Epoch 2067 train loss: 0.5876406137341339\n",
      "Epoch 2067 train accuracy: 82.97230600493556\n",
      "Epoch 2067 val loss: 0.582032357881728\n",
      "Epoch 2067 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2067.pth\n",
      "Epoch 2068 train loss: 0.5876305208688504\n",
      "Epoch 2068 train accuracy: 82.89004661365506\n",
      "Epoch 2068 val loss: 0.5819958077106429\n",
      "Epoch 2068 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2068.pth\n",
      "Epoch 2069 train loss: 0.5876704754814375\n",
      "Epoch 2069 train accuracy: 82.99972580202906\n",
      "Epoch 2069 val loss: 0.5819982176058387\n",
      "Epoch 2069 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2069.pth\n",
      "Epoch 2070 train loss: 0.5876679782134792\n",
      "Epoch 2070 train accuracy: 82.99972580202906\n",
      "Epoch 2070 val loss: 0.5820125711003417\n",
      "Epoch 2070 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2070.pth\n",
      "Epoch 2071 train loss: 0.5877030387586146\n",
      "Epoch 2071 train accuracy: 82.99972580202906\n",
      "Epoch 2071 val loss: 0.5820264063383404\n",
      "Epoch 2071 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2071.pth\n",
      "Epoch 2072 train loss: 0.5877100588394362\n",
      "Epoch 2072 train accuracy: 82.97230600493556\n",
      "Epoch 2072 val loss: 0.5820033023329941\n",
      "Epoch 2072 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2072.pth\n",
      "Epoch 2073 train loss: 0.5876176915572662\n",
      "Epoch 2073 train accuracy: 82.89004661365506\n",
      "Epoch 2073 val loss: 0.5819593747881683\n",
      "Epoch 2073 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2073.pth\n",
      "Epoch 2074 train loss: 0.587578760803138\n",
      "Epoch 2074 train accuracy: 82.97230600493556\n",
      "Epoch 2074 val loss: 0.581947042655788\n",
      "Epoch 2074 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2074.pth\n",
      "Epoch 2075 train loss: 0.5876297376878363\n",
      "Epoch 2075 train accuracy: 82.99972580202906\n",
      "Epoch 2075 val loss: 0.5819529869936799\n",
      "Epoch 2075 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2075.pth\n",
      "Epoch 2076 train loss: 0.5875621639649596\n",
      "Epoch 2076 train accuracy: 82.99972580202906\n",
      "Epoch 2076 val loss: 0.5819494239005604\n",
      "Epoch 2076 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2076.pth\n",
      "Epoch 2077 train loss: 0.5875712217264727\n",
      "Epoch 2077 train accuracy: 82.89004661365506\n",
      "Epoch 2077 val loss: 0.5819261950979892\n",
      "Epoch 2077 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2077.pth\n",
      "Epoch 2078 train loss: 0.587607807005968\n",
      "Epoch 2078 train accuracy: 82.99972580202906\n",
      "Epoch 2078 val loss: 0.5819123633892128\n",
      "Epoch 2078 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2078.pth\n",
      "Epoch 2079 train loss: 0.5874770351505855\n",
      "Epoch 2079 train accuracy: 83.02714559912256\n",
      "Epoch 2079 val loss: 0.5819131524155015\n",
      "Epoch 2079 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2079.pth\n",
      "Epoch 2080 train loss: 0.5874678064592126\n",
      "Epoch 2080 train accuracy: 83.02714559912256\n",
      "Epoch 2080 val loss: 0.5819527113221978\n",
      "Epoch 2080 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2080.pth\n",
      "Epoch 2081 train loss: 0.5875766631705981\n",
      "Epoch 2081 train accuracy: 82.89004661365506\n",
      "Epoch 2081 val loss: 0.5819167294539511\n",
      "Epoch 2081 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2081.pth\n",
      "Epoch 2082 train loss: 0.5875101862638666\n",
      "Epoch 2082 train accuracy: 82.94488620784206\n",
      "Epoch 2082 val loss: 0.5818943915594565\n",
      "Epoch 2082 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2082.pth\n",
      "Epoch 2083 train loss: 0.5875795674591995\n",
      "Epoch 2083 train accuracy: 82.99972580202906\n",
      "Epoch 2083 val loss: 0.5818704983807708\n",
      "Epoch 2083 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2083.pth\n",
      "Epoch 2084 train loss: 0.5874884261488261\n",
      "Epoch 2084 train accuracy: 83.05456539621606\n",
      "Epoch 2084 val loss: 0.5819014280446266\n",
      "Epoch 2084 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2084.pth\n",
      "Epoch 2085 train loss: 0.5874810463732534\n",
      "Epoch 2085 train accuracy: 82.97230600493556\n",
      "Epoch 2085 val loss: 0.5818750055898961\n",
      "Epoch 2085 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2085.pth\n",
      "Epoch 2086 train loss: 0.587477500289025\n",
      "Epoch 2086 train accuracy: 83.02714559912256\n",
      "Epoch 2086 val loss: 0.5818622896545812\n",
      "Epoch 2086 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2086.pth\n",
      "Epoch 2087 train loss: 0.5875053039441506\n",
      "Epoch 2087 train accuracy: 82.99972580202906\n",
      "Epoch 2087 val loss: 0.5818486928351616\n",
      "Epoch 2087 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2087.pth\n",
      "Epoch 2088 train loss: 0.5875143514652001\n",
      "Epoch 2088 train accuracy: 82.99972580202906\n",
      "Epoch 2088 val loss: 0.5818289609037732\n",
      "Epoch 2088 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2088.pth\n",
      "Epoch 2089 train loss: 0.5874793159432317\n",
      "Epoch 2089 train accuracy: 83.13682478749658\n",
      "Epoch 2089 val loss: 0.5818631608823412\n",
      "Epoch 2089 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2089.pth\n",
      "Epoch 2090 train loss: 0.5874601094437183\n",
      "Epoch 2090 train accuracy: 82.94488620784206\n",
      "Epoch 2090 val loss: 0.5818048735443306\n",
      "Epoch 2090 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2090.pth\n",
      "Epoch 2091 train loss: 0.5874943760297212\n",
      "Epoch 2091 train accuracy: 82.99972580202906\n",
      "Epoch 2091 val loss: 0.5817979103640506\n",
      "Epoch 2091 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2091.pth\n",
      "Epoch 2092 train loss: 0.5874887621234449\n",
      "Epoch 2092 train accuracy: 83.02714559912256\n",
      "Epoch 2092 val loss: 0.58180531825086\n",
      "Epoch 2092 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2092.pth\n",
      "Epoch 2093 train loss: 0.5874617403340444\n",
      "Epoch 2093 train accuracy: 83.08198519330956\n",
      "Epoch 2093 val loss: 0.5818151576125896\n",
      "Epoch 2093 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2093.pth\n",
      "Epoch 2094 train loss: 0.5874394069246033\n",
      "Epoch 2094 train accuracy: 83.02714559912256\n",
      "Epoch 2094 val loss: 0.581796771111457\n",
      "Epoch 2094 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2094.pth\n",
      "Epoch 2095 train loss: 0.5874012643553055\n",
      "Epoch 2095 train accuracy: 83.08198519330956\n",
      "Epoch 2095 val loss: 0.5817816288847673\n",
      "Epoch 2095 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2095.pth\n",
      "Epoch 2096 train loss: 0.5874597830779589\n",
      "Epoch 2096 train accuracy: 83.02714559912256\n",
      "Epoch 2096 val loss: 0.5817768267404876\n",
      "Epoch 2096 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2096.pth\n",
      "Epoch 2097 train loss: 0.587445097418886\n",
      "Epoch 2097 train accuracy: 82.99972580202906\n",
      "Epoch 2097 val loss: 0.5817528640067107\n",
      "Epoch 2097 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2097.pth\n",
      "Epoch 2098 train loss: 0.5874366803552237\n",
      "Epoch 2098 train accuracy: 82.99972580202906\n",
      "Epoch 2098 val loss: 0.581751267327682\n",
      "Epoch 2098 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2098.pth\n",
      "Epoch 2099 train loss: 0.5874465284378905\n",
      "Epoch 2099 train accuracy: 83.05456539621606\n",
      "Epoch 2099 val loss: 0.5817471648517408\n",
      "Epoch 2099 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2099.pth\n",
      "Epoch 2100 train loss: 0.5874148201556844\n",
      "Epoch 2100 train accuracy: 83.05456539621606\n",
      "Epoch 2100 val loss: 0.5817699746081704\n",
      "Epoch 2100 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2100.pth\n",
      "Epoch 2101 train loss: 0.5874119039191946\n",
      "Epoch 2101 train accuracy: 82.91746641074856\n",
      "Epoch 2101 val loss: 0.5817165565431902\n",
      "Epoch 2101 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2101.pth\n",
      "Epoch 2102 train loss: 0.5874069757563504\n",
      "Epoch 2102 train accuracy: 83.05456539621606\n",
      "Epoch 2102 val loss: 0.5817358983239453\n",
      "Epoch 2102 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2102.pth\n",
      "Epoch 2103 train loss: 0.5873391441837476\n",
      "Epoch 2103 train accuracy: 83.05456539621606\n",
      "Epoch 2103 val loss: 0.5817155583614582\n",
      "Epoch 2103 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2103.pth\n",
      "Epoch 2104 train loss: 0.5873003296815512\n",
      "Epoch 2104 train accuracy: 82.99972580202906\n",
      "Epoch 2104 val loss: 0.5817216639652064\n",
      "Epoch 2104 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2104.pth\n",
      "Epoch 2105 train loss: 0.5873792737951142\n",
      "Epoch 2105 train accuracy: 82.99972580202906\n",
      "Epoch 2105 val loss: 0.5817078634800295\n",
      "Epoch 2105 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2105.pth\n",
      "Epoch 2106 train loss: 0.5873038006064139\n",
      "Epoch 2106 train accuracy: 82.99972580202906\n",
      "Epoch 2106 val loss: 0.5816849144175649\n",
      "Epoch 2106 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2106.pth\n",
      "Epoch 2107 train loss: 0.5872332922248333\n",
      "Epoch 2107 train accuracy: 83.08198519330956\n",
      "Epoch 2107 val loss: 0.5816697405749246\n",
      "Epoch 2107 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2107.pth\n",
      "Epoch 2108 train loss: 0.587347465011765\n",
      "Epoch 2108 train accuracy: 83.05456539621606\n",
      "Epoch 2108 val loss: 0.5816630629920646\n",
      "Epoch 2108 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2108.pth\n",
      "Epoch 2109 train loss: 0.5873068191862681\n",
      "Epoch 2109 train accuracy: 83.10940499040306\n",
      "Epoch 2109 val loss: 0.5816618199705293\n",
      "Epoch 2109 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2109.pth\n",
      "Epoch 2110 train loss: 0.5873274904136595\n",
      "Epoch 2110 train accuracy: 83.08198519330956\n",
      "Epoch 2110 val loss: 0.5816597107209658\n",
      "Epoch 2110 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2110.pth\n",
      "Epoch 2111 train loss: 0.5873194013134038\n",
      "Epoch 2111 train accuracy: 83.05456539621606\n",
      "Epoch 2111 val loss: 0.5816602021896917\n",
      "Epoch 2111 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2111.pth\n",
      "Epoch 2112 train loss: 0.5872895921041307\n",
      "Epoch 2112 train accuracy: 83.02714559912256\n",
      "Epoch 2112 val loss: 0.581633531929631\n",
      "Epoch 2112 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2112.pth\n",
      "Epoch 2113 train loss: 0.5873240270537504\n",
      "Epoch 2113 train accuracy: 83.02714559912256\n",
      "Epoch 2113 val loss: 0.5816169774257823\n",
      "Epoch 2113 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2113.pth\n",
      "Epoch 2114 train loss: 0.5872256948843418\n",
      "Epoch 2114 train accuracy: 83.13682478749658\n",
      "Epoch 2114 val loss: 0.5816168808133194\n",
      "Epoch 2114 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2114.pth\n",
      "Epoch 2115 train loss: 0.5872479536644134\n",
      "Epoch 2115 train accuracy: 83.02714559912256\n",
      "Epoch 2115 val loss: 0.5816194313627324\n",
      "Epoch 2115 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2115.pth\n",
      "Epoch 2116 train loss: 0.5872477935953883\n",
      "Epoch 2116 train accuracy: 83.02714559912256\n",
      "Epoch 2116 val loss: 0.5815921454739413\n",
      "Epoch 2116 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2116.pth\n",
      "Epoch 2117 train loss: 0.5872798382157558\n",
      "Epoch 2117 train accuracy: 83.05456539621606\n",
      "Epoch 2117 val loss: 0.5816124261013771\n",
      "Epoch 2117 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2117.pth\n",
      "Epoch 2118 train loss: 0.587217473621039\n",
      "Epoch 2118 train accuracy: 83.05456539621606\n",
      "Epoch 2118 val loss: 0.5816286109191807\n",
      "Epoch 2118 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2118.pth\n",
      "Epoch 2119 train loss: 0.5872043843397445\n",
      "Epoch 2119 train accuracy: 82.94488620784206\n",
      "Epoch 2119 val loss: 0.581577849770455\n",
      "Epoch 2119 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2119.pth\n",
      "Epoch 2120 train loss: 0.587271517069128\n",
      "Epoch 2120 train accuracy: 82.97230600493556\n",
      "Epoch 2120 val loss: 0.5815686509993515\n",
      "Epoch 2120 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2120.pth\n",
      "Epoch 2121 train loss: 0.5872477749525978\n",
      "Epoch 2121 train accuracy: 83.08198519330956\n",
      "Epoch 2121 val loss: 0.5815498816143525\n",
      "Epoch 2121 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2121.pth\n",
      "Epoch 2122 train loss: 0.5872396015686702\n",
      "Epoch 2122 train accuracy: 83.13682478749658\n",
      "Epoch 2122 val loss: 0.5815459957444354\n",
      "Epoch 2122 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2122.pth\n",
      "Epoch 2123 train loss: 0.5871705589815974\n",
      "Epoch 2123 train accuracy: 83.10940499040306\n",
      "Epoch 2123 val loss: 0.5815607040728393\n",
      "Epoch 2123 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2123.pth\n",
      "Epoch 2124 train loss: 0.5872097439377716\n",
      "Epoch 2124 train accuracy: 83.05456539621606\n",
      "Epoch 2124 val loss: 0.5815385242029535\n",
      "Epoch 2124 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2124.pth\n",
      "Epoch 2125 train loss: 0.5871360446979994\n",
      "Epoch 2125 train accuracy: 83.13682478749658\n",
      "Epoch 2125 val loss: 0.5815394975146965\n",
      "Epoch 2125 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2125.pth\n",
      "Epoch 2126 train loss: 0.5872151861130669\n",
      "Epoch 2126 train accuracy: 83.10940499040306\n",
      "Epoch 2126 val loss: 0.581526049265736\n",
      "Epoch 2126 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2126.pth\n",
      "Epoch 2127 train loss: 0.5872104229372844\n",
      "Epoch 2127 train accuracy: 83.05456539621606\n",
      "Epoch 2127 val loss: 0.5815050077477568\n",
      "Epoch 2127 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2127.pth\n",
      "Epoch 2128 train loss: 0.5871578590748342\n",
      "Epoch 2128 train accuracy: 83.08198519330956\n",
      "Epoch 2128 val loss: 0.5814950920543388\n",
      "Epoch 2128 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2128.pth\n",
      "Epoch 2129 train loss: 0.5871209373795673\n",
      "Epoch 2129 train accuracy: 83.08198519330956\n",
      "Epoch 2129 val loss: 0.5815072556173331\n",
      "Epoch 2129 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2129.pth\n",
      "Epoch 2130 train loss: 0.587197072044211\n",
      "Epoch 2130 train accuracy: 83.02714559912256\n",
      "Epoch 2130 val loss: 0.5814921144690168\n",
      "Epoch 2130 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2130.pth\n",
      "Epoch 2131 train loss: 0.587154990233677\n",
      "Epoch 2131 train accuracy: 83.08198519330956\n",
      "Epoch 2131 val loss: 0.5814715083198327\n",
      "Epoch 2131 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2131.pth\n",
      "Epoch 2132 train loss: 0.5871393049070448\n",
      "Epoch 2132 train accuracy: 83.08198519330956\n",
      "Epoch 2132 val loss: 0.5814649588183353\n",
      "Epoch 2132 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2132.pth\n",
      "Epoch 2133 train loss: 0.5870849663604116\n",
      "Epoch 2133 train accuracy: 83.10940499040306\n",
      "Epoch 2133 val loss: 0.5814728592277357\n",
      "Epoch 2133 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2133.pth\n",
      "Epoch 2134 train loss: 0.5870949968801844\n",
      "Epoch 2134 train accuracy: 82.94488620784206\n",
      "Epoch 2134 val loss: 0.5814614854262847\n",
      "Epoch 2134 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2134.pth\n",
      "Epoch 2135 train loss: 0.58719708394104\n",
      "Epoch 2135 train accuracy: 83.10940499040306\n",
      "Epoch 2135 val loss: 0.5814272769677796\n",
      "Epoch 2135 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2135.pth\n",
      "Epoch 2136 train loss: 0.58709343491743\n",
      "Epoch 2136 train accuracy: 83.05456539621606\n",
      "Epoch 2136 val loss: 0.581432323633252\n",
      "Epoch 2136 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2136.pth\n",
      "Epoch 2137 train loss: 0.5870755407142273\n",
      "Epoch 2137 train accuracy: 83.08198519330956\n",
      "Epoch 2137 val loss: 0.5814453468805081\n",
      "Epoch 2137 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2137.pth\n",
      "Epoch 2138 train loss: 0.5870645358063803\n",
      "Epoch 2138 train accuracy: 83.02714559912256\n",
      "Epoch 2138 val loss: 0.5814307195771682\n",
      "Epoch 2138 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2138.pth\n",
      "Epoch 2139 train loss: 0.5870638751065391\n",
      "Epoch 2139 train accuracy: 83.05456539621606\n",
      "Epoch 2139 val loss: 0.5814156308149808\n",
      "Epoch 2139 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2139.pth\n",
      "Epoch 2140 train loss: 0.5871896918274855\n",
      "Epoch 2140 train accuracy: 83.13682478749658\n",
      "Epoch 2140 val loss: 0.5814125764085666\n",
      "Epoch 2140 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2140.pth\n",
      "Epoch 2141 train loss: 0.587012566348309\n",
      "Epoch 2141 train accuracy: 82.99972580202906\n",
      "Epoch 2141 val loss: 0.5813855209485873\n",
      "Epoch 2141 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2141.pth\n",
      "Epoch 2142 train loss: 0.5871181695378924\n",
      "Epoch 2142 train accuracy: 83.05456539621606\n",
      "Epoch 2142 val loss: 0.5813887724652886\n",
      "Epoch 2142 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2142.pth\n",
      "Epoch 2143 train loss: 0.5870548244718983\n",
      "Epoch 2143 train accuracy: 83.13682478749658\n",
      "Epoch 2143 val loss: 0.5813783339567875\n",
      "Epoch 2143 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2143.pth\n",
      "Epoch 2144 train loss: 0.5870118473958746\n",
      "Epoch 2144 train accuracy: 83.10940499040306\n",
      "Epoch 2144 val loss: 0.5814109418639227\n",
      "Epoch 2144 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2144.pth\n",
      "Epoch 2145 train loss: 0.5871323995545441\n",
      "Epoch 2145 train accuracy: 83.10940499040306\n",
      "Epoch 2145 val loss: 0.5813959279146633\n",
      "Epoch 2145 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2145.pth\n",
      "Epoch 2146 train loss: 0.5870078364836477\n",
      "Epoch 2146 train accuracy: 82.99972580202906\n",
      "Epoch 2146 val loss: 0.5813956227349607\n",
      "Epoch 2146 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2146.pth\n",
      "Epoch 2147 train loss: 0.5869869425598728\n",
      "Epoch 2147 train accuracy: 82.97230600493556\n",
      "Epoch 2147 val loss: 0.5813409534135932\n",
      "Epoch 2147 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2147.pth\n",
      "Epoch 2148 train loss: 0.5869754060383952\n",
      "Epoch 2148 train accuracy: 83.10940499040306\n",
      "Epoch 2148 val loss: 0.5813504707950511\n",
      "Epoch 2148 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2148.pth\n",
      "Epoch 2149 train loss: 0.5870312721051864\n",
      "Epoch 2149 train accuracy: 83.02714559912256\n",
      "Epoch 2149 val loss: 0.5813534802904254\n",
      "Epoch 2149 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2149.pth\n",
      "Epoch 2150 train loss: 0.5870114950495854\n",
      "Epoch 2150 train accuracy: 82.99972580202906\n",
      "Epoch 2150 val loss: 0.581317201305769\n",
      "Epoch 2150 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2150.pth\n",
      "Epoch 2151 train loss: 0.5870223477638016\n",
      "Epoch 2151 train accuracy: 83.19166438168358\n",
      "Epoch 2151 val loss: 0.5813280969466034\n",
      "Epoch 2151 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2151.pth\n",
      "Epoch 2152 train loss: 0.5868928341293022\n",
      "Epoch 2152 train accuracy: 83.08198519330956\n",
      "Epoch 2152 val loss: 0.581333255885463\n",
      "Epoch 2152 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2152.pth\n",
      "Epoch 2153 train loss: 0.5869961401382298\n",
      "Epoch 2153 train accuracy: 83.05456539621606\n",
      "Epoch 2153 val loss: 0.5812939108153315\n",
      "Epoch 2153 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2153.pth\n",
      "Epoch 2154 train loss: 0.5869479281010858\n",
      "Epoch 2154 train accuracy: 83.10940499040306\n",
      "Epoch 2154 val loss: 0.5812851952781019\n",
      "Epoch 2154 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2154.pth\n",
      "Epoch 2155 train loss: 0.5869303139645541\n",
      "Epoch 2155 train accuracy: 83.02714559912256\n",
      "Epoch 2155 val loss: 0.5812650634662101\n",
      "Epoch 2155 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2155.pth\n",
      "Epoch 2156 train loss: 0.586867820847322\n",
      "Epoch 2156 train accuracy: 83.19166438168358\n",
      "Epoch 2156 val loss: 0.5812623762574635\n",
      "Epoch 2156 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2156.pth\n",
      "Epoch 2157 train loss: 0.5869677059756788\n",
      "Epoch 2157 train accuracy: 83.10940499040306\n",
      "Epoch 2157 val loss: 0.5812473873803882\n",
      "Epoch 2157 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2157.pth\n",
      "Epoch 2158 train loss: 0.5868526039187584\n",
      "Epoch 2158 train accuracy: 83.16424458459008\n",
      "Epoch 2158 val loss: 0.5812472551570911\n",
      "Epoch 2158 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2158.pth\n",
      "Epoch 2159 train loss: 0.5869676337266961\n",
      "Epoch 2159 train accuracy: 83.21908417877708\n",
      "Epoch 2159 val loss: 0.5812431207220805\n",
      "Epoch 2159 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2159.pth\n",
      "Epoch 2160 train loss: 0.5869043920752838\n",
      "Epoch 2160 train accuracy: 83.13682478749658\n",
      "Epoch 2160 val loss: 0.5812724480209382\n",
      "Epoch 2160 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2160.pth\n",
      "Epoch 2161 train loss: 0.586963185386961\n",
      "Epoch 2161 train accuracy: 83.08198519330956\n",
      "Epoch 2161 val loss: 0.5812621373977316\n",
      "Epoch 2161 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2161.pth\n",
      "Epoch 2162 train loss: 0.5869355231294768\n",
      "Epoch 2162 train accuracy: 83.10940499040306\n",
      "Epoch 2162 val loss: 0.5812569466958705\n",
      "Epoch 2162 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2162.pth\n",
      "Epoch 2163 train loss: 0.5869263998445189\n",
      "Epoch 2163 train accuracy: 83.08198519330956\n",
      "Epoch 2163 val loss: 0.581239875160942\n",
      "Epoch 2163 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2163.pth\n",
      "Epoch 2164 train loss: 0.586926174219371\n",
      "Epoch 2164 train accuracy: 83.05456539621606\n",
      "Epoch 2164 val loss: 0.5812226742702095\n",
      "Epoch 2164 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2164.pth\n",
      "Epoch 2165 train loss: 0.5869093293716249\n",
      "Epoch 2165 train accuracy: 83.05456539621606\n",
      "Epoch 2165 val loss: 0.5812261321778734\n",
      "Epoch 2165 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2165.pth\n",
      "Epoch 2166 train loss: 0.5868499827195417\n",
      "Epoch 2166 train accuracy: 83.05456539621606\n",
      "Epoch 2166 val loss: 0.5811987393780759\n",
      "Epoch 2166 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2166.pth\n",
      "Epoch 2167 train loss: 0.5869017041517062\n",
      "Epoch 2167 train accuracy: 83.02714559912256\n",
      "Epoch 2167 val loss: 0.5811973576967017\n",
      "Epoch 2167 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2167.pth\n",
      "Epoch 2168 train loss: 0.5868715166539085\n",
      "Epoch 2168 train accuracy: 82.97230600493556\n",
      "Epoch 2168 val loss: 0.581168333117507\n",
      "Epoch 2168 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2168.pth\n",
      "Epoch 2169 train loss: 0.5868921503588035\n",
      "Epoch 2169 train accuracy: 83.13682478749658\n",
      "Epoch 2169 val loss: 0.5811786298689089\n",
      "Epoch 2169 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2169.pth\n",
      "Epoch 2170 train loss: 0.5868249472492096\n",
      "Epoch 2170 train accuracy: 83.13682478749658\n",
      "Epoch 2170 val loss: 0.5811881510491826\n",
      "Epoch 2170 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2170.pth\n",
      "Epoch 2171 train loss: 0.5869066427429125\n",
      "Epoch 2171 train accuracy: 83.05456539621606\n",
      "Epoch 2171 val loss: 0.5811816040720594\n",
      "Epoch 2171 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2171.pth\n",
      "Epoch 2172 train loss: 0.5868834272729593\n",
      "Epoch 2172 train accuracy: 82.99972580202906\n",
      "Epoch 2172 val loss: 0.5811624121055693\n",
      "Epoch 2172 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2172.pth\n",
      "Epoch 2173 train loss: 0.5867985703475904\n",
      "Epoch 2173 train accuracy: 83.05456539621606\n",
      "Epoch 2173 val loss: 0.5811700736184752\n",
      "Epoch 2173 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2173.pth\n",
      "Epoch 2174 train loss: 0.5868102455871147\n",
      "Epoch 2174 train accuracy: 82.97230600493556\n",
      "Epoch 2174 val loss: 0.5811414350020258\n",
      "Epoch 2174 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2174.pth\n",
      "Epoch 2175 train loss: 0.5868429762041686\n",
      "Epoch 2175 train accuracy: 83.05456539621606\n",
      "Epoch 2175 val loss: 0.5811308267477312\n",
      "Epoch 2175 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2175.pth\n",
      "Epoch 2176 train loss: 0.586728152247113\n",
      "Epoch 2176 train accuracy: 83.19166438168358\n",
      "Epoch 2176 val loss: 0.5811223310026291\n",
      "Epoch 2176 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2176.pth\n",
      "Epoch 2177 train loss: 0.5867707609901565\n",
      "Epoch 2177 train accuracy: 83.13682478749658\n",
      "Epoch 2177 val loss: 0.581122969926678\n",
      "Epoch 2177 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2177.pth\n",
      "Epoch 2178 train loss: 0.5868310940762361\n",
      "Epoch 2178 train accuracy: 83.05456539621606\n",
      "Epoch 2178 val loss: 0.5811361373451195\n",
      "Epoch 2178 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2178.pth\n",
      "Epoch 2179 train loss: 0.5868211692329823\n",
      "Epoch 2179 train accuracy: 82.97230600493556\n",
      "Epoch 2179 val loss: 0.5810983578527444\n",
      "Epoch 2179 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2179.pth\n",
      "Epoch 2180 train loss: 0.5868007586451999\n",
      "Epoch 2180 train accuracy: 83.10940499040306\n",
      "Epoch 2180 val loss: 0.5811013929839981\n",
      "Epoch 2180 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2180.pth\n",
      "Epoch 2181 train loss: 0.5867402828992916\n",
      "Epoch 2181 train accuracy: 83.08198519330956\n",
      "Epoch 2181 val loss: 0.5811054477174031\n",
      "Epoch 2181 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2181.pth\n",
      "Epoch 2182 train loss: 0.5867167739687782\n",
      "Epoch 2182 train accuracy: 83.02714559912256\n",
      "Epoch 2182 val loss: 0.5810678244421357\n",
      "Epoch 2182 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2182.pth\n",
      "Epoch 2183 train loss: 0.5867284709330354\n",
      "Epoch 2183 train accuracy: 83.02714559912256\n",
      "Epoch 2183 val loss: 0.5810720225011832\n",
      "Epoch 2183 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2183.pth\n",
      "Epoch 2184 train loss: 0.586775144937922\n",
      "Epoch 2184 train accuracy: 83.21908417877708\n",
      "Epoch 2184 val loss: 0.5810826241872028\n",
      "Epoch 2184 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2184.pth\n",
      "Epoch 2185 train loss: 0.5867712840830025\n",
      "Epoch 2185 train accuracy: 83.08198519330956\n",
      "Epoch 2185 val loss: 0.5810559510106319\n",
      "Epoch 2185 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2185.pth\n",
      "Epoch 2186 train loss: 0.5866904178585269\n",
      "Epoch 2186 train accuracy: 82.97230600493556\n",
      "Epoch 2186 val loss: 0.5810472812797678\n",
      "Epoch 2186 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2186.pth\n",
      "Epoch 2187 train loss: 0.5867263240445602\n",
      "Epoch 2187 train accuracy: 83.13682478749658\n",
      "Epoch 2187 val loss: 0.5810463117239507\n",
      "Epoch 2187 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2187.pth\n",
      "Epoch 2188 train loss: 0.5866735346549958\n",
      "Epoch 2188 train accuracy: 83.19166438168358\n",
      "Epoch 2188 val loss: 0.5810392571821514\n",
      "Epoch 2188 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2188.pth\n",
      "Epoch 2189 train loss: 0.5867830915539934\n",
      "Epoch 2189 train accuracy: 83.05456539621606\n",
      "Epoch 2189 val loss: 0.5810121191469463\n",
      "Epoch 2189 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2189.pth\n",
      "Epoch 2190 train loss: 0.5866692068970256\n",
      "Epoch 2190 train accuracy: 83.16424458459008\n",
      "Epoch 2190 val loss: 0.5810099026482356\n",
      "Epoch 2190 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2190.pth\n",
      "Epoch 2191 train loss: 0.5866630217387226\n",
      "Epoch 2191 train accuracy: 83.13682478749658\n",
      "Epoch 2191 val loss: 0.5810022484878764\n",
      "Epoch 2191 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2191.pth\n",
      "Epoch 2192 train loss: 0.5867016717562812\n",
      "Epoch 2192 train accuracy: 83.19166438168358\n",
      "Epoch 2192 val loss: 0.5809894077185738\n",
      "Epoch 2192 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2192.pth\n",
      "Epoch 2193 train loss: 0.5866954647200672\n",
      "Epoch 2193 train accuracy: 83.19166438168358\n",
      "Epoch 2193 val loss: 0.581008753972128\n",
      "Epoch 2193 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2193.pth\n",
      "Epoch 2194 train loss: 0.5866458210849056\n",
      "Epoch 2194 train accuracy: 83.10940499040306\n",
      "Epoch 2194 val loss: 0.5809940648706335\n",
      "Epoch 2194 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2194.pth\n",
      "Epoch 2195 train loss: 0.5866892460995076\n",
      "Epoch 2195 train accuracy: 83.16424458459008\n",
      "Epoch 2195 val loss: 0.5809840066848617\n",
      "Epoch 2195 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2195.pth\n",
      "Epoch 2196 train loss: 0.5866870977589044\n",
      "Epoch 2196 train accuracy: 83.05456539621606\n",
      "Epoch 2196 val loss: 0.5809674403679214\n",
      "Epoch 2196 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2196.pth\n",
      "Epoch 2197 train loss: 0.5865756424507453\n",
      "Epoch 2197 train accuracy: 82.97230600493556\n",
      "Epoch 2197 val loss: 0.580951769836247\n",
      "Epoch 2197 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2197.pth\n",
      "Epoch 2198 train loss: 0.5866773586001313\n",
      "Epoch 2198 train accuracy: 83.13682478749658\n",
      "Epoch 2198 val loss: 0.5809476863298761\n",
      "Epoch 2198 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2198.pth\n",
      "Epoch 2199 train loss: 0.5866282110903085\n",
      "Epoch 2199 train accuracy: 83.13682478749658\n",
      "Epoch 2199 val loss: 0.5809587068659695\n",
      "Epoch 2199 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2199.pth\n",
      "Epoch 2200 train loss: 0.5865842466683764\n",
      "Epoch 2200 train accuracy: 83.16424458459008\n",
      "Epoch 2200 val loss: 0.5809442525925604\n",
      "Epoch 2200 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2200.pth\n",
      "Epoch 2201 train loss: 0.5866697204397305\n",
      "Epoch 2201 train accuracy: 83.13682478749658\n",
      "Epoch 2201 val loss: 0.5809336452940969\n",
      "Epoch 2201 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2201.pth\n",
      "Epoch 2202 train loss: 0.5866068011443866\n",
      "Epoch 2202 train accuracy: 83.10940499040306\n",
      "Epoch 2202 val loss: 0.5809124930222568\n",
      "Epoch 2202 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2202.pth\n",
      "Epoch 2203 train loss: 0.5865702441650475\n",
      "Epoch 2203 train accuracy: 83.10940499040306\n",
      "Epoch 2203 val loss: 0.5809054903833097\n",
      "Epoch 2203 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2203.pth\n",
      "Epoch 2204 train loss: 0.5865712737309208\n",
      "Epoch 2204 train accuracy: 83.08198519330956\n",
      "Epoch 2204 val loss: 0.580890846340672\n",
      "Epoch 2204 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2204.pth\n",
      "Epoch 2205 train loss: 0.5866328621121826\n",
      "Epoch 2205 train accuracy: 83.19166438168358\n",
      "Epoch 2205 val loss: 0.5808916466286111\n",
      "Epoch 2205 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2205.pth\n",
      "Epoch 2206 train loss: 0.5866131396114564\n",
      "Epoch 2206 train accuracy: 83.16424458459008\n",
      "Epoch 2206 val loss: 0.5808782818678179\n",
      "Epoch 2206 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2206.pth\n",
      "Epoch 2207 train loss: 0.5866119448226272\n",
      "Epoch 2207 train accuracy: 83.13682478749658\n",
      "Epoch 2207 val loss: 0.5808977496467138\n",
      "Epoch 2207 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2207.pth\n",
      "Epoch 2208 train loss: 0.5865416923300935\n",
      "Epoch 2208 train accuracy: 83.10940499040306\n",
      "Epoch 2208 val loss: 0.580891610417319\n",
      "Epoch 2208 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2208.pth\n",
      "Epoch 2209 train loss: 0.5865646349429562\n",
      "Epoch 2209 train accuracy: 83.19166438168358\n",
      "Epoch 2209 val loss: 0.5808740607217738\n",
      "Epoch 2209 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2209.pth\n",
      "Epoch 2210 train loss: 0.5864728135955438\n",
      "Epoch 2210 train accuracy: 83.16424458459008\n",
      "Epoch 2210 val loss: 0.5808685341555822\n",
      "Epoch 2210 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2210.pth\n",
      "Epoch 2211 train loss: 0.5866147077952822\n",
      "Epoch 2211 train accuracy: 83.16424458459008\n",
      "Epoch 2211 val loss: 0.580893256652512\n",
      "Epoch 2211 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2211.pth\n",
      "Epoch 2212 train loss: 0.5865475626891119\n",
      "Epoch 2212 train accuracy: 83.13682478749658\n",
      "Epoch 2212 val loss: 0.5808797105656642\n",
      "Epoch 2212 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2212.pth\n",
      "Epoch 2213 train loss: 0.5864549104875901\n",
      "Epoch 2213 train accuracy: 83.02714559912256\n",
      "Epoch 2213 val loss: 0.5808305225188011\n",
      "Epoch 2213 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2213.pth\n",
      "Epoch 2214 train loss: 0.586560177894538\n",
      "Epoch 2214 train accuracy: 83.16424458459008\n",
      "Epoch 2214 val loss: 0.5808387360976714\n",
      "Epoch 2214 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2214.pth\n",
      "Epoch 2215 train loss: 0.5865242925815677\n",
      "Epoch 2215 train accuracy: 83.10940499040306\n",
      "Epoch 2215 val loss: 0.5808303942903876\n",
      "Epoch 2215 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2215.pth\n",
      "Epoch 2216 train loss: 0.5865506289543159\n",
      "Epoch 2216 train accuracy: 83.08198519330956\n",
      "Epoch 2216 val loss: 0.5807985290884972\n",
      "Epoch 2216 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2216.pth\n",
      "Epoch 2217 train loss: 0.5864738557945218\n",
      "Epoch 2217 train accuracy: 83.10940499040306\n",
      "Epoch 2217 val loss: 0.5808048682336352\n",
      "Epoch 2217 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2217.pth\n",
      "Epoch 2218 train loss: 0.58647593091193\n",
      "Epoch 2218 train accuracy: 83.27392377296408\n",
      "Epoch 2218 val loss: 0.5808206999576405\n",
      "Epoch 2218 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2218.pth\n",
      "Epoch 2219 train loss: 0.5863847528960098\n",
      "Epoch 2219 train accuracy: 83.05456539621606\n",
      "Epoch 2219 val loss: 0.5808121803657789\n",
      "Epoch 2219 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2219.pth\n",
      "Epoch 2220 train loss: 0.5863945788357676\n",
      "Epoch 2220 train accuracy: 83.16424458459008\n",
      "Epoch 2220 val loss: 0.5808157366945556\n",
      "Epoch 2220 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2220.pth\n",
      "Epoch 2221 train loss: 0.5864218722604084\n",
      "Epoch 2221 train accuracy: 82.99972580202906\n",
      "Epoch 2221 val loss: 0.5807588870374706\n",
      "Epoch 2221 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2221.pth\n",
      "Epoch 2222 train loss: 0.5864594507688787\n",
      "Epoch 2222 train accuracy: 83.21908417877708\n",
      "Epoch 2222 val loss: 0.5807795534890733\n",
      "Epoch 2222 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2222.pth\n",
      "Epoch 2223 train loss: 0.5864335371900284\n",
      "Epoch 2223 train accuracy: 83.13682478749658\n",
      "Epoch 2223 val loss: 0.5807755074806904\n",
      "Epoch 2223 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2223.pth\n",
      "Epoch 2224 train loss: 0.5864259905361554\n",
      "Epoch 2224 train accuracy: 83.19166438168358\n",
      "Epoch 2224 val loss: 0.5807526349335125\n",
      "Epoch 2224 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2224.pth\n",
      "Epoch 2225 train loss: 0.5864610686783859\n",
      "Epoch 2225 train accuracy: 83.21908417877708\n",
      "Epoch 2225 val loss: 0.5807455303515062\n",
      "Epoch 2225 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2225.pth\n",
      "Epoch 2226 train loss: 0.5864326956992348\n",
      "Epoch 2226 train accuracy: 83.19166438168358\n",
      "Epoch 2226 val loss: 0.5807498660624811\n",
      "Epoch 2226 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2226.pth\n",
      "Epoch 2227 train loss: 0.5864803196796984\n",
      "Epoch 2227 train accuracy: 83.16424458459008\n",
      "Epoch 2227 val loss: 0.580748940229808\n",
      "Epoch 2227 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2227.pth\n",
      "Epoch 2228 train loss: 0.5864370094546885\n",
      "Epoch 2228 train accuracy: 83.16424458459008\n",
      "Epoch 2228 val loss: 0.5807428756042531\n",
      "Epoch 2228 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2228.pth\n",
      "Epoch 2229 train loss: 0.5864714729485282\n",
      "Epoch 2229 train accuracy: 83.08198519330956\n",
      "Epoch 2229 val loss: 0.5807247030499735\n",
      "Epoch 2229 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2229.pth\n",
      "Epoch 2230 train loss: 0.5863839783705771\n",
      "Epoch 2230 train accuracy: 83.16424458459008\n",
      "Epoch 2230 val loss: 0.5807044346277651\n",
      "Epoch 2230 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2230.pth\n",
      "Epoch 2231 train loss: 0.5864145961802518\n",
      "Epoch 2231 train accuracy: 83.08198519330956\n",
      "Epoch 2231 val loss: 0.5807098080649188\n",
      "Epoch 2231 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2231.pth\n",
      "Epoch 2232 train loss: 0.5864398733206224\n",
      "Epoch 2232 train accuracy: 83.16424458459008\n",
      "Epoch 2232 val loss: 0.5806888019862143\n",
      "Epoch 2232 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2232.pth\n",
      "Epoch 2233 train loss: 0.5863745564741916\n",
      "Epoch 2233 train accuracy: 83.05456539621606\n",
      "Epoch 2233 val loss: 0.5806755424036008\n",
      "Epoch 2233 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2233.pth\n",
      "Epoch 2234 train loss: 0.5863098451671632\n",
      "Epoch 2234 train accuracy: 83.10940499040306\n",
      "Epoch 2234 val loss: 0.5806790801549429\n",
      "Epoch 2234 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2234.pth\n",
      "Epoch 2235 train loss: 0.5864160075342577\n",
      "Epoch 2235 train accuracy: 83.13682478749658\n",
      "Epoch 2235 val loss: 0.5806915587990692\n",
      "Epoch 2235 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2235.pth\n",
      "Epoch 2236 train loss: 0.5864141585321672\n",
      "Epoch 2236 train accuracy: 83.19166438168358\n",
      "Epoch 2236 val loss: 0.5806844211918744\n",
      "Epoch 2236 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2236.pth\n",
      "Epoch 2237 train loss: 0.5863587879657484\n",
      "Epoch 2237 train accuracy: 83.08198519330956\n",
      "Epoch 2237 val loss: 0.5806913068518043\n",
      "Epoch 2237 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2237.pth\n",
      "Epoch 2238 train loss: 0.5863948740931064\n",
      "Epoch 2238 train accuracy: 83.08198519330956\n",
      "Epoch 2238 val loss: 0.5806544980426368\n",
      "Epoch 2238 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2238.pth\n",
      "Epoch 2239 train loss: 0.5863363065413738\n",
      "Epoch 2239 train accuracy: 83.13682478749658\n",
      "Epoch 2239 val loss: 0.5806605679130084\n",
      "Epoch 2239 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2239.pth\n",
      "Epoch 2240 train loss: 0.5863823767244947\n",
      "Epoch 2240 train accuracy: 83.10940499040306\n",
      "Epoch 2240 val loss: 0.5806334825036558\n",
      "Epoch 2240 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2240.pth\n",
      "Epoch 2241 train loss: 0.5861882214915551\n",
      "Epoch 2241 train accuracy: 83.19166438168358\n",
      "Epoch 2241 val loss: 0.5806468401202246\n",
      "Epoch 2241 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2241.pth\n",
      "Epoch 2242 train loss: 0.5862523861670572\n",
      "Epoch 2242 train accuracy: 83.16424458459008\n",
      "Epoch 2242 val loss: 0.5806339693892943\n",
      "Epoch 2242 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2242.pth\n",
      "Epoch 2243 train loss: 0.5863153116222013\n",
      "Epoch 2243 train accuracy: 83.13682478749658\n",
      "Epoch 2243 val loss: 0.5806399847037698\n",
      "Epoch 2243 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2243.pth\n",
      "Epoch 2244 train loss: 0.5862936944447523\n",
      "Epoch 2244 train accuracy: 83.08198519330956\n",
      "Epoch 2244 val loss: 0.5806108107300181\n",
      "Epoch 2244 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2244.pth\n",
      "Epoch 2245 train loss: 0.5863515670787085\n",
      "Epoch 2245 train accuracy: 83.16424458459008\n",
      "Epoch 2245 val loss: 0.5806029821304899\n",
      "Epoch 2245 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2245.pth\n",
      "Epoch 2246 train loss: 0.5863330796393648\n",
      "Epoch 2246 train accuracy: 83.08198519330956\n",
      "Epoch 2246 val loss: 0.5805715664755553\n",
      "Epoch 2246 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2246.pth\n",
      "Epoch 2247 train loss: 0.5863610081570713\n",
      "Epoch 2247 train accuracy: 83.16424458459008\n",
      "Epoch 2247 val loss: 0.5805836022083991\n",
      "Epoch 2247 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2247.pth\n",
      "Epoch 2248 train loss: 0.5863106846891082\n",
      "Epoch 2248 train accuracy: 83.21908417877708\n",
      "Epoch 2248 val loss: 0.5806025540652243\n",
      "Epoch 2248 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2248.pth\n",
      "Epoch 2249 train loss: 0.5863765856545222\n",
      "Epoch 2249 train accuracy: 83.13682478749658\n",
      "Epoch 2249 val loss: 0.5805868712364157\n",
      "Epoch 2249 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2249.pth\n",
      "Epoch 2250 train loss: 0.586304945920251\n",
      "Epoch 2250 train accuracy: 83.10940499040306\n",
      "Epoch 2250 val loss: 0.5805849034927393\n",
      "Epoch 2250 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2250.pth\n",
      "Epoch 2251 train loss: 0.5862459103789246\n",
      "Epoch 2251 train accuracy: 83.10940499040306\n",
      "Epoch 2251 val loss: 0.5805519223213196\n",
      "Epoch 2251 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2251.pth\n",
      "Epoch 2252 train loss: 0.5862607410659588\n",
      "Epoch 2252 train accuracy: 83.16424458459008\n",
      "Epoch 2252 val loss: 0.5805472226225232\n",
      "Epoch 2252 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2252.pth\n",
      "Epoch 2253 train loss: 0.5862423390672918\n",
      "Epoch 2253 train accuracy: 83.10940499040306\n",
      "Epoch 2253 val loss: 0.5805399621297654\n",
      "Epoch 2253 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2253.pth\n",
      "Epoch 2254 train loss: 0.5862899830334068\n",
      "Epoch 2254 train accuracy: 83.16424458459008\n",
      "Epoch 2254 val loss: 0.5805471683117119\n",
      "Epoch 2254 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2254.pth\n",
      "Epoch 2255 train loss: 0.586228118572188\n",
      "Epoch 2255 train accuracy: 83.10940499040306\n",
      "Epoch 2255 val loss: 0.5805220247589444\n",
      "Epoch 2255 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2255.pth\n",
      "Epoch 2256 train loss: 0.5862643435564742\n",
      "Epoch 2256 train accuracy: 83.19166438168358\n",
      "Epoch 2256 val loss: 0.5805150511135396\n",
      "Epoch 2256 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2256.pth\n",
      "Epoch 2257 train loss: 0.5862112017348409\n",
      "Epoch 2257 train accuracy: 83.24650397587058\n",
      "Epoch 2257 val loss: 0.5805198786302322\n",
      "Epoch 2257 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2257.pth\n",
      "Epoch 2258 train loss: 0.5861071517870745\n",
      "Epoch 2258 train accuracy: 83.16424458459008\n",
      "Epoch 2258 val loss: 0.5805134971528069\n",
      "Epoch 2258 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2258.pth\n",
      "Epoch 2259 train loss: 0.5861519296375806\n",
      "Epoch 2259 train accuracy: 83.21908417877708\n",
      "Epoch 2259 val loss: 0.5805084546660318\n",
      "Epoch 2259 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2259.pth\n",
      "Epoch 2260 train loss: 0.5862519973153738\n",
      "Epoch 2260 train accuracy: 83.13682478749658\n",
      "Epoch 2260 val loss: 0.5805213772936871\n",
      "Epoch 2260 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2260.pth\n",
      "Epoch 2261 train loss: 0.5861804157070685\n",
      "Epoch 2261 train accuracy: 83.21908417877708\n",
      "Epoch 2261 val loss: 0.5805305298417807\n",
      "Epoch 2261 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2261.pth\n",
      "Epoch 2262 train loss: 0.5861806680791473\n",
      "Epoch 2262 train accuracy: 83.05456539621606\n",
      "Epoch 2262 val loss: 0.5804845374077559\n",
      "Epoch 2262 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2262.pth\n",
      "Epoch 2263 train loss: 0.5861691363776723\n",
      "Epoch 2263 train accuracy: 83.13682478749658\n",
      "Epoch 2263 val loss: 0.5804647349899537\n",
      "Epoch 2263 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2263.pth\n",
      "Epoch 2264 train loss: 0.5862279557541274\n",
      "Epoch 2264 train accuracy: 83.21908417877708\n",
      "Epoch 2264 val loss: 0.5804554834153111\n",
      "Epoch 2264 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2264.pth\n",
      "Epoch 2265 train loss: 0.586150658986809\n",
      "Epoch 2265 train accuracy: 83.19166438168358\n",
      "Epoch 2265 val loss: 0.5804745965073571\n",
      "Epoch 2265 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2265.pth\n",
      "Epoch 2266 train loss: 0.5862576626649681\n",
      "Epoch 2266 train accuracy: 83.16424458459008\n",
      "Epoch 2266 val loss: 0.5804432029406982\n",
      "Epoch 2266 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2266.pth\n",
      "Epoch 2267 train loss: 0.5861412396066283\n",
      "Epoch 2267 train accuracy: 83.10940499040306\n",
      "Epoch 2267 val loss: 0.5804352202011567\n",
      "Epoch 2267 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2267.pth\n",
      "Epoch 2268 train loss: 0.5861962021802339\n",
      "Epoch 2268 train accuracy: 83.13682478749658\n",
      "Epoch 2268 val loss: 0.5804249008161653\n",
      "Epoch 2268 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2268.pth\n",
      "Epoch 2269 train loss: 0.5862038113164568\n",
      "Epoch 2269 train accuracy: 83.16424458459008\n",
      "Epoch 2269 val loss: 0.5804466428725343\n",
      "Epoch 2269 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2269.pth\n",
      "Epoch 2270 train loss: 0.5861693773206258\n",
      "Epoch 2270 train accuracy: 83.19166438168358\n",
      "Epoch 2270 val loss: 0.5804689381957838\n",
      "Epoch 2270 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2270.pth\n",
      "Epoch 2271 train loss: 0.5861362636154681\n",
      "Epoch 2271 train accuracy: 83.13682478749658\n",
      "Epoch 2271 val loss: 0.5804346320464423\n",
      "Epoch 2271 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2271.pth\n",
      "Epoch 2272 train loss: 0.586176535065629\n",
      "Epoch 2272 train accuracy: 83.10940499040306\n",
      "Epoch 2272 val loss: 0.5804137290504418\n",
      "Epoch 2272 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2272.pth\n",
      "Epoch 2273 train loss: 0.5861735188549286\n",
      "Epoch 2273 train accuracy: 83.13682478749658\n",
      "Epoch 2273 val loss: 0.580395403563192\n",
      "Epoch 2273 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2273.pth\n",
      "Epoch 2274 train loss: 0.5861495768001891\n",
      "Epoch 2274 train accuracy: 83.16424458459008\n",
      "Epoch 2274 val loss: 0.580402074479743\n",
      "Epoch 2274 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2274.pth\n",
      "Epoch 2275 train loss: 0.5861614964935079\n",
      "Epoch 2275 train accuracy: 83.19166438168358\n",
      "Epoch 2275 val loss: 0.5803942268616274\n",
      "Epoch 2275 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2275.pth\n",
      "Epoch 2276 train loss: 0.5861018351524284\n",
      "Epoch 2276 train accuracy: 83.08198519330956\n",
      "Epoch 2276 val loss: 0.5803780595428849\n",
      "Epoch 2276 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2276.pth\n",
      "Epoch 2277 train loss: 0.5861404041449229\n",
      "Epoch 2277 train accuracy: 83.13682478749658\n",
      "Epoch 2277 val loss: 0.5803744573097088\n",
      "Epoch 2277 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2277.pth\n",
      "Epoch 2278 train loss: 0.5861391080543399\n",
      "Epoch 2278 train accuracy: 83.16424458459008\n",
      "Epoch 2278 val loss: 0.5803694350546912\n",
      "Epoch 2278 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2278.pth\n",
      "Epoch 2279 train loss: 0.5860732468662032\n",
      "Epoch 2279 train accuracy: 83.24650397587058\n",
      "Epoch 2279 val loss: 0.5803834896436647\n",
      "Epoch 2279 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2279.pth\n",
      "Epoch 2280 train loss: 0.5861162297068196\n",
      "Epoch 2280 train accuracy: 83.13682478749658\n",
      "Epoch 2280 val loss: 0.5803628445750004\n",
      "Epoch 2280 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2280.pth\n",
      "Epoch 2281 train loss: 0.5860810516924974\n",
      "Epoch 2281 train accuracy: 83.13682478749658\n",
      "Epoch 2281 val loss: 0.5803315688267743\n",
      "Epoch 2281 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2281.pth\n",
      "Epoch 2282 train loss: 0.5860367184423172\n",
      "Epoch 2282 train accuracy: 83.19166438168358\n",
      "Epoch 2282 val loss: 0.58032194824007\n",
      "Epoch 2282 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2282.pth\n",
      "Epoch 2283 train loss: 0.5860985099223622\n",
      "Epoch 2283 train accuracy: 83.21908417877708\n",
      "Epoch 2283 val loss: 0.580314764900035\n",
      "Epoch 2283 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2283.pth\n",
      "Epoch 2284 train loss: 0.5859896698966622\n",
      "Epoch 2284 train accuracy: 83.21908417877708\n",
      "Epoch 2284 val loss: 0.5803133262639963\n",
      "Epoch 2284 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2284.pth\n",
      "Epoch 2285 train loss: 0.5860334236497518\n",
      "Epoch 2285 train accuracy: 83.24650397587058\n",
      "Epoch 2285 val loss: 0.5803404118571627\n",
      "Epoch 2285 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2285.pth\n",
      "Epoch 2286 train loss: 0.5860820190384657\n",
      "Epoch 2286 train accuracy: 83.24650397587058\n",
      "Epoch 2286 val loss: 0.5803235459974722\n",
      "Epoch 2286 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2286.pth\n",
      "Epoch 2287 train loss: 0.5860903116296405\n",
      "Epoch 2287 train accuracy: 83.19166438168358\n",
      "Epoch 2287 val loss: 0.5802955157858761\n",
      "Epoch 2287 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2287.pth\n",
      "Epoch 2288 train loss: 0.5860723839386514\n",
      "Epoch 2288 train accuracy: 83.13682478749658\n",
      "Epoch 2288 val loss: 0.5803053729040059\n",
      "Epoch 2288 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2288.pth\n",
      "Epoch 2289 train loss: 0.5859825061021471\n",
      "Epoch 2289 train accuracy: 83.16424458459008\n",
      "Epoch 2289 val loss: 0.5802793265075276\n",
      "Epoch 2289 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2289.pth\n",
      "Epoch 2290 train loss: 0.5860534460823003\n",
      "Epoch 2290 train accuracy: 83.27392377296408\n",
      "Epoch 2290 val loss: 0.580280321699224\n",
      "Epoch 2290 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2290.pth\n",
      "Epoch 2291 train loss: 0.5860202280608448\n",
      "Epoch 2291 train accuracy: 83.08198519330956\n",
      "Epoch 2291 val loss: 0.5803233440965414\n",
      "Epoch 2291 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2291.pth\n",
      "Epoch 2292 train loss: 0.5860465669579673\n",
      "Epoch 2292 train accuracy: 83.16424458459008\n",
      "Epoch 2292 val loss: 0.5802711540048844\n",
      "Epoch 2292 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2292.pth\n",
      "Epoch 2293 train loss: 0.5859740631033977\n",
      "Epoch 2293 train accuracy: 83.13682478749658\n",
      "Epoch 2293 val loss: 0.580270003512085\n",
      "Epoch 2293 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2293.pth\n",
      "Epoch 2294 train loss: 0.5860368708197615\n",
      "Epoch 2294 train accuracy: 83.16424458459008\n",
      "Epoch 2294 val loss: 0.5802464877304278\n",
      "Epoch 2294 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2294.pth\n",
      "Epoch 2295 train loss: 0.5860316648000949\n",
      "Epoch 2295 train accuracy: 83.16424458459008\n",
      "Epoch 2295 val loss: 0.5802458135509178\n",
      "Epoch 2295 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2295.pth\n",
      "Epoch 2296 train loss: 0.5859581504278538\n",
      "Epoch 2296 train accuracy: 83.16424458459008\n",
      "Epoch 2296 val loss: 0.5802455730246086\n",
      "Epoch 2296 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2296.pth\n",
      "Epoch 2297 train loss: 0.5860127689512936\n",
      "Epoch 2297 train accuracy: 83.24650397587058\n",
      "Epoch 2297 val loss: 0.5802232407425579\n",
      "Epoch 2297 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2297.pth\n",
      "Epoch 2298 train loss: 0.5860102404145884\n",
      "Epoch 2298 train accuracy: 83.19166438168358\n",
      "Epoch 2298 val loss: 0.5802175828712758\n",
      "Epoch 2298 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2298.pth\n",
      "Epoch 2299 train loss: 0.5860078852672718\n",
      "Epoch 2299 train accuracy: 83.19166438168358\n",
      "Epoch 2299 val loss: 0.5801998983676496\n",
      "Epoch 2299 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2299.pth\n",
      "Epoch 2300 train loss: 0.5859893326598563\n",
      "Epoch 2300 train accuracy: 83.19166438168358\n",
      "Epoch 2300 val loss: 0.5802014309814886\n",
      "Epoch 2300 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2300.pth\n",
      "Epoch 2301 train loss: 0.5859713899298457\n",
      "Epoch 2301 train accuracy: 83.13682478749658\n",
      "Epoch 2301 val loss: 0.5802177534879822\n",
      "Epoch 2301 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2301.pth\n",
      "Epoch 2302 train loss: 0.5859630583834491\n",
      "Epoch 2302 train accuracy: 83.13682478749658\n",
      "Epoch 2302 val loss: 0.5802232073619962\n",
      "Epoch 2302 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2302.pth\n",
      "Epoch 2303 train loss: 0.5859228291685628\n",
      "Epoch 2303 train accuracy: 83.19166438168358\n",
      "Epoch 2303 val loss: 0.5802391760639454\n",
      "Epoch 2303 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2303.pth\n",
      "Epoch 2304 train loss: 0.5859047196674765\n",
      "Epoch 2304 train accuracy: 83.05456539621606\n",
      "Epoch 2304 val loss: 0.5801744126763783\n",
      "Epoch 2304 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2304.pth\n",
      "Epoch 2305 train loss: 0.5859610253348619\n",
      "Epoch 2305 train accuracy: 83.16424458459008\n",
      "Epoch 2305 val loss: 0.5801883424191099\n",
      "Epoch 2305 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2305.pth\n",
      "Epoch 2306 train loss: 0.5859588813700451\n",
      "Epoch 2306 train accuracy: 83.16424458459008\n",
      "Epoch 2306 val loss: 0.5801635836496165\n",
      "Epoch 2306 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2306.pth\n",
      "Epoch 2307 train loss: 0.5858812763829503\n",
      "Epoch 2307 train accuracy: 83.21908417877708\n",
      "Epoch 2307 val loss: 0.5801726734559787\n",
      "Epoch 2307 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2307.pth\n",
      "Epoch 2308 train loss: 0.5859439606663951\n",
      "Epoch 2308 train accuracy: 83.21908417877708\n",
      "Epoch 2308 val loss: 0.580146009764193\n",
      "Epoch 2308 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2308.pth\n",
      "Epoch 2309 train loss: 0.5859292605238264\n",
      "Epoch 2309 train accuracy: 83.16424458459008\n",
      "Epoch 2309 val loss: 0.5801359093502948\n",
      "Epoch 2309 val accuracy: 83.96381578947368\n",
      "Saved model to .\\test_models/MLP_2309.pth\n",
      "Epoch 2310 train loss: 0.5858921454239049\n",
      "Epoch 2310 train accuracy: 83.10940499040306\n",
      "Epoch 2310 val loss: 0.5801414688558955\n",
      "Epoch 2310 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2310.pth\n",
      "Epoch 2311 train loss: 0.5859168345239341\n",
      "Epoch 2311 train accuracy: 83.24650397587058\n",
      "Epoch 2311 val loss: 0.5801312871718485\n",
      "Epoch 2311 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2311.pth\n",
      "Epoch 2312 train loss: 0.5859037386416867\n",
      "Epoch 2312 train accuracy: 83.21908417877708\n",
      "Epoch 2312 val loss: 0.5801552753209284\n",
      "Epoch 2312 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2312.pth\n",
      "Epoch 2313 train loss: 0.5858386291942576\n",
      "Epoch 2313 train accuracy: 83.27392377296408\n",
      "Epoch 2313 val loss: 0.5801614760666302\n",
      "Epoch 2313 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2313.pth\n",
      "Epoch 2314 train loss: 0.5858640966838912\n",
      "Epoch 2314 train accuracy: 83.16424458459008\n",
      "Epoch 2314 val loss: 0.5801274881845242\n",
      "Epoch 2314 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2314.pth\n",
      "Epoch 2315 train loss: 0.5857815246604252\n",
      "Epoch 2315 train accuracy: 83.19166438168358\n",
      "Epoch 2315 val loss: 0.5801159556660997\n",
      "Epoch 2315 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2315.pth\n",
      "Epoch 2316 train loss: 0.5858609377357521\n",
      "Epoch 2316 train accuracy: 83.16424458459008\n",
      "Epoch 2316 val loss: 0.5800988409227055\n",
      "Epoch 2316 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2316.pth\n",
      "Epoch 2317 train loss: 0.5858859396784714\n",
      "Epoch 2317 train accuracy: 83.10940499040306\n",
      "Epoch 2317 val loss: 0.580082403103772\n",
      "Epoch 2317 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2317.pth\n",
      "Epoch 2318 train loss: 0.585917059062539\n",
      "Epoch 2318 train accuracy: 83.19166438168358\n",
      "Epoch 2318 val loss: 0.5800766966697809\n",
      "Epoch 2318 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2318.pth\n",
      "Epoch 2319 train loss: 0.5857543377777594\n",
      "Epoch 2319 train accuracy: 83.13682478749658\n",
      "Epoch 2319 val loss: 0.580067418956835\n",
      "Epoch 2319 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2319.pth\n",
      "Epoch 2320 train loss: 0.5858606481189398\n",
      "Epoch 2320 train accuracy: 83.19166438168358\n",
      "Epoch 2320 val loss: 0.5800673177367762\n",
      "Epoch 2320 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2320.pth\n",
      "Epoch 2321 train loss: 0.5857714060939064\n",
      "Epoch 2321 train accuracy: 83.21908417877708\n",
      "Epoch 2321 val loss: 0.5800587853024665\n",
      "Epoch 2321 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2321.pth\n",
      "Epoch 2322 train loss: 0.5857456906192136\n",
      "Epoch 2322 train accuracy: 83.19166438168358\n",
      "Epoch 2322 val loss: 0.5800510040533385\n",
      "Epoch 2322 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2322.pth\n",
      "Epoch 2323 train loss: 0.5858397522058926\n",
      "Epoch 2323 train accuracy: 83.16424458459008\n",
      "Epoch 2323 val loss: 0.5800652882133267\n",
      "Epoch 2323 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2323.pth\n",
      "Epoch 2324 train loss: 0.5857943683567053\n",
      "Epoch 2324 train accuracy: 83.05456539621606\n",
      "Epoch 2324 val loss: 0.580045145470649\n",
      "Epoch 2324 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2324.pth\n",
      "Epoch 2325 train loss: 0.5858359057783035\n",
      "Epoch 2325 train accuracy: 83.19166438168358\n",
      "Epoch 2325 val loss: 0.5800444032800826\n",
      "Epoch 2325 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2325.pth\n",
      "Epoch 2326 train loss: 0.5857707133124533\n",
      "Epoch 2326 train accuracy: 83.19166438168358\n",
      "Epoch 2326 val loss: 0.580032314566013\n",
      "Epoch 2326 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2326.pth\n",
      "Epoch 2327 train loss: 0.5857983053449476\n",
      "Epoch 2327 train accuracy: 83.21908417877708\n",
      "Epoch 2327 val loss: 0.5800369242206216\n",
      "Epoch 2327 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2327.pth\n",
      "Epoch 2328 train loss: 0.5856881721786505\n",
      "Epoch 2328 train accuracy: 83.16424458459008\n",
      "Epoch 2328 val loss: 0.5800146089474622\n",
      "Epoch 2328 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2328.pth\n",
      "Epoch 2329 train loss: 0.5857647190609816\n",
      "Epoch 2329 train accuracy: 83.16424458459008\n",
      "Epoch 2329 val loss: 0.5800055493355581\n",
      "Epoch 2329 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2329.pth\n",
      "Epoch 2330 train loss: 0.5857954509883073\n",
      "Epoch 2330 train accuracy: 83.13682478749658\n",
      "Epoch 2330 val loss: 0.5800234005896767\n",
      "Epoch 2330 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2330.pth\n",
      "Epoch 2331 train loss: 0.5857289209471721\n",
      "Epoch 2331 train accuracy: 83.13682478749658\n",
      "Epoch 2331 val loss: 0.5800113214768077\n",
      "Epoch 2331 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2331.pth\n",
      "Epoch 2332 train loss: 0.5857879922749769\n",
      "Epoch 2332 train accuracy: 83.13682478749658\n",
      "Epoch 2332 val loss: 0.5799845537464869\n",
      "Epoch 2332 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2332.pth\n",
      "Epoch 2333 train loss: 0.5857291853365799\n",
      "Epoch 2333 train accuracy: 83.21908417877708\n",
      "Epoch 2333 val loss: 0.5799750294291267\n",
      "Epoch 2333 val accuracy: 83.96381578947368\n",
      "Saved model to .\\test_models/MLP_2333.pth\n",
      "Epoch 2334 train loss: 0.585706209900915\n",
      "Epoch 2334 train accuracy: 83.16424458459008\n",
      "Epoch 2334 val loss: 0.5799931802443767\n",
      "Epoch 2334 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2334.pth\n",
      "Epoch 2335 train loss: 0.585687704204598\n",
      "Epoch 2335 train accuracy: 83.13682478749658\n",
      "Epoch 2335 val loss: 0.5799769288125006\n",
      "Epoch 2335 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2335.pth\n",
      "Epoch 2336 train loss: 0.5857716625106517\n",
      "Epoch 2336 train accuracy: 83.21908417877708\n",
      "Epoch 2336 val loss: 0.579974616093463\n",
      "Epoch 2336 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2336.pth\n",
      "Epoch 2337 train loss: 0.585766100994589\n",
      "Epoch 2337 train accuracy: 83.16424458459008\n",
      "Epoch 2337 val loss: 0.5799632064115844\n",
      "Epoch 2337 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2337.pth\n",
      "Epoch 2338 train loss: 0.5856920234397414\n",
      "Epoch 2338 train accuracy: 83.21908417877708\n",
      "Epoch 2338 val loss: 0.5799765496661788\n",
      "Epoch 2338 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2338.pth\n",
      "Epoch 2339 train loss: 0.5856450419253139\n",
      "Epoch 2339 train accuracy: 83.13682478749658\n",
      "Epoch 2339 val loss: 0.5799406582587644\n",
      "Epoch 2339 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2339.pth\n",
      "Epoch 2340 train loss: 0.5857596362597848\n",
      "Epoch 2340 train accuracy: 83.24650397587058\n",
      "Epoch 2340 val loss: 0.5799525402682392\n",
      "Epoch 2340 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2340.pth\n",
      "Epoch 2341 train loss: 0.5856732164035764\n",
      "Epoch 2341 train accuracy: 83.19166438168358\n",
      "Epoch 2341 val loss: 0.5799536862851757\n",
      "Epoch 2341 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2341.pth\n",
      "Epoch 2342 train loss: 0.5857361565883222\n",
      "Epoch 2342 train accuracy: 83.19166438168358\n",
      "Epoch 2342 val loss: 0.5799294373902836\n",
      "Epoch 2342 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2342.pth\n",
      "Epoch 2343 train loss: 0.585733225487434\n",
      "Epoch 2343 train accuracy: 83.16424458459008\n",
      "Epoch 2343 val loss: 0.5799324048290911\n",
      "Epoch 2343 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2343.pth\n",
      "Epoch 2344 train loss: 0.5856771466175192\n",
      "Epoch 2344 train accuracy: 83.24650397587058\n",
      "Epoch 2344 val loss: 0.5799093001865243\n",
      "Epoch 2344 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2344.pth\n",
      "Epoch 2345 train loss: 0.5856250838188684\n",
      "Epoch 2345 train accuracy: 83.27392377296408\n",
      "Epoch 2345 val loss: 0.5799072878435254\n",
      "Epoch 2345 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2345.pth\n",
      "Epoch 2346 train loss: 0.5857156925393563\n",
      "Epoch 2346 train accuracy: 83.19166438168358\n",
      "Epoch 2346 val loss: 0.5798990037292242\n",
      "Epoch 2346 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2346.pth\n",
      "Epoch 2347 train loss: 0.5855850228108466\n",
      "Epoch 2347 train accuracy: 83.24650397587058\n",
      "Epoch 2347 val loss: 0.5798962478048021\n",
      "Epoch 2347 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2347.pth\n",
      "Epoch 2348 train loss: 0.5856862553997065\n",
      "Epoch 2348 train accuracy: 83.19166438168358\n",
      "Epoch 2348 val loss: 0.5798939311337706\n",
      "Epoch 2348 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2348.pth\n",
      "Epoch 2349 train loss: 0.5856977071165793\n",
      "Epoch 2349 train accuracy: 83.21908417877708\n",
      "Epoch 2349 val loss: 0.5798830798287925\n",
      "Epoch 2349 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2349.pth\n",
      "Epoch 2350 train loss: 0.5855596823160324\n",
      "Epoch 2350 train accuracy: 83.10940499040306\n",
      "Epoch 2350 val loss: 0.5798799018620661\n",
      "Epoch 2350 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2350.pth\n",
      "Epoch 2351 train loss: 0.5856851522336927\n",
      "Epoch 2351 train accuracy: 83.21908417877708\n",
      "Epoch 2351 val loss: 0.5798800274435627\n",
      "Epoch 2351 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2351.pth\n",
      "Epoch 2352 train loss: 0.585621236601391\n",
      "Epoch 2352 train accuracy: 83.13682478749658\n",
      "Epoch 2352 val loss: 0.5798696812830473\n",
      "Epoch 2352 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2352.pth\n",
      "Epoch 2353 train loss: 0.5856404375742402\n",
      "Epoch 2353 train accuracy: 83.19166438168358\n",
      "Epoch 2353 val loss: 0.5798815162852407\n",
      "Epoch 2353 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2353.pth\n",
      "Epoch 2354 train loss: 0.5855900040876708\n",
      "Epoch 2354 train accuracy: 83.19166438168358\n",
      "Epoch 2354 val loss: 0.5798667559498235\n",
      "Epoch 2354 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2354.pth\n",
      "Epoch 2355 train loss: 0.5856023194399058\n",
      "Epoch 2355 train accuracy: 83.16424458459008\n",
      "Epoch 2355 val loss: 0.5798477341518983\n",
      "Epoch 2355 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2355.pth\n",
      "Epoch 2356 train loss: 0.5856598015637708\n",
      "Epoch 2356 train accuracy: 83.19166438168358\n",
      "Epoch 2356 val loss: 0.5798576084749871\n",
      "Epoch 2356 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2356.pth\n",
      "Epoch 2357 train loss: 0.5856513320713451\n",
      "Epoch 2357 train accuracy: 83.21908417877708\n",
      "Epoch 2357 val loss: 0.5798327390006498\n",
      "Epoch 2357 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2357.pth\n",
      "Epoch 2358 train loss: 0.585631656411447\n",
      "Epoch 2358 train accuracy: 83.19166438168358\n",
      "Epoch 2358 val loss: 0.5798383270341315\n",
      "Epoch 2358 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2358.pth\n",
      "Epoch 2359 train loss: 0.585633366450406\n",
      "Epoch 2359 train accuracy: 83.19166438168358\n",
      "Epoch 2359 val loss: 0.5798360724492293\n",
      "Epoch 2359 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2359.pth\n",
      "Epoch 2360 train loss: 0.5855957759884308\n",
      "Epoch 2360 train accuracy: 83.19166438168358\n",
      "Epoch 2360 val loss: 0.5798483786026114\n",
      "Epoch 2360 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2360.pth\n",
      "Epoch 2361 train loss: 0.5856273480641999\n",
      "Epoch 2361 train accuracy: 83.24650397587058\n",
      "Epoch 2361 val loss: 0.579822225349122\n",
      "Epoch 2361 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2361.pth\n",
      "Epoch 2362 train loss: 0.5855537410417017\n",
      "Epoch 2362 train accuracy: 83.24650397587058\n",
      "Epoch 2362 val loss: 0.5798127231629271\n",
      "Epoch 2362 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2362.pth\n",
      "Epoch 2363 train loss: 0.585578065136807\n",
      "Epoch 2363 train accuracy: 83.16424458459008\n",
      "Epoch 2363 val loss: 0.5797898043437224\n",
      "Epoch 2363 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2363.pth\n",
      "Epoch 2364 train loss: 0.5856124712807829\n",
      "Epoch 2364 train accuracy: 83.19166438168358\n",
      "Epoch 2364 val loss: 0.5798081431145731\n",
      "Epoch 2364 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2364.pth\n",
      "Epoch 2365 train loss: 0.5856303296934225\n",
      "Epoch 2365 train accuracy: 83.24650397587058\n",
      "Epoch 2365 val loss: 0.5797814039611503\n",
      "Epoch 2365 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2365.pth\n",
      "Epoch 2366 train loss: 0.5855543969950655\n",
      "Epoch 2366 train accuracy: 83.13682478749658\n",
      "Epoch 2366 val loss: 0.5798350276033345\n",
      "Epoch 2366 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2366.pth\n",
      "Epoch 2367 train loss: 0.5856077469427857\n",
      "Epoch 2367 train accuracy: 83.19166438168358\n",
      "Epoch 2367 val loss: 0.5797935907918911\n",
      "Epoch 2367 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2367.pth\n",
      "Epoch 2368 train loss: 0.5855843502938289\n",
      "Epoch 2368 train accuracy: 83.21908417877708\n",
      "Epoch 2368 val loss: 0.5797901014846406\n",
      "Epoch 2368 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2368.pth\n",
      "Epoch 2369 train loss: 0.5855746291120324\n",
      "Epoch 2369 train accuracy: 83.19166438168358\n",
      "Epoch 2369 val loss: 0.5797613814081016\n",
      "Epoch 2369 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2369.pth\n",
      "Epoch 2370 train loss: 0.5854918438728833\n",
      "Epoch 2370 train accuracy: 83.21908417877708\n",
      "Epoch 2370 val loss: 0.5797582073627334\n",
      "Epoch 2370 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2370.pth\n",
      "Epoch 2371 train loss: 0.5855608758957762\n",
      "Epoch 2371 train accuracy: 83.21908417877708\n",
      "Epoch 2371 val loss: 0.5797481149140942\n",
      "Epoch 2371 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2371.pth\n",
      "Epoch 2372 train loss: 0.5855442941321056\n",
      "Epoch 2372 train accuracy: 83.24650397587058\n",
      "Epoch 2372 val loss: 0.5797450905175585\n",
      "Epoch 2372 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2372.pth\n",
      "Epoch 2373 train loss: 0.5855622563935947\n",
      "Epoch 2373 train accuracy: 83.13682478749658\n",
      "Epoch 2373 val loss: 0.5797351398750356\n",
      "Epoch 2373 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2373.pth\n",
      "Epoch 2374 train loss: 0.5855539685376642\n",
      "Epoch 2374 train accuracy: 83.10940499040306\n",
      "Epoch 2374 val loss: 0.5797279027388677\n",
      "Epoch 2374 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2374.pth\n",
      "Epoch 2375 train loss: 0.5854829289509278\n",
      "Epoch 2375 train accuracy: 83.21908417877708\n",
      "Epoch 2375 val loss: 0.5797147436165496\n",
      "Epoch 2375 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2375.pth\n",
      "Epoch 2376 train loss: 0.5855562746108166\n",
      "Epoch 2376 train accuracy: 83.16424458459008\n",
      "Epoch 2376 val loss: 0.5797071918158939\n",
      "Epoch 2376 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2376.pth\n",
      "Epoch 2377 train loss: 0.5854731386919555\n",
      "Epoch 2377 train accuracy: 83.13682478749658\n",
      "Epoch 2377 val loss: 0.5797055421495124\n",
      "Epoch 2377 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2377.pth\n",
      "Epoch 2378 train loss: 0.5855028896608896\n",
      "Epoch 2378 train accuracy: 83.19166438168358\n",
      "Epoch 2378 val loss: 0.5796964822925235\n",
      "Epoch 2378 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2378.pth\n",
      "Epoch 2379 train loss: 0.5854162993971586\n",
      "Epoch 2379 train accuracy: 83.21908417877708\n",
      "Epoch 2379 val loss: 0.5797322243972878\n",
      "Epoch 2379 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2379.pth\n",
      "Epoch 2380 train loss: 0.585569132511553\n",
      "Epoch 2380 train accuracy: 83.13682478749658\n",
      "Epoch 2380 val loss: 0.5796941579196995\n",
      "Epoch 2380 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2380.pth\n",
      "Epoch 2381 train loss: 0.5855172167148179\n",
      "Epoch 2381 train accuracy: 83.21908417877708\n",
      "Epoch 2381 val loss: 0.5796839203685522\n",
      "Epoch 2381 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2381.pth\n",
      "Epoch 2382 train loss: 0.5854396833793113\n",
      "Epoch 2382 train accuracy: 83.21908417877708\n",
      "Epoch 2382 val loss: 0.5796728747847834\n",
      "Epoch 2382 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2382.pth\n",
      "Epoch 2383 train loss: 0.5855208533619972\n",
      "Epoch 2383 train accuracy: 83.30134357005758\n",
      "Epoch 2383 val loss: 0.5796900779915679\n",
      "Epoch 2383 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2383.pth\n",
      "Epoch 2384 train loss: 0.585441172743837\n",
      "Epoch 2384 train accuracy: 83.24650397587058\n",
      "Epoch 2384 val loss: 0.5796761904892168\n",
      "Epoch 2384 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2384.pth\n",
      "Epoch 2385 train loss: 0.5854260960201684\n",
      "Epoch 2385 train accuracy: 83.27392377296408\n",
      "Epoch 2385 val loss: 0.5796660367203387\n",
      "Epoch 2385 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2385.pth\n",
      "Epoch 2386 train loss: 0.5854131876235202\n",
      "Epoch 2386 train accuracy: 83.19166438168358\n",
      "Epoch 2386 val loss: 0.5796496117193448\n",
      "Epoch 2386 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2386.pth\n",
      "Epoch 2387 train loss: 0.5854295968453873\n",
      "Epoch 2387 train accuracy: 83.10940499040306\n",
      "Epoch 2387 val loss: 0.5796623502024695\n",
      "Epoch 2387 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2387.pth\n",
      "Epoch 2388 train loss: 0.5854128395583023\n",
      "Epoch 2388 train accuracy: 83.21908417877708\n",
      "Epoch 2388 val loss: 0.5796469079918767\n",
      "Epoch 2388 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2388.pth\n",
      "Epoch 2389 train loss: 0.585453364238339\n",
      "Epoch 2389 train accuracy: 83.13682478749658\n",
      "Epoch 2389 val loss: 0.5796590845443701\n",
      "Epoch 2389 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2389.pth\n",
      "Epoch 2390 train loss: 0.5854054396939382\n",
      "Epoch 2390 train accuracy: 83.19166438168358\n",
      "Epoch 2390 val loss: 0.5796487234826935\n",
      "Epoch 2390 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2390.pth\n",
      "Epoch 2391 train loss: 0.5854266424287569\n",
      "Epoch 2391 train accuracy: 83.16424458459008\n",
      "Epoch 2391 val loss: 0.5796319443340364\n",
      "Epoch 2391 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2391.pth\n",
      "Epoch 2392 train loss: 0.5853820772874251\n",
      "Epoch 2392 train accuracy: 83.21908417877708\n",
      "Epoch 2392 val loss: 0.5796370988858766\n",
      "Epoch 2392 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2392.pth\n",
      "Epoch 2393 train loss: 0.5854329840492523\n",
      "Epoch 2393 train accuracy: 83.16424458459008\n",
      "Epoch 2393 val loss: 0.5796064073219895\n",
      "Epoch 2393 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2393.pth\n",
      "Epoch 2394 train loss: 0.585349790849968\n",
      "Epoch 2394 train accuracy: 83.13682478749658\n",
      "Epoch 2394 val loss: 0.5796300613958585\n",
      "Epoch 2394 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2394.pth\n",
      "Epoch 2395 train loss: 0.585366368620542\n",
      "Epoch 2395 train accuracy: 83.19166438168358\n",
      "Epoch 2395 val loss: 0.5796086527407169\n",
      "Epoch 2395 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2395.pth\n",
      "Epoch 2396 train loss: 0.585410802036916\n",
      "Epoch 2396 train accuracy: 83.27392377296408\n",
      "Epoch 2396 val loss: 0.5795988409632915\n",
      "Epoch 2396 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2396.pth\n",
      "Epoch 2397 train loss: 0.5854246882525714\n",
      "Epoch 2397 train accuracy: 83.27392377296408\n",
      "Epoch 2397 val loss: 0.579593182492413\n",
      "Epoch 2397 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2397.pth\n",
      "Epoch 2398 train loss: 0.5854133782303778\n",
      "Epoch 2398 train accuracy: 83.21908417877708\n",
      "Epoch 2398 val loss: 0.5795917351681151\n",
      "Epoch 2398 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2398.pth\n",
      "Epoch 2399 train loss: 0.5853429261611349\n",
      "Epoch 2399 train accuracy: 83.24650397587058\n",
      "Epoch 2399 val loss: 0.5795789334530893\n",
      "Epoch 2399 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2399.pth\n",
      "Epoch 2400 train loss: 0.5853788794749498\n",
      "Epoch 2400 train accuracy: 83.19166438168358\n",
      "Epoch 2400 val loss: 0.5795694564126039\n",
      "Epoch 2400 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2400.pth\n",
      "Epoch 2401 train loss: 0.5853483558942875\n",
      "Epoch 2401 train accuracy: 83.21908417877708\n",
      "Epoch 2401 val loss: 0.5795779842393178\n",
      "Epoch 2401 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2401.pth\n",
      "Epoch 2402 train loss: 0.5853780675061627\n",
      "Epoch 2402 train accuracy: 83.21908417877708\n",
      "Epoch 2402 val loss: 0.5795544184450256\n",
      "Epoch 2402 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2402.pth\n",
      "Epoch 2403 train loss: 0.5853311890315493\n",
      "Epoch 2403 train accuracy: 83.10940499040306\n",
      "Epoch 2403 val loss: 0.5795475946445214\n",
      "Epoch 2403 val accuracy: 83.88157894736842\n",
      "Saved model to .\\test_models/MLP_2403.pth\n",
      "Epoch 2404 train loss: 0.5853837056640994\n",
      "Epoch 2404 train accuracy: 83.19166438168358\n",
      "Epoch 2404 val loss: 0.5795432930616172\n",
      "Epoch 2404 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2404.pth\n",
      "Epoch 2405 train loss: 0.5853063569551236\n",
      "Epoch 2405 train accuracy: 83.16424458459008\n",
      "Epoch 2405 val loss: 0.5795420980522115\n",
      "Epoch 2405 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2405.pth\n",
      "Epoch 2406 train loss: 0.5853696125151034\n",
      "Epoch 2406 train accuracy: 83.27392377296408\n",
      "Epoch 2406 val loss: 0.5795265738852322\n",
      "Epoch 2406 val accuracy: 83.88157894736842\n",
      "Saved model to .\\test_models/MLP_2406.pth\n",
      "Epoch 2407 train loss: 0.5853127936481318\n",
      "Epoch 2407 train accuracy: 83.19166438168358\n",
      "Epoch 2407 val loss: 0.5795452260951462\n",
      "Epoch 2407 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2407.pth\n",
      "Epoch 2408 train loss: 0.5852981574931427\n",
      "Epoch 2408 train accuracy: 83.35618316424458\n",
      "Epoch 2408 val loss: 0.5795306768268347\n",
      "Epoch 2408 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2408.pth\n",
      "Epoch 2409 train loss: 0.5853362125507965\n",
      "Epoch 2409 train accuracy: 83.19166438168358\n",
      "Epoch 2409 val loss: 0.5795423249518009\n",
      "Epoch 2409 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2409.pth\n",
      "Epoch 2410 train loss: 0.5852727190378988\n",
      "Epoch 2410 train accuracy: 83.19166438168358\n",
      "Epoch 2410 val loss: 0.5795161522140628\n",
      "Epoch 2410 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2410.pth\n",
      "Epoch 2411 train loss: 0.5852872883541542\n",
      "Epoch 2411 train accuracy: 83.24650397587058\n",
      "Epoch 2411 val loss: 0.5795160028103151\n",
      "Epoch 2411 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2411.pth\n",
      "Epoch 2412 train loss: 0.5853050139348692\n",
      "Epoch 2412 train accuracy: 83.19166438168358\n",
      "Epoch 2412 val loss: 0.5795098363764977\n",
      "Epoch 2412 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2412.pth\n",
      "Epoch 2413 train loss: 0.5852880515117329\n",
      "Epoch 2413 train accuracy: 83.16424458459008\n",
      "Epoch 2413 val loss: 0.5795063911201922\n",
      "Epoch 2413 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2413.pth\n",
      "Epoch 2414 train loss: 0.5853242393370652\n",
      "Epoch 2414 train accuracy: 83.19166438168358\n",
      "Epoch 2414 val loss: 0.5794970950748968\n",
      "Epoch 2414 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2414.pth\n",
      "Epoch 2415 train loss: 0.5852548433222661\n",
      "Epoch 2415 train accuracy: 83.30134357005758\n",
      "Epoch 2415 val loss: 0.5794892235610046\n",
      "Epoch 2415 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2415.pth\n",
      "Epoch 2416 train loss: 0.5853092533519917\n",
      "Epoch 2416 train accuracy: 83.24650397587058\n",
      "Epoch 2416 val loss: 0.5794757182562822\n",
      "Epoch 2416 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2416.pth\n",
      "Epoch 2417 train loss: 0.5853018398843951\n",
      "Epoch 2417 train accuracy: 83.21908417877708\n",
      "Epoch 2417 val loss: 0.5794630060462576\n",
      "Epoch 2417 val accuracy: 83.88157894736842\n",
      "Saved model to .\\test_models/MLP_2417.pth\n",
      "Epoch 2418 train loss: 0.5852486678611553\n",
      "Epoch 2418 train accuracy: 83.19166438168358\n",
      "Epoch 2418 val loss: 0.5794830677975704\n",
      "Epoch 2418 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2418.pth\n",
      "Epoch 2419 train loss: 0.5852318560671911\n",
      "Epoch 2419 train accuracy: 83.19166438168358\n",
      "Epoch 2419 val loss: 0.5794634131138752\n",
      "Epoch 2419 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2419.pth\n",
      "Epoch 2420 train loss: 0.5852936340430588\n",
      "Epoch 2420 train accuracy: 83.19166438168358\n",
      "Epoch 2420 val loss: 0.5794753151896753\n",
      "Epoch 2420 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2420.pth\n",
      "Epoch 2421 train loss: 0.5852217184514493\n",
      "Epoch 2421 train accuracy: 83.21908417877708\n",
      "Epoch 2421 val loss: 0.5794467265521618\n",
      "Epoch 2421 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2421.pth\n",
      "Epoch 2422 train loss: 0.5852935995402125\n",
      "Epoch 2422 train accuracy: 83.19166438168358\n",
      "Epoch 2422 val loss: 0.5794448722153902\n",
      "Epoch 2422 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2422.pth\n",
      "Epoch 2423 train loss: 0.5852670538516944\n",
      "Epoch 2423 train accuracy: 83.21908417877708\n",
      "Epoch 2423 val loss: 0.5794476294203809\n",
      "Epoch 2423 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2423.pth\n",
      "Epoch 2424 train loss: 0.585188666587336\n",
      "Epoch 2424 train accuracy: 83.08198519330956\n",
      "Epoch 2424 val loss: 0.5794356753559489\n",
      "Epoch 2424 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2424.pth\n",
      "Epoch 2425 train loss: 0.5852725596346876\n",
      "Epoch 2425 train accuracy: 83.16424458459008\n",
      "Epoch 2425 val loss: 0.5794259099976012\n",
      "Epoch 2425 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2425.pth\n",
      "Epoch 2426 train loss: 0.5852475304712068\n",
      "Epoch 2426 train accuracy: 83.21908417877708\n",
      "Epoch 2426 val loss: 0.5794331838229769\n",
      "Epoch 2426 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2426.pth\n",
      "Epoch 2427 train loss: 0.5852439792647043\n",
      "Epoch 2427 train accuracy: 83.24650397587058\n",
      "Epoch 2427 val loss: 0.579443251591568\n",
      "Epoch 2427 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2427.pth\n",
      "Epoch 2428 train loss: 0.5851806161206281\n",
      "Epoch 2428 train accuracy: 83.16424458459008\n",
      "Epoch 2428 val loss: 0.5794162345363906\n",
      "Epoch 2428 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2428.pth\n",
      "Epoch 2429 train loss: 0.5852388732396719\n",
      "Epoch 2429 train accuracy: 83.24650397587058\n",
      "Epoch 2429 val loss: 0.5794129121411395\n",
      "Epoch 2429 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2429.pth\n",
      "Epoch 2430 train loss: 0.5852481676102207\n",
      "Epoch 2430 train accuracy: 83.21908417877708\n",
      "Epoch 2430 val loss: 0.5794060498377994\n",
      "Epoch 2430 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2430.pth\n",
      "Epoch 2431 train loss: 0.5852333181210908\n",
      "Epoch 2431 train accuracy: 83.21908417877708\n",
      "Epoch 2431 val loss: 0.579391497922571\n",
      "Epoch 2431 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2431.pth\n",
      "Epoch 2432 train loss: 0.585159740737525\n",
      "Epoch 2432 train accuracy: 83.24650397587058\n",
      "Epoch 2432 val loss: 0.5793827815030358\n",
      "Epoch 2432 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2432.pth\n",
      "Epoch 2433 train loss: 0.5852121227061409\n",
      "Epoch 2433 train accuracy: 83.19166438168358\n",
      "Epoch 2433 val loss: 0.57939077575544\n",
      "Epoch 2433 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2433.pth\n",
      "Epoch 2434 train loss: 0.5852234341253183\n",
      "Epoch 2434 train accuracy: 83.19166438168358\n",
      "Epoch 2434 val loss: 0.5793986641556809\n",
      "Epoch 2434 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2434.pth\n",
      "Epoch 2435 train loss: 0.5851301335466192\n",
      "Epoch 2435 train accuracy: 83.19166438168358\n",
      "Epoch 2435 val loss: 0.5793714132159948\n",
      "Epoch 2435 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2435.pth\n",
      "Epoch 2436 train loss: 0.5852077241513159\n",
      "Epoch 2436 train accuracy: 83.21908417877708\n",
      "Epoch 2436 val loss: 0.5793651900695342\n",
      "Epoch 2436 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2436.pth\n",
      "Epoch 2437 train loss: 0.585067281029759\n",
      "Epoch 2437 train accuracy: 83.21908417877708\n",
      "Epoch 2437 val loss: 0.5793608980694491\n",
      "Epoch 2437 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2437.pth\n",
      "Epoch 2438 train loss: 0.5851966623756054\n",
      "Epoch 2438 train accuracy: 83.21908417877708\n",
      "Epoch 2438 val loss: 0.5793584385690721\n",
      "Epoch 2438 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2438.pth\n",
      "Epoch 2439 train loss: 0.5851850276322741\n",
      "Epoch 2439 train accuracy: 83.21908417877708\n",
      "Epoch 2439 val loss: 0.579345092275425\n",
      "Epoch 2439 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2439.pth\n",
      "Epoch 2440 train loss: 0.5851709496948803\n",
      "Epoch 2440 train accuracy: 83.19166438168358\n",
      "Epoch 2440 val loss: 0.5793498584412431\n",
      "Epoch 2440 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2440.pth\n",
      "Epoch 2441 train loss: 0.5851660932254928\n",
      "Epoch 2441 train accuracy: 83.13682478749658\n",
      "Epoch 2441 val loss: 0.5793345776435576\n",
      "Epoch 2441 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2441.pth\n",
      "Epoch 2442 train loss: 0.5851465484633911\n",
      "Epoch 2442 train accuracy: 83.27392377296408\n",
      "Epoch 2442 val loss: 0.5793295766373998\n",
      "Epoch 2442 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2442.pth\n",
      "Epoch 2443 train loss: 0.5851620896596854\n",
      "Epoch 2443 train accuracy: 83.16424458459008\n",
      "Epoch 2443 val loss: 0.5793245761214119\n",
      "Epoch 2443 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2443.pth\n",
      "Epoch 2444 train loss: 0.5851231597572271\n",
      "Epoch 2444 train accuracy: 83.21908417877708\n",
      "Epoch 2444 val loss: 0.5793194387010053\n",
      "Epoch 2444 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2444.pth\n",
      "Epoch 2445 train loss: 0.5851112319352595\n",
      "Epoch 2445 train accuracy: 83.16424458459008\n",
      "Epoch 2445 val loss: 0.579308632712223\n",
      "Epoch 2445 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2445.pth\n",
      "Epoch 2446 train loss: 0.58512591501992\n",
      "Epoch 2446 train accuracy: 83.21908417877708\n",
      "Epoch 2446 val loss: 0.5793093852698803\n",
      "Epoch 2446 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2446.pth\n",
      "Epoch 2447 train loss: 0.5851366521480182\n",
      "Epoch 2447 train accuracy: 83.21908417877708\n",
      "Epoch 2447 val loss: 0.5793043624021506\n",
      "Epoch 2447 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2447.pth\n",
      "Epoch 2448 train loss: 0.5850544223855985\n",
      "Epoch 2448 train accuracy: 83.24650397587058\n",
      "Epoch 2448 val loss: 0.5792914565750643\n",
      "Epoch 2448 val accuracy: 83.88157894736842\n",
      "Saved model to .\\test_models/MLP_2448.pth\n",
      "Epoch 2449 train loss: 0.5850922662290957\n",
      "Epoch 2449 train accuracy: 83.21908417877708\n",
      "Epoch 2449 val loss: 0.5792910902221736\n",
      "Epoch 2449 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2449.pth\n",
      "Epoch 2450 train loss: 0.5850666777410528\n",
      "Epoch 2450 train accuracy: 83.16424458459008\n",
      "Epoch 2450 val loss: 0.5792863058710569\n",
      "Epoch 2450 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2450.pth\n",
      "Epoch 2451 train loss: 0.5851099267928747\n",
      "Epoch 2451 train accuracy: 83.21908417877708\n",
      "Epoch 2451 val loss: 0.579279901606864\n",
      "Epoch 2451 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2451.pth\n",
      "Epoch 2452 train loss: 0.585119614165211\n",
      "Epoch 2452 train accuracy: 83.21908417877708\n",
      "Epoch 2452 val loss: 0.5792766122245475\n",
      "Epoch 2452 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2452.pth\n",
      "Epoch 2453 train loss: 0.5851061207389361\n",
      "Epoch 2453 train accuracy: 83.21908417877708\n",
      "Epoch 2453 val loss: 0.5792774869815299\n",
      "Epoch 2453 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2453.pth\n",
      "Epoch 2454 train loss: 0.5851022286193543\n",
      "Epoch 2454 train accuracy: 83.21908417877708\n",
      "Epoch 2454 val loss: 0.5792666394876218\n",
      "Epoch 2454 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2454.pth\n",
      "Epoch 2455 train loss: 0.5850243827066662\n",
      "Epoch 2455 train accuracy: 83.24650397587058\n",
      "Epoch 2455 val loss: 0.5792555730593832\n",
      "Epoch 2455 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2455.pth\n",
      "Epoch 2456 train loss: 0.5850849993069444\n",
      "Epoch 2456 train accuracy: 83.19166438168358\n",
      "Epoch 2456 val loss: 0.5792543228078437\n",
      "Epoch 2456 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2456.pth\n",
      "Epoch 2457 train loss: 0.5850819032802655\n",
      "Epoch 2457 train accuracy: 83.24650397587058\n",
      "Epoch 2457 val loss: 0.5792481823285159\n",
      "Epoch 2457 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2457.pth\n",
      "Epoch 2458 train loss: 0.5850843193842784\n",
      "Epoch 2458 train accuracy: 83.24650397587058\n",
      "Epoch 2458 val loss: 0.5792419100180268\n",
      "Epoch 2458 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2458.pth\n",
      "Epoch 2459 train loss: 0.5850771173442665\n",
      "Epoch 2459 train accuracy: 83.21908417877708\n",
      "Epoch 2459 val loss: 0.5792413827914157\n",
      "Epoch 2459 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2459.pth\n",
      "Epoch 2460 train loss: 0.5849436570302045\n",
      "Epoch 2460 train accuracy: 83.19166438168358\n",
      "Epoch 2460 val loss: 0.5792309740974911\n",
      "Epoch 2460 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2460.pth\n",
      "Epoch 2461 train loss: 0.5850668449951499\n",
      "Epoch 2461 train accuracy: 83.19166438168358\n",
      "Epoch 2461 val loss: 0.5792249492614677\n",
      "Epoch 2461 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2461.pth\n",
      "Epoch 2462 train loss: 0.5849608747174212\n",
      "Epoch 2462 train accuracy: 83.19166438168358\n",
      "Epoch 2462 val loss: 0.5792199527158549\n",
      "Epoch 2462 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2462.pth\n",
      "Epoch 2463 train loss: 0.5849817717088419\n",
      "Epoch 2463 train accuracy: 83.27392377296408\n",
      "Epoch 2463 val loss: 0.5792124167967\n",
      "Epoch 2463 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2463.pth\n",
      "Epoch 2464 train loss: 0.5849731325318939\n",
      "Epoch 2464 train accuracy: 83.02714559912256\n",
      "Epoch 2464 val loss: 0.5792291805662803\n",
      "Epoch 2464 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2464.pth\n",
      "Epoch 2465 train loss: 0.5849180950766855\n",
      "Epoch 2465 train accuracy: 83.19166438168358\n",
      "Epoch 2465 val loss: 0.5792078009659523\n",
      "Epoch 2465 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2465.pth\n",
      "Epoch 2466 train loss: 0.5850455529187202\n",
      "Epoch 2466 train accuracy: 83.21908417877708\n",
      "Epoch 2466 val loss: 0.5792060628729431\n",
      "Epoch 2466 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2466.pth\n",
      "Epoch 2467 train loss: 0.585024019539879\n",
      "Epoch 2467 train accuracy: 83.21908417877708\n",
      "Epoch 2467 val loss: 0.5792002257841983\n",
      "Epoch 2467 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2467.pth\n",
      "Epoch 2468 train loss: 0.5850211646195436\n",
      "Epoch 2468 train accuracy: 83.19166438168358\n",
      "Epoch 2468 val loss: 0.5791908280531827\n",
      "Epoch 2468 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2468.pth\n",
      "Epoch 2469 train loss: 0.5849942599848044\n",
      "Epoch 2469 train accuracy: 83.13682478749658\n",
      "Epoch 2469 val loss: 0.5791980338675019\n",
      "Epoch 2469 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2469.pth\n",
      "Epoch 2470 train loss: 0.5850037773744318\n",
      "Epoch 2470 train accuracy: 83.16424458459008\n",
      "Epoch 2470 val loss: 0.5791822969913483\n",
      "Epoch 2470 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2470.pth\n",
      "Epoch 2471 train loss: 0.584970481890004\n",
      "Epoch 2471 train accuracy: 83.27392377296408\n",
      "Epoch 2471 val loss: 0.5791735455001655\n",
      "Epoch 2471 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2471.pth\n",
      "Epoch 2472 train loss: 0.5849357183385444\n",
      "Epoch 2472 train accuracy: 83.19166438168358\n",
      "Epoch 2472 val loss: 0.5791679307524311\n",
      "Epoch 2472 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2472.pth\n",
      "Epoch 2473 train loss: 0.58497394997552\n",
      "Epoch 2473 train accuracy: 83.21908417877708\n",
      "Epoch 2473 val loss: 0.5791656728833914\n",
      "Epoch 2473 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2473.pth\n",
      "Epoch 2474 train loss: 0.5849992970756271\n",
      "Epoch 2474 train accuracy: 83.19166438168358\n",
      "Epoch 2474 val loss: 0.5791571766236111\n",
      "Epoch 2474 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2474.pth\n",
      "Epoch 2475 train loss: 0.5848798502661419\n",
      "Epoch 2475 train accuracy: 83.24650397587058\n",
      "Epoch 2475 val loss: 0.5791735331969041\n",
      "Epoch 2475 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2475.pth\n",
      "Epoch 2476 train loss: 0.5848505040875783\n",
      "Epoch 2476 train accuracy: 83.13682478749658\n",
      "Epoch 2476 val loss: 0.579143668328853\n",
      "Epoch 2476 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2476.pth\n",
      "Epoch 2477 train loss: 0.5848765447245616\n",
      "Epoch 2477 train accuracy: 83.21908417877708\n",
      "Epoch 2477 val loss: 0.5791386124481889\n",
      "Epoch 2477 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2477.pth\n",
      "Epoch 2478 train loss: 0.5849644773018857\n",
      "Epoch 2478 train accuracy: 83.21908417877708\n",
      "Epoch 2478 val loss: 0.5791476243910821\n",
      "Epoch 2478 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2478.pth\n",
      "Epoch 2479 train loss: 0.5849043495397557\n",
      "Epoch 2479 train accuracy: 83.13682478749658\n",
      "Epoch 2479 val loss: 0.579121253551229\n",
      "Epoch 2479 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2479.pth\n",
      "Epoch 2480 train loss: 0.5849594034626263\n",
      "Epoch 2480 train accuracy: 83.24650397587058\n",
      "Epoch 2480 val loss: 0.5791241900113068\n",
      "Epoch 2480 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2480.pth\n",
      "Epoch 2481 train loss: 0.5849025936454142\n",
      "Epoch 2481 train accuracy: 83.24650397587058\n",
      "Epoch 2481 val loss: 0.5791124236328822\n",
      "Epoch 2481 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2481.pth\n",
      "Epoch 2482 train loss: 0.584906941002006\n",
      "Epoch 2482 train accuracy: 83.19166438168358\n",
      "Epoch 2482 val loss: 0.5791078246149578\n",
      "Epoch 2482 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2482.pth\n",
      "Epoch 2483 train loss: 0.584940094778543\n",
      "Epoch 2483 train accuracy: 83.19166438168358\n",
      "Epoch 2483 val loss: 0.5790984941995703\n",
      "Epoch 2483 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2483.pth\n",
      "Epoch 2484 train loss: 0.584873106820803\n",
      "Epoch 2484 train accuracy: 83.27392377296408\n",
      "Epoch 2484 val loss: 0.5790922163838619\n",
      "Epoch 2484 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2484.pth\n",
      "Epoch 2485 train loss: 0.5849368666582577\n",
      "Epoch 2485 train accuracy: 83.16424458459008\n",
      "Epoch 2485 val loss: 0.5791005994634408\n",
      "Epoch 2485 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2485.pth\n",
      "Epoch 2486 train loss: 0.5848686589222205\n",
      "Epoch 2486 train accuracy: 83.21908417877708\n",
      "Epoch 2486 val loss: 0.5790928207631958\n",
      "Epoch 2486 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2486.pth\n",
      "Epoch 2487 train loss: 0.5848532396352344\n",
      "Epoch 2487 train accuracy: 83.19166438168358\n",
      "Epoch 2487 val loss: 0.5790767912801943\n",
      "Epoch 2487 val accuracy: 83.71710526315789\n",
      "Saved model to .\\test_models/MLP_2487.pth\n",
      "Epoch 2488 train loss: 0.5849128709452456\n",
      "Epoch 2488 train accuracy: 83.21908417877708\n",
      "Epoch 2488 val loss: 0.5790736208620825\n",
      "Epoch 2488 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2488.pth\n",
      "Epoch 2489 train loss: 0.584894624840991\n",
      "Epoch 2489 train accuracy: 83.21908417877708\n",
      "Epoch 2489 val loss: 0.5790605238565293\n",
      "Epoch 2489 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2489.pth\n",
      "Epoch 2490 train loss: 0.5849028272623719\n",
      "Epoch 2490 train accuracy: 83.19166438168358\n",
      "Epoch 2490 val loss: 0.5790820258032334\n",
      "Epoch 2490 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2490.pth\n",
      "Epoch 2491 train loss: 0.5848436218016503\n",
      "Epoch 2491 train accuracy: 83.16424458459008\n",
      "Epoch 2491 val loss: 0.5790540280408765\n",
      "Epoch 2491 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2491.pth\n",
      "Epoch 2492 train loss: 0.5848342283841288\n",
      "Epoch 2492 train accuracy: 83.21908417877708\n",
      "Epoch 2492 val loss: 0.5790536558059486\n",
      "Epoch 2492 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2492.pth\n",
      "Epoch 2493 train loss: 0.5848912478081489\n",
      "Epoch 2493 train accuracy: 83.19166438168358\n",
      "Epoch 2493 val loss: 0.5790404941102392\n",
      "Epoch 2493 val accuracy: 83.79934210526316\n",
      "Saved model to .\\test_models/MLP_2493.pth\n",
      "Epoch 2494 train loss: 0.5848835432338283\n",
      "Epoch 2494 train accuracy: 83.27392377296408\n",
      "Epoch 2494 val loss: 0.579050848113471\n",
      "Epoch 2494 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2494.pth\n",
      "Epoch 2495 train loss: 0.5848697085554401\n",
      "Epoch 2495 train accuracy: 83.19166438168358\n",
      "Epoch 2495 val loss: 0.5790354100693214\n",
      "Epoch 2495 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2495.pth\n",
      "Epoch 2496 train loss: 0.5848171632949328\n",
      "Epoch 2496 train accuracy: 83.16424458459008\n",
      "Epoch 2496 val loss: 0.5790456318737645\n",
      "Epoch 2496 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2496.pth\n",
      "Epoch 2497 train loss: 0.5848449709612811\n",
      "Epoch 2497 train accuracy: 83.24650397587058\n",
      "Epoch 2497 val loss: 0.5790375408618466\n",
      "Epoch 2497 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2497.pth\n",
      "Epoch 2498 train loss: 0.5848551050416733\n",
      "Epoch 2498 train accuracy: 83.19166438168358\n",
      "Epoch 2498 val loss: 0.5790292857655961\n",
      "Epoch 2498 val accuracy: 83.63486842105263\n",
      "Saved model to .\\test_models/MLP_2498.pth\n",
      "Epoch 2499 train loss: 0.584840305623386\n",
      "Epoch 2499 train accuracy: 83.27392377296408\n",
      "Epoch 2499 val loss: 0.5790327772694198\n",
      "Epoch 2499 val accuracy: 83.55263157894737\n",
      "Saved model to .\\test_models/MLP_2499.pth\n"
     ]
    }
   ],
   "source": [
    "train_loss_values, train_acc_values, val_loss_values, val_acc_values = training_loop(hyperparams, model, train_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x2700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define figure\n",
    "fig, axes = plt.subplots(2, 1, figsize=(4, 9), dpi=300, facecolor='w')\n",
    "\n",
    "train_loss_values = np.array(train_loss_values)\n",
    "train_acc_values = np.array(train_acc_values)\n",
    "val_loss_values = np.array(val_loss_values)\n",
    "val_acc_values = np.array(val_acc_values)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "\n",
    "    if (i % 2) == 0:\n",
    "\n",
    "        train_acc, = ax.plot(np.arange(0,2500,1),train_acc_values, label='Training Accuracy')\n",
    "        val_acc, = ax.plot(np.arange(0,2500,1),val_acc_values, label='Validation Accuracy')\n",
    "\n",
    "        # make legend \n",
    "        ax.legend(handles=[train_acc, val_acc], fontsize=6)\n",
    "        \n",
    "        # Hide the right and top spines\n",
    "        ax.spines.right.set_visible(False)\n",
    "        ax.spines.top.set_visible(False)\n",
    "        \n",
    "        # make the labels\n",
    "        ax.set_xlabel(\"epochs\")\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "        ax.set_title('Accuracy of One-layer Neural Net with full data', fontweight='bold', fontsize=8, pad=14)\n",
    "\n",
    "    else:\n",
    "        train_loss, = ax.plot(np.arange(0,2500,1),train_loss_values, label='Training Accuracy')\n",
    "        val_loss, = ax.plot(np.arange(0,2500,1),val_loss_values, label='Validation Accuracy')\n",
    "\n",
    "        # make legend \n",
    "        ax.legend(handles=[train_loss, val_loss], fontsize=6)\n",
    "        \n",
    "        # Hide the right and top spines\n",
    "        ax.spines.right.set_visible(False)\n",
    "        ax.spines.top.set_visible(False)\n",
    "        \n",
    "        # make the labels\n",
    "        ax.set_xlabel(\"epochs\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_title('Loss of One-layer Neural Net with full data', fontweight='bold', fontsize=8, pad=14)\n",
    "\n",
    "\n",
    "# set the spacing between subplots\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.8, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_list_v2 = ['earliest_funding', \n",
    "                    'domain', \n",
    "                    'org_uuid',\n",
    "                    'country_code',\n",
    "                    'series_a_funding_log',\n",
    "                    'org_name',\n",
    "                    'seed_funding_log',\n",
    "                    'series_a_funding', \n",
    "                    'city', \n",
    "                    'short_description', \n",
    "                    'founded_on', \n",
    "                    'category_list', \n",
    "                    'seed_funding', \n",
    "                    'time_first_funding', \n",
    "                    'status', \n",
    "                    'Unnamed: 0', \n",
    "                    'time_till_series_a', \n",
    "                    'category_groups_list', \n",
    "                    'series_a_funding_date',\n",
    "                    'series_a_n_rounds', \n",
    "                    'series_a_funding_normalised']\n",
    "\n",
    "df_all_clean_reduced = df_all_merged.drop(labels = drop_col_list_v2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0]\n",
      "[1]\n",
      "torch.Size([3647, 6]) torch.Size([3647, 1])\n"
     ]
    }
   ],
   "source": [
    "# data, model wants all features in range [0,1] hence we use max-min norm again\n",
    "y_all = df_all_clean_reduced.pop('success_flag').to_frame()\n",
    "X_all = df_all_clean_reduced\n",
    "X_all = X_all.to_numpy()\n",
    "y_all = y_all.to_numpy()\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_all[:,0:4] = min_max_scaler.fit_transform(X_all[:,0:4])\n",
    "print(X_all.min(axis=0))\n",
    "print(X_all.max(axis=0))\n",
    "y_all[:,0:4] = min_max_scaler.fit_transform(y_all[:,0:4])\n",
    "print(y_all.min(axis=0))\n",
    "print(y_all.max(axis=0))\n",
    "\n",
    "# make the train, test, and validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "X_train = torch.from_numpy(X_train).to(torch.float32)\n",
    "Y_train = torch.from_numpy(y_train).to(torch.float32)\n",
    "X_val = torch.from_numpy(X_val).to(torch.float32)\n",
    "Y_val = torch.from_numpy(y_val).to(torch.float32)\n",
    "X_test = torch.from_numpy(X_test).to(torch.float32)\n",
    "Y_test = torch.from_numpy(y_test).to(torch.float32)\n",
    "\n",
    "print(X_train.size(), Y_train.size())\n",
    "train_set_all = CustomDataset(input_tensors=(X_train, Y_train))\n",
    "train_loader = DataLoader(train_set_all,\n",
    "                              batch_size=4,\n",
    "                              shuffle=True)\n",
    "validation_set_all = CustomDataset(input_tensors=(X_val, Y_val))\n",
    "validation_loader = DataLoader(validation_set_all,\n",
    "                                batch_size=4,\n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallMLPv2(nn.Module):\n",
    "    \"\"\"A small MLP for small experiments.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model_path: str = r'.\\models',\n",
    "                 model_name: str = 'MLP',\n",
    "                 num_units: tuple = (6, 100, 1),  # first layer is the input size\n",
    "                 activation_fn: Module = nn.ReLU,\n",
    "                 output_fn: Module = nn.Linear,\n",
    "                 cuda: bool = False):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "\n",
    "        # encoder\n",
    "        layer_stack = []\n",
    "        for layer, units in enumerate(num_units[1:]):\n",
    "            activation = activation_fn if layer != len(num_units) else output_fn\n",
    "            layer_stack.append(nn.Sequential(nn.Linear(in_features=num_units[layer], out_features=units),\n",
    "                                             activation()))\n",
    "        self.encoder = nn.ModuleList(layer_stack)\n",
    "\n",
    "        # Option for CUDA in case we want it. But for small nets usually not good\n",
    "        if cuda:\n",
    "            self.to('cuda')\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def save_model(self, checkpoint_number: int, optimizer: Optimizer):\n",
    "        \"\"\"Saves model and optimizer state.\"\"\"\n",
    "        checkpoint_number = str(checkpoint_number)\n",
    "        saveroot = os.path.join(self.model_path)\n",
    "        savepath = os.path.join(saveroot, f'{self.model_name}_{checkpoint_number}.pth')\n",
    "        if not os.path.exists(saveroot):\n",
    "            os.mkdir(saveroot)\n",
    "\n",
    "        torch.save({\n",
    "            'model_name': self.model_name,\n",
    "            'model_params': self.state_dict(),\n",
    "            'optimizer': optimizer,\n",
    "            'optimizer_params': optimizer.state_dict()},\n",
    "            savepath)\n",
    "        print(fr'Saved model to {savepath}')\n",
    "\n",
    "    def load_model(self, checkpoint_number: int, full_loadpath: str = 'default') -> Optimizer:\n",
    "        \"\"\"Loads model and optimizer state. Returns optimizer.\"\"\"\n",
    "        if full_loadpath != 'default':\n",
    "            load_directory = full_loadpath\n",
    "        else:\n",
    "            load_directory = os.path.join(self.model_path,\n",
    "                                          f'{self.model_name}_{str(checkpoint_number)}.pth')\n",
    "        saved_dict = torch.load(load_directory)\n",
    "        self.load_state_dict(saved_dict['model_params'])\n",
    "        optimizer = saved_dict['optimizer']\n",
    "        optimizer.load_state_dict(saved_dict['optimizer_params'])\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallMLPv2(model_path=r'.\\test_modelsv2')\n",
    "hyperparams = {'optimizer': Adam(model.parameters(), lr=1e-5),\n",
    "                       'loss_fn': torch.nn.BCEWithLogitsLoss(),\n",
    "                       'num_epochs': 2500,\n",
    "                       'model_save_interval': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.7109547429309603\n",
      "Epoch 0 train accuracy: 64.68330134357005\n",
      "Epoch 0 val loss: 0.7037840424791763\n",
      "Epoch 0 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_0.pth\n",
      "Epoch 1 train loss: 0.6977855615448534\n",
      "Epoch 1 train accuracy: 64.68330134357005\n",
      "Epoch 1 val loss: 0.6932319453672359\n",
      "Epoch 1 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_1.pth\n",
      "Epoch 2 train loss: 0.6928658887351814\n",
      "Epoch 2 train accuracy: 64.68330134357005\n",
      "Epoch 2 val loss: 0.6925671237863993\n",
      "Epoch 2 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2.pth\n",
      "Epoch 3 train loss: 0.6925478990663562\n",
      "Epoch 3 train accuracy: 64.68330134357005\n",
      "Epoch 3 val loss: 0.6923508187265772\n",
      "Epoch 3 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_3.pth\n",
      "Epoch 4 train loss: 0.6923407250851915\n",
      "Epoch 4 train accuracy: 64.68330134357005\n",
      "Epoch 4 val loss: 0.6921190129298913\n",
      "Epoch 4 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_4.pth\n",
      "Epoch 5 train loss: 0.692130890789262\n",
      "Epoch 5 train accuracy: 64.68330134357005\n",
      "Epoch 5 val loss: 0.6918792150130397\n",
      "Epoch 5 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_5.pth\n",
      "Epoch 6 train loss: 0.6919386306483495\n",
      "Epoch 6 train accuracy: 64.68330134357005\n",
      "Epoch 6 val loss: 0.6916596069931984\n",
      "Epoch 6 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_6.pth\n",
      "Epoch 7 train loss: 0.6917573992620435\n",
      "Epoch 7 train accuracy: 64.68330134357005\n",
      "Epoch 7 val loss: 0.6914493882734525\n",
      "Epoch 7 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_7.pth\n",
      "Epoch 8 train loss: 0.6915693596789712\n",
      "Epoch 8 train accuracy: 64.68330134357005\n",
      "Epoch 8 val loss: 0.6912196625612284\n",
      "Epoch 8 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_8.pth\n",
      "Epoch 9 train loss: 0.6913991529952016\n",
      "Epoch 9 train accuracy: 64.68330134357005\n",
      "Epoch 9 val loss: 0.6910465183226686\n",
      "Epoch 9 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_9.pth\n",
      "Epoch 10 train loss: 0.6912355548457095\n",
      "Epoch 10 train accuracy: 64.68330134357005\n",
      "Epoch 10 val loss: 0.69088623182554\n",
      "Epoch 10 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_10.pth\n",
      "Epoch 11 train loss: 0.6910993130714224\n",
      "Epoch 11 train accuracy: 64.68330134357005\n",
      "Epoch 11 val loss: 0.6907086199835727\n",
      "Epoch 11 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_11.pth\n",
      "Epoch 12 train loss: 0.6909643467188927\n",
      "Epoch 12 train accuracy: 64.68330134357005\n",
      "Epoch 12 val loss: 0.6905885605435622\n",
      "Epoch 12 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_12.pth\n",
      "Epoch 13 train loss: 0.6908371519754853\n",
      "Epoch 13 train accuracy: 64.68330134357005\n",
      "Epoch 13 val loss: 0.6904046076693033\n",
      "Epoch 13 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_13.pth\n",
      "Epoch 14 train loss: 0.6907161298420346\n",
      "Epoch 14 train accuracy: 64.68330134357005\n",
      "Epoch 14 val loss: 0.6902519256660813\n",
      "Epoch 14 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_14.pth\n",
      "Epoch 15 train loss: 0.6905852942482421\n",
      "Epoch 15 train accuracy: 64.68330134357005\n",
      "Epoch 15 val loss: 0.690105945852242\n",
      "Epoch 15 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_15.pth\n",
      "Epoch 16 train loss: 0.690469899786669\n",
      "Epoch 16 train accuracy: 64.68330134357005\n",
      "Epoch 16 val loss: 0.6899774592173727\n",
      "Epoch 16 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_16.pth\n",
      "Epoch 17 train loss: 0.6903366171346422\n",
      "Epoch 17 train accuracy: 64.68330134357005\n",
      "Epoch 17 val loss: 0.6898584442311212\n",
      "Epoch 17 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_17.pth\n",
      "Epoch 18 train loss: 0.6902136700064466\n",
      "Epoch 18 train accuracy: 64.68330134357005\n",
      "Epoch 18 val loss: 0.6896484672631088\n",
      "Epoch 18 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_18.pth\n",
      "Epoch 19 train loss: 0.6900918153032922\n",
      "Epoch 19 train accuracy: 64.68330134357005\n",
      "Epoch 19 val loss: 0.6895111677678007\n",
      "Epoch 19 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_19.pth\n",
      "Epoch 20 train loss: 0.6899666811682676\n",
      "Epoch 20 train accuracy: 64.68330134357005\n",
      "Epoch 20 val loss: 0.6893579722627213\n",
      "Epoch 20 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_20.pth\n",
      "Epoch 21 train loss: 0.6898444907314945\n",
      "Epoch 21 train accuracy: 64.68330134357005\n",
      "Epoch 21 val loss: 0.6892370960037959\n",
      "Epoch 21 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_21.pth\n",
      "Epoch 22 train loss: 0.6897126545377991\n",
      "Epoch 22 train accuracy: 64.68330134357005\n",
      "Epoch 22 val loss: 0.6890576221048832\n",
      "Epoch 22 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_22.pth\n",
      "Epoch 23 train loss: 0.6895878791416946\n",
      "Epoch 23 train accuracy: 64.68330134357005\n",
      "Epoch 23 val loss: 0.6889151675920737\n",
      "Epoch 23 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_23.pth\n",
      "Epoch 24 train loss: 0.6894546363568097\n",
      "Epoch 24 train accuracy: 64.68330134357005\n",
      "Epoch 24 val loss: 0.688739045670158\n",
      "Epoch 24 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_24.pth\n",
      "Epoch 25 train loss: 0.6893100971192644\n",
      "Epoch 25 train accuracy: 64.68330134357005\n",
      "Epoch 25 val loss: 0.6885875937970061\n",
      "Epoch 25 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_25.pth\n",
      "Epoch 26 train loss: 0.6891640807060819\n",
      "Epoch 26 train accuracy: 64.68330134357005\n",
      "Epoch 26 val loss: 0.6883959236897921\n",
      "Epoch 26 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_26.pth\n",
      "Epoch 27 train loss: 0.6890092760063055\n",
      "Epoch 27 train accuracy: 64.68330134357005\n",
      "Epoch 27 val loss: 0.6882209964096546\n",
      "Epoch 27 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_27.pth\n",
      "Epoch 28 train loss: 0.6888542251105894\n",
      "Epoch 28 train accuracy: 64.68330134357005\n",
      "Epoch 28 val loss: 0.6880433714311374\n",
      "Epoch 28 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_28.pth\n",
      "Epoch 29 train loss: 0.6887005549250987\n",
      "Epoch 29 train accuracy: 64.68330134357005\n",
      "Epoch 29 val loss: 0.6878672871542605\n",
      "Epoch 29 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_29.pth\n",
      "Epoch 30 train loss: 0.6885524594077939\n",
      "Epoch 30 train accuracy: 64.68330134357005\n",
      "Epoch 30 val loss: 0.6876767775730083\n",
      "Epoch 30 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_30.pth\n",
      "Epoch 31 train loss: 0.6883889487699458\n",
      "Epoch 31 train accuracy: 64.68330134357005\n",
      "Epoch 31 val loss: 0.6874916573104105\n",
      "Epoch 31 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_31.pth\n",
      "Epoch 32 train loss: 0.6882310064607545\n",
      "Epoch 32 train accuracy: 64.68330134357005\n",
      "Epoch 32 val loss: 0.6873225679523066\n",
      "Epoch 32 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_32.pth\n",
      "Epoch 33 train loss: 0.6880781888438944\n",
      "Epoch 33 train accuracy: 64.68330134357005\n",
      "Epoch 33 val loss: 0.6871297335938403\n",
      "Epoch 33 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_33.pth\n",
      "Epoch 34 train loss: 0.6879130271835285\n",
      "Epoch 34 train accuracy: 64.68330134357005\n",
      "Epoch 34 val loss: 0.6869417450537807\n",
      "Epoch 34 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_34.pth\n",
      "Epoch 35 train loss: 0.6877611621299333\n",
      "Epoch 35 train accuracy: 64.68330134357005\n",
      "Epoch 35 val loss: 0.6867570906485382\n",
      "Epoch 35 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_35.pth\n",
      "Epoch 36 train loss: 0.6875960975231832\n",
      "Epoch 36 train accuracy: 64.68330134357005\n",
      "Epoch 36 val loss: 0.6865799942691075\n",
      "Epoch 36 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_36.pth\n",
      "Epoch 37 train loss: 0.687445217710838\n",
      "Epoch 37 train accuracy: 64.68330134357005\n",
      "Epoch 37 val loss: 0.6863844098621293\n",
      "Epoch 37 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_37.pth\n",
      "Epoch 38 train loss: 0.6872844658792019\n",
      "Epoch 38 train accuracy: 64.68330134357005\n",
      "Epoch 38 val loss: 0.6862244480534604\n",
      "Epoch 38 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_38.pth\n",
      "Epoch 39 train loss: 0.6871333383677298\n",
      "Epoch 39 train accuracy: 64.68330134357005\n",
      "Epoch 39 val loss: 0.6860343631553022\n",
      "Epoch 39 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_39.pth\n",
      "Epoch 40 train loss: 0.6869773320330862\n",
      "Epoch 40 train accuracy: 64.68330134357005\n",
      "Epoch 40 val loss: 0.685853373063238\n",
      "Epoch 40 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_40.pth\n",
      "Epoch 41 train loss: 0.6868282006236545\n",
      "Epoch 41 train accuracy: 64.68330134357005\n",
      "Epoch 41 val loss: 0.6856660111562202\n",
      "Epoch 41 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_41.pth\n",
      "Epoch 42 train loss: 0.6866700552534639\n",
      "Epoch 42 train accuracy: 64.68330134357005\n",
      "Epoch 42 val loss: 0.6854977909671632\n",
      "Epoch 42 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_42.pth\n",
      "Epoch 43 train loss: 0.6865299609408044\n",
      "Epoch 43 train accuracy: 64.68330134357005\n",
      "Epoch 43 val loss: 0.6853285225990572\n",
      "Epoch 43 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_43.pth\n",
      "Epoch 44 train loss: 0.6863895184768919\n",
      "Epoch 44 train accuracy: 64.68330134357005\n",
      "Epoch 44 val loss: 0.6851570137629384\n",
      "Epoch 44 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_44.pth\n",
      "Epoch 45 train loss: 0.6862292404106834\n",
      "Epoch 45 train accuracy: 64.68330134357005\n",
      "Epoch 45 val loss: 0.6849567392154744\n",
      "Epoch 45 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_45.pth\n",
      "Epoch 46 train loss: 0.6860799162011397\n",
      "Epoch 46 train accuracy: 64.68330134357005\n",
      "Epoch 46 val loss: 0.68481047275035\n",
      "Epoch 46 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_46.pth\n",
      "Epoch 47 train loss: 0.6859186267512932\n",
      "Epoch 47 train accuracy: 64.68330134357005\n",
      "Epoch 47 val loss: 0.6846018892369772\n",
      "Epoch 47 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_47.pth\n",
      "Epoch 48 train loss: 0.6857702335375443\n",
      "Epoch 48 train accuracy: 64.68330134357005\n",
      "Epoch 48 val loss: 0.6844386909353105\n",
      "Epoch 48 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_48.pth\n",
      "Epoch 49 train loss: 0.685626180483061\n",
      "Epoch 49 train accuracy: 64.68330134357005\n",
      "Epoch 49 val loss: 0.6842522044715128\n",
      "Epoch 49 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_49.pth\n",
      "Epoch 50 train loss: 0.6854962425535185\n",
      "Epoch 50 train accuracy: 64.68330134357005\n",
      "Epoch 50 val loss: 0.684070215021309\n",
      "Epoch 50 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_50.pth\n",
      "Epoch 51 train loss: 0.6853424866209951\n",
      "Epoch 51 train accuracy: 64.68330134357005\n",
      "Epoch 51 val loss: 0.6839041380505813\n",
      "Epoch 51 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_51.pth\n",
      "Epoch 52 train loss: 0.6852082400337646\n",
      "Epoch 52 train accuracy: 64.68330134357005\n",
      "Epoch 52 val loss: 0.6837494755653959\n",
      "Epoch 52 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_52.pth\n",
      "Epoch 53 train loss: 0.6850642710924149\n",
      "Epoch 53 train accuracy: 64.68330134357005\n",
      "Epoch 53 val loss: 0.6835684856693995\n",
      "Epoch 53 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_53.pth\n",
      "Epoch 54 train loss: 0.6849206648113435\n",
      "Epoch 54 train accuracy: 64.68330134357005\n",
      "Epoch 54 val loss: 0.6834328890238938\n",
      "Epoch 54 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_54.pth\n",
      "Epoch 55 train loss: 0.6847791705738034\n",
      "Epoch 55 train accuracy: 64.68330134357005\n",
      "Epoch 55 val loss: 0.683243608984508\n",
      "Epoch 55 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_55.pth\n",
      "Epoch 56 train loss: 0.6846475302519506\n",
      "Epoch 56 train accuracy: 64.68330134357005\n",
      "Epoch 56 val loss: 0.6830686203351146\n",
      "Epoch 56 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_56.pth\n",
      "Epoch 57 train loss: 0.6845057349848119\n",
      "Epoch 57 train accuracy: 64.68330134357005\n",
      "Epoch 57 val loss: 0.6829230971634388\n",
      "Epoch 57 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_57.pth\n",
      "Epoch 58 train loss: 0.6843681865486136\n",
      "Epoch 58 train accuracy: 64.68330134357005\n",
      "Epoch 58 val loss: 0.6827479675412178\n",
      "Epoch 58 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_58.pth\n",
      "Epoch 59 train loss: 0.6842402998161944\n",
      "Epoch 59 train accuracy: 64.68330134357005\n",
      "Epoch 59 val loss: 0.6825850088345377\n",
      "Epoch 59 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_59.pth\n",
      "Epoch 60 train loss: 0.6841083623861012\n",
      "Epoch 60 train accuracy: 64.68330134357005\n",
      "Epoch 60 val loss: 0.6824201763068375\n",
      "Epoch 60 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_60.pth\n",
      "Epoch 61 train loss: 0.6839816033709467\n",
      "Epoch 61 train accuracy: 64.68330134357005\n",
      "Epoch 61 val loss: 0.6822822852746436\n",
      "Epoch 61 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_61.pth\n",
      "Epoch 62 train loss: 0.6838633077578586\n",
      "Epoch 62 train accuracy: 64.71072114066357\n",
      "Epoch 62 val loss: 0.6820933756075407\n",
      "Epoch 62 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_62.pth\n",
      "Epoch 63 train loss: 0.6837172854626388\n",
      "Epoch 63 train accuracy: 64.71072114066357\n",
      "Epoch 63 val loss: 0.681951147161032\n",
      "Epoch 63 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_63.pth\n",
      "Epoch 64 train loss: 0.6835724710111033\n",
      "Epoch 64 train accuracy: 64.71072114066357\n",
      "Epoch 64 val loss: 0.6817779009671587\n",
      "Epoch 64 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_64.pth\n",
      "Epoch 65 train loss: 0.6834580347987643\n",
      "Epoch 65 train accuracy: 64.71072114066357\n",
      "Epoch 65 val loss: 0.6816219163960532\n",
      "Epoch 65 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_65.pth\n",
      "Epoch 66 train loss: 0.6833021902201468\n",
      "Epoch 66 train accuracy: 64.71072114066357\n",
      "Epoch 66 val loss: 0.6814691755724581\n",
      "Epoch 66 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_66.pth\n",
      "Epoch 67 train loss: 0.6831896648203072\n",
      "Epoch 67 train accuracy: 64.71072114066357\n",
      "Epoch 67 val loss: 0.681318181713945\n",
      "Epoch 67 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_67.pth\n",
      "Epoch 68 train loss: 0.6830948483394949\n",
      "Epoch 68 train accuracy: 64.71072114066357\n",
      "Epoch 68 val loss: 0.6811774931848049\n",
      "Epoch 68 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_68.pth\n",
      "Epoch 69 train loss: 0.6829540931472653\n",
      "Epoch 69 train accuracy: 64.71072114066357\n",
      "Epoch 69 val loss: 0.6810039344586825\n",
      "Epoch 69 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_69.pth\n",
      "Epoch 70 train loss: 0.6828259127051161\n",
      "Epoch 70 train accuracy: 64.71072114066357\n",
      "Epoch 70 val loss: 0.6808525265047425\n",
      "Epoch 70 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_70.pth\n",
      "Epoch 71 train loss: 0.6826930297702029\n",
      "Epoch 71 train accuracy: 64.71072114066357\n",
      "Epoch 71 val loss: 0.6806937532597467\n",
      "Epoch 71 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_71.pth\n",
      "Epoch 72 train loss: 0.6825557583779619\n",
      "Epoch 72 train accuracy: 64.71072114066357\n",
      "Epoch 72 val loss: 0.6805457341435709\n",
      "Epoch 72 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_72.pth\n",
      "Epoch 73 train loss: 0.6824417673704917\n",
      "Epoch 73 train accuracy: 64.71072114066357\n",
      "Epoch 73 val loss: 0.6803748895855326\n",
      "Epoch 73 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_73.pth\n",
      "Epoch 74 train loss: 0.6823020606840912\n",
      "Epoch 74 train accuracy: 64.71072114066357\n",
      "Epoch 74 val loss: 0.680245039690482\n",
      "Epoch 74 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_74.pth\n",
      "Epoch 75 train loss: 0.6822074647143221\n",
      "Epoch 75 train accuracy: 64.71072114066357\n",
      "Epoch 75 val loss: 0.6800711247089662\n",
      "Epoch 75 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_75.pth\n",
      "Epoch 76 train loss: 0.6820842334837244\n",
      "Epoch 76 train accuracy: 64.73814093775707\n",
      "Epoch 76 val loss: 0.6799272914466105\n",
      "Epoch 76 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_76.pth\n",
      "Epoch 77 train loss: 0.6819464155195052\n",
      "Epoch 77 train accuracy: 64.73814093775707\n",
      "Epoch 77 val loss: 0.679769025429299\n",
      "Epoch 77 val accuracy: 64.63815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_77.pth\n",
      "Epoch 78 train loss: 0.6818198196982083\n",
      "Epoch 78 train accuracy: 64.76556073485057\n",
      "Epoch 78 val loss: 0.6796274638097537\n",
      "Epoch 78 val accuracy: 64.72039473684211\n",
      "Saved model to .\\test_modelsv2/MLP_78.pth\n",
      "Epoch 79 train loss: 0.6817251901354706\n",
      "Epoch 79 train accuracy: 64.82040032903757\n",
      "Epoch 79 val loss: 0.6794619317117491\n",
      "Epoch 79 val accuracy: 64.88486842105263\n",
      "Saved model to .\\test_modelsv2/MLP_79.pth\n",
      "Epoch 80 train loss: 0.6815962636549222\n",
      "Epoch 80 train accuracy: 65.01233890869207\n",
      "Epoch 80 val loss: 0.6793049020986808\n",
      "Epoch 80 val accuracy: 64.80263157894737\n",
      "Saved model to .\\test_modelsv2/MLP_80.pth\n",
      "Epoch 81 train loss: 0.6814891043723675\n",
      "Epoch 81 train accuracy: 65.09459829997257\n",
      "Epoch 81 val loss: 0.6791654374254378\n",
      "Epoch 81 val accuracy: 64.80263157894737\n",
      "Saved model to .\\test_modelsv2/MLP_81.pth\n",
      "Epoch 82 train loss: 0.6813519982000192\n",
      "Epoch 82 train accuracy: 65.12201809706607\n",
      "Epoch 82 val loss: 0.6790172263587776\n",
      "Epoch 82 val accuracy: 64.88486842105263\n",
      "Saved model to .\\test_modelsv2/MLP_82.pth\n",
      "Epoch 83 train loss: 0.6812284301901073\n",
      "Epoch 83 train accuracy: 65.14943789415959\n",
      "Epoch 83 val loss: 0.6788774122925181\n",
      "Epoch 83 val accuracy: 64.88486842105263\n",
      "Saved model to .\\test_modelsv2/MLP_83.pth\n",
      "Epoch 84 train loss: 0.6811196479227459\n",
      "Epoch 84 train accuracy: 65.17685769125309\n",
      "Epoch 84 val loss: 0.6787047233236464\n",
      "Epoch 84 val accuracy: 64.96710526315789\n",
      "Saved model to .\\test_modelsv2/MLP_84.pth\n",
      "Epoch 85 train loss: 0.6809813588073379\n",
      "Epoch 85 train accuracy: 65.28653687962709\n",
      "Epoch 85 val loss: 0.6785507596244937\n",
      "Epoch 85 val accuracy: 65.04934210526316\n",
      "Saved model to .\\test_modelsv2/MLP_85.pth\n",
      "Epoch 86 train loss: 0.6808876301112928\n",
      "Epoch 86 train accuracy: 65.4236358650946\n",
      "Epoch 86 val loss: 0.678406965771788\n",
      "Epoch 86 val accuracy: 65.29605263157895\n",
      "Saved model to .\\test_modelsv2/MLP_86.pth\n",
      "Epoch 87 train loss: 0.6807660119313943\n",
      "Epoch 87 train accuracy: 65.5058952563751\n",
      "Epoch 87 val loss: 0.678271251485536\n",
      "Epoch 87 val accuracy: 65.29605263157895\n",
      "Saved model to .\\test_modelsv2/MLP_87.pth\n",
      "Epoch 88 train loss: 0.6806540034319225\n",
      "Epoch 88 train accuracy: 65.5607348505621\n",
      "Epoch 88 val loss: 0.6781240793827333\n",
      "Epoch 88 val accuracy: 65.46052631578948\n",
      "Saved model to .\\test_modelsv2/MLP_88.pth\n",
      "Epoch 89 train loss: 0.6805344289332106\n",
      "Epoch 89 train accuracy: 65.5607348505621\n",
      "Epoch 89 val loss: 0.6779989357057371\n",
      "Epoch 89 val accuracy: 65.54276315789474\n",
      "Saved model to .\\test_modelsv2/MLP_89.pth\n",
      "Epoch 90 train loss: 0.6804287141483081\n",
      "Epoch 90 train accuracy: 65.67041403893612\n",
      "Epoch 90 val loss: 0.6778628753596231\n",
      "Epoch 90 val accuracy: 65.54276315789474\n",
      "Saved model to .\\test_modelsv2/MLP_90.pth\n",
      "Epoch 91 train loss: 0.6803453306487778\n",
      "Epoch 91 train accuracy: 65.75267343021662\n",
      "Epoch 91 val loss: 0.6777222101625643\n",
      "Epoch 91 val accuracy: 65.8717105263158\n",
      "Saved model to .\\test_modelsv2/MLP_91.pth\n",
      "Epoch 92 train loss: 0.6802266817213151\n",
      "Epoch 92 train accuracy: 65.80751302440362\n",
      "Epoch 92 val loss: 0.6775812212573854\n",
      "Epoch 92 val accuracy: 66.03618421052632\n",
      "Saved model to .\\test_modelsv2/MLP_92.pth\n",
      "Epoch 93 train loss: 0.6801057722615568\n",
      "Epoch 93 train accuracy: 65.94461200987112\n",
      "Epoch 93 val loss: 0.6774642373386183\n",
      "Epoch 93 val accuracy: 66.03618421052632\n",
      "Saved model to .\\test_modelsv2/MLP_93.pth\n",
      "Epoch 94 train loss: 0.6799900562486105\n",
      "Epoch 94 train accuracy: 65.99945160405812\n",
      "Epoch 94 val loss: 0.6773238021292185\n",
      "Epoch 94 val accuracy: 66.20065789473684\n",
      "Saved model to .\\test_modelsv2/MLP_94.pth\n",
      "Epoch 95 train loss: 0.6798671543467463\n",
      "Epoch 95 train accuracy: 65.97203180696462\n",
      "Epoch 95 val loss: 0.6771946167083163\n",
      "Epoch 95 val accuracy: 66.28289473684211\n",
      "Saved model to .\\test_modelsv2/MLP_95.pth\n",
      "Epoch 96 train loss: 0.6797929648636726\n",
      "Epoch 96 train accuracy: 65.97203180696462\n",
      "Epoch 96 val loss: 0.6770581930483642\n",
      "Epoch 96 val accuracy: 66.36513157894737\n",
      "Saved model to .\\test_modelsv2/MLP_96.pth\n",
      "Epoch 97 train loss: 0.6797000476273528\n",
      "Epoch 97 train accuracy: 66.13655058952564\n",
      "Epoch 97 val loss: 0.6769343124408471\n",
      "Epoch 97 val accuracy: 66.36513157894737\n",
      "Saved model to .\\test_modelsv2/MLP_97.pth\n",
      "Epoch 98 train loss: 0.6795860685146692\n",
      "Epoch 98 train accuracy: 66.10913079243214\n",
      "Epoch 98 val loss: 0.6768036482757643\n",
      "Epoch 98 val accuracy: 66.77631578947368\n",
      "Saved model to .\\test_modelsv2/MLP_98.pth\n",
      "Epoch 99 train loss: 0.679460445190208\n",
      "Epoch 99 train accuracy: 66.19139018371264\n",
      "Epoch 99 val loss: 0.676675787881801\n",
      "Epoch 99 val accuracy: 66.77631578947368\n",
      "Saved model to .\\test_modelsv2/MLP_99.pth\n",
      "Epoch 100 train loss: 0.6794059362850691\n",
      "Epoch 100 train accuracy: 66.57526734302166\n",
      "Epoch 100 val loss: 0.6765518939416659\n",
      "Epoch 100 val accuracy: 67.02302631578948\n",
      "Saved model to .\\test_modelsv2/MLP_100.pth\n",
      "Epoch 101 train loss: 0.6792552851205855\n",
      "Epoch 101 train accuracy: 66.63010693720867\n",
      "Epoch 101 val loss: 0.676431406485407\n",
      "Epoch 101 val accuracy: 67.26973684210526\n",
      "Saved model to .\\test_modelsv2/MLP_101.pth\n",
      "Epoch 102 train loss: 0.6792181298267423\n",
      "Epoch 102 train accuracy: 66.73978612558267\n",
      "Epoch 102 val loss: 0.6763080689860018\n",
      "Epoch 102 val accuracy: 67.35197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_102.pth\n",
      "Epoch 103 train loss: 0.6791117267127622\n",
      "Epoch 103 train accuracy: 66.82204551686317\n",
      "Epoch 103 val loss: 0.6761813385314063\n",
      "Epoch 103 val accuracy: 67.51644736842105\n",
      "Saved model to .\\test_modelsv2/MLP_103.pth\n",
      "Epoch 104 train loss: 0.6789971983485055\n",
      "Epoch 104 train accuracy: 67.2059226761722\n",
      "Epoch 104 val loss: 0.6760616447580489\n",
      "Epoch 104 val accuracy: 67.68092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_104.pth\n",
      "Epoch 105 train loss: 0.6789219922533161\n",
      "Epoch 105 train accuracy: 67.2607622703592\n",
      "Epoch 105 val loss: 0.6759410706397734\n",
      "Epoch 105 val accuracy: 68.00986842105263\n",
      "Saved model to .\\test_modelsv2/MLP_105.pth\n",
      "Epoch 106 train loss: 0.678826619168384\n",
      "Epoch 106 train accuracy: 67.48012064710721\n",
      "Epoch 106 val loss: 0.6758267030512032\n",
      "Epoch 106 val accuracy: 68.09210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_106.pth\n",
      "Epoch 107 train loss: 0.6787320829666498\n",
      "Epoch 107 train accuracy: 67.53496024129421\n",
      "Epoch 107 val loss: 0.6757076210097263\n",
      "Epoch 107 val accuracy: 68.09210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_107.pth\n",
      "Epoch 108 train loss: 0.6786436747694224\n",
      "Epoch 108 train accuracy: 67.61721963257472\n",
      "Epoch 108 val loss: 0.6755986941096029\n",
      "Epoch 108 val accuracy: 68.09210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_108.pth\n",
      "Epoch 109 train loss: 0.6786115951836109\n",
      "Epoch 109 train accuracy: 67.89141760350974\n",
      "Epoch 109 val loss: 0.6754829709074999\n",
      "Epoch 109 val accuracy: 68.25657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_109.pth\n",
      "Epoch 110 train loss: 0.6784774689820775\n",
      "Epoch 110 train accuracy: 67.80915821222924\n",
      "Epoch 110 val loss: 0.6753758535181221\n",
      "Epoch 110 val accuracy: 68.33881578947368\n",
      "Saved model to .\\test_modelsv2/MLP_110.pth\n",
      "Epoch 111 train loss: 0.6783714089542627\n",
      "Epoch 111 train accuracy: 68.05593638607074\n",
      "Epoch 111 val loss: 0.6752673479679384\n",
      "Epoch 111 val accuracy: 68.5032894736842\n",
      "Saved model to .\\test_modelsv2/MLP_111.pth\n",
      "Epoch 112 train loss: 0.6783144053463873\n",
      "Epoch 112 train accuracy: 68.11077598025774\n",
      "Epoch 112 val loss: 0.6751571776051271\n",
      "Epoch 112 val accuracy: 68.75\n",
      "Saved model to .\\test_modelsv2/MLP_112.pth\n",
      "Epoch 113 train loss: 0.6781910014779944\n",
      "Epoch 113 train accuracy: 68.19303537153824\n",
      "Epoch 113 val loss: 0.6750541911705544\n",
      "Epoch 113 val accuracy: 68.83223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_113.pth\n",
      "Epoch 114 train loss: 0.6781205715317475\n",
      "Epoch 114 train accuracy: 68.30271455991226\n",
      "Epoch 114 val loss: 0.6749455830768535\n",
      "Epoch 114 val accuracy: 68.75\n",
      "Saved model to .\\test_modelsv2/MLP_114.pth\n",
      "Epoch 115 train loss: 0.6780494413616365\n",
      "Epoch 115 train accuracy: 68.43981354537976\n",
      "Epoch 115 val loss: 0.6748325480638366\n",
      "Epoch 115 val accuracy: 68.83223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_115.pth\n",
      "Epoch 116 train loss: 0.6779345817406449\n",
      "Epoch 116 train accuracy: 68.52207293666027\n",
      "Epoch 116 val loss: 0.6747369752510598\n",
      "Epoch 116 val accuracy: 68.83223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_116.pth\n",
      "Epoch 117 train loss: 0.6778729961237364\n",
      "Epoch 117 train accuracy: 68.57691253084727\n",
      "Epoch 117 val loss: 0.6746257580816746\n",
      "Epoch 117 val accuracy: 68.91447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_117.pth\n",
      "Epoch 118 train loss: 0.6777968360928067\n",
      "Epoch 118 train accuracy: 68.57691253084727\n",
      "Epoch 118 val loss: 0.6745193288906625\n",
      "Epoch 118 val accuracy: 69.07894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_118.pth\n",
      "Epoch 119 train loss: 0.6777130950307637\n",
      "Epoch 119 train accuracy: 68.63175212503427\n",
      "Epoch 119 val loss: 0.6744164695080958\n",
      "Epoch 119 val accuracy: 69.16118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_119.pth\n",
      "Epoch 120 train loss: 0.677600865235977\n",
      "Epoch 120 train accuracy: 68.63175212503427\n",
      "Epoch 120 val loss: 0.6743237256611648\n",
      "Epoch 120 val accuracy: 69.32565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_120.pth\n",
      "Epoch 121 train loss: 0.6775827798012056\n",
      "Epoch 121 train accuracy: 68.76885111050179\n",
      "Epoch 121 val loss: 0.6742230802774429\n",
      "Epoch 121 val accuracy: 69.32565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_121.pth\n",
      "Epoch 122 train loss: 0.6774647950537895\n",
      "Epoch 122 train accuracy: 68.82369070468879\n",
      "Epoch 122 val loss: 0.674119886403021\n",
      "Epoch 122 val accuracy: 69.57236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_122.pth\n",
      "Epoch 123 train loss: 0.6773905127979162\n",
      "Epoch 123 train accuracy: 68.98820948724979\n",
      "Epoch 123 val loss: 0.67402420467452\n",
      "Epoch 123 val accuracy: 69.57236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_123.pth\n",
      "Epoch 124 train loss: 0.6773097131466657\n",
      "Epoch 124 train accuracy: 68.98820948724979\n",
      "Epoch 124 val loss: 0.6739204080873414\n",
      "Epoch 124 val accuracy: 69.81907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_124.pth\n",
      "Epoch 125 train loss: 0.677234439702149\n",
      "Epoch 125 train accuracy: 69.20756786399781\n",
      "Epoch 125 val loss: 0.6738244079445538\n",
      "Epoch 125 val accuracy: 69.98355263157895\n",
      "Saved model to .\\test_modelsv2/MLP_125.pth\n",
      "Epoch 126 train loss: 0.6771350489243081\n",
      "Epoch 126 train accuracy: 69.42692624074581\n",
      "Epoch 126 val loss: 0.6737216340475961\n",
      "Epoch 126 val accuracy: 70.0657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_126.pth\n",
      "Epoch 127 train loss: 0.6770785002920189\n",
      "Epoch 127 train accuracy: 69.37208664655881\n",
      "Epoch 127 val loss: 0.6736271195113659\n",
      "Epoch 127 val accuracy: 70.0657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_127.pth\n",
      "Epoch 128 train loss: 0.6770053498054805\n",
      "Epoch 128 train accuracy: 69.78338360296134\n",
      "Epoch 128 val loss: 0.673534014311276\n",
      "Epoch 128 val accuracy: 70.14802631578948\n",
      "Saved model to .\\test_modelsv2/MLP_128.pth\n",
      "Epoch 129 train loss: 0.6769513923086619\n",
      "Epoch 129 train accuracy: 69.81080340005484\n",
      "Epoch 129 val loss: 0.6734371822523443\n",
      "Epoch 129 val accuracy: 70.23026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_129.pth\n",
      "Epoch 130 train loss: 0.6768487940231959\n",
      "Epoch 130 train accuracy: 69.92048258842884\n",
      "Epoch 130 val loss: 0.673348881500332\n",
      "Epoch 130 val accuracy: 70.3125\n",
      "Saved model to .\\test_modelsv2/MLP_130.pth\n",
      "Epoch 131 train loss: 0.6767662014942943\n",
      "Epoch 131 train accuracy: 69.92048258842884\n",
      "Epoch 131 val loss: 0.6732518569027123\n",
      "Epoch 131 val accuracy: 70.3125\n",
      "Saved model to .\\test_modelsv2/MLP_131.pth\n",
      "Epoch 132 train loss: 0.6766913261983478\n",
      "Epoch 132 train accuracy: 69.94790238552234\n",
      "Epoch 132 val loss: 0.6731662148315656\n",
      "Epoch 132 val accuracy: 70.23026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_132.pth\n",
      "Epoch 133 train loss: 0.6766453274901498\n",
      "Epoch 133 train accuracy: 70.00274197970936\n",
      "Epoch 133 val loss: 0.6730769786395525\n",
      "Epoch 133 val accuracy: 70.39473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_133.pth\n",
      "Epoch 134 train loss: 0.6765692193518605\n",
      "Epoch 134 train accuracy: 69.92048258842884\n",
      "Epoch 134 val loss: 0.6729785847036462\n",
      "Epoch 134 val accuracy: 70.47697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_134.pth\n",
      "Epoch 135 train loss: 0.6764693631088001\n",
      "Epoch 135 train accuracy: 70.11242116808336\n",
      "Epoch 135 val loss: 0.672894576858533\n",
      "Epoch 135 val accuracy: 70.72368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_135.pth\n",
      "Epoch 136 train loss: 0.6764001792068022\n",
      "Epoch 136 train accuracy: 70.00274197970936\n",
      "Epoch 136 val loss: 0.6728051822436484\n",
      "Epoch 136 val accuracy: 70.80592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_136.pth\n",
      "Epoch 137 train loss: 0.6763629512044421\n",
      "Epoch 137 train accuracy: 70.16726076227036\n",
      "Epoch 137 val loss: 0.6727100061742883\n",
      "Epoch 137 val accuracy: 70.88815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_137.pth\n",
      "Epoch 138 train loss: 0.6762865388341117\n",
      "Epoch 138 train accuracy: 70.30435974773786\n",
      "Epoch 138 val loss: 0.6726339208452325\n",
      "Epoch 138 val accuracy: 70.88815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_138.pth\n",
      "Epoch 139 train loss: 0.6762195688982805\n",
      "Epoch 139 train accuracy: 70.38661913901836\n",
      "Epoch 139 val loss: 0.6725379152125434\n",
      "Epoch 139 val accuracy: 71.21710526315789\n",
      "Saved model to .\\test_modelsv2/MLP_139.pth\n",
      "Epoch 140 train loss: 0.6761475586446754\n",
      "Epoch 140 train accuracy: 70.27693995064436\n",
      "Epoch 140 val loss: 0.672454862414222\n",
      "Epoch 140 val accuracy: 71.13486842105263\n",
      "Saved model to .\\test_modelsv2/MLP_140.pth\n",
      "Epoch 141 train loss: 0.6760875407867787\n",
      "Epoch 141 train accuracy: 70.44145873320538\n",
      "Epoch 141 val loss: 0.6723689021248567\n",
      "Epoch 141 val accuracy: 71.38157894736842\n",
      "Saved model to .\\test_modelsv2/MLP_141.pth\n",
      "Epoch 142 train loss: 0.6760302585990805\n",
      "Epoch 142 train accuracy: 70.46887853029888\n",
      "Epoch 142 val loss: 0.6722827471400562\n",
      "Epoch 142 val accuracy: 71.29934210526316\n",
      "Saved model to .\\test_modelsv2/MLP_142.pth\n",
      "Epoch 143 train loss: 0.6759086037871608\n",
      "Epoch 143 train accuracy: 70.44145873320538\n",
      "Epoch 143 val loss: 0.6722026707506493\n",
      "Epoch 143 val accuracy: 71.29934210526316\n",
      "Saved model to .\\test_modelsv2/MLP_143.pth\n",
      "Epoch 144 train loss: 0.6759054990517989\n",
      "Epoch 144 train accuracy: 70.44145873320538\n",
      "Epoch 144 val loss: 0.6721158685456765\n",
      "Epoch 144 val accuracy: 71.29934210526316\n",
      "Saved model to .\\test_modelsv2/MLP_144.pth\n",
      "Epoch 145 train loss: 0.6757979377319938\n",
      "Epoch 145 train accuracy: 70.68823690704689\n",
      "Epoch 145 val loss: 0.6720320572586436\n",
      "Epoch 145 val accuracy: 71.38157894736842\n",
      "Saved model to .\\test_modelsv2/MLP_145.pth\n",
      "Epoch 146 train loss: 0.6757509028702452\n",
      "Epoch 146 train accuracy: 70.79791609542089\n",
      "Epoch 146 val loss: 0.6719576451731356\n",
      "Epoch 146 val accuracy: 71.38157894736842\n",
      "Saved model to .\\test_modelsv2/MLP_146.pth\n",
      "Epoch 147 train loss: 0.6756712864234782\n",
      "Epoch 147 train accuracy: 70.82533589251439\n",
      "Epoch 147 val loss: 0.6718694097117374\n",
      "Epoch 147 val accuracy: 71.29934210526316\n",
      "Saved model to .\\test_modelsv2/MLP_147.pth\n",
      "Epoch 148 train loss: 0.6756152687757685\n",
      "Epoch 148 train accuracy: 70.79791609542089\n",
      "Epoch 148 val loss: 0.6717909631368361\n",
      "Epoch 148 val accuracy: 71.46381578947368\n",
      "Saved model to .\\test_modelsv2/MLP_148.pth\n",
      "Epoch 149 train loss: 0.675537231884766\n",
      "Epoch 149 train accuracy: 70.9075952837949\n",
      "Epoch 149 val loss: 0.6717191634601668\n",
      "Epoch 149 val accuracy: 71.46381578947368\n",
      "Saved model to .\\test_modelsv2/MLP_149.pth\n",
      "Epoch 150 train loss: 0.6754810619576458\n",
      "Epoch 150 train accuracy: 70.9075952837949\n",
      "Epoch 150 val loss: 0.6716299480513522\n",
      "Epoch 150 val accuracy: 71.6282894736842\n",
      "Saved model to .\\test_modelsv2/MLP_150.pth\n",
      "Epoch 151 train loss: 0.6754320552082438\n",
      "Epoch 151 train accuracy: 70.9075952837949\n",
      "Epoch 151 val loss: 0.6715438048306265\n",
      "Epoch 151 val accuracy: 71.71052631578948\n",
      "Saved model to .\\test_modelsv2/MLP_151.pth\n",
      "Epoch 152 train loss: 0.6753666637171256\n",
      "Epoch 152 train accuracy: 70.9624348779819\n",
      "Epoch 152 val loss: 0.6714743167946213\n",
      "Epoch 152 val accuracy: 71.79276315789474\n",
      "Saved model to .\\test_modelsv2/MLP_152.pth\n",
      "Epoch 153 train loss: 0.6753073824210125\n",
      "Epoch 153 train accuracy: 71.0172744721689\n",
      "Epoch 153 val loss: 0.6713899650463933\n",
      "Epoch 153 val accuracy: 71.95723684210526\n",
      "Saved model to .\\test_modelsv2/MLP_153.pth\n",
      "Epoch 154 train loss: 0.6752166587271189\n",
      "Epoch 154 train accuracy: 71.12695366054291\n",
      "Epoch 154 val loss: 0.6713238593779112\n",
      "Epoch 154 val accuracy: 71.95723684210526\n",
      "Saved model to .\\test_modelsv2/MLP_154.pth\n",
      "Epoch 155 train loss: 0.6751898381728352\n",
      "Epoch 155 train accuracy: 71.20921305182341\n",
      "Epoch 155 val loss: 0.6712360029157839\n",
      "Epoch 155 val accuracy: 72.03947368421052\n",
      "Saved model to .\\test_modelsv2/MLP_155.pth\n",
      "Epoch 156 train loss: 0.6751521211444286\n",
      "Epoch 156 train accuracy: 71.23663284891691\n",
      "Epoch 156 val loss: 0.6711699327355937\n",
      "Epoch 156 val accuracy: 72.1217105263158\n",
      "Saved model to .\\test_modelsv2/MLP_156.pth\n",
      "Epoch 157 train loss: 0.6750634451511136\n",
      "Epoch 157 train accuracy: 71.23663284891691\n",
      "Epoch 157 val loss: 0.6710934931118238\n",
      "Epoch 157 val accuracy: 72.1217105263158\n",
      "Saved model to .\\test_modelsv2/MLP_157.pth\n",
      "Epoch 158 train loss: 0.6750078108161688\n",
      "Epoch 158 train accuracy: 71.34631203729093\n",
      "Epoch 158 val loss: 0.6710176633572892\n",
      "Epoch 158 val accuracy: 72.28618421052632\n",
      "Saved model to .\\test_modelsv2/MLP_158.pth\n",
      "Epoch 159 train loss: 0.6749509209930374\n",
      "Epoch 159 train accuracy: 71.51083081985193\n",
      "Epoch 159 val loss: 0.6709441266169673\n",
      "Epoch 159 val accuracy: 72.28618421052632\n",
      "Saved model to .\\test_modelsv2/MLP_159.pth\n",
      "Epoch 160 train loss: 0.6748652459498037\n",
      "Epoch 160 train accuracy: 71.53825061694543\n",
      "Epoch 160 val loss: 0.6708767892498719\n",
      "Epoch 160 val accuracy: 72.28618421052632\n",
      "Saved model to .\\test_modelsv2/MLP_160.pth\n",
      "Epoch 161 train loss: 0.6748752240091562\n",
      "Epoch 161 train accuracy: 71.73018919659995\n",
      "Epoch 161 val loss: 0.6708080413702288\n",
      "Epoch 161 val accuracy: 72.36842105263158\n",
      "Saved model to .\\test_modelsv2/MLP_161.pth\n",
      "Epoch 162 train loss: 0.6747760918448892\n",
      "Epoch 162 train accuracy: 71.70276939950644\n",
      "Epoch 162 val loss: 0.6707307414985016\n",
      "Epoch 162 val accuracy: 72.45065789473684\n",
      "Saved model to .\\test_modelsv2/MLP_162.pth\n",
      "Epoch 163 train loss: 0.6747154003956861\n",
      "Epoch 163 train accuracy: 71.83986838497395\n",
      "Epoch 163 val loss: 0.6706554797527037\n",
      "Epoch 163 val accuracy: 72.61513157894737\n",
      "Saved model to .\\test_modelsv2/MLP_163.pth\n",
      "Epoch 164 train loss: 0.6746643108495495\n",
      "Epoch 164 train accuracy: 71.83986838497395\n",
      "Epoch 164 val loss: 0.6705972681704321\n",
      "Epoch 164 val accuracy: 72.61513157894737\n",
      "Saved model to .\\test_modelsv2/MLP_164.pth\n",
      "Epoch 165 train loss: 0.674559038589921\n",
      "Epoch 165 train accuracy: 72.00438716753496\n",
      "Epoch 165 val loss: 0.670528206876234\n",
      "Epoch 165 val accuracy: 72.53289473684211\n",
      "Saved model to .\\test_modelsv2/MLP_165.pth\n",
      "Epoch 166 train loss: 0.6745693010130995\n",
      "Epoch 166 train accuracy: 71.92212777625446\n",
      "Epoch 166 val loss: 0.6704575821365181\n",
      "Epoch 166 val accuracy: 72.69736842105263\n",
      "Saved model to .\\test_modelsv2/MLP_166.pth\n",
      "Epoch 167 train loss: 0.6745016933337116\n",
      "Epoch 167 train accuracy: 71.94954757334796\n",
      "Epoch 167 val loss: 0.6703928525706655\n",
      "Epoch 167 val accuracy: 72.86184210526316\n",
      "Saved model to .\\test_modelsv2/MLP_167.pth\n",
      "Epoch 168 train loss: 0.6743965957379132\n",
      "Epoch 168 train accuracy: 72.03180696462846\n",
      "Epoch 168 val loss: 0.6703402981358139\n",
      "Epoch 168 val accuracy: 72.86184210526316\n",
      "Saved model to .\\test_modelsv2/MLP_168.pth\n",
      "Epoch 169 train loss: 0.6743847877440745\n",
      "Epoch 169 train accuracy: 72.03180696462846\n",
      "Epoch 169 val loss: 0.6702716705438337\n",
      "Epoch 169 val accuracy: 72.86184210526316\n",
      "Saved model to .\\test_modelsv2/MLP_169.pth\n",
      "Epoch 170 train loss: 0.6743172305848515\n",
      "Epoch 170 train accuracy: 71.94954757334796\n",
      "Epoch 170 val loss: 0.6702239182042448\n",
      "Epoch 170 val accuracy: 72.86184210526316\n",
      "Saved model to .\\test_modelsv2/MLP_170.pth\n",
      "Epoch 171 train loss: 0.6742692374411905\n",
      "Epoch 171 train accuracy: 72.05922676172196\n",
      "Epoch 171 val loss: 0.6701561927207207\n",
      "Epoch 171 val accuracy: 72.94407894736842\n",
      "Saved model to .\\test_modelsv2/MLP_171.pth\n",
      "Epoch 172 train loss: 0.6742138224408815\n",
      "Epoch 172 train accuracy: 72.03180696462846\n",
      "Epoch 172 val loss: 0.6700850454600233\n",
      "Epoch 172 val accuracy: 72.86184210526316\n",
      "Saved model to .\\test_modelsv2/MLP_172.pth\n",
      "Epoch 173 train loss: 0.6741537806953777\n",
      "Epoch 173 train accuracy: 72.08664655881546\n",
      "Epoch 173 val loss: 0.6700386523612236\n",
      "Epoch 173 val accuracy: 72.94407894736842\n",
      "Saved model to .\\test_modelsv2/MLP_173.pth\n",
      "Epoch 174 train loss: 0.6740973894729426\n",
      "Epoch 174 train accuracy: 72.08664655881546\n",
      "Epoch 174 val loss: 0.669983667566588\n",
      "Epoch 174 val accuracy: 72.86184210526316\n",
      "Saved model to .\\test_modelsv2/MLP_174.pth\n",
      "Epoch 175 train loss: 0.6740307509899139\n",
      "Epoch 175 train accuracy: 72.05922676172196\n",
      "Epoch 175 val loss: 0.6699244622141123\n",
      "Epoch 175 val accuracy: 73.10855263157895\n",
      "Saved model to .\\test_modelsv2/MLP_175.pth\n",
      "Epoch 176 train loss: 0.6739861346585186\n",
      "Epoch 176 train accuracy: 72.16890595009598\n",
      "Epoch 176 val loss: 0.6698756796356878\n",
      "Epoch 176 val accuracy: 73.10855263157895\n",
      "Saved model to .\\test_modelsv2/MLP_176.pth\n",
      "Epoch 177 train loss: 0.6739280718917909\n",
      "Epoch 177 train accuracy: 72.19632574718948\n",
      "Epoch 177 val loss: 0.6698256699662459\n",
      "Epoch 177 val accuracy: 73.10855263157895\n",
      "Saved model to .\\test_modelsv2/MLP_177.pth\n",
      "Epoch 178 train loss: 0.6738634879063619\n",
      "Epoch 178 train accuracy: 72.05922676172196\n",
      "Epoch 178 val loss: 0.6697806501270909\n",
      "Epoch 178 val accuracy: 73.10855263157895\n",
      "Saved model to .\\test_modelsv2/MLP_178.pth\n",
      "Epoch 179 train loss: 0.6737497907720114\n",
      "Epoch 179 train accuracy: 72.14148615300246\n",
      "Epoch 179 val loss: 0.6697247052859319\n",
      "Epoch 179 val accuracy: 73.10855263157895\n",
      "Saved model to .\\test_modelsv2/MLP_179.pth\n",
      "Epoch 180 train loss: 0.6737522404771625\n",
      "Epoch 180 train accuracy: 72.22374554428298\n",
      "Epoch 180 val loss: 0.6696689153384221\n",
      "Epoch 180 val accuracy: 73.10855263157895\n",
      "Saved model to .\\test_modelsv2/MLP_180.pth\n",
      "Epoch 181 train loss: 0.6736916669301296\n",
      "Epoch 181 train accuracy: 72.14148615300246\n",
      "Epoch 181 val loss: 0.669620791352109\n",
      "Epoch 181 val accuracy: 73.10855263157895\n",
      "Saved model to .\\test_modelsv2/MLP_181.pth\n",
      "Epoch 182 train loss: 0.6736293666456875\n",
      "Epoch 182 train accuracy: 72.16890595009598\n",
      "Epoch 182 val loss: 0.669564303108736\n",
      "Epoch 182 val accuracy: 73.1907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_182.pth\n",
      "Epoch 183 train loss: 0.6735739547171091\n",
      "Epoch 183 train accuracy: 72.19632574718948\n",
      "Epoch 183 val loss: 0.6695099708281065\n",
      "Epoch 183 val accuracy: 73.1907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_183.pth\n",
      "Epoch 184 train loss: 0.6735124202412471\n",
      "Epoch 184 train accuracy: 72.22374554428298\n",
      "Epoch 184 val loss: 0.6694524087207882\n",
      "Epoch 184 val accuracy: 73.27302631578948\n",
      "Saved model to .\\test_modelsv2/MLP_184.pth\n",
      "Epoch 185 train loss: 0.6734584507189298\n",
      "Epoch 185 train accuracy: 72.16890595009598\n",
      "Epoch 185 val loss: 0.6693928677000498\n",
      "Epoch 185 val accuracy: 73.27302631578948\n",
      "Saved model to .\\test_modelsv2/MLP_185.pth\n",
      "Epoch 186 train loss: 0.6733983947911806\n",
      "Epoch 186 train accuracy: 72.22374554428298\n",
      "Epoch 186 val loss: 0.6693221774736517\n",
      "Epoch 186 val accuracy: 73.4375\n",
      "Saved model to .\\test_modelsv2/MLP_186.pth\n",
      "Epoch 187 train loss: 0.673313199330056\n",
      "Epoch 187 train accuracy: 72.27858513846998\n",
      "Epoch 187 val loss: 0.6692634045489525\n",
      "Epoch 187 val accuracy: 73.4375\n",
      "Saved model to .\\test_modelsv2/MLP_187.pth\n",
      "Epoch 188 train loss: 0.6733017103713855\n",
      "Epoch 188 train accuracy: 72.27858513846998\n",
      "Epoch 188 val loss: 0.6691862182985795\n",
      "Epoch 188 val accuracy: 73.51973684210526\n",
      "Saved model to .\\test_modelsv2/MLP_188.pth\n",
      "Epoch 189 train loss: 0.6732121050488531\n",
      "Epoch 189 train accuracy: 72.27858513846998\n",
      "Epoch 189 val loss: 0.669139369047786\n",
      "Epoch 189 val accuracy: 73.51973684210526\n",
      "Saved model to .\\test_modelsv2/MLP_189.pth\n",
      "Epoch 190 train loss: 0.6731155084674818\n",
      "Epoch 190 train accuracy: 72.30600493556348\n",
      "Epoch 190 val loss: 0.6690641300458657\n",
      "Epoch 190 val accuracy: 73.51973684210526\n",
      "Saved model to .\\test_modelsv2/MLP_190.pth\n",
      "Epoch 191 train loss: 0.6731253991132242\n",
      "Epoch 191 train accuracy: 72.33342473265698\n",
      "Epoch 191 val loss: 0.6689912314085584\n",
      "Epoch 191 val accuracy: 73.51973684210526\n",
      "Saved model to .\\test_modelsv2/MLP_191.pth\n",
      "Epoch 192 train loss: 0.6730646641042671\n",
      "Epoch 192 train accuracy: 72.33342473265698\n",
      "Epoch 192 val loss: 0.6689237912038439\n",
      "Epoch 192 val accuracy: 73.51973684210526\n",
      "Saved model to .\\test_modelsv2/MLP_192.pth\n",
      "Epoch 193 train loss: 0.6730350375240832\n",
      "Epoch 193 train accuracy: 72.38826432684398\n",
      "Epoch 193 val loss: 0.6688506331686911\n",
      "Epoch 193 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_193.pth\n",
      "Epoch 194 train loss: 0.6729316553917893\n",
      "Epoch 194 train accuracy: 72.33342473265698\n",
      "Epoch 194 val loss: 0.6687926012826594\n",
      "Epoch 194 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_194.pth\n",
      "Epoch 195 train loss: 0.672850205121856\n",
      "Epoch 195 train accuracy: 72.41568412393748\n",
      "Epoch 195 val loss: 0.6687208666025024\n",
      "Epoch 195 val accuracy: 73.6842105263158\n",
      "Saved model to .\\test_modelsv2/MLP_195.pth\n",
      "Epoch 196 train loss: 0.6728381179273129\n",
      "Epoch 196 train accuracy: 72.41568412393748\n",
      "Epoch 196 val loss: 0.6686516580613036\n",
      "Epoch 196 val accuracy: 73.6842105263158\n",
      "Saved model to .\\test_modelsv2/MLP_196.pth\n",
      "Epoch 197 train loss: 0.6727445415433562\n",
      "Epoch 197 train accuracy: 72.41568412393748\n",
      "Epoch 197 val loss: 0.668584677929941\n",
      "Epoch 197 val accuracy: 73.6842105263158\n",
      "Saved model to .\\test_modelsv2/MLP_197.pth\n",
      "Epoch 198 train loss: 0.6726932517465269\n",
      "Epoch 198 train accuracy: 72.44310392103098\n",
      "Epoch 198 val loss: 0.6685217009171059\n",
      "Epoch 198 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_198.pth\n",
      "Epoch 199 train loss: 0.6727419247556674\n",
      "Epoch 199 train accuracy: 72.52536331231148\n",
      "Epoch 199 val loss: 0.668448696305093\n",
      "Epoch 199 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_199.pth\n",
      "Epoch 200 train loss: 0.6726270697749498\n",
      "Epoch 200 train accuracy: 72.607622703592\n",
      "Epoch 200 val loss: 0.6684009644546007\n",
      "Epoch 200 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_200.pth\n",
      "Epoch 201 train loss: 0.6725802465031544\n",
      "Epoch 201 train accuracy: 72.607622703592\n",
      "Epoch 201 val loss: 0.6683576828555057\n",
      "Epoch 201 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_201.pth\n",
      "Epoch 202 train loss: 0.6725169766302171\n",
      "Epoch 202 train accuracy: 72.52536331231148\n",
      "Epoch 202 val loss: 0.6682832735149484\n",
      "Epoch 202 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_202.pth\n",
      "Epoch 203 train loss: 0.6724179300495929\n",
      "Epoch 203 train accuracy: 72.58020290649849\n",
      "Epoch 203 val loss: 0.6682231021358779\n",
      "Epoch 203 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_203.pth\n",
      "Epoch 204 train loss: 0.6724148768800915\n",
      "Epoch 204 train accuracy: 72.6350425006855\n",
      "Epoch 204 val loss: 0.6681668830937461\n",
      "Epoch 204 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_204.pth\n",
      "Epoch 205 train loss: 0.6723341378791813\n",
      "Epoch 205 train accuracy: 72.662462297779\n",
      "Epoch 205 val loss: 0.6681114499898333\n",
      "Epoch 205 val accuracy: 73.60197368421052\n",
      "Saved model to .\\test_modelsv2/MLP_205.pth\n",
      "Epoch 206 train loss: 0.6723247481542721\n",
      "Epoch 206 train accuracy: 72.6898820948725\n",
      "Epoch 206 val loss: 0.6680506506052456\n",
      "Epoch 206 val accuracy: 73.76644736842105\n",
      "Saved model to .\\test_modelsv2/MLP_206.pth\n",
      "Epoch 207 train loss: 0.6722357827647213\n",
      "Epoch 207 train accuracy: 72.6350425006855\n",
      "Epoch 207 val loss: 0.6679952387747011\n",
      "Epoch 207 val accuracy: 73.76644736842105\n",
      "Saved model to .\\test_modelsv2/MLP_207.pth\n",
      "Epoch 208 train loss: 0.6721773505733725\n",
      "Epoch 208 train accuracy: 72.607622703592\n",
      "Epoch 208 val loss: 0.6679326642892862\n",
      "Epoch 208 val accuracy: 73.76644736842105\n",
      "Saved model to .\\test_modelsv2/MLP_208.pth\n",
      "Epoch 209 train loss: 0.6721459076200661\n",
      "Epoch 209 train accuracy: 72.6898820948725\n",
      "Epoch 209 val loss: 0.6678621043500147\n",
      "Epoch 209 val accuracy: 74.01315789473684\n",
      "Saved model to .\\test_modelsv2/MLP_209.pth\n",
      "Epoch 210 train loss: 0.6721177085123041\n",
      "Epoch 210 train accuracy: 72.7447216890595\n",
      "Epoch 210 val loss: 0.6678005710832382\n",
      "Epoch 210 val accuracy: 74.01315789473684\n",
      "Saved model to .\\test_modelsv2/MLP_210.pth\n",
      "Epoch 211 train loss: 0.6720731937767643\n",
      "Epoch 211 train accuracy: 72.717301891966\n",
      "Epoch 211 val loss: 0.6677548906912929\n",
      "Epoch 211 val accuracy: 74.01315789473684\n",
      "Saved model to .\\test_modelsv2/MLP_211.pth\n",
      "Epoch 212 train loss: 0.6720110796261252\n",
      "Epoch 212 train accuracy: 72.7447216890595\n",
      "Epoch 212 val loss: 0.6677120166193498\n",
      "Epoch 212 val accuracy: 74.01315789473684\n",
      "Saved model to .\\test_modelsv2/MLP_212.pth\n",
      "Epoch 213 train loss: 0.6719492254942133\n",
      "Epoch 213 train accuracy: 72.82698108034\n",
      "Epoch 213 val loss: 0.6676552635862639\n",
      "Epoch 213 val accuracy: 74.01315789473684\n",
      "Saved model to .\\test_modelsv2/MLP_213.pth\n",
      "Epoch 214 train loss: 0.6719164831988644\n",
      "Epoch 214 train accuracy: 72.7995612832465\n",
      "Epoch 214 val loss: 0.6675947409515318\n",
      "Epoch 214 val accuracy: 74.09539473684211\n",
      "Saved model to .\\test_modelsv2/MLP_214.pth\n",
      "Epoch 215 train loss: 0.671885055800279\n",
      "Epoch 215 train accuracy: 72.772141486153\n",
      "Epoch 215 val loss: 0.667536542799912\n",
      "Epoch 215 val accuracy: 74.09539473684211\n",
      "Saved model to .\\test_modelsv2/MLP_215.pth\n",
      "Epoch 216 train loss: 0.6718155686139015\n",
      "Epoch 216 train accuracy: 72.881820674527\n",
      "Epoch 216 val loss: 0.6674847689114118\n",
      "Epoch 216 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_216.pth\n",
      "Epoch 217 train loss: 0.6717434022575617\n",
      "Epoch 217 train accuracy: 72.8544008774335\n",
      "Epoch 217 val loss: 0.6674452239745542\n",
      "Epoch 217 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_217.pth\n",
      "Epoch 218 train loss: 0.6716721309512331\n",
      "Epoch 218 train accuracy: 72.82698108034\n",
      "Epoch 218 val loss: 0.6673819897206206\n",
      "Epoch 218 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_218.pth\n",
      "Epoch 219 train loss: 0.6716670137094823\n",
      "Epoch 219 train accuracy: 72.96408006580751\n",
      "Epoch 219 val loss: 0.6673207879066467\n",
      "Epoch 219 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_219.pth\n",
      "Epoch 220 train loss: 0.671602618929587\n",
      "Epoch 220 train accuracy: 72.881820674527\n",
      "Epoch 220 val loss: 0.6672720944410876\n",
      "Epoch 220 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_220.pth\n",
      "Epoch 221 train loss: 0.6715369500023755\n",
      "Epoch 221 train accuracy: 72.96408006580751\n",
      "Epoch 221 val loss: 0.6672066220719564\n",
      "Epoch 221 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_221.pth\n",
      "Epoch 222 train loss: 0.6715565702567498\n",
      "Epoch 222 train accuracy: 72.93666026871401\n",
      "Epoch 222 val loss: 0.6671535905058447\n",
      "Epoch 222 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_222.pth\n",
      "Epoch 223 train loss: 0.6714672492980435\n",
      "Epoch 223 train accuracy: 72.881820674527\n",
      "Epoch 223 val loss: 0.6671081416701016\n",
      "Epoch 223 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_223.pth\n",
      "Epoch 224 train loss: 0.671456940439448\n",
      "Epoch 224 train accuracy: 72.99149986290101\n",
      "Epoch 224 val loss: 0.6670500747859478\n",
      "Epoch 224 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_224.pth\n",
      "Epoch 225 train loss: 0.6713626069392551\n",
      "Epoch 225 train accuracy: 72.93666026871401\n",
      "Epoch 225 val loss: 0.6670008313498998\n",
      "Epoch 225 val accuracy: 74.17763157894737\n",
      "Saved model to .\\test_modelsv2/MLP_225.pth\n",
      "Epoch 226 train loss: 0.6713528876568664\n",
      "Epoch 226 train accuracy: 72.99149986290101\n",
      "Epoch 226 val loss: 0.6669413123868013\n",
      "Epoch 226 val accuracy: 74.34210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_226.pth\n",
      "Epoch 227 train loss: 0.671304048284104\n",
      "Epoch 227 train accuracy: 72.96408006580751\n",
      "Epoch 227 val loss: 0.6668902182657468\n",
      "Epoch 227 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_227.pth\n",
      "Epoch 228 train loss: 0.6712368167283242\n",
      "Epoch 228 train accuracy: 72.96408006580751\n",
      "Epoch 228 val loss: 0.6668368788730157\n",
      "Epoch 228 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_228.pth\n",
      "Epoch 229 train loss: 0.6712662667166769\n",
      "Epoch 229 train accuracy: 73.04633945708802\n",
      "Epoch 229 val loss: 0.6667818497670325\n",
      "Epoch 229 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_229.pth\n",
      "Epoch 230 train loss: 0.6711754364271959\n",
      "Epoch 230 train accuracy: 73.01891965999451\n",
      "Epoch 230 val loss: 0.6667377183115796\n",
      "Epoch 230 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_230.pth\n",
      "Epoch 231 train loss: 0.6711587336633289\n",
      "Epoch 231 train accuracy: 73.01891965999451\n",
      "Epoch 231 val loss: 0.6666867042842665\n",
      "Epoch 231 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_231.pth\n",
      "Epoch 232 train loss: 0.671067568163077\n",
      "Epoch 232 train accuracy: 73.01891965999451\n",
      "Epoch 232 val loss: 0.6666296161711216\n",
      "Epoch 232 val accuracy: 74.34210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_232.pth\n",
      "Epoch 233 train loss: 0.6710337978836737\n",
      "Epoch 233 train accuracy: 73.07375925418152\n",
      "Epoch 233 val loss: 0.6665874935294452\n",
      "Epoch 233 val accuracy: 74.34210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_233.pth\n",
      "Epoch 234 train loss: 0.6710090174159983\n",
      "Epoch 234 train accuracy: 73.07375925418152\n",
      "Epoch 234 val loss: 0.6665341927620926\n",
      "Epoch 234 val accuracy: 74.34210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_234.pth\n",
      "Epoch 235 train loss: 0.6709580655422127\n",
      "Epoch 235 train accuracy: 73.07375925418152\n",
      "Epoch 235 val loss: 0.6664674140905079\n",
      "Epoch 235 val accuracy: 74.34210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_235.pth\n",
      "Epoch 236 train loss: 0.6709257343359161\n",
      "Epoch 236 train accuracy: 73.01891965999451\n",
      "Epoch 236 val loss: 0.6664263670773882\n",
      "Epoch 236 val accuracy: 74.34210526315789\n",
      "Saved model to .\\test_modelsv2/MLP_236.pth\n",
      "Epoch 237 train loss: 0.670856660166592\n",
      "Epoch 237 train accuracy: 73.04633945708802\n",
      "Epoch 237 val loss: 0.6663663365731114\n",
      "Epoch 237 val accuracy: 74.42434210526316\n",
      "Saved model to .\\test_modelsv2/MLP_237.pth\n",
      "Epoch 238 train loss: 0.6708366605208108\n",
      "Epoch 238 train accuracy: 73.07375925418152\n",
      "Epoch 238 val loss: 0.6663232411404973\n",
      "Epoch 238 val accuracy: 74.42434210526316\n",
      "Saved model to .\\test_modelsv2/MLP_238.pth\n",
      "Epoch 239 train loss: 0.6708031376464325\n",
      "Epoch 239 train accuracy: 73.07375925418152\n",
      "Epoch 239 val loss: 0.6662751026451588\n",
      "Epoch 239 val accuracy: 74.50657894736842\n",
      "Saved model to .\\test_modelsv2/MLP_239.pth\n",
      "Epoch 240 train loss: 0.6707825298960272\n",
      "Epoch 240 train accuracy: 73.10117905127503\n",
      "Epoch 240 val loss: 0.6662101189752943\n",
      "Epoch 240 val accuracy: 74.58881578947368\n",
      "Saved model to .\\test_modelsv2/MLP_240.pth\n",
      "Epoch 241 train loss: 0.6707033588828748\n",
      "Epoch 241 train accuracy: 73.04633945708802\n",
      "Epoch 241 val loss: 0.6661722076762664\n",
      "Epoch 241 val accuracy: 74.58881578947368\n",
      "Saved model to .\\test_modelsv2/MLP_241.pth\n",
      "Epoch 242 train loss: 0.6706882789731026\n",
      "Epoch 242 train accuracy: 73.04633945708802\n",
      "Epoch 242 val loss: 0.666117430517548\n",
      "Epoch 242 val accuracy: 74.67105263157895\n",
      "Saved model to .\\test_modelsv2/MLP_242.pth\n",
      "Epoch 243 train loss: 0.6706460249659262\n",
      "Epoch 243 train accuracy: 73.01891965999451\n",
      "Epoch 243 val loss: 0.6660605566085953\n",
      "Epoch 243 val accuracy: 74.67105263157895\n",
      "Saved model to .\\test_modelsv2/MLP_243.pth\n",
      "Epoch 244 train loss: 0.6706101486230629\n",
      "Epoch 244 train accuracy: 73.04633945708802\n",
      "Epoch 244 val loss: 0.6660190807949555\n",
      "Epoch 244 val accuracy: 74.67105263157895\n",
      "Saved model to .\\test_modelsv2/MLP_244.pth\n",
      "Epoch 245 train loss: 0.6705636355633798\n",
      "Epoch 245 train accuracy: 73.01891965999451\n",
      "Epoch 245 val loss: 0.665972844648518\n",
      "Epoch 245 val accuracy: 74.67105263157895\n",
      "Saved model to .\\test_modelsv2/MLP_245.pth\n",
      "Epoch 246 train loss: 0.6705314543490347\n",
      "Epoch 246 train accuracy: 73.04633945708802\n",
      "Epoch 246 val loss: 0.6659547545407948\n",
      "Epoch 246 val accuracy: 74.67105263157895\n",
      "Saved model to .\\test_modelsv2/MLP_246.pth\n",
      "Epoch 247 train loss: 0.6704947803038777\n",
      "Epoch 247 train accuracy: 73.04633945708802\n",
      "Epoch 247 val loss: 0.665894912163678\n",
      "Epoch 247 val accuracy: 74.7532894736842\n",
      "Saved model to .\\test_modelsv2/MLP_247.pth\n",
      "Epoch 248 train loss: 0.6704491157934331\n",
      "Epoch 248 train accuracy: 73.10117905127503\n",
      "Epoch 248 val loss: 0.6658580330641646\n",
      "Epoch 248 val accuracy: 74.7532894736842\n",
      "Saved model to .\\test_modelsv2/MLP_248.pth\n",
      "Epoch 249 train loss: 0.6704198442595569\n",
      "Epoch 249 train accuracy: 73.04633945708802\n",
      "Epoch 249 val loss: 0.6658014757068533\n",
      "Epoch 249 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_249.pth\n",
      "Epoch 250 train loss: 0.6703851603690469\n",
      "Epoch 250 train accuracy: 73.10117905127503\n",
      "Epoch 250 val loss: 0.6657618174427434\n",
      "Epoch 250 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_250.pth\n",
      "Epoch 251 train loss: 0.6703462733053848\n",
      "Epoch 251 train accuracy: 73.04633945708802\n",
      "Epoch 251 val loss: 0.6657121517744503\n",
      "Epoch 251 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_251.pth\n",
      "Epoch 252 train loss: 0.670291392001928\n",
      "Epoch 252 train accuracy: 73.04633945708802\n",
      "Epoch 252 val loss: 0.6656800685940605\n",
      "Epoch 252 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_252.pth\n",
      "Epoch 253 train loss: 0.6702450024650285\n",
      "Epoch 253 train accuracy: 73.04633945708802\n",
      "Epoch 253 val loss: 0.6656339489119617\n",
      "Epoch 253 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_253.pth\n",
      "Epoch 254 train loss: 0.6702286740928366\n",
      "Epoch 254 train accuracy: 73.07375925418152\n",
      "Epoch 254 val loss: 0.6656013667387398\n",
      "Epoch 254 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_254.pth\n",
      "Epoch 255 train loss: 0.6701700749496619\n",
      "Epoch 255 train accuracy: 73.07375925418152\n",
      "Epoch 255 val loss: 0.6655515524509706\n",
      "Epoch 255 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_255.pth\n",
      "Epoch 256 train loss: 0.6702058107445115\n",
      "Epoch 256 train accuracy: 73.04633945708802\n",
      "Epoch 256 val loss: 0.6655034849322156\n",
      "Epoch 256 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_256.pth\n",
      "Epoch 257 train loss: 0.6701273441380053\n",
      "Epoch 257 train accuracy: 73.07375925418152\n",
      "Epoch 257 val loss: 0.6654685356311107\n",
      "Epoch 257 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_257.pth\n",
      "Epoch 258 train loss: 0.6700772658774727\n",
      "Epoch 258 train accuracy: 73.04633945708802\n",
      "Epoch 258 val loss: 0.6654257327318192\n",
      "Epoch 258 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_258.pth\n",
      "Epoch 259 train loss: 0.670060827674573\n",
      "Epoch 259 train accuracy: 73.07375925418152\n",
      "Epoch 259 val loss: 0.6653826915119824\n",
      "Epoch 259 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_259.pth\n",
      "Epoch 260 train loss: 0.670006102114393\n",
      "Epoch 260 train accuracy: 73.04633945708802\n",
      "Epoch 260 val loss: 0.6653338577598333\n",
      "Epoch 260 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_260.pth\n",
      "Epoch 261 train loss: 0.6699906554595944\n",
      "Epoch 261 train accuracy: 73.07375925418152\n",
      "Epoch 261 val loss: 0.6652997302773752\n",
      "Epoch 261 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_261.pth\n",
      "Epoch 262 train loss: 0.6699342903795472\n",
      "Epoch 262 train accuracy: 73.04633945708802\n",
      "Epoch 262 val loss: 0.6652539063637194\n",
      "Epoch 262 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_262.pth\n",
      "Epoch 263 train loss: 0.6699109413710079\n",
      "Epoch 263 train accuracy: 73.07375925418152\n",
      "Epoch 263 val loss: 0.6652196379084336\n",
      "Epoch 263 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_263.pth\n",
      "Epoch 264 train loss: 0.669875040062164\n",
      "Epoch 264 train accuracy: 73.07375925418152\n",
      "Epoch 264 val loss: 0.66515210378719\n",
      "Epoch 264 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_264.pth\n",
      "Epoch 265 train loss: 0.6698825127984348\n",
      "Epoch 265 train accuracy: 73.23827803674253\n",
      "Epoch 265 val loss: 0.6651190277189016\n",
      "Epoch 265 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_265.pth\n",
      "Epoch 266 train loss: 0.6698119338078979\n",
      "Epoch 266 train accuracy: 73.07375925418152\n",
      "Epoch 266 val loss: 0.6650761226682287\n",
      "Epoch 266 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_266.pth\n",
      "Epoch 267 train loss: 0.669773166509051\n",
      "Epoch 267 train accuracy: 73.12859884836853\n",
      "Epoch 267 val loss: 0.6650335463254076\n",
      "Epoch 267 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_267.pth\n",
      "Epoch 268 train loss: 0.6697071876311511\n",
      "Epoch 268 train accuracy: 73.10117905127503\n",
      "Epoch 268 val loss: 0.664983340980191\n",
      "Epoch 268 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_268.pth\n",
      "Epoch 269 train loss: 0.6696858343325163\n",
      "Epoch 269 train accuracy: 73.12859884836853\n",
      "Epoch 269 val loss: 0.664931855801689\n",
      "Epoch 269 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_269.pth\n",
      "Epoch 270 train loss: 0.6696438813222605\n",
      "Epoch 270 train accuracy: 73.10117905127503\n",
      "Epoch 270 val loss: 0.6648733904095072\n",
      "Epoch 270 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_270.pth\n",
      "Epoch 271 train loss: 0.6695997483636204\n",
      "Epoch 271 train accuracy: 73.34795722511653\n",
      "Epoch 271 val loss: 0.6648483278327867\n",
      "Epoch 271 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_271.pth\n",
      "Epoch 272 train loss: 0.6696037266468793\n",
      "Epoch 272 train accuracy: 73.21085823964903\n",
      "Epoch 272 val loss: 0.6648053047492316\n",
      "Epoch 272 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_272.pth\n",
      "Epoch 273 train loss: 0.669575541361905\n",
      "Epoch 273 train accuracy: 73.23827803674253\n",
      "Epoch 273 val loss: 0.6647745325769249\n",
      "Epoch 273 val accuracy: 74.83552631578948\n",
      "Saved model to .\\test_modelsv2/MLP_273.pth\n",
      "Epoch 274 train loss: 0.6695408395965371\n",
      "Epoch 274 train accuracy: 73.21085823964903\n",
      "Epoch 274 val loss: 0.6647264680972225\n",
      "Epoch 274 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_274.pth\n",
      "Epoch 275 train loss: 0.6694758565475544\n",
      "Epoch 275 train accuracy: 73.21085823964903\n",
      "Epoch 275 val loss: 0.6646839841023872\n",
      "Epoch 275 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_275.pth\n",
      "Epoch 276 train loss: 0.6694729408543361\n",
      "Epoch 276 train accuracy: 73.23827803674253\n",
      "Epoch 276 val loss: 0.6646330289934811\n",
      "Epoch 276 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_276.pth\n",
      "Epoch 277 train loss: 0.669415065365141\n",
      "Epoch 277 train accuracy: 73.26569783383603\n",
      "Epoch 277 val loss: 0.6645969460277181\n",
      "Epoch 277 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_277.pth\n",
      "Epoch 278 train loss: 0.6693586000943916\n",
      "Epoch 278 train accuracy: 73.32053742802303\n",
      "Epoch 278 val loss: 0.6645471071334261\n",
      "Epoch 278 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_278.pth\n",
      "Epoch 279 train loss: 0.6693675428824989\n",
      "Epoch 279 train accuracy: 73.40279681930353\n",
      "Epoch 279 val loss: 0.6645146370130149\n",
      "Epoch 279 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_279.pth\n",
      "Epoch 280 train loss: 0.669314413445822\n",
      "Epoch 280 train accuracy: 73.37537702221003\n",
      "Epoch 280 val loss: 0.6644673738628626\n",
      "Epoch 280 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_280.pth\n",
      "Epoch 281 train loss: 0.6692989317275453\n",
      "Epoch 281 train accuracy: 73.34795722511653\n",
      "Epoch 281 val loss: 0.6644253565096542\n",
      "Epoch 281 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_281.pth\n",
      "Epoch 282 train loss: 0.6693031279076087\n",
      "Epoch 282 train accuracy: 73.34795722511653\n",
      "Epoch 282 val loss: 0.6643926101295572\n",
      "Epoch 282 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_282.pth\n",
      "Epoch 283 train loss: 0.6692974972947124\n",
      "Epoch 283 train accuracy: 73.48505621058405\n",
      "Epoch 283 val loss: 0.6643627010481922\n",
      "Epoch 283 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_283.pth\n",
      "Epoch 284 train loss: 0.6692271633890637\n",
      "Epoch 284 train accuracy: 73.37537702221003\n",
      "Epoch 284 val loss: 0.6643319351500586\n",
      "Epoch 284 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_284.pth\n",
      "Epoch 285 train loss: 0.6691789865297707\n",
      "Epoch 285 train accuracy: 73.48505621058405\n",
      "Epoch 285 val loss: 0.6642851702084667\n",
      "Epoch 285 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_285.pth\n",
      "Epoch 286 train loss: 0.6691328883497861\n",
      "Epoch 286 train accuracy: 73.43021661639703\n",
      "Epoch 286 val loss: 0.6642527609671417\n",
      "Epoch 286 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_286.pth\n",
      "Epoch 287 train loss: 0.6691213302444994\n",
      "Epoch 287 train accuracy: 73.40279681930353\n",
      "Epoch 287 val loss: 0.6642085563783583\n",
      "Epoch 287 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_287.pth\n",
      "Epoch 288 train loss: 0.6690761178013003\n",
      "Epoch 288 train accuracy: 73.45763641349053\n",
      "Epoch 288 val loss: 0.6641803423040792\n",
      "Epoch 288 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_288.pth\n",
      "Epoch 289 train loss: 0.6690569369351131\n",
      "Epoch 289 train accuracy: 73.48505621058405\n",
      "Epoch 289 val loss: 0.6641485839101829\n",
      "Epoch 289 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_289.pth\n",
      "Epoch 290 train loss: 0.6690435197138995\n",
      "Epoch 290 train accuracy: 73.48505621058405\n",
      "Epoch 290 val loss: 0.6641036983775465\n",
      "Epoch 290 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_290.pth\n",
      "Epoch 291 train loss: 0.6689256116943924\n",
      "Epoch 291 train accuracy: 73.43021661639703\n",
      "Epoch 291 val loss: 0.6640687277050394\n",
      "Epoch 291 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_291.pth\n",
      "Epoch 292 train loss: 0.6689903548216087\n",
      "Epoch 292 train accuracy: 73.48505621058405\n",
      "Epoch 292 val loss: 0.664041657098814\n",
      "Epoch 292 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_292.pth\n",
      "Epoch 293 train loss: 0.6689074152525056\n",
      "Epoch 293 train accuracy: 73.45763641349053\n",
      "Epoch 293 val loss: 0.6639958923976672\n",
      "Epoch 293 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_293.pth\n",
      "Epoch 294 train loss: 0.6689281091420797\n",
      "Epoch 294 train accuracy: 73.51247600767755\n",
      "Epoch 294 val loss: 0.6639563986345342\n",
      "Epoch 294 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_294.pth\n",
      "Epoch 295 train loss: 0.6688481128790922\n",
      "Epoch 295 train accuracy: 73.45763641349053\n",
      "Epoch 295 val loss: 0.6639317003519911\n",
      "Epoch 295 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_295.pth\n",
      "Epoch 296 train loss: 0.668869374352589\n",
      "Epoch 296 train accuracy: 73.45763641349053\n",
      "Epoch 296 val loss: 0.6638882875834641\n",
      "Epoch 296 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_296.pth\n",
      "Epoch 297 train loss: 0.6688787016298687\n",
      "Epoch 297 train accuracy: 73.45763641349053\n",
      "Epoch 297 val loss: 0.6638518773803586\n",
      "Epoch 297 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_297.pth\n",
      "Epoch 298 train loss: 0.6688135820195863\n",
      "Epoch 298 train accuracy: 73.53989580477105\n",
      "Epoch 298 val loss: 0.6638204301462362\n",
      "Epoch 298 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_298.pth\n",
      "Epoch 299 train loss: 0.6687855167281732\n",
      "Epoch 299 train accuracy: 73.51247600767755\n",
      "Epoch 299 val loss: 0.6637908691834462\n",
      "Epoch 299 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_299.pth\n",
      "Epoch 300 train loss: 0.6687672221542973\n",
      "Epoch 300 train accuracy: 73.53989580477105\n",
      "Epoch 300 val loss: 0.6637479400164202\n",
      "Epoch 300 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_300.pth\n",
      "Epoch 301 train loss: 0.6686876092040748\n",
      "Epoch 301 train accuracy: 73.51247600767755\n",
      "Epoch 301 val loss: 0.6637185951204676\n",
      "Epoch 301 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_301.pth\n",
      "Epoch 302 train loss: 0.6686980425331154\n",
      "Epoch 302 train accuracy: 73.62215519605155\n",
      "Epoch 302 val loss: 0.6636839636454457\n",
      "Epoch 302 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_302.pth\n",
      "Epoch 303 train loss: 0.6686677256631747\n",
      "Epoch 303 train accuracy: 73.51247600767755\n",
      "Epoch 303 val loss: 0.6636549549079255\n",
      "Epoch 303 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_303.pth\n",
      "Epoch 304 train loss: 0.6686388003525504\n",
      "Epoch 304 train accuracy: 73.51247600767755\n",
      "Epoch 304 val loss: 0.6636216260100666\n",
      "Epoch 304 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_304.pth\n",
      "Epoch 305 train loss: 0.6685788330474967\n",
      "Epoch 305 train accuracy: 73.62215519605155\n",
      "Epoch 305 val loss: 0.663591168820858\n",
      "Epoch 305 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_305.pth\n",
      "Epoch 306 train loss: 0.6685857937197414\n",
      "Epoch 306 train accuracy: 73.62215519605155\n",
      "Epoch 306 val loss: 0.663557564251517\n",
      "Epoch 306 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_306.pth\n",
      "Epoch 307 train loss: 0.6685528322858246\n",
      "Epoch 307 train accuracy: 73.56731560186455\n",
      "Epoch 307 val loss: 0.6635144252918268\n",
      "Epoch 307 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_307.pth\n",
      "Epoch 308 train loss: 0.668541043768065\n",
      "Epoch 308 train accuracy: 73.70441458733205\n",
      "Epoch 308 val loss: 0.6634809595385665\n",
      "Epoch 308 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_308.pth\n",
      "Epoch 309 train loss: 0.6684671595954058\n",
      "Epoch 309 train accuracy: 73.62215519605155\n",
      "Epoch 309 val loss: 0.6634488992000881\n",
      "Epoch 309 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_309.pth\n",
      "Epoch 310 train loss: 0.668468996228879\n",
      "Epoch 310 train accuracy: 73.73183438442555\n",
      "Epoch 310 val loss: 0.6634170225772419\n",
      "Epoch 310 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_310.pth\n",
      "Epoch 311 train loss: 0.6684438890793867\n",
      "Epoch 311 train accuracy: 73.75925418151905\n",
      "Epoch 311 val loss: 0.6633787374747427\n",
      "Epoch 311 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_311.pth\n",
      "Epoch 312 train loss: 0.6684198601726901\n",
      "Epoch 312 train accuracy: 73.62215519605155\n",
      "Epoch 312 val loss: 0.6633531772776654\n",
      "Epoch 312 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_312.pth\n",
      "Epoch 313 train loss: 0.6683878447664412\n",
      "Epoch 313 train accuracy: 73.78667397861255\n",
      "Epoch 313 val loss: 0.6633159378053326\n",
      "Epoch 313 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_313.pth\n",
      "Epoch 314 train loss: 0.6683206324253166\n",
      "Epoch 314 train accuracy: 73.64957499314505\n",
      "Epoch 314 val loss: 0.6632774332048077\n",
      "Epoch 314 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_314.pth\n",
      "Epoch 315 train loss: 0.6683377693488932\n",
      "Epoch 315 train accuracy: 73.70441458733205\n",
      "Epoch 315 val loss: 0.663240828600369\n",
      "Epoch 315 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_315.pth\n",
      "Epoch 316 train loss: 0.6683225987250345\n",
      "Epoch 316 train accuracy: 73.75925418151905\n",
      "Epoch 316 val loss: 0.6632068119943142\n",
      "Epoch 316 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_316.pth\n",
      "Epoch 317 train loss: 0.6682757285276526\n",
      "Epoch 317 train accuracy: 73.78667397861255\n",
      "Epoch 317 val loss: 0.6631829342559764\n",
      "Epoch 317 val accuracy: 74.91776315789474\n",
      "Saved model to .\\test_modelsv2/MLP_317.pth\n",
      "Epoch 318 train loss: 0.6682638456031942\n",
      "Epoch 318 train accuracy: 73.75925418151905\n",
      "Epoch 318 val loss: 0.6631459570244739\n",
      "Epoch 318 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_318.pth\n",
      "Epoch 319 train loss: 0.6682785314164663\n",
      "Epoch 319 train accuracy: 73.73183438442555\n",
      "Epoch 319 val loss: 0.6631090584162035\n",
      "Epoch 319 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_319.pth\n",
      "Epoch 320 train loss: 0.6682369727314564\n",
      "Epoch 320 train accuracy: 73.73183438442555\n",
      "Epoch 320 val loss: 0.6630829465820601\n",
      "Epoch 320 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_320.pth\n",
      "Epoch 321 train loss: 0.668103752853839\n",
      "Epoch 321 train accuracy: 73.75925418151905\n",
      "Epoch 321 val loss: 0.6630519420692795\n",
      "Epoch 321 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_321.pth\n",
      "Epoch 322 train loss: 0.6681506080520258\n",
      "Epoch 322 train accuracy: 73.81409377570606\n",
      "Epoch 322 val loss: 0.6630192704890904\n",
      "Epoch 322 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_322.pth\n",
      "Epoch 323 train loss: 0.6680552697364699\n",
      "Epoch 323 train accuracy: 73.75925418151905\n",
      "Epoch 323 val loss: 0.6629866115552815\n",
      "Epoch 323 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_323.pth\n",
      "Epoch 324 train loss: 0.6680945631508765\n",
      "Epoch 324 train accuracy: 73.84151357279956\n",
      "Epoch 324 val loss: 0.6629482195957711\n",
      "Epoch 324 val accuracy: 75.0\n",
      "Saved model to .\\test_modelsv2/MLP_324.pth\n",
      "Epoch 325 train loss: 0.6680745126254726\n",
      "Epoch 325 train accuracy: 73.70441458733205\n",
      "Epoch 325 val loss: 0.6629158885855424\n",
      "Epoch 325 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_325.pth\n",
      "Epoch 326 train loss: 0.6680238993446294\n",
      "Epoch 326 train accuracy: 73.78667397861255\n",
      "Epoch 326 val loss: 0.6628839901011241\n",
      "Epoch 326 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_326.pth\n",
      "Epoch 327 train loss: 0.6679822567915707\n",
      "Epoch 327 train accuracy: 73.84151357279956\n",
      "Epoch 327 val loss: 0.6628516694824946\n",
      "Epoch 327 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_327.pth\n",
      "Epoch 328 train loss: 0.6679927797563243\n",
      "Epoch 328 train accuracy: 73.84151357279956\n",
      "Epoch 328 val loss: 0.6628145338281205\n",
      "Epoch 328 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_328.pth\n",
      "Epoch 329 train loss: 0.66796829022075\n",
      "Epoch 329 train accuracy: 73.81409377570606\n",
      "Epoch 329 val loss: 0.6627872588210985\n",
      "Epoch 329 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_329.pth\n",
      "Epoch 330 train loss: 0.6679454250097797\n",
      "Epoch 330 train accuracy: 73.81409377570606\n",
      "Epoch 330 val loss: 0.6627525033331231\n",
      "Epoch 330 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_330.pth\n",
      "Epoch 331 train loss: 0.6679192581132316\n",
      "Epoch 331 train accuracy: 73.84151357279956\n",
      "Epoch 331 val loss: 0.6627236954671772\n",
      "Epoch 331 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_331.pth\n",
      "Epoch 332 train loss: 0.6678806072787234\n",
      "Epoch 332 train accuracy: 73.81409377570606\n",
      "Epoch 332 val loss: 0.6626860027838695\n",
      "Epoch 332 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_332.pth\n",
      "Epoch 333 train loss: 0.6678889334005745\n",
      "Epoch 333 train accuracy: 73.81409377570606\n",
      "Epoch 333 val loss: 0.6626566075964978\n",
      "Epoch 333 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_333.pth\n",
      "Epoch 334 train loss: 0.6678016745534382\n",
      "Epoch 334 train accuracy: 73.84151357279956\n",
      "Epoch 334 val loss: 0.6626357327362424\n",
      "Epoch 334 val accuracy: 75.08223684210526\n",
      "Saved model to .\\test_modelsv2/MLP_334.pth\n",
      "Epoch 335 train loss: 0.6677802526637128\n",
      "Epoch 335 train accuracy: 73.78667397861255\n",
      "Epoch 335 val loss: 0.6625875870844251\n",
      "Epoch 335 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_335.pth\n",
      "Epoch 336 train loss: 0.6677887240065294\n",
      "Epoch 336 train accuracy: 73.78667397861255\n",
      "Epoch 336 val loss: 0.6625616272029123\n",
      "Epoch 336 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_336.pth\n",
      "Epoch 337 train loss: 0.6677568682975936\n",
      "Epoch 337 train accuracy: 73.73183438442555\n",
      "Epoch 337 val loss: 0.6625321564313612\n",
      "Epoch 337 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_337.pth\n",
      "Epoch 338 train loss: 0.6677418143341416\n",
      "Epoch 338 train accuracy: 73.78667397861255\n",
      "Epoch 338 val loss: 0.6625028070258466\n",
      "Epoch 338 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_338.pth\n",
      "Epoch 339 train loss: 0.6677293518329399\n",
      "Epoch 339 train accuracy: 73.78667397861255\n",
      "Epoch 339 val loss: 0.6624620471541819\n",
      "Epoch 339 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_339.pth\n",
      "Epoch 340 train loss: 0.6676891183382586\n",
      "Epoch 340 train accuracy: 73.78667397861255\n",
      "Epoch 340 val loss: 0.6624279413372278\n",
      "Epoch 340 val accuracy: 75.16447368421052\n",
      "Saved model to .\\test_modelsv2/MLP_340.pth\n",
      "Epoch 341 train loss: 0.6676354669034481\n",
      "Epoch 341 train accuracy: 73.78667397861255\n",
      "Epoch 341 val loss: 0.6623878677032495\n",
      "Epoch 341 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_341.pth\n",
      "Epoch 342 train loss: 0.6676981732445327\n",
      "Epoch 342 train accuracy: 73.78667397861255\n",
      "Epoch 342 val loss: 0.6623608796416145\n",
      "Epoch 342 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_342.pth\n",
      "Epoch 343 train loss: 0.6676000216485638\n",
      "Epoch 343 train accuracy: 73.78667397861255\n",
      "Epoch 343 val loss: 0.6623260778816122\n",
      "Epoch 343 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_343.pth\n",
      "Epoch 344 train loss: 0.6676663369789981\n",
      "Epoch 344 train accuracy: 73.75925418151905\n",
      "Epoch 344 val loss: 0.6622858678824023\n",
      "Epoch 344 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_344.pth\n",
      "Epoch 345 train loss: 0.6675705761044172\n",
      "Epoch 345 train accuracy: 73.81409377570606\n",
      "Epoch 345 val loss: 0.662267420833048\n",
      "Epoch 345 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_345.pth\n",
      "Epoch 346 train loss: 0.6676221181099352\n",
      "Epoch 346 train accuracy: 73.81409377570606\n",
      "Epoch 346 val loss: 0.6622414793819189\n",
      "Epoch 346 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_346.pth\n",
      "Epoch 347 train loss: 0.6674995374326643\n",
      "Epoch 347 train accuracy: 73.78667397861255\n",
      "Epoch 347 val loss: 0.6622150389379576\n",
      "Epoch 347 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_347.pth\n",
      "Epoch 348 train loss: 0.6674995158325162\n",
      "Epoch 348 train accuracy: 73.78667397861255\n",
      "Epoch 348 val loss: 0.6621797623014763\n",
      "Epoch 348 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_348.pth\n",
      "Epoch 349 train loss: 0.6674353112711718\n",
      "Epoch 349 train accuracy: 73.75925418151905\n",
      "Epoch 349 val loss: 0.6621365739326728\n",
      "Epoch 349 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_349.pth\n",
      "Epoch 350 train loss: 0.6674258979527574\n",
      "Epoch 350 train accuracy: 73.78667397861255\n",
      "Epoch 350 val loss: 0.6620968968460434\n",
      "Epoch 350 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_350.pth\n",
      "Epoch 351 train loss: 0.6674075330558576\n",
      "Epoch 351 train accuracy: 73.81409377570606\n",
      "Epoch 351 val loss: 0.6620783090199295\n",
      "Epoch 351 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_351.pth\n",
      "Epoch 352 train loss: 0.667313104626118\n",
      "Epoch 352 train accuracy: 73.84151357279956\n",
      "Epoch 352 val loss: 0.6620532331105909\n",
      "Epoch 352 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_352.pth\n",
      "Epoch 353 train loss: 0.6673622588839447\n",
      "Epoch 353 train accuracy: 73.81409377570606\n",
      "Epoch 353 val loss: 0.6620200110697433\n",
      "Epoch 353 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_353.pth\n",
      "Epoch 354 train loss: 0.6673694578440565\n",
      "Epoch 354 train accuracy: 73.75925418151905\n",
      "Epoch 354 val loss: 0.6619763409620837\n",
      "Epoch 354 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_354.pth\n",
      "Epoch 355 train loss: 0.6673895130750903\n",
      "Epoch 355 train accuracy: 73.84151357279956\n",
      "Epoch 355 val loss: 0.6619428117808542\n",
      "Epoch 355 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_355.pth\n",
      "Epoch 356 train loss: 0.6673832334120545\n",
      "Epoch 356 train accuracy: 73.86893336989306\n",
      "Epoch 356 val loss: 0.6619181769262803\n",
      "Epoch 356 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_356.pth\n",
      "Epoch 357 train loss: 0.6672677604906392\n",
      "Epoch 357 train accuracy: 73.86893336989306\n",
      "Epoch 357 val loss: 0.6618835085904912\n",
      "Epoch 357 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_357.pth\n",
      "Epoch 358 train loss: 0.6672535973290602\n",
      "Epoch 358 train accuracy: 73.86893336989306\n",
      "Epoch 358 val loss: 0.661849718246805\n",
      "Epoch 358 val accuracy: 75.2467105263158\n",
      "Saved model to .\\test_modelsv2/MLP_358.pth\n",
      "Epoch 359 train loss: 0.6671741596962276\n",
      "Epoch 359 train accuracy: 73.89635316698656\n",
      "Epoch 359 val loss: 0.6618179996546946\n",
      "Epoch 359 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_359.pth\n",
      "Epoch 360 train loss: 0.6672250039614084\n",
      "Epoch 360 train accuracy: 73.92377296408007\n",
      "Epoch 360 val loss: 0.6617879159748554\n",
      "Epoch 360 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_360.pth\n",
      "Epoch 361 train loss: 0.6671515630002607\n",
      "Epoch 361 train accuracy: 73.89635316698656\n",
      "Epoch 361 val loss: 0.6617539908344808\n",
      "Epoch 361 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_361.pth\n",
      "Epoch 362 train loss: 0.6671376990383131\n",
      "Epoch 362 train accuracy: 73.84151357279956\n",
      "Epoch 362 val loss: 0.6617226609470028\n",
      "Epoch 362 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_362.pth\n",
      "Epoch 363 train loss: 0.6671728963326466\n",
      "Epoch 363 train accuracy: 73.92377296408007\n",
      "Epoch 363 val loss: 0.6616931972338965\n",
      "Epoch 363 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_363.pth\n",
      "Epoch 364 train loss: 0.6671126672442544\n",
      "Epoch 364 train accuracy: 73.92377296408007\n",
      "Epoch 364 val loss: 0.6616623787895629\n",
      "Epoch 364 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_364.pth\n",
      "Epoch 365 train loss: 0.6671301003937659\n",
      "Epoch 365 train accuracy: 73.95119276117357\n",
      "Epoch 365 val loss: 0.6616354220987934\n",
      "Epoch 365 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_365.pth\n",
      "Epoch 366 train loss: 0.6671108260685414\n",
      "Epoch 366 train accuracy: 73.89635316698656\n",
      "Epoch 366 val loss: 0.6615988949411794\n",
      "Epoch 366 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_366.pth\n",
      "Epoch 367 train loss: 0.6671128045244697\n",
      "Epoch 367 train accuracy: 73.89635316698656\n",
      "Epoch 367 val loss: 0.6615867545141986\n",
      "Epoch 367 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_367.pth\n",
      "Epoch 368 train loss: 0.6670878863844433\n",
      "Epoch 368 train accuracy: 73.92377296408007\n",
      "Epoch 368 val loss: 0.6615528919194874\n",
      "Epoch 368 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_368.pth\n",
      "Epoch 369 train loss: 0.6670408942328211\n",
      "Epoch 369 train accuracy: 73.92377296408007\n",
      "Epoch 369 val loss: 0.661524369724487\n",
      "Epoch 369 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_369.pth\n",
      "Epoch 370 train loss: 0.6670063168071864\n",
      "Epoch 370 train accuracy: 73.92377296408007\n",
      "Epoch 370 val loss: 0.6614982954373485\n",
      "Epoch 370 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_370.pth\n",
      "Epoch 371 train loss: 0.6669823542694774\n",
      "Epoch 371 train accuracy: 73.97861255826707\n",
      "Epoch 371 val loss: 0.6614714952087716\n",
      "Epoch 371 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_371.pth\n",
      "Epoch 372 train loss: 0.6670052443157163\n",
      "Epoch 372 train accuracy: 73.95119276117357\n",
      "Epoch 372 val loss: 0.6614336990016071\n",
      "Epoch 372 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_372.pth\n",
      "Epoch 373 train loss: 0.6669647622069246\n",
      "Epoch 373 train accuracy: 73.92377296408007\n",
      "Epoch 373 val loss: 0.6614045931124374\n",
      "Epoch 373 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_373.pth\n",
      "Epoch 374 train loss: 0.6669670235234917\n",
      "Epoch 374 train accuracy: 73.95119276117357\n",
      "Epoch 374 val loss: 0.6613792573150835\n",
      "Epoch 374 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_374.pth\n",
      "Epoch 375 train loss: 0.6668647449921098\n",
      "Epoch 375 train accuracy: 73.95119276117357\n",
      "Epoch 375 val loss: 0.6613560814998651\n",
      "Epoch 375 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_375.pth\n",
      "Epoch 376 train loss: 0.6669059978111794\n",
      "Epoch 376 train accuracy: 74.00603235536057\n",
      "Epoch 376 val loss: 0.6613265316149122\n",
      "Epoch 376 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_376.pth\n",
      "Epoch 377 train loss: 0.6668831309663099\n",
      "Epoch 377 train accuracy: 73.97861255826707\n",
      "Epoch 377 val loss: 0.6613045636760561\n",
      "Epoch 377 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_377.pth\n",
      "Epoch 378 train loss: 0.6668660367855377\n",
      "Epoch 378 train accuracy: 73.89635316698656\n",
      "Epoch 378 val loss: 0.661271640246636\n",
      "Epoch 378 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_378.pth\n",
      "Epoch 379 train loss: 0.6668386835147414\n",
      "Epoch 379 train accuracy: 73.95119276117357\n",
      "Epoch 379 val loss: 0.6612470059802658\n",
      "Epoch 379 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_379.pth\n",
      "Epoch 380 train loss: 0.6668113515826694\n",
      "Epoch 380 train accuracy: 73.97861255826707\n",
      "Epoch 380 val loss: 0.6612243431767351\n",
      "Epoch 380 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_380.pth\n",
      "Epoch 381 train loss: 0.6668094799510742\n",
      "Epoch 381 train accuracy: 74.00603235536057\n",
      "Epoch 381 val loss: 0.6611908562481403\n",
      "Epoch 381 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_381.pth\n",
      "Epoch 382 train loss: 0.6667592704884315\n",
      "Epoch 382 train accuracy: 73.95119276117357\n",
      "Epoch 382 val loss: 0.6611626269785982\n",
      "Epoch 382 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_382.pth\n",
      "Epoch 383 train loss: 0.6667510549162041\n",
      "Epoch 383 train accuracy: 73.97861255826707\n",
      "Epoch 383 val loss: 0.6611364289726082\n",
      "Epoch 383 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_383.pth\n",
      "Epoch 384 train loss: 0.6667472863929313\n",
      "Epoch 384 train accuracy: 74.00603235536057\n",
      "Epoch 384 val loss: 0.6611056802304167\n",
      "Epoch 384 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_384.pth\n",
      "Epoch 385 train loss: 0.6667273174317783\n",
      "Epoch 385 train accuracy: 74.00603235536057\n",
      "Epoch 385 val loss: 0.6610867890872454\n",
      "Epoch 385 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_385.pth\n",
      "Epoch 386 train loss: 0.666706192682971\n",
      "Epoch 386 train accuracy: 74.00603235536057\n",
      "Epoch 386 val loss: 0.6610526843486648\n",
      "Epoch 386 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_386.pth\n",
      "Epoch 387 train loss: 0.6666823931757295\n",
      "Epoch 387 train accuracy: 74.06087194954758\n",
      "Epoch 387 val loss: 0.6610281294897983\n",
      "Epoch 387 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_387.pth\n",
      "Epoch 388 train loss: 0.6666462640686516\n",
      "Epoch 388 train accuracy: 74.03345215245407\n",
      "Epoch 388 val loss: 0.661006888766822\n",
      "Epoch 388 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_388.pth\n",
      "Epoch 389 train loss: 0.6666206713896572\n",
      "Epoch 389 train accuracy: 74.00603235536057\n",
      "Epoch 389 val loss: 0.6609790833961022\n",
      "Epoch 389 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_389.pth\n",
      "Epoch 390 train loss: 0.6666949776311716\n",
      "Epoch 390 train accuracy: 74.00603235536057\n",
      "Epoch 390 val loss: 0.6609429862154158\n",
      "Epoch 390 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_390.pth\n",
      "Epoch 391 train loss: 0.6666077985836748\n",
      "Epoch 391 train accuracy: 74.06087194954758\n",
      "Epoch 391 val loss: 0.6609254031393089\n",
      "Epoch 391 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_391.pth\n",
      "Epoch 392 train loss: 0.6665912564647826\n",
      "Epoch 392 train accuracy: 74.06087194954758\n",
      "Epoch 392 val loss: 0.6608940414888295\n",
      "Epoch 392 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_392.pth\n",
      "Epoch 393 train loss: 0.6665753772188174\n",
      "Epoch 393 train accuracy: 74.06087194954758\n",
      "Epoch 393 val loss: 0.660871544362683\n",
      "Epoch 393 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_393.pth\n",
      "Epoch 394 train loss: 0.6665192335647973\n",
      "Epoch 394 train accuracy: 74.03345215245407\n",
      "Epoch 394 val loss: 0.6608486185340505\n",
      "Epoch 394 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_394.pth\n",
      "Epoch 395 train loss: 0.6665304123767113\n",
      "Epoch 395 train accuracy: 74.06087194954758\n",
      "Epoch 395 val loss: 0.660824398657209\n",
      "Epoch 395 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_395.pth\n",
      "Epoch 396 train loss: 0.6665364803190816\n",
      "Epoch 396 train accuracy: 74.08829174664108\n",
      "Epoch 396 val loss: 0.6607965277017731\n",
      "Epoch 396 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_396.pth\n",
      "Epoch 397 train loss: 0.6664355605056411\n",
      "Epoch 397 train accuracy: 74.08829174664108\n",
      "Epoch 397 val loss: 0.6607708819210529\n",
      "Epoch 397 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_397.pth\n",
      "Epoch 398 train loss: 0.6664280055515599\n",
      "Epoch 398 train accuracy: 74.06087194954758\n",
      "Epoch 398 val loss: 0.6607393863561907\n",
      "Epoch 398 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_398.pth\n",
      "Epoch 399 train loss: 0.6664577743790129\n",
      "Epoch 399 train accuracy: 74.06087194954758\n",
      "Epoch 399 val loss: 0.6607204546269617\n",
      "Epoch 399 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_399.pth\n",
      "Epoch 400 train loss: 0.6664345461483064\n",
      "Epoch 400 train accuracy: 74.06087194954758\n",
      "Epoch 400 val loss: 0.6606913615802401\n",
      "Epoch 400 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_400.pth\n",
      "Epoch 401 train loss: 0.6664189671476682\n",
      "Epoch 401 train accuracy: 74.08829174664108\n",
      "Epoch 401 val loss: 0.6606697452891814\n",
      "Epoch 401 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_401.pth\n",
      "Epoch 402 train loss: 0.6663493331064257\n",
      "Epoch 402 train accuracy: 74.14313134082808\n",
      "Epoch 402 val loss: 0.6606511867752201\n",
      "Epoch 402 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_402.pth\n",
      "Epoch 403 train loss: 0.6663543252895275\n",
      "Epoch 403 train accuracy: 74.06087194954758\n",
      "Epoch 403 val loss: 0.6606299371311539\n",
      "Epoch 403 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_403.pth\n",
      "Epoch 404 train loss: 0.6663599915214276\n",
      "Epoch 404 train accuracy: 74.11571154373458\n",
      "Epoch 404 val loss: 0.6606066112259501\n",
      "Epoch 404 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_404.pth\n",
      "Epoch 405 train loss: 0.6663478098875075\n",
      "Epoch 405 train accuracy: 74.11571154373458\n",
      "Epoch 405 val loss: 0.6605877772365746\n",
      "Epoch 405 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_405.pth\n",
      "Epoch 406 train loss: 0.666327007507023\n",
      "Epoch 406 train accuracy: 74.03345215245407\n",
      "Epoch 406 val loss: 0.6605510774411654\n",
      "Epoch 406 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_406.pth\n",
      "Epoch 407 train loss: 0.6663353495430528\n",
      "Epoch 407 train accuracy: 74.08829174664108\n",
      "Epoch 407 val loss: 0.6605263828839126\n",
      "Epoch 407 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_407.pth\n",
      "Epoch 408 train loss: 0.6662910131312776\n",
      "Epoch 408 train accuracy: 74.06087194954758\n",
      "Epoch 408 val loss: 0.6605065663002039\n",
      "Epoch 408 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_408.pth\n",
      "Epoch 409 train loss: 0.6662595342975437\n",
      "Epoch 409 train accuracy: 74.11571154373458\n",
      "Epoch 409 val loss: 0.6604811079604062\n",
      "Epoch 409 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_409.pth\n",
      "Epoch 410 train loss: 0.6662601339712477\n",
      "Epoch 410 train accuracy: 74.08829174664108\n",
      "Epoch 410 val loss: 0.6604540092184356\n",
      "Epoch 410 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_410.pth\n",
      "Epoch 411 train loss: 0.6661704470517865\n",
      "Epoch 411 train accuracy: 74.17055113792158\n",
      "Epoch 411 val loss: 0.66042637844619\n",
      "Epoch 411 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_411.pth\n",
      "Epoch 412 train loss: 0.6662210217889464\n",
      "Epoch 412 train accuracy: 74.11571154373458\n",
      "Epoch 412 val loss: 0.6604070819326138\n",
      "Epoch 412 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_412.pth\n",
      "Epoch 413 train loss: 0.6662027272477484\n",
      "Epoch 413 train accuracy: 74.08829174664108\n",
      "Epoch 413 val loss: 0.6603816690805712\n",
      "Epoch 413 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_413.pth\n",
      "Epoch 414 train loss: 0.6661871274312338\n",
      "Epoch 414 train accuracy: 74.08829174664108\n",
      "Epoch 414 val loss: 0.6603524869209841\n",
      "Epoch 414 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_414.pth\n",
      "Epoch 415 train loss: 0.66616840320721\n",
      "Epoch 415 train accuracy: 74.11571154373458\n",
      "Epoch 415 val loss: 0.6603249372228196\n",
      "Epoch 415 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_415.pth\n",
      "Epoch 416 train loss: 0.6661058873787784\n",
      "Epoch 416 train accuracy: 74.14313134082808\n",
      "Epoch 416 val loss: 0.6602991573316487\n",
      "Epoch 416 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_416.pth\n",
      "Epoch 417 train loss: 0.6661547291043558\n",
      "Epoch 417 train accuracy: 74.22539073210858\n",
      "Epoch 417 val loss: 0.6602745476718012\n",
      "Epoch 417 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_417.pth\n",
      "Epoch 418 train loss: 0.6661289580035628\n",
      "Epoch 418 train accuracy: 74.22539073210858\n",
      "Epoch 418 val loss: 0.6602597809151599\n",
      "Epoch 418 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_418.pth\n",
      "Epoch 419 train loss: 0.6660814594412059\n",
      "Epoch 419 train accuracy: 74.25281052920208\n",
      "Epoch 419 val loss: 0.660244017447296\n",
      "Epoch 419 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_419.pth\n",
      "Epoch 420 train loss: 0.6661003524797005\n",
      "Epoch 420 train accuracy: 74.25281052920208\n",
      "Epoch 420 val loss: 0.6602194819011187\n",
      "Epoch 420 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_420.pth\n",
      "Epoch 421 train loss: 0.6660639657393882\n",
      "Epoch 421 train accuracy: 74.25281052920208\n",
      "Epoch 421 val loss: 0.6601951968316969\n",
      "Epoch 421 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_421.pth\n",
      "Epoch 422 train loss: 0.6659884088133511\n",
      "Epoch 422 train accuracy: 74.17055113792158\n",
      "Epoch 422 val loss: 0.660182769655397\n",
      "Epoch 422 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_422.pth\n",
      "Epoch 423 train loss: 0.6660305180243755\n",
      "Epoch 423 train accuracy: 74.19797093501508\n",
      "Epoch 423 val loss: 0.6601468039382445\n",
      "Epoch 423 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_423.pth\n",
      "Epoch 424 train loss: 0.6660316126388416\n",
      "Epoch 424 train accuracy: 74.22539073210858\n",
      "Epoch 424 val loss: 0.6601297007383484\n",
      "Epoch 424 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_424.pth\n",
      "Epoch 425 train loss: 0.6660033834346554\n",
      "Epoch 425 train accuracy: 74.19797093501508\n",
      "Epoch 425 val loss: 0.6601022069195384\n",
      "Epoch 425 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_425.pth\n",
      "Epoch 426 train loss: 0.6659867058328369\n",
      "Epoch 426 train accuracy: 74.25281052920208\n",
      "Epoch 426 val loss: 0.660085916715233\n",
      "Epoch 426 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_426.pth\n",
      "Epoch 427 train loss: 0.6658830977976322\n",
      "Epoch 427 train accuracy: 74.08829174664108\n",
      "Epoch 427 val loss: 0.6600587717992695\n",
      "Epoch 427 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_427.pth\n",
      "Epoch 428 train loss: 0.6659520183150706\n",
      "Epoch 428 train accuracy: 74.25281052920208\n",
      "Epoch 428 val loss: 0.6600377254776264\n",
      "Epoch 428 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_428.pth\n",
      "Epoch 429 train loss: 0.6659246712204134\n",
      "Epoch 429 train accuracy: 74.19797093501508\n",
      "Epoch 429 val loss: 0.6600161168332163\n",
      "Epoch 429 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_429.pth\n",
      "Epoch 430 train loss: 0.6658932996685045\n",
      "Epoch 430 train accuracy: 74.17055113792158\n",
      "Epoch 430 val loss: 0.6599882107816244\n",
      "Epoch 430 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_430.pth\n",
      "Epoch 431 train loss: 0.6659174630777878\n",
      "Epoch 431 train accuracy: 74.22539073210858\n",
      "Epoch 431 val loss: 0.659971850581075\n",
      "Epoch 431 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_431.pth\n",
      "Epoch 432 train loss: 0.6658503324969819\n",
      "Epoch 432 train accuracy: 74.22539073210858\n",
      "Epoch 432 val loss: 0.6599542005477768\n",
      "Epoch 432 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_432.pth\n",
      "Epoch 433 train loss: 0.6658430265818249\n",
      "Epoch 433 train accuracy: 74.28023032629558\n",
      "Epoch 433 val loss: 0.6599361976902736\n",
      "Epoch 433 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_433.pth\n",
      "Epoch 434 train loss: 0.6658406205671398\n",
      "Epoch 434 train accuracy: 74.22539073210858\n",
      "Epoch 434 val loss: 0.6599144220940376\n",
      "Epoch 434 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_434.pth\n",
      "Epoch 435 train loss: 0.6658366238861754\n",
      "Epoch 435 train accuracy: 74.30765012338908\n",
      "Epoch 435 val loss: 0.6598968714671699\n",
      "Epoch 435 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_435.pth\n",
      "Epoch 436 train loss: 0.6658112262620738\n",
      "Epoch 436 train accuracy: 74.17055113792158\n",
      "Epoch 436 val loss: 0.6598695688145725\n",
      "Epoch 436 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_436.pth\n",
      "Epoch 437 train loss: 0.6657913517402975\n",
      "Epoch 437 train accuracy: 74.30765012338908\n",
      "Epoch 437 val loss: 0.6598485303356459\n",
      "Epoch 437 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_437.pth\n",
      "Epoch 438 train loss: 0.6658053225919343\n",
      "Epoch 438 train accuracy: 74.22539073210858\n",
      "Epoch 438 val loss: 0.6598267400343167\n",
      "Epoch 438 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_438.pth\n",
      "Epoch 439 train loss: 0.6657740842354926\n",
      "Epoch 439 train accuracy: 74.30765012338908\n",
      "Epoch 439 val loss: 0.6597986649721861\n",
      "Epoch 439 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_439.pth\n",
      "Epoch 440 train loss: 0.6657413861207795\n",
      "Epoch 440 train accuracy: 74.25281052920208\n",
      "Epoch 440 val loss: 0.6597740441364678\n",
      "Epoch 440 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_440.pth\n",
      "Epoch 441 train loss: 0.665731629095318\n",
      "Epoch 441 train accuracy: 74.33506992048258\n",
      "Epoch 441 val loss: 0.6597561200002307\n",
      "Epoch 441 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_441.pth\n",
      "Epoch 442 train loss: 0.6657402711152508\n",
      "Epoch 442 train accuracy: 74.25281052920208\n",
      "Epoch 442 val loss: 0.6597315726899787\n",
      "Epoch 442 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_442.pth\n",
      "Epoch 443 train loss: 0.6656606621190644\n",
      "Epoch 443 train accuracy: 74.33506992048258\n",
      "Epoch 443 val loss: 0.6597056442773656\n",
      "Epoch 443 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_443.pth\n",
      "Epoch 444 train loss: 0.6656739739864542\n",
      "Epoch 444 train accuracy: 74.25281052920208\n",
      "Epoch 444 val loss: 0.6596818496718219\n",
      "Epoch 444 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_444.pth\n",
      "Epoch 445 train loss: 0.6656154807526291\n",
      "Epoch 445 train accuracy: 74.28023032629558\n",
      "Epoch 445 val loss: 0.6596756979430977\n",
      "Epoch 445 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_445.pth\n",
      "Epoch 446 train loss: 0.6656427788956646\n",
      "Epoch 446 train accuracy: 74.33506992048258\n",
      "Epoch 446 val loss: 0.6596430159713093\n",
      "Epoch 446 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_446.pth\n",
      "Epoch 447 train loss: 0.6656277988824928\n",
      "Epoch 447 train accuracy: 74.28023032629558\n",
      "Epoch 447 val loss: 0.6596243341306323\n",
      "Epoch 447 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_447.pth\n",
      "Epoch 448 train loss: 0.6656127810282143\n",
      "Epoch 448 train accuracy: 74.30765012338908\n",
      "Epoch 448 val loss: 0.659596755218349\n",
      "Epoch 448 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_448.pth\n",
      "Epoch 449 train loss: 0.6655965534022503\n",
      "Epoch 449 train accuracy: 74.33506992048258\n",
      "Epoch 449 val loss: 0.6595773544946784\n",
      "Epoch 449 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_449.pth\n",
      "Epoch 450 train loss: 0.6655819102337486\n",
      "Epoch 450 train accuracy: 74.33506992048258\n",
      "Epoch 450 val loss: 0.6595669656403755\n",
      "Epoch 450 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_450.pth\n",
      "Epoch 451 train loss: 0.665541620794357\n",
      "Epoch 451 train accuracy: 74.33506992048258\n",
      "Epoch 451 val loss: 0.6595479697969399\n",
      "Epoch 451 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_451.pth\n",
      "Epoch 452 train loss: 0.6655377165267342\n",
      "Epoch 452 train accuracy: 74.33506992048258\n",
      "Epoch 452 val loss: 0.6595306088657755\n",
      "Epoch 452 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_452.pth\n",
      "Epoch 453 train loss: 0.6655178416455001\n",
      "Epoch 453 train accuracy: 74.30765012338908\n",
      "Epoch 453 val loss: 0.6595010763328326\n",
      "Epoch 453 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_453.pth\n",
      "Epoch 454 train loss: 0.6654501213577756\n",
      "Epoch 454 train accuracy: 74.30765012338908\n",
      "Epoch 454 val loss: 0.6594909985402697\n",
      "Epoch 454 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_454.pth\n",
      "Epoch 455 train loss: 0.6654975123768836\n",
      "Epoch 455 train accuracy: 74.3624897175761\n",
      "Epoch 455 val loss: 0.6594697351714498\n",
      "Epoch 455 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_455.pth\n",
      "Epoch 456 train loss: 0.6654518604801413\n",
      "Epoch 456 train accuracy: 74.3899095146696\n",
      "Epoch 456 val loss: 0.6594508023638475\n",
      "Epoch 456 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_456.pth\n",
      "Epoch 457 train loss: 0.6654784158525759\n",
      "Epoch 457 train accuracy: 74.30765012338908\n",
      "Epoch 457 val loss: 0.6594168006589538\n",
      "Epoch 457 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_457.pth\n",
      "Epoch 458 train loss: 0.6654421306100854\n",
      "Epoch 458 train accuracy: 74.33506992048258\n",
      "Epoch 458 val loss: 0.6593919389538074\n",
      "Epoch 458 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_458.pth\n",
      "Epoch 459 train loss: 0.6654538333154562\n",
      "Epoch 459 train accuracy: 74.28023032629558\n",
      "Epoch 459 val loss: 0.6593714199568096\n",
      "Epoch 459 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_459.pth\n",
      "Epoch 460 train loss: 0.6654240849117438\n",
      "Epoch 460 train accuracy: 74.30765012338908\n",
      "Epoch 460 val loss: 0.6593524702873669\n",
      "Epoch 460 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_460.pth\n",
      "Epoch 461 train loss: 0.6653612577274703\n",
      "Epoch 461 train accuracy: 74.33506992048258\n",
      "Epoch 461 val loss: 0.6593289779205072\n",
      "Epoch 461 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_461.pth\n",
      "Epoch 462 train loss: 0.6653401314754758\n",
      "Epoch 462 train accuracy: 74.33506992048258\n",
      "Epoch 462 val loss: 0.6593024694409809\n",
      "Epoch 462 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_462.pth\n",
      "Epoch 463 train loss: 0.6653516282441846\n",
      "Epoch 463 train accuracy: 74.33506992048258\n",
      "Epoch 463 val loss: 0.6592848474453938\n",
      "Epoch 463 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_463.pth\n",
      "Epoch 464 train loss: 0.6653569292669234\n",
      "Epoch 464 train accuracy: 74.30765012338908\n",
      "Epoch 464 val loss: 0.6592686104735261\n",
      "Epoch 464 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_464.pth\n",
      "Epoch 465 train loss: 0.6653080505825448\n",
      "Epoch 465 train accuracy: 74.30765012338908\n",
      "Epoch 465 val loss: 0.6592453532901249\n",
      "Epoch 465 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_465.pth\n",
      "Epoch 466 train loss: 0.665394920038811\n",
      "Epoch 466 train accuracy: 74.3624897175761\n",
      "Epoch 466 val loss: 0.6592309217115766\n",
      "Epoch 466 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_466.pth\n",
      "Epoch 467 train loss: 0.6653651244154102\n",
      "Epoch 467 train accuracy: 74.30765012338908\n",
      "Epoch 467 val loss: 0.659213432061829\n",
      "Epoch 467 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_467.pth\n",
      "Epoch 468 train loss: 0.6652972726314738\n",
      "Epoch 468 train accuracy: 74.30765012338908\n",
      "Epoch 468 val loss: 0.659189822152257\n",
      "Epoch 468 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_468.pth\n",
      "Epoch 469 train loss: 0.6652803266453639\n",
      "Epoch 469 train accuracy: 74.33506992048258\n",
      "Epoch 469 val loss: 0.6591637494336617\n",
      "Epoch 469 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_469.pth\n",
      "Epoch 470 train loss: 0.6652636073464364\n",
      "Epoch 470 train accuracy: 74.33506992048258\n",
      "Epoch 470 val loss: 0.6591424261660952\n",
      "Epoch 470 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_470.pth\n",
      "Epoch 471 train loss: 0.6652095631876013\n",
      "Epoch 471 train accuracy: 74.33506992048258\n",
      "Epoch 471 val loss: 0.6591336705574864\n",
      "Epoch 471 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_471.pth\n",
      "Epoch 472 train loss: 0.665228101196127\n",
      "Epoch 472 train accuracy: 74.28023032629558\n",
      "Epoch 472 val loss: 0.6591160549341064\n",
      "Epoch 472 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_472.pth\n",
      "Epoch 473 train loss: 0.6651689640589451\n",
      "Epoch 473 train accuracy: 74.30765012338908\n",
      "Epoch 473 val loss: 0.6590933800723991\n",
      "Epoch 473 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_473.pth\n",
      "Epoch 474 train loss: 0.6651904010132217\n",
      "Epoch 474 train accuracy: 74.3624897175761\n",
      "Epoch 474 val loss: 0.6590767046926838\n",
      "Epoch 474 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_474.pth\n",
      "Epoch 475 train loss: 0.6651639785748302\n",
      "Epoch 475 train accuracy: 74.3624897175761\n",
      "Epoch 475 val loss: 0.6590468963902247\n",
      "Epoch 475 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_475.pth\n",
      "Epoch 476 train loss: 0.6650991258129739\n",
      "Epoch 476 train accuracy: 74.33506992048258\n",
      "Epoch 476 val loss: 0.6590312883061799\n",
      "Epoch 476 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_476.pth\n",
      "Epoch 477 train loss: 0.6651450372709516\n",
      "Epoch 477 train accuracy: 74.33506992048258\n",
      "Epoch 477 val loss: 0.6590091281227375\n",
      "Epoch 477 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_477.pth\n",
      "Epoch 478 train loss: 0.6651175795286371\n",
      "Epoch 478 train accuracy: 74.3624897175761\n",
      "Epoch 478 val loss: 0.65898448797433\n",
      "Epoch 478 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_478.pth\n",
      "Epoch 479 train loss: 0.6650616228907255\n",
      "Epoch 479 train accuracy: 74.28023032629558\n",
      "Epoch 479 val loss: 0.6589720856006208\n",
      "Epoch 479 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_479.pth\n",
      "Epoch 480 train loss: 0.665079440954223\n",
      "Epoch 480 train accuracy: 74.33506992048258\n",
      "Epoch 480 val loss: 0.6589456980949954\n",
      "Epoch 480 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_480.pth\n",
      "Epoch 481 train loss: 0.6651529770083072\n",
      "Epoch 481 train accuracy: 74.30765012338908\n",
      "Epoch 481 val loss: 0.6589167289631931\n",
      "Epoch 481 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_481.pth\n",
      "Epoch 482 train loss: 0.6650397897485578\n",
      "Epoch 482 train accuracy: 74.3624897175761\n",
      "Epoch 482 val loss: 0.6589177302820118\n",
      "Epoch 482 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_482.pth\n",
      "Epoch 483 train loss: 0.6650938612261885\n",
      "Epoch 483 train accuracy: 74.28023032629558\n",
      "Epoch 483 val loss: 0.6588938436225841\n",
      "Epoch 483 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_483.pth\n",
      "Epoch 484 train loss: 0.6650103001218093\n",
      "Epoch 484 train accuracy: 74.33506992048258\n",
      "Epoch 484 val loss: 0.6588750777668074\n",
      "Epoch 484 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_484.pth\n",
      "Epoch 485 train loss: 0.6650324998782915\n",
      "Epoch 485 train accuracy: 74.28023032629558\n",
      "Epoch 485 val loss: 0.6588601569988226\n",
      "Epoch 485 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_485.pth\n",
      "Epoch 486 train loss: 0.665016557825239\n",
      "Epoch 486 train accuracy: 74.30765012338908\n",
      "Epoch 486 val loss: 0.6588339211517259\n",
      "Epoch 486 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_486.pth\n",
      "Epoch 487 train loss: 0.6650150677744757\n",
      "Epoch 487 train accuracy: 74.33506992048258\n",
      "Epoch 487 val loss: 0.6588230269323838\n",
      "Epoch 487 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_487.pth\n",
      "Epoch 488 train loss: 0.6650008309893963\n",
      "Epoch 488 train accuracy: 74.33506992048258\n",
      "Epoch 488 val loss: 0.658793594786211\n",
      "Epoch 488 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_488.pth\n",
      "Epoch 489 train loss: 0.6649473945430496\n",
      "Epoch 489 train accuracy: 74.33506992048258\n",
      "Epoch 489 val loss: 0.65878246636375\n",
      "Epoch 489 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_489.pth\n",
      "Epoch 490 train loss: 0.6650156155555395\n",
      "Epoch 490 train accuracy: 74.33506992048258\n",
      "Epoch 490 val loss: 0.6587721344671751\n",
      "Epoch 490 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_490.pth\n",
      "Epoch 491 train loss: 0.6648984783770222\n",
      "Epoch 491 train accuracy: 74.30765012338908\n",
      "Epoch 491 val loss: 0.658754687560232\n",
      "Epoch 491 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_491.pth\n",
      "Epoch 492 train loss: 0.6649294565513468\n",
      "Epoch 492 train accuracy: 74.30765012338908\n",
      "Epoch 492 val loss: 0.6587332925318103\n",
      "Epoch 492 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_492.pth\n",
      "Epoch 493 train loss: 0.6649166606693414\n",
      "Epoch 493 train accuracy: 74.30765012338908\n",
      "Epoch 493 val loss: 0.6587114731143964\n",
      "Epoch 493 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_493.pth\n",
      "Epoch 494 train loss: 0.6648800361313318\n",
      "Epoch 494 train accuracy: 74.33506992048258\n",
      "Epoch 494 val loss: 0.6587005700719984\n",
      "Epoch 494 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_494.pth\n",
      "Epoch 495 train loss: 0.6648829484587175\n",
      "Epoch 495 train accuracy: 74.3624897175761\n",
      "Epoch 495 val loss: 0.6586842673193467\n",
      "Epoch 495 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_495.pth\n",
      "Epoch 496 train loss: 0.6649165630928779\n",
      "Epoch 496 train accuracy: 74.33506992048258\n",
      "Epoch 496 val loss: 0.6586640642857865\n",
      "Epoch 496 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_496.pth\n",
      "Epoch 497 train loss: 0.6648539048864653\n",
      "Epoch 497 train accuracy: 74.33506992048258\n",
      "Epoch 497 val loss: 0.6586464576815304\n",
      "Epoch 497 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_497.pth\n",
      "Epoch 498 train loss: 0.6648670744085521\n",
      "Epoch 498 train accuracy: 74.3624897175761\n",
      "Epoch 498 val loss: 0.6586294552605403\n",
      "Epoch 498 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_498.pth\n",
      "Epoch 499 train loss: 0.6647394546879488\n",
      "Epoch 499 train accuracy: 74.4173293117631\n",
      "Epoch 499 val loss: 0.6586140586357367\n",
      "Epoch 499 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_499.pth\n",
      "Epoch 500 train loss: 0.6647652443498373\n",
      "Epoch 500 train accuracy: 74.3624897175761\n",
      "Epoch 500 val loss: 0.6585989005275463\n",
      "Epoch 500 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_500.pth\n",
      "Epoch 501 train loss: 0.6647850323403091\n",
      "Epoch 501 train accuracy: 74.3624897175761\n",
      "Epoch 501 val loss: 0.6585932074016646\n",
      "Epoch 501 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_501.pth\n",
      "Epoch 502 train loss: 0.6647268868002453\n",
      "Epoch 502 train accuracy: 74.4173293117631\n",
      "Epoch 502 val loss: 0.6585704703864298\n",
      "Epoch 502 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_502.pth\n",
      "Epoch 503 train loss: 0.6647634929078713\n",
      "Epoch 503 train accuracy: 74.33506992048258\n",
      "Epoch 503 val loss: 0.6585410530433843\n",
      "Epoch 503 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_503.pth\n",
      "Epoch 504 train loss: 0.664740752690194\n",
      "Epoch 504 train accuracy: 74.33506992048258\n",
      "Epoch 504 val loss: 0.6585268197875274\n",
      "Epoch 504 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_504.pth\n",
      "Epoch 505 train loss: 0.6647356479641116\n",
      "Epoch 505 train accuracy: 74.33506992048258\n",
      "Epoch 505 val loss: 0.6585096837462563\n",
      "Epoch 505 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_505.pth\n",
      "Epoch 506 train loss: 0.6646506373950264\n",
      "Epoch 506 train accuracy: 74.3899095146696\n",
      "Epoch 506 val loss: 0.6584880433388447\n",
      "Epoch 506 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_506.pth\n",
      "Epoch 507 train loss: 0.6647078252087036\n",
      "Epoch 507 train accuracy: 74.33506992048258\n",
      "Epoch 507 val loss: 0.6584766790466873\n",
      "Epoch 507 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_507.pth\n",
      "Epoch 508 train loss: 0.6647146481105632\n",
      "Epoch 508 train accuracy: 74.3624897175761\n",
      "Epoch 508 val loss: 0.6584530281589219\n",
      "Epoch 508 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_508.pth\n",
      "Epoch 509 train loss: 0.6646787741531929\n",
      "Epoch 509 train accuracy: 74.3624897175761\n",
      "Epoch 509 val loss: 0.6584407603858333\n",
      "Epoch 509 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_509.pth\n",
      "Epoch 510 train loss: 0.6646067906628575\n",
      "Epoch 510 train accuracy: 74.33506992048258\n",
      "Epoch 510 val loss: 0.6584173135067287\n",
      "Epoch 510 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_510.pth\n",
      "Epoch 511 train loss: 0.6646289406834465\n",
      "Epoch 511 train accuracy: 74.33506992048258\n",
      "Epoch 511 val loss: 0.6584059964669379\n",
      "Epoch 511 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_511.pth\n",
      "Epoch 512 train loss: 0.6646176539034697\n",
      "Epoch 512 train accuracy: 74.33506992048258\n",
      "Epoch 512 val loss: 0.6583890781590813\n",
      "Epoch 512 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_512.pth\n",
      "Epoch 513 train loss: 0.6645870773742596\n",
      "Epoch 513 train accuracy: 74.30765012338908\n",
      "Epoch 513 val loss: 0.658371504788336\n",
      "Epoch 513 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_513.pth\n",
      "Epoch 514 train loss: 0.6645605238644701\n",
      "Epoch 514 train accuracy: 74.3624897175761\n",
      "Epoch 514 val loss: 0.6583438066667632\n",
      "Epoch 514 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_514.pth\n",
      "Epoch 515 train loss: 0.6645798638724444\n",
      "Epoch 515 train accuracy: 74.33506992048258\n",
      "Epoch 515 val loss: 0.6583273609806048\n",
      "Epoch 515 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_515.pth\n",
      "Epoch 516 train loss: 0.66446730514106\n",
      "Epoch 516 train accuracy: 74.33506992048258\n",
      "Epoch 516 val loss: 0.6583216346212124\n",
      "Epoch 516 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_516.pth\n",
      "Epoch 517 train loss: 0.6645490817333523\n",
      "Epoch 517 train accuracy: 74.3624897175761\n",
      "Epoch 517 val loss: 0.6583013672773775\n",
      "Epoch 517 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_517.pth\n",
      "Epoch 518 train loss: 0.6645176169511519\n",
      "Epoch 518 train accuracy: 74.3624897175761\n",
      "Epoch 518 val loss: 0.6582895259519941\n",
      "Epoch 518 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_518.pth\n",
      "Epoch 519 train loss: 0.6645069575558106\n",
      "Epoch 519 train accuracy: 74.33506992048258\n",
      "Epoch 519 val loss: 0.6582689806818962\n",
      "Epoch 519 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_519.pth\n",
      "Epoch 520 train loss: 0.6645190274310216\n",
      "Epoch 520 train accuracy: 74.30765012338908\n",
      "Epoch 520 val loss: 0.6582463008204573\n",
      "Epoch 520 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_520.pth\n",
      "Epoch 521 train loss: 0.6645035034274323\n",
      "Epoch 521 train accuracy: 74.33506992048258\n",
      "Epoch 521 val loss: 0.6582331417226478\n",
      "Epoch 521 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_521.pth\n",
      "Epoch 522 train loss: 0.6644893269332355\n",
      "Epoch 522 train accuracy: 74.30765012338908\n",
      "Epoch 522 val loss: 0.6582102518724767\n",
      "Epoch 522 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_522.pth\n",
      "Epoch 523 train loss: 0.6644827518285367\n",
      "Epoch 523 train accuracy: 74.3624897175761\n",
      "Epoch 523 val loss: 0.6581961066511116\n",
      "Epoch 523 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_523.pth\n",
      "Epoch 524 train loss: 0.6644601689553574\n",
      "Epoch 524 train accuracy: 74.30765012338908\n",
      "Epoch 524 val loss: 0.6581817716360092\n",
      "Epoch 524 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_524.pth\n",
      "Epoch 525 train loss: 0.6644112437375282\n",
      "Epoch 525 train accuracy: 74.33506992048258\n",
      "Epoch 525 val loss: 0.6581636030030878\n",
      "Epoch 525 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_525.pth\n",
      "Epoch 526 train loss: 0.6644344435710656\n",
      "Epoch 526 train accuracy: 74.28023032629558\n",
      "Epoch 526 val loss: 0.6581519051013809\n",
      "Epoch 526 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_526.pth\n",
      "Epoch 527 train loss: 0.6643924258583993\n",
      "Epoch 527 train accuracy: 74.33506992048258\n",
      "Epoch 527 val loss: 0.6581344768208893\n",
      "Epoch 527 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_527.pth\n",
      "Epoch 528 train loss: 0.6644042758761268\n",
      "Epoch 528 train accuracy: 74.3624897175761\n",
      "Epoch 528 val loss: 0.6581043273602661\n",
      "Epoch 528 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_528.pth\n",
      "Epoch 529 train loss: 0.6643996244263753\n",
      "Epoch 529 train accuracy: 74.28023032629558\n",
      "Epoch 529 val loss: 0.6580710433619587\n",
      "Epoch 529 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_529.pth\n",
      "Epoch 530 train loss: 0.6643742267369178\n",
      "Epoch 530 train accuracy: 74.28023032629558\n",
      "Epoch 530 val loss: 0.658056952059269\n",
      "Epoch 530 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_530.pth\n",
      "Epoch 531 train loss: 0.6643611517195639\n",
      "Epoch 531 train accuracy: 74.28023032629558\n",
      "Epoch 531 val loss: 0.6580297530285621\n",
      "Epoch 531 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_531.pth\n",
      "Epoch 532 train loss: 0.6644155198479431\n",
      "Epoch 532 train accuracy: 74.33506992048258\n",
      "Epoch 532 val loss: 0.6580136144827855\n",
      "Epoch 532 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_532.pth\n",
      "Epoch 533 train loss: 0.6643291732721162\n",
      "Epoch 533 train accuracy: 74.30765012338908\n",
      "Epoch 533 val loss: 0.6580057195142696\n",
      "Epoch 533 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_533.pth\n",
      "Epoch 534 train loss: 0.6643290716762605\n",
      "Epoch 534 train accuracy: 74.30765012338908\n",
      "Epoch 534 val loss: 0.6579773708393699\n",
      "Epoch 534 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_534.pth\n",
      "Epoch 535 train loss: 0.6642887125347268\n",
      "Epoch 535 train accuracy: 74.30765012338908\n",
      "Epoch 535 val loss: 0.6579651248298193\n",
      "Epoch 535 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_535.pth\n",
      "Epoch 536 train loss: 0.6642926494149786\n",
      "Epoch 536 train accuracy: 74.33506992048258\n",
      "Epoch 536 val loss: 0.6579440417454431\n",
      "Epoch 536 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_536.pth\n",
      "Epoch 537 train loss: 0.664252189004369\n",
      "Epoch 537 train accuracy: 74.28023032629558\n",
      "Epoch 537 val loss: 0.6579301568042291\n",
      "Epoch 537 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_537.pth\n",
      "Epoch 538 train loss: 0.6642690656804725\n",
      "Epoch 538 train accuracy: 74.30765012338908\n",
      "Epoch 538 val loss: 0.6579103834534946\n",
      "Epoch 538 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_538.pth\n",
      "Epoch 539 train loss: 0.6642304576541248\n",
      "Epoch 539 train accuracy: 74.30765012338908\n",
      "Epoch 539 val loss: 0.6578923583422837\n",
      "Epoch 539 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_539.pth\n",
      "Epoch 540 train loss: 0.6641865222339045\n",
      "Epoch 540 train accuracy: 74.30765012338908\n",
      "Epoch 540 val loss: 0.6578790775843357\n",
      "Epoch 540 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_540.pth\n",
      "Epoch 541 train loss: 0.6642247523720327\n",
      "Epoch 541 train accuracy: 74.30765012338908\n",
      "Epoch 541 val loss: 0.6578538849165565\n",
      "Epoch 541 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_541.pth\n",
      "Epoch 542 train loss: 0.664214982928937\n",
      "Epoch 542 train accuracy: 74.33506992048258\n",
      "Epoch 542 val loss: 0.6578389635603679\n",
      "Epoch 542 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_542.pth\n",
      "Epoch 543 train loss: 0.6642152873243679\n",
      "Epoch 543 train accuracy: 74.33506992048258\n",
      "Epoch 543 val loss: 0.6578287616568176\n",
      "Epoch 543 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_543.pth\n",
      "Epoch 544 train loss: 0.664162262947413\n",
      "Epoch 544 train accuracy: 74.28023032629558\n",
      "Epoch 544 val loss: 0.6578106128267551\n",
      "Epoch 544 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_544.pth\n",
      "Epoch 545 train loss: 0.6641705284842796\n",
      "Epoch 545 train accuracy: 74.30765012338908\n",
      "Epoch 545 val loss: 0.6577992967673039\n",
      "Epoch 545 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_545.pth\n",
      "Epoch 546 train loss: 0.6641823333410317\n",
      "Epoch 546 train accuracy: 74.30765012338908\n",
      "Epoch 546 val loss: 0.6577715683532389\n",
      "Epoch 546 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_546.pth\n",
      "Epoch 547 train loss: 0.6641569847992638\n",
      "Epoch 547 train accuracy: 74.33506992048258\n",
      "Epoch 547 val loss: 0.6577499587284891\n",
      "Epoch 547 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_547.pth\n",
      "Epoch 548 train loss: 0.6641362488858009\n",
      "Epoch 548 train accuracy: 74.3624897175761\n",
      "Epoch 548 val loss: 0.6577285371328655\n",
      "Epoch 548 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_548.pth\n",
      "Epoch 549 train loss: 0.664122790653716\n",
      "Epoch 549 train accuracy: 74.33506992048258\n",
      "Epoch 549 val loss: 0.6577056497335434\n",
      "Epoch 549 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_549.pth\n",
      "Epoch 550 train loss: 0.6641130642802046\n",
      "Epoch 550 train accuracy: 74.3624897175761\n",
      "Epoch 550 val loss: 0.6576886891730522\n",
      "Epoch 550 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_550.pth\n",
      "Epoch 551 train loss: 0.6640962062305525\n",
      "Epoch 551 train accuracy: 74.3624897175761\n",
      "Epoch 551 val loss: 0.6576791428225605\n",
      "Epoch 551 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_551.pth\n",
      "Epoch 552 train loss: 0.6641293750716406\n",
      "Epoch 552 train accuracy: 74.33506992048258\n",
      "Epoch 552 val loss: 0.6576603743198671\n",
      "Epoch 552 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_552.pth\n",
      "Epoch 553 train loss: 0.6640687962634522\n",
      "Epoch 553 train accuracy: 74.3624897175761\n",
      "Epoch 553 val loss: 0.6576519480073139\n",
      "Epoch 553 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_553.pth\n",
      "Epoch 554 train loss: 0.6641237006702444\n",
      "Epoch 554 train accuracy: 74.33506992048258\n",
      "Epoch 554 val loss: 0.6576430388775311\n",
      "Epoch 554 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_554.pth\n",
      "Epoch 555 train loss: 0.6640116735443211\n",
      "Epoch 555 train accuracy: 74.22539073210858\n",
      "Epoch 555 val loss: 0.657621068879962\n",
      "Epoch 555 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_555.pth\n",
      "Epoch 556 train loss: 0.6639957133876649\n",
      "Epoch 556 train accuracy: 74.3624897175761\n",
      "Epoch 556 val loss: 0.6575923594401071\n",
      "Epoch 556 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_556.pth\n",
      "Epoch 557 train loss: 0.6640169733906525\n",
      "Epoch 557 train accuracy: 74.3624897175761\n",
      "Epoch 557 val loss: 0.6575858954732355\n",
      "Epoch 557 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_557.pth\n",
      "Epoch 558 train loss: 0.6639921408342687\n",
      "Epoch 558 train accuracy: 74.3899095146696\n",
      "Epoch 558 val loss: 0.657563262864163\n",
      "Epoch 558 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_558.pth\n",
      "Epoch 559 train loss: 0.6639178362266537\n",
      "Epoch 559 train accuracy: 74.3899095146696\n",
      "Epoch 559 val loss: 0.6575502790510654\n",
      "Epoch 559 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_559.pth\n",
      "Epoch 560 train loss: 0.6639830926269815\n",
      "Epoch 560 train accuracy: 74.30765012338908\n",
      "Epoch 560 val loss: 0.6575310581216687\n",
      "Epoch 560 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_560.pth\n",
      "Epoch 561 train loss: 0.663966513712678\n",
      "Epoch 561 train accuracy: 74.33506992048258\n",
      "Epoch 561 val loss: 0.6575081550369137\n",
      "Epoch 561 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_561.pth\n",
      "Epoch 562 train loss: 0.663956690220195\n",
      "Epoch 562 train accuracy: 74.4173293117631\n",
      "Epoch 562 val loss: 0.6574964076280594\n",
      "Epoch 562 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_562.pth\n",
      "Epoch 563 train loss: 0.6638650165772751\n",
      "Epoch 563 train accuracy: 74.3899095146696\n",
      "Epoch 563 val loss: 0.6574843797440592\n",
      "Epoch 563 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_563.pth\n",
      "Epoch 564 train loss: 0.6639301500103453\n",
      "Epoch 564 train accuracy: 74.30765012338908\n",
      "Epoch 564 val loss: 0.6574540372545782\n",
      "Epoch 564 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_564.pth\n",
      "Epoch 565 train loss: 0.663958754651902\n",
      "Epoch 565 train accuracy: 74.4173293117631\n",
      "Epoch 565 val loss: 0.6574402027028171\n",
      "Epoch 565 val accuracy: 75.32894736842105\n",
      "Saved model to .\\test_modelsv2/MLP_565.pth\n",
      "Epoch 566 train loss: 0.6639159143363175\n",
      "Epoch 566 train accuracy: 74.3899095146696\n",
      "Epoch 566 val loss: 0.6574252318394812\n",
      "Epoch 566 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_566.pth\n",
      "Epoch 567 train loss: 0.66389420785402\n",
      "Epoch 567 train accuracy: 74.33506992048258\n",
      "Epoch 567 val loss: 0.6574021418039736\n",
      "Epoch 567 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_567.pth\n",
      "Epoch 568 train loss: 0.6638613836349625\n",
      "Epoch 568 train accuracy: 74.3624897175761\n",
      "Epoch 568 val loss: 0.657374624947184\n",
      "Epoch 568 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_568.pth\n",
      "Epoch 569 train loss: 0.663826650498729\n",
      "Epoch 569 train accuracy: 74.3899095146696\n",
      "Epoch 569 val loss: 0.6573568563908339\n",
      "Epoch 569 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_569.pth\n",
      "Epoch 570 train loss: 0.6637774741832625\n",
      "Epoch 570 train accuracy: 74.4173293117631\n",
      "Epoch 570 val loss: 0.6573407743126154\n",
      "Epoch 570 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_570.pth\n",
      "Epoch 571 train loss: 0.6638423323696643\n",
      "Epoch 571 train accuracy: 74.3624897175761\n",
      "Epoch 571 val loss: 0.6573260014778689\n",
      "Epoch 571 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_571.pth\n",
      "Epoch 572 train loss: 0.663818381334606\n",
      "Epoch 572 train accuracy: 74.3899095146696\n",
      "Epoch 572 val loss: 0.6573093193338105\n",
      "Epoch 572 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_572.pth\n",
      "Epoch 573 train loss: 0.663775920606496\n",
      "Epoch 573 train accuracy: 74.4173293117631\n",
      "Epoch 573 val loss: 0.6573026248891103\n",
      "Epoch 573 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_573.pth\n",
      "Epoch 574 train loss: 0.6636931615505826\n",
      "Epoch 574 train accuracy: 74.3624897175761\n",
      "Epoch 574 val loss: 0.657271297844617\n",
      "Epoch 574 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_574.pth\n",
      "Epoch 575 train loss: 0.6637008537522011\n",
      "Epoch 575 train accuracy: 74.3624897175761\n",
      "Epoch 575 val loss: 0.6572653944359014\n",
      "Epoch 575 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_575.pth\n",
      "Epoch 576 train loss: 0.663757751091269\n",
      "Epoch 576 train accuracy: 74.4447491088566\n",
      "Epoch 576 val loss: 0.6572565493222914\n",
      "Epoch 576 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_576.pth\n",
      "Epoch 577 train loss: 0.6637779715421953\n",
      "Epoch 577 train accuracy: 74.3624897175761\n",
      "Epoch 577 val loss: 0.657233169890548\n",
      "Epoch 577 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_577.pth\n",
      "Epoch 578 train loss: 0.66379837917262\n",
      "Epoch 578 train accuracy: 74.3899095146696\n",
      "Epoch 578 val loss: 0.6572181948117519\n",
      "Epoch 578 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_578.pth\n",
      "Epoch 579 train loss: 0.6637422159118088\n",
      "Epoch 579 train accuracy: 74.4173293117631\n",
      "Epoch 579 val loss: 0.657203127483004\n",
      "Epoch 579 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_579.pth\n",
      "Epoch 580 train loss: 0.6637350853140417\n",
      "Epoch 580 train accuracy: 74.4173293117631\n",
      "Epoch 580 val loss: 0.6571945525509747\n",
      "Epoch 580 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_580.pth\n",
      "Epoch 581 train loss: 0.6637221591775877\n",
      "Epoch 581 train accuracy: 74.3899095146696\n",
      "Epoch 581 val loss: 0.657175786597164\n",
      "Epoch 581 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_581.pth\n",
      "Epoch 582 train loss: 0.6636577940039468\n",
      "Epoch 582 train accuracy: 74.4721689059501\n",
      "Epoch 582 val loss: 0.6571603572290194\n",
      "Epoch 582 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_582.pth\n",
      "Epoch 583 train loss: 0.6636569338867015\n",
      "Epoch 583 train accuracy: 74.3624897175761\n",
      "Epoch 583 val loss: 0.6571271615593057\n",
      "Epoch 583 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_583.pth\n",
      "Epoch 584 train loss: 0.6636514488869069\n",
      "Epoch 584 train accuracy: 74.4447491088566\n",
      "Epoch 584 val loss: 0.6571185888820573\n",
      "Epoch 584 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_584.pth\n",
      "Epoch 585 train loss: 0.6636324930740031\n",
      "Epoch 585 train accuracy: 74.4995887030436\n",
      "Epoch 585 val loss: 0.6571082467899511\n",
      "Epoch 585 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_585.pth\n",
      "Epoch 586 train loss: 0.663599648169781\n",
      "Epoch 586 train accuracy: 74.4173293117631\n",
      "Epoch 586 val loss: 0.6570803276998433\n",
      "Epoch 586 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_586.pth\n",
      "Epoch 587 train loss: 0.6636467158402267\n",
      "Epoch 587 train accuracy: 74.4721689059501\n",
      "Epoch 587 val loss: 0.6570751635651839\n",
      "Epoch 587 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_587.pth\n",
      "Epoch 588 train loss: 0.6636388322436496\n",
      "Epoch 588 train accuracy: 74.5544282972306\n",
      "Epoch 588 val loss: 0.6570685006874172\n",
      "Epoch 588 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_588.pth\n",
      "Epoch 589 train loss: 0.6636263057589531\n",
      "Epoch 589 train accuracy: 74.3624897175761\n",
      "Epoch 589 val loss: 0.6570527904519909\n",
      "Epoch 589 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_589.pth\n",
      "Epoch 590 train loss: 0.6636171799741293\n",
      "Epoch 590 train accuracy: 74.5818480943241\n",
      "Epoch 590 val loss: 0.6570416702643821\n",
      "Epoch 590 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_590.pth\n",
      "Epoch 591 train loss: 0.6635514922243985\n",
      "Epoch 591 train accuracy: 74.33506992048258\n",
      "Epoch 591 val loss: 0.6570211673449529\n",
      "Epoch 591 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_591.pth\n",
      "Epoch 592 train loss: 0.6635580987979969\n",
      "Epoch 592 train accuracy: 74.5270085001371\n",
      "Epoch 592 val loss: 0.6570083574440918\n",
      "Epoch 592 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_592.pth\n",
      "Epoch 593 train loss: 0.663545095802922\n",
      "Epoch 593 train accuracy: 74.3899095146696\n",
      "Epoch 593 val loss: 0.6569944483865249\n",
      "Epoch 593 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_593.pth\n",
      "Epoch 594 train loss: 0.6635663843991464\n",
      "Epoch 594 train accuracy: 74.4995887030436\n",
      "Epoch 594 val loss: 0.6569697098120263\n",
      "Epoch 594 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_594.pth\n",
      "Epoch 595 train loss: 0.6635137519946224\n",
      "Epoch 595 train accuracy: 74.3899095146696\n",
      "Epoch 595 val loss: 0.6569556488998627\n",
      "Epoch 595 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_595.pth\n",
      "Epoch 596 train loss: 0.6635427124014026\n",
      "Epoch 596 train accuracy: 74.4447491088566\n",
      "Epoch 596 val loss: 0.6569486473147806\n",
      "Epoch 596 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_596.pth\n",
      "Epoch 597 train loss: 0.6635317178279684\n",
      "Epoch 597 train accuracy: 74.4721689059501\n",
      "Epoch 597 val loss: 0.6569309488527084\n",
      "Epoch 597 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_597.pth\n",
      "Epoch 598 train loss: 0.6635229036930883\n",
      "Epoch 598 train accuracy: 74.4173293117631\n",
      "Epoch 598 val loss: 0.6569127522801098\n",
      "Epoch 598 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_598.pth\n",
      "Epoch 599 train loss: 0.6634737135548341\n",
      "Epoch 599 train accuracy: 74.4447491088566\n",
      "Epoch 599 val loss: 0.6568968645051906\n",
      "Epoch 599 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_599.pth\n",
      "Epoch 600 train loss: 0.6634969623399931\n",
      "Epoch 600 train accuracy: 74.4173293117631\n",
      "Epoch 600 val loss: 0.6568786667561844\n",
      "Epoch 600 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_600.pth\n",
      "Epoch 601 train loss: 0.6634583913051245\n",
      "Epoch 601 train accuracy: 74.5544282972306\n",
      "Epoch 601 val loss: 0.6568682042783812\n",
      "Epoch 601 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_601.pth\n",
      "Epoch 602 train loss: 0.6634713235850397\n",
      "Epoch 602 train accuracy: 74.4173293117631\n",
      "Epoch 602 val loss: 0.6568547381382239\n",
      "Epoch 602 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_602.pth\n",
      "Epoch 603 train loss: 0.6634571549662373\n",
      "Epoch 603 train accuracy: 74.4173293117631\n",
      "Epoch 603 val loss: 0.6568385679274797\n",
      "Epoch 603 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_603.pth\n",
      "Epoch 604 train loss: 0.6634515033087187\n",
      "Epoch 604 train accuracy: 74.5544282972306\n",
      "Epoch 604 val loss: 0.6568271018760768\n",
      "Epoch 604 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_604.pth\n",
      "Epoch 605 train loss: 0.6634249612689018\n",
      "Epoch 605 train accuracy: 74.4721689059501\n",
      "Epoch 605 val loss: 0.656813085275261\n",
      "Epoch 605 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_605.pth\n",
      "Epoch 606 train loss: 0.6634395970521789\n",
      "Epoch 606 train accuracy: 74.4721689059501\n",
      "Epoch 606 val loss: 0.6568016994156336\n",
      "Epoch 606 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_606.pth\n",
      "Epoch 607 train loss: 0.6634576442210298\n",
      "Epoch 607 train accuracy: 74.5270085001371\n",
      "Epoch 607 val loss: 0.6567774240515734\n",
      "Epoch 607 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_607.pth\n",
      "Epoch 608 train loss: 0.6633334031099813\n",
      "Epoch 608 train accuracy: 74.5818480943241\n",
      "Epoch 608 val loss: 0.6567661241677246\n",
      "Epoch 608 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_608.pth\n",
      "Epoch 609 train loss: 0.6633405968742935\n",
      "Epoch 609 train accuracy: 74.4173293117631\n",
      "Epoch 609 val loss: 0.6567507207785782\n",
      "Epoch 609 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_609.pth\n",
      "Epoch 610 train loss: 0.6633314408296556\n",
      "Epoch 610 train accuracy: 74.4447491088566\n",
      "Epoch 610 val loss: 0.656729742688568\n",
      "Epoch 610 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_610.pth\n",
      "Epoch 611 train loss: 0.6633300655766537\n",
      "Epoch 611 train accuracy: 74.5544282972306\n",
      "Epoch 611 val loss: 0.6567218535040554\n",
      "Epoch 611 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_611.pth\n",
      "Epoch 612 train loss: 0.6633743859762162\n",
      "Epoch 612 train accuracy: 74.5544282972306\n",
      "Epoch 612 val loss: 0.6567065725593191\n",
      "Epoch 612 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_612.pth\n",
      "Epoch 613 train loss: 0.6633451809747177\n",
      "Epoch 613 train accuracy: 74.4721689059501\n",
      "Epoch 613 val loss: 0.6566934914965379\n",
      "Epoch 613 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_613.pth\n",
      "Epoch 614 train loss: 0.6633592253191429\n",
      "Epoch 614 train accuracy: 74.5818480943241\n",
      "Epoch 614 val loss: 0.6566693812216583\n",
      "Epoch 614 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_614.pth\n",
      "Epoch 615 train loss: 0.6633224685006497\n",
      "Epoch 615 train accuracy: 74.5818480943241\n",
      "Epoch 615 val loss: 0.656657598814682\n",
      "Epoch 615 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_615.pth\n",
      "Epoch 616 train loss: 0.6633063354447746\n",
      "Epoch 616 train accuracy: 74.4721689059501\n",
      "Epoch 616 val loss: 0.6566478039481138\n",
      "Epoch 616 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_616.pth\n",
      "Epoch 617 train loss: 0.6632983255151071\n",
      "Epoch 617 train accuracy: 74.5544282972306\n",
      "Epoch 617 val loss: 0.6566227720560212\n",
      "Epoch 617 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_617.pth\n",
      "Epoch 618 train loss: 0.6632812866908416\n",
      "Epoch 618 train accuracy: 74.5818480943241\n",
      "Epoch 618 val loss: 0.6566113824711034\n",
      "Epoch 618 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_618.pth\n",
      "Epoch 619 train loss: 0.663240360063419\n",
      "Epoch 619 train accuracy: 74.5544282972306\n",
      "Epoch 619 val loss: 0.6565919956682544\n",
      "Epoch 619 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_619.pth\n",
      "Epoch 620 train loss: 0.6632552888048323\n",
      "Epoch 620 train accuracy: 74.6092678914176\n",
      "Epoch 620 val loss: 0.6565758309474117\n",
      "Epoch 620 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_620.pth\n",
      "Epoch 621 train loss: 0.6632482910103965\n",
      "Epoch 621 train accuracy: 74.6366876885111\n",
      "Epoch 621 val loss: 0.6565611212465324\n",
      "Epoch 621 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_621.pth\n",
      "Epoch 622 train loss: 0.6632120463212854\n",
      "Epoch 622 train accuracy: 74.6092678914176\n",
      "Epoch 622 val loss: 0.6565429633973461\n",
      "Epoch 622 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_622.pth\n",
      "Epoch 623 train loss: 0.6632294015011244\n",
      "Epoch 623 train accuracy: 74.6366876885111\n",
      "Epoch 623 val loss: 0.6565341913190327\n",
      "Epoch 623 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_623.pth\n",
      "Epoch 624 train loss: 0.6631842020310854\n",
      "Epoch 624 train accuracy: 74.6641074856046\n",
      "Epoch 624 val loss: 0.6565105656259939\n",
      "Epoch 624 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_624.pth\n",
      "Epoch 625 train loss: 0.6632217077963185\n",
      "Epoch 625 train accuracy: 74.6641074856046\n",
      "Epoch 625 val loss: 0.6564979972807985\n",
      "Epoch 625 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_625.pth\n",
      "Epoch 626 train loss: 0.6631662080293161\n",
      "Epoch 626 train accuracy: 74.6915272826981\n",
      "Epoch 626 val loss: 0.6564930273514045\n",
      "Epoch 626 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_626.pth\n",
      "Epoch 627 train loss: 0.6631420537698687\n",
      "Epoch 627 train accuracy: 74.6641074856046\n",
      "Epoch 627 val loss: 0.6564792741678263\n",
      "Epoch 627 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_627.pth\n",
      "Epoch 628 train loss: 0.6631172794456545\n",
      "Epoch 628 train accuracy: 74.6092678914176\n",
      "Epoch 628 val loss: 0.6564724054187536\n",
      "Epoch 628 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_628.pth\n",
      "Epoch 629 train loss: 0.66315429393006\n",
      "Epoch 629 train accuracy: 74.6641074856046\n",
      "Epoch 629 val loss: 0.6564440034133824\n",
      "Epoch 629 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_629.pth\n",
      "Epoch 630 train loss: 0.6631406727655415\n",
      "Epoch 630 train accuracy: 74.6641074856046\n",
      "Epoch 630 val loss: 0.6564290237269903\n",
      "Epoch 630 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_630.pth\n",
      "Epoch 631 train loss: 0.6631287889587775\n",
      "Epoch 631 train accuracy: 74.6366876885111\n",
      "Epoch 631 val loss: 0.6564136107305163\n",
      "Epoch 631 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_631.pth\n",
      "Epoch 632 train loss: 0.663117090044053\n",
      "Epoch 632 train accuracy: 74.6641074856046\n",
      "Epoch 632 val loss: 0.6564068839346108\n",
      "Epoch 632 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_632.pth\n",
      "Epoch 633 train loss: 0.6630744957283401\n",
      "Epoch 633 train accuracy: 74.6092678914176\n",
      "Epoch 633 val loss: 0.6563954568026882\n",
      "Epoch 633 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_633.pth\n",
      "Epoch 634 train loss: 0.6630929410784391\n",
      "Epoch 634 train accuracy: 74.6915272826981\n",
      "Epoch 634 val loss: 0.6563922745224676\n",
      "Epoch 634 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_634.pth\n",
      "Epoch 635 train loss: 0.663075833467015\n",
      "Epoch 635 train accuracy: 74.5818480943241\n",
      "Epoch 635 val loss: 0.6563821366350902\n",
      "Epoch 635 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_635.pth\n",
      "Epoch 636 train loss: 0.663046647157324\n",
      "Epoch 636 train accuracy: 74.6366876885111\n",
      "Epoch 636 val loss: 0.6563664091456878\n",
      "Epoch 636 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_636.pth\n",
      "Epoch 637 train loss: 0.6629980152244108\n",
      "Epoch 637 train accuracy: 74.6366876885111\n",
      "Epoch 637 val loss: 0.6563483976611966\n",
      "Epoch 637 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_637.pth\n",
      "Epoch 638 train loss: 0.6630512679551255\n",
      "Epoch 638 train accuracy: 74.7189470797916\n",
      "Epoch 638 val loss: 0.6563367197584165\n",
      "Epoch 638 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_638.pth\n",
      "Epoch 639 train loss: 0.6630168418939176\n",
      "Epoch 639 train accuracy: 74.6641074856046\n",
      "Epoch 639 val loss: 0.6563214711648854\n",
      "Epoch 639 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_639.pth\n",
      "Epoch 640 train loss: 0.6630246778459925\n",
      "Epoch 640 train accuracy: 74.5818480943241\n",
      "Epoch 640 val loss: 0.6563161844877821\n",
      "Epoch 640 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_640.pth\n",
      "Epoch 641 train loss: 0.6629366440404403\n",
      "Epoch 641 train accuracy: 74.6641074856046\n",
      "Epoch 641 val loss: 0.6563011353933498\n",
      "Epoch 641 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_641.pth\n",
      "Epoch 642 train loss: 0.66292869708125\n",
      "Epoch 642 train accuracy: 74.5818480943241\n",
      "Epoch 642 val loss: 0.6562896474803749\n",
      "Epoch 642 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_642.pth\n",
      "Epoch 643 train loss: 0.6629871112670291\n",
      "Epoch 643 train accuracy: 74.6366876885111\n",
      "Epoch 643 val loss: 0.6562751078684079\n",
      "Epoch 643 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_643.pth\n",
      "Epoch 644 train loss: 0.6629789303988218\n",
      "Epoch 644 train accuracy: 74.6092678914176\n",
      "Epoch 644 val loss: 0.6562617931907114\n",
      "Epoch 644 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_644.pth\n",
      "Epoch 645 train loss: 0.6629211130764401\n",
      "Epoch 645 train accuracy: 74.5818480943241\n",
      "Epoch 645 val loss: 0.656246516755537\n",
      "Epoch 645 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_645.pth\n",
      "Epoch 646 train loss: 0.6629501965811901\n",
      "Epoch 646 train accuracy: 74.6092678914176\n",
      "Epoch 646 val loss: 0.6562289551488663\n",
      "Epoch 646 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_646.pth\n",
      "Epoch 647 train loss: 0.6629458455401555\n",
      "Epoch 647 train accuracy: 74.6092678914176\n",
      "Epoch 647 val loss: 0.6562090263162789\n",
      "Epoch 647 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_647.pth\n",
      "Epoch 648 train loss: 0.6629737222795946\n",
      "Epoch 648 train accuracy: 74.6641074856046\n",
      "Epoch 648 val loss: 0.6561939821235443\n",
      "Epoch 648 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_648.pth\n",
      "Epoch 649 train loss: 0.6629094504342791\n",
      "Epoch 649 train accuracy: 74.5818480943241\n",
      "Epoch 649 val loss: 0.6561815412224907\n",
      "Epoch 649 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_649.pth\n",
      "Epoch 650 train loss: 0.6629063124327284\n",
      "Epoch 650 train accuracy: 74.6366876885111\n",
      "Epoch 650 val loss: 0.6561657582458696\n",
      "Epoch 650 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_650.pth\n",
      "Epoch 651 train loss: 0.6627893141356477\n",
      "Epoch 651 train accuracy: 74.5818480943241\n",
      "Epoch 651 val loss: 0.6561617855178682\n",
      "Epoch 651 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_651.pth\n",
      "Epoch 652 train loss: 0.6629412046453932\n",
      "Epoch 652 train accuracy: 74.6366876885111\n",
      "Epoch 652 val loss: 0.6561350420509514\n",
      "Epoch 652 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_652.pth\n",
      "Epoch 653 train loss: 0.662879145459125\n",
      "Epoch 653 train accuracy: 74.6641074856046\n",
      "Epoch 653 val loss: 0.6561278107723123\n",
      "Epoch 653 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_653.pth\n",
      "Epoch 654 train loss: 0.6628575052151031\n",
      "Epoch 654 train accuracy: 74.5818480943241\n",
      "Epoch 654 val loss: 0.6561062498704383\n",
      "Epoch 654 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_654.pth\n",
      "Epoch 655 train loss: 0.6629323136518922\n",
      "Epoch 655 train accuracy: 74.6366876885111\n",
      "Epoch 655 val loss: 0.6561031038627813\n",
      "Epoch 655 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_655.pth\n",
      "Epoch 656 train loss: 0.6627721587490094\n",
      "Epoch 656 train accuracy: 74.6092678914176\n",
      "Epoch 656 val loss: 0.6560880128098162\n",
      "Epoch 656 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_656.pth\n",
      "Epoch 657 train loss: 0.6628295382190692\n",
      "Epoch 657 train accuracy: 74.5544282972306\n",
      "Epoch 657 val loss: 0.6560796887466782\n",
      "Epoch 657 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_657.pth\n",
      "Epoch 658 train loss: 0.6628144359575552\n",
      "Epoch 658 train accuracy: 74.6092678914176\n",
      "Epoch 658 val loss: 0.656057996969474\n",
      "Epoch 658 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_658.pth\n",
      "Epoch 659 train loss: 0.6627204231917858\n",
      "Epoch 659 train accuracy: 74.6366876885111\n",
      "Epoch 659 val loss: 0.6560603688029867\n",
      "Epoch 659 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_659.pth\n",
      "Epoch 660 train loss: 0.6627368043062457\n",
      "Epoch 660 train accuracy: 74.6092678914176\n",
      "Epoch 660 val loss: 0.6560490175493454\n",
      "Epoch 660 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_660.pth\n",
      "Epoch 661 train loss: 0.6627752836957052\n",
      "Epoch 661 train accuracy: 74.6092678914176\n",
      "Epoch 661 val loss: 0.6560406696639562\n",
      "Epoch 661 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_661.pth\n",
      "Epoch 662 train loss: 0.6627547446180854\n",
      "Epoch 662 train accuracy: 74.6092678914176\n",
      "Epoch 662 val loss: 0.6560178684364808\n",
      "Epoch 662 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_662.pth\n",
      "Epoch 663 train loss: 0.6627190831656519\n",
      "Epoch 663 train accuracy: 74.6092678914176\n",
      "Epoch 663 val loss: 0.6560033483332709\n",
      "Epoch 663 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_663.pth\n",
      "Epoch 664 train loss: 0.6627068670237797\n",
      "Epoch 664 train accuracy: 74.5818480943241\n",
      "Epoch 664 val loss: 0.6559964640948334\n",
      "Epoch 664 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_664.pth\n",
      "Epoch 665 train loss: 0.6626967346263036\n",
      "Epoch 665 train accuracy: 74.6641074856046\n",
      "Epoch 665 val loss: 0.6559907456761912\n",
      "Epoch 665 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_665.pth\n",
      "Epoch 666 train loss: 0.6627196227772194\n",
      "Epoch 666 train accuracy: 74.6092678914176\n",
      "Epoch 666 val loss: 0.6559751954321799\n",
      "Epoch 666 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_666.pth\n",
      "Epoch 667 train loss: 0.6627075951546431\n",
      "Epoch 667 train accuracy: 74.6092678914176\n",
      "Epoch 667 val loss: 0.6559590454164305\n",
      "Epoch 667 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_667.pth\n",
      "Epoch 668 train loss: 0.6626401958954439\n",
      "Epoch 668 train accuracy: 74.5818480943241\n",
      "Epoch 668 val loss: 0.6559434523315806\n",
      "Epoch 668 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_668.pth\n",
      "Epoch 669 train loss: 0.6626562849013952\n",
      "Epoch 669 train accuracy: 74.6366876885111\n",
      "Epoch 669 val loss: 0.6559352705157117\n",
      "Epoch 669 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_669.pth\n",
      "Epoch 670 train loss: 0.662624600588491\n",
      "Epoch 670 train accuracy: 74.6366876885111\n",
      "Epoch 670 val loss: 0.6559268307725066\n",
      "Epoch 670 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_670.pth\n",
      "Epoch 671 train loss: 0.662661955838925\n",
      "Epoch 671 train accuracy: 74.6366876885111\n",
      "Epoch 671 val loss: 0.6559075902363187\n",
      "Epoch 671 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_671.pth\n",
      "Epoch 672 train loss: 0.6626463739299461\n",
      "Epoch 672 train accuracy: 74.6366876885111\n",
      "Epoch 672 val loss: 0.6559046700008606\n",
      "Epoch 672 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_672.pth\n",
      "Epoch 673 train loss: 0.6626316808948391\n",
      "Epoch 673 train accuracy: 74.6366876885111\n",
      "Epoch 673 val loss: 0.6558934260944003\n",
      "Epoch 673 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_673.pth\n",
      "Epoch 674 train loss: 0.6625329322067269\n",
      "Epoch 674 train accuracy: 74.6092678914176\n",
      "Epoch 674 val loss: 0.6558792015635654\n",
      "Epoch 674 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_674.pth\n",
      "Epoch 675 train loss: 0.6625709181095947\n",
      "Epoch 675 train accuracy: 74.6366876885111\n",
      "Epoch 675 val loss: 0.6558765149430225\n",
      "Epoch 675 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_675.pth\n",
      "Epoch 676 train loss: 0.6625986289429037\n",
      "Epoch 676 train accuracy: 74.6366876885111\n",
      "Epoch 676 val loss: 0.6558601348415801\n",
      "Epoch 676 val accuracy: 75.41118421052632\n",
      "Saved model to .\\test_modelsv2/MLP_676.pth\n",
      "Epoch 677 train loss: 0.6626045595070249\n",
      "Epoch 677 train accuracy: 74.6092678914176\n",
      "Epoch 677 val loss: 0.6558393247817692\n",
      "Epoch 677 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_677.pth\n",
      "Epoch 678 train loss: 0.6625910909813747\n",
      "Epoch 678 train accuracy: 74.6092678914176\n",
      "Epoch 678 val loss: 0.6558300710626339\n",
      "Epoch 678 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_678.pth\n",
      "Epoch 679 train loss: 0.6625613708114415\n",
      "Epoch 679 train accuracy: 74.5818480943241\n",
      "Epoch 679 val loss: 0.6558098530298785\n",
      "Epoch 679 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_679.pth\n",
      "Epoch 680 train loss: 0.6625197494500562\n",
      "Epoch 680 train accuracy: 74.6366876885111\n",
      "Epoch 680 val loss: 0.6558073148327438\n",
      "Epoch 680 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_680.pth\n",
      "Epoch 681 train loss: 0.6626734895337569\n",
      "Epoch 681 train accuracy: 74.6366876885111\n",
      "Epoch 681 val loss: 0.6557880192995071\n",
      "Epoch 681 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_681.pth\n",
      "Epoch 682 train loss: 0.6624041036620998\n",
      "Epoch 682 train accuracy: 74.5818480943241\n",
      "Epoch 682 val loss: 0.6557865665343247\n",
      "Epoch 682 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_682.pth\n",
      "Epoch 683 train loss: 0.6625363209137791\n",
      "Epoch 683 train accuracy: 74.6366876885111\n",
      "Epoch 683 val loss: 0.6557688836596514\n",
      "Epoch 683 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_683.pth\n",
      "Epoch 684 train loss: 0.6625443159096074\n",
      "Epoch 684 train accuracy: 74.6092678914176\n",
      "Epoch 684 val loss: 0.6557664974151474\n",
      "Epoch 684 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_684.pth\n",
      "Epoch 685 train loss: 0.6624928180847252\n",
      "Epoch 685 train accuracy: 74.6366876885111\n",
      "Epoch 685 val loss: 0.6557507328689098\n",
      "Epoch 685 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_685.pth\n",
      "Epoch 686 train loss: 0.6624369557228005\n",
      "Epoch 686 train accuracy: 74.6366876885111\n",
      "Epoch 686 val loss: 0.6557318561367298\n",
      "Epoch 686 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_686.pth\n",
      "Epoch 687 train loss: 0.6624667877494766\n",
      "Epoch 687 train accuracy: 74.6366876885111\n",
      "Epoch 687 val loss: 0.6557150547833819\n",
      "Epoch 687 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_687.pth\n",
      "Epoch 688 train loss: 0.6624542357759517\n",
      "Epoch 688 train accuracy: 74.6092678914176\n",
      "Epoch 688 val loss: 0.6557239821474803\n",
      "Epoch 688 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_688.pth\n",
      "Epoch 689 train loss: 0.662445556797218\n",
      "Epoch 689 train accuracy: 74.6092678914176\n",
      "Epoch 689 val loss: 0.65571283019687\n",
      "Epoch 689 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_689.pth\n",
      "Epoch 690 train loss: 0.662415001688427\n",
      "Epoch 690 train accuracy: 74.5818480943241\n",
      "Epoch 690 val loss: 0.6556926633378393\n",
      "Epoch 690 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_690.pth\n",
      "Epoch 691 train loss: 0.6623774959068549\n",
      "Epoch 691 train accuracy: 74.6092678914176\n",
      "Epoch 691 val loss: 0.6556838807698927\n",
      "Epoch 691 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_691.pth\n",
      "Epoch 692 train loss: 0.6624127300946336\n",
      "Epoch 692 train accuracy: 74.6092678914176\n",
      "Epoch 692 val loss: 0.6556676580129486\n",
      "Epoch 692 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_692.pth\n",
      "Epoch 693 train loss: 0.6624761540769485\n",
      "Epoch 693 train accuracy: 74.5818480943241\n",
      "Epoch 693 val loss: 0.6556550304552442\n",
      "Epoch 693 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_693.pth\n",
      "Epoch 694 train loss: 0.6622900126926732\n",
      "Epoch 694 train accuracy: 74.6092678914176\n",
      "Epoch 694 val loss: 0.6556483132666663\n",
      "Epoch 694 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_694.pth\n",
      "Epoch 695 train loss: 0.6624391026664198\n",
      "Epoch 695 train accuracy: 74.5818480943241\n",
      "Epoch 695 val loss: 0.65562808876367\n",
      "Epoch 695 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_695.pth\n",
      "Epoch 696 train loss: 0.662368031055258\n",
      "Epoch 696 train accuracy: 74.6092678914176\n",
      "Epoch 696 val loss: 0.6556323839253501\n",
      "Epoch 696 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_696.pth\n",
      "Epoch 697 train loss: 0.6623685876266998\n",
      "Epoch 697 train accuracy: 74.6092678914176\n",
      "Epoch 697 val loss: 0.6556047209979672\n",
      "Epoch 697 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_697.pth\n",
      "Epoch 698 train loss: 0.6623322037293723\n",
      "Epoch 698 train accuracy: 74.6366876885111\n",
      "Epoch 698 val loss: 0.6555891001695081\n",
      "Epoch 698 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_698.pth\n",
      "Epoch 699 train loss: 0.6623589666396902\n",
      "Epoch 699 train accuracy: 74.6092678914176\n",
      "Epoch 699 val loss: 0.6555676740643225\n",
      "Epoch 699 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_699.pth\n",
      "Epoch 700 train loss: 0.6623211556947545\n",
      "Epoch 700 train accuracy: 74.6366876885111\n",
      "Epoch 700 val loss: 0.6555657028955849\n",
      "Epoch 700 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_700.pth\n",
      "Epoch 701 train loss: 0.6623115571248427\n",
      "Epoch 701 train accuracy: 74.6366876885111\n",
      "Epoch 701 val loss: 0.655557665581766\n",
      "Epoch 701 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_701.pth\n",
      "Epoch 702 train loss: 0.6622665684278074\n",
      "Epoch 702 train accuracy: 74.6915272826981\n",
      "Epoch 702 val loss: 0.6555418960357967\n",
      "Epoch 702 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_702.pth\n",
      "Epoch 703 train loss: 0.6622662524643698\n",
      "Epoch 703 train accuracy: 74.6915272826981\n",
      "Epoch 703 val loss: 0.6555267795920372\n",
      "Epoch 703 val accuracy: 75.49342105263158\n",
      "Saved model to .\\test_modelsv2/MLP_703.pth\n",
      "Epoch 704 train loss: 0.6622532785853796\n",
      "Epoch 704 train accuracy: 74.6366876885111\n",
      "Epoch 704 val loss: 0.6555004963945401\n",
      "Epoch 704 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_704.pth\n",
      "Epoch 705 train loss: 0.6622844388414371\n",
      "Epoch 705 train accuracy: 74.6366876885111\n",
      "Epoch 705 val loss: 0.6555021766965327\n",
      "Epoch 705 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_705.pth\n",
      "Epoch 706 train loss: 0.6622577902060329\n",
      "Epoch 706 train accuracy: 74.6641074856046\n",
      "Epoch 706 val loss: 0.6554974646944749\n",
      "Epoch 706 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_706.pth\n",
      "Epoch 707 train loss: 0.6622468907255352\n",
      "Epoch 707 train accuracy: 74.6641074856046\n",
      "Epoch 707 val loss: 0.6554741652584389\n",
      "Epoch 707 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_707.pth\n",
      "Epoch 708 train loss: 0.6622182293876744\n",
      "Epoch 708 train accuracy: 74.6915272826981\n",
      "Epoch 708 val loss: 0.655459625646472\n",
      "Epoch 708 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_708.pth\n",
      "Epoch 709 train loss: 0.6621701115121444\n",
      "Epoch 709 train accuracy: 74.6366876885111\n",
      "Epoch 709 val loss: 0.6554532802026523\n",
      "Epoch 709 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_709.pth\n",
      "Epoch 710 train loss: 0.6622067111822074\n",
      "Epoch 710 train accuracy: 74.6641074856046\n",
      "Epoch 710 val loss: 0.6554514075580397\n",
      "Epoch 710 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_710.pth\n",
      "Epoch 711 train loss: 0.6621793490556771\n",
      "Epoch 711 train accuracy: 74.6641074856046\n",
      "Epoch 711 val loss: 0.6554383727672853\n",
      "Epoch 711 val accuracy: 75.57565789473684\n",
      "Saved model to .\\test_modelsv2/MLP_711.pth\n",
      "Epoch 712 train loss: 0.6621562641506132\n",
      "Epoch 712 train accuracy: 74.6915272826981\n",
      "Epoch 712 val loss: 0.6554180106246158\n",
      "Epoch 712 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_712.pth\n",
      "Epoch 713 train loss: 0.6622426927481827\n",
      "Epoch 713 train accuracy: 74.6366876885111\n",
      "Epoch 713 val loss: 0.6553993772127127\n",
      "Epoch 713 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_713.pth\n",
      "Epoch 714 train loss: 0.6621722458420616\n",
      "Epoch 714 train accuracy: 74.6641074856046\n",
      "Epoch 714 val loss: 0.6553811416225997\n",
      "Epoch 714 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_714.pth\n",
      "Epoch 715 train loss: 0.6621407675965313\n",
      "Epoch 715 train accuracy: 74.6641074856046\n",
      "Epoch 715 val loss: 0.6553743493400122\n",
      "Epoch 715 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_715.pth\n",
      "Epoch 716 train loss: 0.6621458810476357\n",
      "Epoch 716 train accuracy: 74.6366876885111\n",
      "Epoch 716 val loss: 0.6553574835783557\n",
      "Epoch 716 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_716.pth\n",
      "Epoch 717 train loss: 0.6621353923620885\n",
      "Epoch 717 train accuracy: 74.6366876885111\n",
      "Epoch 717 val loss: 0.6553613728794613\n",
      "Epoch 717 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_717.pth\n",
      "Epoch 718 train loss: 0.6620827181950996\n",
      "Epoch 718 train accuracy: 74.6641074856046\n",
      "Epoch 718 val loss: 0.6553494373434469\n",
      "Epoch 718 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_718.pth\n",
      "Epoch 719 train loss: 0.6621151624672246\n",
      "Epoch 719 train accuracy: 74.6366876885111\n",
      "Epoch 719 val loss: 0.6553362561879974\n",
      "Epoch 719 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_719.pth\n",
      "Epoch 720 train loss: 0.6621069371896354\n",
      "Epoch 720 train accuracy: 74.6092678914176\n",
      "Epoch 720 val loss: 0.6553358400338575\n",
      "Epoch 720 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_720.pth\n",
      "Epoch 721 train loss: 0.6621497187502029\n",
      "Epoch 721 train accuracy: 74.6915272826981\n",
      "Epoch 721 val loss: 0.6553189389799771\n",
      "Epoch 721 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_721.pth\n",
      "Epoch 722 train loss: 0.6620849530424988\n",
      "Epoch 722 train accuracy: 74.7189470797916\n",
      "Epoch 722 val loss: 0.6553130683146025\n",
      "Epoch 722 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_722.pth\n",
      "Epoch 723 train loss: 0.6621179956158525\n",
      "Epoch 723 train accuracy: 74.6915272826981\n",
      "Epoch 723 val loss: 0.655299059752571\n",
      "Epoch 723 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_723.pth\n",
      "Epoch 724 train loss: 0.6620630594460588\n",
      "Epoch 724 train accuracy: 74.6366876885111\n",
      "Epoch 724 val loss: 0.6552966385099449\n",
      "Epoch 724 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_724.pth\n",
      "Epoch 725 train loss: 0.6620712453466758\n",
      "Epoch 725 train accuracy: 74.6641074856046\n",
      "Epoch 725 val loss: 0.6552841136918256\n",
      "Epoch 725 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_725.pth\n",
      "Epoch 726 train loss: 0.6620421520712083\n",
      "Epoch 726 train accuracy: 74.6915272826981\n",
      "Epoch 726 val loss: 0.6552724871588381\n",
      "Epoch 726 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_726.pth\n",
      "Epoch 727 train loss: 0.6619982213239398\n",
      "Epoch 727 train accuracy: 74.7463668768851\n",
      "Epoch 727 val loss: 0.6552495414293126\n",
      "Epoch 727 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_727.pth\n",
      "Epoch 728 train loss: 0.6620230674416873\n",
      "Epoch 728 train accuracy: 74.7189470797916\n",
      "Epoch 728 val loss: 0.6552353466027662\n",
      "Epoch 728 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_728.pth\n",
      "Epoch 729 train loss: 0.6619890246932444\n",
      "Epoch 729 train accuracy: 74.6915272826981\n",
      "Epoch 729 val loss: 0.6552399216513884\n",
      "Epoch 729 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_729.pth\n",
      "Epoch 730 train loss: 0.6619729019309345\n",
      "Epoch 730 train accuracy: 74.7463668768851\n",
      "Epoch 730 val loss: 0.65522388790391\n",
      "Epoch 730 val accuracy: 75.65789473684211\n",
      "Saved model to .\\test_modelsv2/MLP_730.pth\n",
      "Epoch 731 train loss: 0.6619857044465709\n",
      "Epoch 731 train accuracy: 74.6915272826981\n",
      "Epoch 731 val loss: 0.6552025223837087\n",
      "Epoch 731 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_731.pth\n",
      "Epoch 732 train loss: 0.6619789311172146\n",
      "Epoch 732 train accuracy: 74.7189470797916\n",
      "Epoch 732 val loss: 0.6551917823717782\n",
      "Epoch 732 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_732.pth\n",
      "Epoch 733 train loss: 0.6619416906318644\n",
      "Epoch 733 train accuracy: 74.6915272826981\n",
      "Epoch 733 val loss: 0.6551727803522035\n",
      "Epoch 733 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_733.pth\n",
      "Epoch 734 train loss: 0.6619574983457202\n",
      "Epoch 734 train accuracy: 74.7189470797916\n",
      "Epoch 734 val loss: 0.655162123473067\n",
      "Epoch 734 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_734.pth\n",
      "Epoch 735 train loss: 0.6619328517924276\n",
      "Epoch 735 train accuracy: 74.7737866739786\n",
      "Epoch 735 val loss: 0.6551545049603048\n",
      "Epoch 735 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_735.pth\n",
      "Epoch 736 train loss: 0.6619254173220772\n",
      "Epoch 736 train accuracy: 74.7463668768851\n",
      "Epoch 736 val loss: 0.6551513615015306\n",
      "Epoch 736 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_736.pth\n",
      "Epoch 737 train loss: 0.6619275079288504\n",
      "Epoch 737 train accuracy: 74.7189470797916\n",
      "Epoch 737 val loss: 0.6551360719298062\n",
      "Epoch 737 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_737.pth\n",
      "Epoch 738 train loss: 0.661961822460095\n",
      "Epoch 738 train accuracy: 74.6915272826981\n",
      "Epoch 738 val loss: 0.6551286601706555\n",
      "Epoch 738 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_738.pth\n",
      "Epoch 739 train loss: 0.6619091747132572\n",
      "Epoch 739 train accuracy: 74.6915272826981\n",
      "Epoch 739 val loss: 0.6551310413173939\n",
      "Epoch 739 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_739.pth\n",
      "Epoch 740 train loss: 0.6618964718491361\n",
      "Epoch 740 train accuracy: 74.6915272826981\n",
      "Epoch 740 val loss: 0.6551225546159243\n",
      "Epoch 740 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_740.pth\n",
      "Epoch 741 train loss: 0.6618863178841901\n",
      "Epoch 741 train accuracy: 74.6915272826981\n",
      "Epoch 741 val loss: 0.6551135472561184\n",
      "Epoch 741 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_741.pth\n",
      "Epoch 742 train loss: 0.6618797057880121\n",
      "Epoch 742 train accuracy: 74.7189470797916\n",
      "Epoch 742 val loss: 0.6551025966672521\n",
      "Epoch 742 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_742.pth\n",
      "Epoch 743 train loss: 0.6618150118084853\n",
      "Epoch 743 train accuracy: 74.6641074856046\n",
      "Epoch 743 val loss: 0.6550610096831071\n",
      "Epoch 743 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_743.pth\n",
      "Epoch 744 train loss: 0.6618606588852248\n",
      "Epoch 744 train accuracy: 74.7463668768851\n",
      "Epoch 744 val loss: 0.6550525153349889\n",
      "Epoch 744 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_744.pth\n",
      "Epoch 745 train loss: 0.6618454190330547\n",
      "Epoch 745 train accuracy: 74.7737866739786\n",
      "Epoch 745 val loss: 0.6550508821873289\n",
      "Epoch 745 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_745.pth\n",
      "Epoch 746 train loss: 0.6619131787304293\n",
      "Epoch 746 train accuracy: 74.7189470797916\n",
      "Epoch 746 val loss: 0.6550333804794048\n",
      "Epoch 746 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_746.pth\n",
      "Epoch 747 train loss: 0.6617659972000279\n",
      "Epoch 747 train accuracy: 74.7463668768851\n",
      "Epoch 747 val loss: 0.6550377474019402\n",
      "Epoch 747 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_747.pth\n",
      "Epoch 748 train loss: 0.6618150266116125\n",
      "Epoch 748 train accuracy: 74.7189470797916\n",
      "Epoch 748 val loss: 0.6550312156936056\n",
      "Epoch 748 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_748.pth\n",
      "Epoch 749 train loss: 0.6617423902151355\n",
      "Epoch 749 train accuracy: 74.7463668768851\n",
      "Epoch 749 val loss: 0.6549979503217497\n",
      "Epoch 749 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_749.pth\n",
      "Epoch 750 train loss: 0.6618030486922515\n",
      "Epoch 750 train accuracy: 74.7189470797916\n",
      "Epoch 750 val loss: 0.6549852553166842\n",
      "Epoch 750 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_750.pth\n",
      "Epoch 751 train loss: 0.661844367422817\n",
      "Epoch 751 train accuracy: 74.7189470797916\n",
      "Epoch 751 val loss: 0.6549868421923173\n",
      "Epoch 751 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_751.pth\n",
      "Epoch 752 train loss: 0.6617272550142125\n",
      "Epoch 752 train accuracy: 74.7189470797916\n",
      "Epoch 752 val loss: 0.6549887245422915\n",
      "Epoch 752 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_752.pth\n",
      "Epoch 753 train loss: 0.6617164519664488\n",
      "Epoch 753 train accuracy: 74.7737866739786\n",
      "Epoch 753 val loss: 0.6549767504789328\n",
      "Epoch 753 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_753.pth\n",
      "Epoch 754 train loss: 0.6617697204806303\n",
      "Epoch 754 train accuracy: 74.6915272826981\n",
      "Epoch 754 val loss: 0.6549793826906305\n",
      "Epoch 754 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_754.pth\n",
      "Epoch 755 train loss: 0.6617738990962767\n",
      "Epoch 755 train accuracy: 74.7463668768851\n",
      "Epoch 755 val loss: 0.6549681777036503\n",
      "Epoch 755 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_755.pth\n",
      "Epoch 756 train loss: 0.661732970197734\n",
      "Epoch 756 train accuracy: 74.7463668768851\n",
      "Epoch 756 val loss: 0.6549483374937585\n",
      "Epoch 756 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_756.pth\n",
      "Epoch 757 train loss: 0.6617302517815117\n",
      "Epoch 757 train accuracy: 74.6641074856046\n",
      "Epoch 757 val loss: 0.6549383711658026\n",
      "Epoch 757 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_757.pth\n",
      "Epoch 758 train loss: 0.6617790754361633\n",
      "Epoch 758 train accuracy: 74.7463668768851\n",
      "Epoch 758 val loss: 0.654908800595685\n",
      "Epoch 758 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_758.pth\n",
      "Epoch 759 train loss: 0.6616711017855427\n",
      "Epoch 759 train accuracy: 74.7189470797916\n",
      "Epoch 759 val loss: 0.6549026735715175\n",
      "Epoch 759 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_759.pth\n",
      "Epoch 760 train loss: 0.6616346769100219\n",
      "Epoch 760 train accuracy: 74.7189470797916\n",
      "Epoch 760 val loss: 0.6549109080316204\n",
      "Epoch 760 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_760.pth\n",
      "Epoch 761 train loss: 0.6617337054197203\n",
      "Epoch 761 train accuracy: 74.7463668768851\n",
      "Epoch 761 val loss: 0.654908553256016\n",
      "Epoch 761 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_761.pth\n",
      "Epoch 762 train loss: 0.661592137264578\n",
      "Epoch 762 train accuracy: 74.7463668768851\n",
      "Epoch 762 val loss: 0.6548931637876912\n",
      "Epoch 762 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_762.pth\n",
      "Epoch 763 train loss: 0.6617260570066017\n",
      "Epoch 763 train accuracy: 74.7737866739786\n",
      "Epoch 763 val loss: 0.6548642641619632\n",
      "Epoch 763 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_763.pth\n",
      "Epoch 764 train loss: 0.6617109658229247\n",
      "Epoch 764 train accuracy: 74.7463668768851\n",
      "Epoch 764 val loss: 0.6548456218289701\n",
      "Epoch 764 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_764.pth\n",
      "Epoch 765 train loss: 0.6616514510426083\n",
      "Epoch 765 train accuracy: 74.7737866739786\n",
      "Epoch 765 val loss: 0.654851325444485\n",
      "Epoch 765 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_765.pth\n",
      "Epoch 766 train loss: 0.661640747728055\n",
      "Epoch 766 train accuracy: 74.80120647107212\n",
      "Epoch 766 val loss: 0.6548474970224657\n",
      "Epoch 766 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_766.pth\n",
      "Epoch 767 train loss: 0.661627782247307\n",
      "Epoch 767 train accuracy: 74.82862626816562\n",
      "Epoch 767 val loss: 0.6548308145843054\n",
      "Epoch 767 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_767.pth\n",
      "Epoch 768 train loss: 0.6616584927562559\n",
      "Epoch 768 train accuracy: 74.7463668768851\n",
      "Epoch 768 val loss: 0.6547972270728726\n",
      "Epoch 768 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_768.pth\n",
      "Epoch 769 train loss: 0.6615643175155447\n",
      "Epoch 769 train accuracy: 74.7189470797916\n",
      "Epoch 769 val loss: 0.654810086480881\n",
      "Epoch 769 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_769.pth\n",
      "Epoch 770 train loss: 0.6615666027197189\n",
      "Epoch 770 train accuracy: 74.80120647107212\n",
      "Epoch 770 val loss: 0.6548130070104411\n",
      "Epoch 770 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_770.pth\n",
      "Epoch 771 train loss: 0.6616261650791817\n",
      "Epoch 771 train accuracy: 74.7463668768851\n",
      "Epoch 771 val loss: 0.654789370827769\n",
      "Epoch 771 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_771.pth\n",
      "Epoch 772 train loss: 0.6616043523607547\n",
      "Epoch 772 train accuracy: 74.80120647107212\n",
      "Epoch 772 val loss: 0.6547768145407501\n",
      "Epoch 772 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_772.pth\n",
      "Epoch 773 train loss: 0.6615737987061342\n",
      "Epoch 773 train accuracy: 74.7737866739786\n",
      "Epoch 773 val loss: 0.6547627170619211\n",
      "Epoch 773 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_773.pth\n",
      "Epoch 774 train loss: 0.6616212987063224\n",
      "Epoch 774 train accuracy: 74.80120647107212\n",
      "Epoch 774 val loss: 0.6547592963631216\n",
      "Epoch 774 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_774.pth\n",
      "Epoch 775 train loss: 0.6615113645399872\n",
      "Epoch 775 train accuracy: 74.7737866739786\n",
      "Epoch 775 val loss: 0.6547298530410779\n",
      "Epoch 775 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_775.pth\n",
      "Epoch 776 train loss: 0.6614909968747381\n",
      "Epoch 776 train accuracy: 74.7463668768851\n",
      "Epoch 776 val loss: 0.6547381523996592\n",
      "Epoch 776 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_776.pth\n",
      "Epoch 777 train loss: 0.6614441695508727\n",
      "Epoch 777 train accuracy: 74.7737866739786\n",
      "Epoch 777 val loss: 0.654727330529376\n",
      "Epoch 777 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_777.pth\n",
      "Epoch 778 train loss: 0.6615446186379382\n",
      "Epoch 778 train accuracy: 74.80120647107212\n",
      "Epoch 778 val loss: 0.6546989355824495\n",
      "Epoch 778 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_778.pth\n",
      "Epoch 779 train loss: 0.6615163189473382\n",
      "Epoch 779 train accuracy: 74.6915272826981\n",
      "Epoch 779 val loss: 0.6547049230062648\n",
      "Epoch 779 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_779.pth\n",
      "Epoch 780 train loss: 0.6614428661567601\n",
      "Epoch 780 train accuracy: 74.7737866739786\n",
      "Epoch 780 val loss: 0.6546844801816502\n",
      "Epoch 780 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_780.pth\n",
      "Epoch 781 train loss: 0.6614998311719351\n",
      "Epoch 781 train accuracy: 74.80120647107212\n",
      "Epoch 781 val loss: 0.6546717036123338\n",
      "Epoch 781 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_781.pth\n",
      "Epoch 782 train loss: 0.6614515813427013\n",
      "Epoch 782 train accuracy: 74.7737866739786\n",
      "Epoch 782 val loss: 0.6546564830565139\n",
      "Epoch 782 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_782.pth\n",
      "Epoch 783 train loss: 0.6613987749932628\n",
      "Epoch 783 train accuracy: 74.7737866739786\n",
      "Epoch 783 val loss: 0.654657014988755\n",
      "Epoch 783 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_783.pth\n",
      "Epoch 784 train loss: 0.661466743502962\n",
      "Epoch 784 train accuracy: 74.6915272826981\n",
      "Epoch 784 val loss: 0.6546412849504697\n",
      "Epoch 784 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_784.pth\n",
      "Epoch 785 train loss: 0.6614619260163683\n",
      "Epoch 785 train accuracy: 74.7737866739786\n",
      "Epoch 785 val loss: 0.6546369939062157\n",
      "Epoch 785 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_785.pth\n",
      "Epoch 786 train loss: 0.6614491380097574\n",
      "Epoch 786 train accuracy: 74.7189470797916\n",
      "Epoch 786 val loss: 0.6546415910124779\n",
      "Epoch 786 val accuracy: 75.74013157894737\n",
      "Saved model to .\\test_modelsv2/MLP_786.pth\n",
      "Epoch 787 train loss: 0.661450062600667\n",
      "Epoch 787 train accuracy: 74.7737866739786\n",
      "Epoch 787 val loss: 0.6546125572762991\n",
      "Epoch 787 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_787.pth\n",
      "Epoch 788 train loss: 0.6614218935566513\n",
      "Epoch 788 train accuracy: 74.7737866739786\n",
      "Epoch 788 val loss: 0.6546043086012727\n",
      "Epoch 788 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_788.pth\n",
      "Epoch 789 train loss: 0.6613455911150627\n",
      "Epoch 789 train accuracy: 74.7463668768851\n",
      "Epoch 789 val loss: 0.6545867253781149\n",
      "Epoch 789 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_789.pth\n",
      "Epoch 790 train loss: 0.6613005655245823\n",
      "Epoch 790 train accuracy: 74.7737866739786\n",
      "Epoch 790 val loss: 0.6545699217209691\n",
      "Epoch 790 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_790.pth\n",
      "Epoch 791 train loss: 0.6613283440339983\n",
      "Epoch 791 train accuracy: 74.7463668768851\n",
      "Epoch 791 val loss: 0.6545482636674455\n",
      "Epoch 791 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_791.pth\n",
      "Epoch 792 train loss: 0.661373246559187\n",
      "Epoch 792 train accuracy: 74.80120647107212\n",
      "Epoch 792 val loss: 0.654543084533591\n",
      "Epoch 792 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_792.pth\n",
      "Epoch 793 train loss: 0.6613862101446119\n",
      "Epoch 793 train accuracy: 74.82862626816562\n",
      "Epoch 793 val loss: 0.654549109700479\n",
      "Epoch 793 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_793.pth\n",
      "Epoch 794 train loss: 0.6614509059214279\n",
      "Epoch 794 train accuracy: 74.82862626816562\n",
      "Epoch 794 val loss: 0.6545201479212234\n",
      "Epoch 794 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_794.pth\n",
      "Epoch 795 train loss: 0.661327427449195\n",
      "Epoch 795 train accuracy: 74.7737866739786\n",
      "Epoch 795 val loss: 0.654520945819585\n",
      "Epoch 795 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_795.pth\n",
      "Epoch 796 train loss: 0.6613630186766386\n",
      "Epoch 796 train accuracy: 74.80120647107212\n",
      "Epoch 796 val loss: 0.6545180642095051\n",
      "Epoch 796 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_796.pth\n",
      "Epoch 797 train loss: 0.6612875344591183\n",
      "Epoch 797 train accuracy: 74.80120647107212\n",
      "Epoch 797 val loss: 0.6545070475457531\n",
      "Epoch 797 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_797.pth\n",
      "Epoch 798 train loss: 0.6613469642766735\n",
      "Epoch 798 train accuracy: 74.7737866739786\n",
      "Epoch 798 val loss: 0.65450105100478\n",
      "Epoch 798 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_798.pth\n",
      "Epoch 799 train loss: 0.6613327872923069\n",
      "Epoch 799 train accuracy: 74.80120647107212\n",
      "Epoch 799 val loss: 0.6544939084468704\n",
      "Epoch 799 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_799.pth\n",
      "Epoch 800 train loss: 0.6613282687112427\n",
      "Epoch 800 train accuracy: 74.80120647107212\n",
      "Epoch 800 val loss: 0.6544828116893768\n",
      "Epoch 800 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_800.pth\n",
      "Epoch 801 train loss: 0.6612751094068874\n",
      "Epoch 801 train accuracy: 74.80120647107212\n",
      "Epoch 801 val loss: 0.654476087736456\n",
      "Epoch 801 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_801.pth\n",
      "Epoch 802 train loss: 0.6612760021040837\n",
      "Epoch 802 train accuracy: 74.7737866739786\n",
      "Epoch 802 val loss: 0.6544645182592305\n",
      "Epoch 802 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_802.pth\n",
      "Epoch 803 train loss: 0.6612950008231819\n",
      "Epoch 803 train accuracy: 74.7463668768851\n",
      "Epoch 803 val loss: 0.6544439937723311\n",
      "Epoch 803 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_803.pth\n",
      "Epoch 804 train loss: 0.6613067519573266\n",
      "Epoch 804 train accuracy: 74.7463668768851\n",
      "Epoch 804 val loss: 0.6544264699087331\n",
      "Epoch 804 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_804.pth\n",
      "Epoch 805 train loss: 0.6612413125929603\n",
      "Epoch 805 train accuracy: 74.80120647107212\n",
      "Epoch 805 val loss: 0.6544251337059235\n",
      "Epoch 805 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_805.pth\n",
      "Epoch 806 train loss: 0.6613298475807696\n",
      "Epoch 806 train accuracy: 74.7737866739786\n",
      "Epoch 806 val loss: 0.6544095027799669\n",
      "Epoch 806 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_806.pth\n",
      "Epoch 807 train loss: 0.6612335169655189\n",
      "Epoch 807 train accuracy: 74.80120647107212\n",
      "Epoch 807 val loss: 0.6543936159853873\n",
      "Epoch 807 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_807.pth\n",
      "Epoch 808 train loss: 0.6612447684859497\n",
      "Epoch 808 train accuracy: 74.82862626816562\n",
      "Epoch 808 val loss: 0.654389472286168\n",
      "Epoch 808 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_808.pth\n",
      "Epoch 809 train loss: 0.661213059272421\n",
      "Epoch 809 train accuracy: 74.7737866739786\n",
      "Epoch 809 val loss: 0.6543818417152292\n",
      "Epoch 809 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_809.pth\n",
      "Epoch 810 train loss: 0.6612974453325334\n",
      "Epoch 810 train accuracy: 74.7737866739786\n",
      "Epoch 810 val loss: 0.6543824023714191\n",
      "Epoch 810 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_810.pth\n",
      "Epoch 811 train loss: 0.6611847442558461\n",
      "Epoch 811 train accuracy: 74.80120647107212\n",
      "Epoch 811 val loss: 0.6543423454032132\n",
      "Epoch 811 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_811.pth\n",
      "Epoch 812 train loss: 0.6611553101489941\n",
      "Epoch 812 train accuracy: 74.7463668768851\n",
      "Epoch 812 val loss: 0.6543576754629612\n",
      "Epoch 812 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_812.pth\n",
      "Epoch 813 train loss: 0.6612059713847804\n",
      "Epoch 813 train accuracy: 74.7737866739786\n",
      "Epoch 813 val loss: 0.6543363353335544\n",
      "Epoch 813 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_813.pth\n",
      "Epoch 814 train loss: 0.6611950598134283\n",
      "Epoch 814 train accuracy: 74.82862626816562\n",
      "Epoch 814 val loss: 0.6543237395388516\n",
      "Epoch 814 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_814.pth\n",
      "Epoch 815 train loss: 0.6611882015539888\n",
      "Epoch 815 train accuracy: 74.7463668768851\n",
      "Epoch 815 val loss: 0.6543053641523185\n",
      "Epoch 815 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_815.pth\n",
      "Epoch 816 train loss: 0.6611698208409443\n",
      "Epoch 816 train accuracy: 74.80120647107212\n",
      "Epoch 816 val loss: 0.6543011695734764\n",
      "Epoch 816 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_816.pth\n",
      "Epoch 817 train loss: 0.6611123899030581\n",
      "Epoch 817 train accuracy: 74.7737866739786\n",
      "Epoch 817 val loss: 0.6543012495691839\n",
      "Epoch 817 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_817.pth\n",
      "Epoch 818 train loss: 0.6611464586631771\n",
      "Epoch 818 train accuracy: 74.82862626816562\n",
      "Epoch 818 val loss: 0.6543000499276739\n",
      "Epoch 818 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_818.pth\n",
      "Epoch 819 train loss: 0.6611411767897376\n",
      "Epoch 819 train accuracy: 74.7737866739786\n",
      "Epoch 819 val loss: 0.6542924855296549\n",
      "Epoch 819 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_819.pth\n",
      "Epoch 820 train loss: 0.6611393657431268\n",
      "Epoch 820 train accuracy: 74.82862626816562\n",
      "Epoch 820 val loss: 0.6542815251373931\n",
      "Epoch 820 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_820.pth\n",
      "Epoch 821 train loss: 0.661124569707011\n",
      "Epoch 821 train accuracy: 74.7737866739786\n",
      "Epoch 821 val loss: 0.6542660797897139\n",
      "Epoch 821 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_821.pth\n",
      "Epoch 822 train loss: 0.6610995435008877\n",
      "Epoch 822 train accuracy: 74.85604606525912\n",
      "Epoch 822 val loss: 0.654266226056375\n",
      "Epoch 822 val accuracy: 75.82236842105263\n",
      "Saved model to .\\test_modelsv2/MLP_822.pth\n",
      "Epoch 823 train loss: 0.6611138181597517\n",
      "Epoch 823 train accuracy: 74.85604606525912\n",
      "Epoch 823 val loss: 0.654242338024472\n",
      "Epoch 823 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_823.pth\n",
      "Epoch 824 train loss: 0.6610907566194472\n",
      "Epoch 824 train accuracy: 74.7463668768851\n",
      "Epoch 824 val loss: 0.6542129175443399\n",
      "Epoch 824 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_824.pth\n",
      "Epoch 825 train loss: 0.6611001785321716\n",
      "Epoch 825 train accuracy: 74.7737866739786\n",
      "Epoch 825 val loss: 0.6542170610474912\n",
      "Epoch 825 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_825.pth\n",
      "Epoch 826 train loss: 0.6610840659327152\n",
      "Epoch 826 train accuracy: 74.82862626816562\n",
      "Epoch 826 val loss: 0.6541858960531259\n",
      "Epoch 826 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_826.pth\n",
      "Epoch 827 train loss: 0.6610439580848866\n",
      "Epoch 827 train accuracy: 74.85604606525912\n",
      "Epoch 827 val loss: 0.6541966733179594\n",
      "Epoch 827 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_827.pth\n",
      "Epoch 828 train loss: 0.6610908768744322\n",
      "Epoch 828 train accuracy: 74.80120647107212\n",
      "Epoch 828 val loss: 0.6541812248331936\n",
      "Epoch 828 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_828.pth\n",
      "Epoch 829 train loss: 0.6610610838325923\n",
      "Epoch 829 train accuracy: 74.7737866739786\n",
      "Epoch 829 val loss: 0.6541700611185086\n",
      "Epoch 829 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_829.pth\n",
      "Epoch 830 train loss: 0.6610535093697539\n",
      "Epoch 830 train accuracy: 74.80120647107212\n",
      "Epoch 830 val loss: 0.6541610124864077\n",
      "Epoch 830 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_830.pth\n",
      "Epoch 831 train loss: 0.6610782080771107\n",
      "Epoch 831 train accuracy: 74.80120647107212\n",
      "Epoch 831 val loss: 0.6541511134097451\n",
      "Epoch 831 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_831.pth\n",
      "Epoch 832 train loss: 0.6609934741598472\n",
      "Epoch 832 train accuracy: 74.82862626816562\n",
      "Epoch 832 val loss: 0.6541504667777764\n",
      "Epoch 832 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_832.pth\n",
      "Epoch 833 train loss: 0.6610253707162643\n",
      "Epoch 833 train accuracy: 74.82862626816562\n",
      "Epoch 833 val loss: 0.6541248898168928\n",
      "Epoch 833 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_833.pth\n",
      "Epoch 834 train loss: 0.6610196643557987\n",
      "Epoch 834 train accuracy: 74.82862626816562\n",
      "Epoch 834 val loss: 0.6541150606384403\n",
      "Epoch 834 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_834.pth\n",
      "Epoch 835 train loss: 0.660992301052861\n",
      "Epoch 835 train accuracy: 74.85604606525912\n",
      "Epoch 835 val loss: 0.65411427764124\n",
      "Epoch 835 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_835.pth\n",
      "Epoch 836 train loss: 0.6609930560123503\n",
      "Epoch 836 train accuracy: 74.85604606525912\n",
      "Epoch 836 val loss: 0.65412563605136\n",
      "Epoch 836 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_836.pth\n",
      "Epoch 837 train loss: 0.6609556951739809\n",
      "Epoch 837 train accuracy: 74.82862626816562\n",
      "Epoch 837 val loss: 0.654122787478723\n",
      "Epoch 837 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_837.pth\n",
      "Epoch 838 train loss: 0.660983953265506\n",
      "Epoch 838 train accuracy: 74.82862626816562\n",
      "Epoch 838 val loss: 0.6540954404167438\n",
      "Epoch 838 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_838.pth\n",
      "Epoch 839 train loss: 0.660972826901758\n",
      "Epoch 839 train accuracy: 74.82862626816562\n",
      "Epoch 839 val loss: 0.6540783612841838\n",
      "Epoch 839 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_839.pth\n",
      "Epoch 840 train loss: 0.6609616140067055\n",
      "Epoch 840 train accuracy: 74.82862626816562\n",
      "Epoch 840 val loss: 0.6540787197453412\n",
      "Epoch 840 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_840.pth\n",
      "Epoch 841 train loss: 0.6610080654683866\n",
      "Epoch 841 train accuracy: 74.80120647107212\n",
      "Epoch 841 val loss: 0.6540564001586876\n",
      "Epoch 841 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_841.pth\n",
      "Epoch 842 train loss: 0.6609434282505199\n",
      "Epoch 842 train accuracy: 74.85604606525912\n",
      "Epoch 842 val loss: 0.6540758337237333\n",
      "Epoch 842 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_842.pth\n",
      "Epoch 843 train loss: 0.6609402734524848\n",
      "Epoch 843 train accuracy: 74.82862626816562\n",
      "Epoch 843 val loss: 0.6540597717424756\n",
      "Epoch 843 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_843.pth\n",
      "Epoch 844 train loss: 0.6608879658671325\n",
      "Epoch 844 train accuracy: 74.85604606525912\n",
      "Epoch 844 val loss: 0.654041984363606\n",
      "Epoch 844 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_844.pth\n",
      "Epoch 845 train loss: 0.6608823931269479\n",
      "Epoch 845 train accuracy: 74.82862626816562\n",
      "Epoch 845 val loss: 0.6540297901159838\n",
      "Epoch 845 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_845.pth\n",
      "Epoch 846 train loss: 0.6609022034038055\n",
      "Epoch 846 train accuracy: 74.80120647107212\n",
      "Epoch 846 val loss: 0.654031300427098\n",
      "Epoch 846 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_846.pth\n",
      "Epoch 847 train loss: 0.6609310373794615\n",
      "Epoch 847 train accuracy: 74.82862626816562\n",
      "Epoch 847 val loss: 0.654007771395539\n",
      "Epoch 847 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_847.pth\n",
      "Epoch 848 train loss: 0.6608944620871753\n",
      "Epoch 848 train accuracy: 74.82862626816562\n",
      "Epoch 848 val loss: 0.6540047330291647\n",
      "Epoch 848 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_848.pth\n",
      "Epoch 849 train loss: 0.6608384104543611\n",
      "Epoch 849 train accuracy: 74.80120647107212\n",
      "Epoch 849 val loss: 0.6539879627525806\n",
      "Epoch 849 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_849.pth\n",
      "Epoch 850 train loss: 0.6608444733969998\n",
      "Epoch 850 train accuracy: 74.80120647107212\n",
      "Epoch 850 val loss: 0.6539717864637312\n",
      "Epoch 850 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_850.pth\n",
      "Epoch 851 train loss: 0.6608393335420835\n",
      "Epoch 851 train accuracy: 74.82862626816562\n",
      "Epoch 851 val loss: 0.6539609299874619\n",
      "Epoch 851 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_851.pth\n",
      "Epoch 852 train loss: 0.660857048539216\n",
      "Epoch 852 train accuracy: 74.85604606525912\n",
      "Epoch 852 val loss: 0.6539476049181662\n",
      "Epoch 852 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_852.pth\n",
      "Epoch 853 train loss: 0.6608310464050686\n",
      "Epoch 853 train accuracy: 74.85604606525912\n",
      "Epoch 853 val loss: 0.6539545027833236\n",
      "Epoch 853 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_853.pth\n",
      "Epoch 854 train loss: 0.6607975734953295\n",
      "Epoch 854 train accuracy: 74.88346586235262\n",
      "Epoch 854 val loss: 0.6539239595203024\n",
      "Epoch 854 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_854.pth\n",
      "Epoch 855 train loss: 0.6608385873076162\n",
      "Epoch 855 train accuracy: 74.82862626816562\n",
      "Epoch 855 val loss: 0.6539093642250488\n",
      "Epoch 855 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_855.pth\n",
      "Epoch 856 train loss: 0.6607856183198461\n",
      "Epoch 856 train accuracy: 74.80120647107212\n",
      "Epoch 856 val loss: 0.6539108967898708\n",
      "Epoch 856 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_856.pth\n",
      "Epoch 857 train loss: 0.6608099886461308\n",
      "Epoch 857 train accuracy: 74.85604606525912\n",
      "Epoch 857 val loss: 0.6539039984345436\n",
      "Epoch 857 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_857.pth\n",
      "Epoch 858 train loss: 0.6608888004301933\n",
      "Epoch 858 train accuracy: 74.80120647107212\n",
      "Epoch 858 val loss: 0.6538843535082904\n",
      "Epoch 858 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_858.pth\n",
      "Epoch 859 train loss: 0.6607380103189171\n",
      "Epoch 859 train accuracy: 74.88346586235262\n",
      "Epoch 859 val loss: 0.6539018868811821\n",
      "Epoch 859 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_859.pth\n",
      "Epoch 860 train loss: 0.6607830685873827\n",
      "Epoch 860 train accuracy: 74.85604606525912\n",
      "Epoch 860 val loss: 0.6538857017692766\n",
      "Epoch 860 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_860.pth\n",
      "Epoch 861 train loss: 0.6608397031954506\n",
      "Epoch 861 train accuracy: 74.80120647107212\n",
      "Epoch 861 val loss: 0.6538542385556196\n",
      "Epoch 861 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_861.pth\n",
      "Epoch 862 train loss: 0.6607651113810247\n",
      "Epoch 862 train accuracy: 74.82862626816562\n",
      "Epoch 862 val loss: 0.6538492619599167\n",
      "Epoch 862 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_862.pth\n",
      "Epoch 863 train loss: 0.6607367071535504\n",
      "Epoch 863 train accuracy: 74.85604606525912\n",
      "Epoch 863 val loss: 0.6538606816412587\n",
      "Epoch 863 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_863.pth\n",
      "Epoch 864 train loss: 0.6607474276240457\n",
      "Epoch 864 train accuracy: 74.80120647107212\n",
      "Epoch 864 val loss: 0.6538363755925706\n",
      "Epoch 864 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_864.pth\n",
      "Epoch 865 train loss: 0.6607156414538622\n",
      "Epoch 865 train accuracy: 74.82862626816562\n",
      "Epoch 865 val loss: 0.6538653783500195\n",
      "Epoch 865 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_865.pth\n",
      "Epoch 866 train loss: 0.6607122355255118\n",
      "Epoch 866 train accuracy: 74.82862626816562\n",
      "Epoch 866 val loss: 0.6538362089348467\n",
      "Epoch 866 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_866.pth\n",
      "Epoch 867 train loss: 0.6607344183874758\n",
      "Epoch 867 train accuracy: 74.82862626816562\n",
      "Epoch 867 val loss: 0.6538008343624441\n",
      "Epoch 867 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_867.pth\n",
      "Epoch 868 train loss: 0.660706676444725\n",
      "Epoch 868 train accuracy: 74.82862626816562\n",
      "Epoch 868 val loss: 0.6538251753112203\n",
      "Epoch 868 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_868.pth\n",
      "Epoch 869 train loss: 0.6606712418755418\n",
      "Epoch 869 train accuracy: 74.85604606525912\n",
      "Epoch 869 val loss: 0.6538002195915109\n",
      "Epoch 869 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_869.pth\n",
      "Epoch 870 train loss: 0.6606540180285249\n",
      "Epoch 870 train accuracy: 74.85604606525912\n",
      "Epoch 870 val loss: 0.6537863791577125\n",
      "Epoch 870 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_870.pth\n",
      "Epoch 871 train loss: 0.6606461321771667\n",
      "Epoch 871 train accuracy: 74.88346586235262\n",
      "Epoch 871 val loss: 0.6537825500494555\n",
      "Epoch 871 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_871.pth\n",
      "Epoch 872 train loss: 0.6606610257897461\n",
      "Epoch 872 train accuracy: 74.85604606525912\n",
      "Epoch 872 val loss: 0.6537683164994967\n",
      "Epoch 872 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_872.pth\n",
      "Epoch 873 train loss: 0.6606726095799291\n",
      "Epoch 873 train accuracy: 74.82862626816562\n",
      "Epoch 873 val loss: 0.6537484100186511\n",
      "Epoch 873 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_873.pth\n",
      "Epoch 874 train loss: 0.6606680897571016\n",
      "Epoch 874 train accuracy: 74.88346586235262\n",
      "Epoch 874 val loss: 0.6537404676997348\n",
      "Epoch 874 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_874.pth\n",
      "Epoch 875 train loss: 0.660618219459266\n",
      "Epoch 875 train accuracy: 74.85604606525912\n",
      "Epoch 875 val loss: 0.6537482564974773\n",
      "Epoch 875 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_875.pth\n",
      "Epoch 876 train loss: 0.6606357292059744\n",
      "Epoch 876 train accuracy: 74.85604606525912\n",
      "Epoch 876 val loss: 0.6537267344170495\n",
      "Epoch 876 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_876.pth\n",
      "Epoch 877 train loss: 0.6605492707407266\n",
      "Epoch 877 train accuracy: 74.7737866739786\n",
      "Epoch 877 val loss: 0.6537036758504415\n",
      "Epoch 877 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_877.pth\n",
      "Epoch 878 train loss: 0.6606272080619084\n",
      "Epoch 878 train accuracy: 74.88346586235262\n",
      "Epoch 878 val loss: 0.6537055715330338\n",
      "Epoch 878 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_878.pth\n",
      "Epoch 879 train loss: 0.6606236200518253\n",
      "Epoch 879 train accuracy: 74.82862626816562\n",
      "Epoch 879 val loss: 0.6537037736883289\n",
      "Epoch 879 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_879.pth\n",
      "Epoch 880 train loss: 0.6605569562760362\n",
      "Epoch 880 train accuracy: 74.88346586235262\n",
      "Epoch 880 val loss: 0.6536882234443175\n",
      "Epoch 880 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_880.pth\n",
      "Epoch 881 train loss: 0.6606619368846479\n",
      "Epoch 881 train accuracy: 74.85604606525912\n",
      "Epoch 881 val loss: 0.6536924288068947\n",
      "Epoch 881 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_881.pth\n",
      "Epoch 882 train loss: 0.6605955068871641\n",
      "Epoch 882 train accuracy: 74.85604606525912\n",
      "Epoch 882 val loss: 0.6536793605865616\n",
      "Epoch 882 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_882.pth\n",
      "Epoch 883 train loss: 0.6606599873160584\n",
      "Epoch 883 train accuracy: 74.80120647107212\n",
      "Epoch 883 val loss: 0.653663326937117\n",
      "Epoch 883 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_883.pth\n",
      "Epoch 884 train loss: 0.6605380190242278\n",
      "Epoch 884 train accuracy: 74.91088565944612\n",
      "Epoch 884 val loss: 0.6536549738559284\n",
      "Epoch 884 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_884.pth\n",
      "Epoch 885 train loss: 0.6605685418308304\n",
      "Epoch 885 train accuracy: 74.82862626816562\n",
      "Epoch 885 val loss: 0.6536423959034053\n",
      "Epoch 885 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_885.pth\n",
      "Epoch 886 train loss: 0.6605472989837852\n",
      "Epoch 886 train accuracy: 74.82862626816562\n",
      "Epoch 886 val loss: 0.6536479485466292\n",
      "Epoch 886 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_886.pth\n",
      "Epoch 887 train loss: 0.6605496459493512\n",
      "Epoch 887 train accuracy: 74.85604606525912\n",
      "Epoch 887 val loss: 0.6536273107324776\n",
      "Epoch 887 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_887.pth\n",
      "Epoch 888 train loss: 0.6605986829912454\n",
      "Epoch 888 train accuracy: 74.85604606525912\n",
      "Epoch 888 val loss: 0.6536134913759796\n",
      "Epoch 888 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_888.pth\n",
      "Epoch 889 train loss: 0.6605941202622234\n",
      "Epoch 889 train accuracy: 74.80120647107212\n",
      "Epoch 889 val loss: 0.6535969022661448\n",
      "Epoch 889 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_889.pth\n",
      "Epoch 890 train loss: 0.6604871467213359\n",
      "Epoch 890 train accuracy: 74.88346586235262\n",
      "Epoch 890 val loss: 0.65359583114715\n",
      "Epoch 890 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_890.pth\n",
      "Epoch 891 train loss: 0.6604898574582317\n",
      "Epoch 891 train accuracy: 74.85604606525912\n",
      "Epoch 891 val loss: 0.6535989800958257\n",
      "Epoch 891 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_891.pth\n",
      "Epoch 892 train loss: 0.6604914674372003\n",
      "Epoch 892 train accuracy: 74.80120647107212\n",
      "Epoch 892 val loss: 0.6536000448426134\n",
      "Epoch 892 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_892.pth\n",
      "Epoch 893 train loss: 0.6605027119972204\n",
      "Epoch 893 train accuracy: 74.82862626816562\n",
      "Epoch 893 val loss: 0.6536029795870969\n",
      "Epoch 893 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_893.pth\n",
      "Epoch 894 train loss: 0.6605020678487786\n",
      "Epoch 894 train accuracy: 74.82862626816562\n",
      "Epoch 894 val loss: 0.6535836367034599\n",
      "Epoch 894 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_894.pth\n",
      "Epoch 895 train loss: 0.660499833654939\n",
      "Epoch 895 train accuracy: 74.82862626816562\n",
      "Epoch 895 val loss: 0.6535604824557116\n",
      "Epoch 895 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_895.pth\n",
      "Epoch 896 train loss: 0.6604977814121205\n",
      "Epoch 896 train accuracy: 74.85604606525912\n",
      "Epoch 896 val loss: 0.6535589908690829\n",
      "Epoch 896 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_896.pth\n",
      "Epoch 897 train loss: 0.6604699540817947\n",
      "Epoch 897 train accuracy: 74.88346586235262\n",
      "Epoch 897 val loss: 0.6535413556389118\n",
      "Epoch 897 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_897.pth\n",
      "Epoch 898 train loss: 0.6604591451519937\n",
      "Epoch 898 train accuracy: 74.91088565944612\n",
      "Epoch 898 val loss: 0.6535339088816392\n",
      "Epoch 898 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_898.pth\n",
      "Epoch 899 train loss: 0.660450875170921\n",
      "Epoch 899 train accuracy: 74.82862626816562\n",
      "Epoch 899 val loss: 0.6535166254953334\n",
      "Epoch 899 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_899.pth\n",
      "Epoch 900 train loss: 0.6604427079947894\n",
      "Epoch 900 train accuracy: 74.85604606525912\n",
      "Epoch 900 val loss: 0.6535012710251307\n",
      "Epoch 900 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_900.pth\n",
      "Epoch 901 train loss: 0.6604338563782605\n",
      "Epoch 901 train accuracy: 74.88346586235262\n",
      "Epoch 901 val loss: 0.6534866545545427\n",
      "Epoch 901 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_901.pth\n",
      "Epoch 902 train loss: 0.660424530604168\n",
      "Epoch 902 train accuracy: 74.91088565944612\n",
      "Epoch 902 val loss: 0.6534826778071491\n",
      "Epoch 902 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_902.pth\n",
      "Epoch 903 train loss: 0.6604142180202823\n",
      "Epoch 903 train accuracy: 74.91088565944612\n",
      "Epoch 903 val loss: 0.653453988660323\n",
      "Epoch 903 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_903.pth\n",
      "Epoch 904 train loss: 0.6603702836457574\n",
      "Epoch 904 train accuracy: 74.88346586235262\n",
      "Epoch 904 val loss: 0.6534523745312503\n",
      "Epoch 904 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_904.pth\n",
      "Epoch 905 train loss: 0.660349264675588\n",
      "Epoch 905 train accuracy: 74.85604606525912\n",
      "Epoch 905 val loss: 0.6534587369349442\n",
      "Epoch 905 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_905.pth\n",
      "Epoch 906 train loss: 0.6603359937210355\n",
      "Epoch 906 train accuracy: 74.85604606525912\n",
      "Epoch 906 val loss: 0.6534261838778069\n",
      "Epoch 906 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_906.pth\n",
      "Epoch 907 train loss: 0.660379954989542\n",
      "Epoch 907 train accuracy: 74.91088565944612\n",
      "Epoch 907 val loss: 0.6534325751034837\n",
      "Epoch 907 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_907.pth\n",
      "Epoch 908 train loss: 0.6603303552000669\n",
      "Epoch 908 train accuracy: 74.82862626816562\n",
      "Epoch 908 val loss: 0.653420423500632\n",
      "Epoch 908 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_908.pth\n",
      "Epoch 909 train loss: 0.6603271794554434\n",
      "Epoch 909 train accuracy: 74.88346586235262\n",
      "Epoch 909 val loss: 0.6534321633608717\n",
      "Epoch 909 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_909.pth\n",
      "Epoch 910 train loss: 0.660356064539468\n",
      "Epoch 910 train accuracy: 74.85604606525912\n",
      "Epoch 910 val loss: 0.6534172509257731\n",
      "Epoch 910 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_910.pth\n",
      "Epoch 911 train loss: 0.6603436380820839\n",
      "Epoch 911 train accuracy: 74.85604606525912\n",
      "Epoch 911 val loss: 0.6534337397468718\n",
      "Epoch 911 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_911.pth\n",
      "Epoch 912 train loss: 0.6602992212171095\n",
      "Epoch 912 train accuracy: 74.88346586235262\n",
      "Epoch 912 val loss: 0.6534108798950911\n",
      "Epoch 912 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_912.pth\n",
      "Epoch 913 train loss: 0.6603317658106486\n",
      "Epoch 913 train accuracy: 74.91088565944612\n",
      "Epoch 913 val loss: 0.6533910055693827\n",
      "Epoch 913 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_913.pth\n",
      "Epoch 914 train loss: 0.6603228071083626\n",
      "Epoch 914 train accuracy: 74.88346586235262\n",
      "Epoch 914 val loss: 0.6533849066809604\n",
      "Epoch 914 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_914.pth\n",
      "Epoch 915 train loss: 0.6603107448798\n",
      "Epoch 915 train accuracy: 74.91088565944612\n",
      "Epoch 915 val loss: 0.653375013780437\n",
      "Epoch 915 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_915.pth\n",
      "Epoch 916 train loss: 0.6602981138092122\n",
      "Epoch 916 train accuracy: 74.91088565944612\n",
      "Epoch 916 val loss: 0.6533562099855197\n",
      "Epoch 916 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_916.pth\n",
      "Epoch 917 train loss: 0.660299889841362\n",
      "Epoch 917 train accuracy: 74.88346586235262\n",
      "Epoch 917 val loss: 0.6533488151862433\n",
      "Epoch 917 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_917.pth\n",
      "Epoch 918 train loss: 0.6602783614377442\n",
      "Epoch 918 train accuracy: 74.88346586235262\n",
      "Epoch 918 val loss: 0.6533374502078483\n",
      "Epoch 918 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_918.pth\n",
      "Epoch 919 train loss: 0.6602430384148631\n",
      "Epoch 919 train accuracy: 74.93830545653962\n",
      "Epoch 919 val loss: 0.6533448660844251\n",
      "Epoch 919 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_919.pth\n",
      "Epoch 920 train loss: 0.6602508845297914\n",
      "Epoch 920 train accuracy: 74.91088565944612\n",
      "Epoch 920 val loss: 0.653350298145884\n",
      "Epoch 920 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_920.pth\n",
      "Epoch 921 train loss: 0.6602641671830625\n",
      "Epoch 921 train accuracy: 74.85604606525912\n",
      "Epoch 921 val loss: 0.6533385877938647\n",
      "Epoch 921 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_921.pth\n",
      "Epoch 922 train loss: 0.6602507809405787\n",
      "Epoch 922 train accuracy: 74.88346586235262\n",
      "Epoch 922 val loss: 0.6533150938584616\n",
      "Epoch 922 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_922.pth\n",
      "Epoch 923 train loss: 0.6602424953721071\n",
      "Epoch 923 train accuracy: 74.88346586235262\n",
      "Epoch 923 val loss: 0.6532919285328764\n",
      "Epoch 923 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_923.pth\n",
      "Epoch 924 train loss: 0.660234406034936\n",
      "Epoch 924 train accuracy: 74.88346586235262\n",
      "Epoch 924 val loss: 0.6532888510509541\n",
      "Epoch 924 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_924.pth\n",
      "Epoch 925 train loss: 0.6602290086121413\n",
      "Epoch 925 train accuracy: 74.85604606525912\n",
      "Epoch 925 val loss: 0.6532713710085342\n",
      "Epoch 925 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_925.pth\n",
      "Epoch 926 train loss: 0.6602140300368008\n",
      "Epoch 926 train accuracy: 74.88346586235262\n",
      "Epoch 926 val loss: 0.6532763655444509\n",
      "Epoch 926 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_926.pth\n",
      "Epoch 927 train loss: 0.6602096274625837\n",
      "Epoch 927 train accuracy: 74.82862626816562\n",
      "Epoch 927 val loss: 0.653269146814158\n",
      "Epoch 927 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_927.pth\n",
      "Epoch 928 train loss: 0.6601652974556935\n",
      "Epoch 928 train accuracy: 74.91088565944612\n",
      "Epoch 928 val loss: 0.6532459401182438\n",
      "Epoch 928 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_928.pth\n",
      "Epoch 929 train loss: 0.6601091985705129\n",
      "Epoch 929 train accuracy: 74.85604606525912\n",
      "Epoch 929 val loss: 0.6532503703707143\n",
      "Epoch 929 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_929.pth\n",
      "Epoch 930 train loss: 0.6602182020678332\n",
      "Epoch 930 train accuracy: 74.85604606525912\n",
      "Epoch 930 val loss: 0.6532556594006325\n",
      "Epoch 930 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_930.pth\n",
      "Epoch 931 train loss: 0.6601757580708516\n",
      "Epoch 931 train accuracy: 74.85604606525912\n",
      "Epoch 931 val loss: 0.653245530238277\n",
      "Epoch 931 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_931.pth\n",
      "Epoch 932 train loss: 0.660236242864477\n",
      "Epoch 932 train accuracy: 74.88346586235262\n",
      "Epoch 932 val loss: 0.6532252643649515\n",
      "Epoch 932 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_932.pth\n",
      "Epoch 933 train loss: 0.6601194786071255\n",
      "Epoch 933 train accuracy: 74.88346586235262\n",
      "Epoch 933 val loss: 0.6532294936478138\n",
      "Epoch 933 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_933.pth\n",
      "Epoch 934 train loss: 0.6601379847055987\n",
      "Epoch 934 train accuracy: 74.82862626816562\n",
      "Epoch 934 val loss: 0.6532113859920126\n",
      "Epoch 934 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_934.pth\n",
      "Epoch 935 train loss: 0.6601529382496026\n",
      "Epoch 935 train accuracy: 74.82862626816562\n",
      "Epoch 935 val loss: 0.653196398658972\n",
      "Epoch 935 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_935.pth\n",
      "Epoch 936 train loss: 0.6601878039440826\n",
      "Epoch 936 train accuracy: 74.85604606525912\n",
      "Epoch 936 val loss: 0.6531887911260128\n",
      "Epoch 936 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_936.pth\n",
      "Epoch 937 train loss: 0.6600228250026703\n",
      "Epoch 937 train accuracy: 74.88346586235262\n",
      "Epoch 937 val loss: 0.6531813138801801\n",
      "Epoch 937 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_937.pth\n",
      "Epoch 938 train loss: 0.6600752767632928\n",
      "Epoch 938 train accuracy: 74.88346586235262\n",
      "Epoch 938 val loss: 0.6531672696337888\n",
      "Epoch 938 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_938.pth\n",
      "Epoch 939 train loss: 0.6601079969683237\n",
      "Epoch 939 train accuracy: 74.85604606525912\n",
      "Epoch 939 val loss: 0.6531656898166004\n",
      "Epoch 939 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_939.pth\n",
      "Epoch 940 train loss: 0.6600680306325095\n",
      "Epoch 940 train accuracy: 74.88346586235262\n",
      "Epoch 940 val loss: 0.65316186384543\n",
      "Epoch 940 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_940.pth\n",
      "Epoch 941 train loss: 0.6600933888306221\n",
      "Epoch 941 train accuracy: 74.85604606525912\n",
      "Epoch 941 val loss: 0.6531230797500986\n",
      "Epoch 941 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_941.pth\n",
      "Epoch 942 train loss: 0.6600948594379843\n",
      "Epoch 942 train accuracy: 74.88346586235262\n",
      "Epoch 942 val loss: 0.6531229603447413\n",
      "Epoch 942 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_942.pth\n",
      "Epoch 943 train loss: 0.6600140744591492\n",
      "Epoch 943 train accuracy: 74.85604606525912\n",
      "Epoch 943 val loss: 0.6531306861066505\n",
      "Epoch 943 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_943.pth\n",
      "Epoch 944 train loss: 0.6600431879949674\n",
      "Epoch 944 train accuracy: 74.80120647107212\n",
      "Epoch 944 val loss: 0.6531396955251694\n",
      "Epoch 944 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_944.pth\n",
      "Epoch 945 train loss: 0.660005763990053\n",
      "Epoch 945 train accuracy: 74.85604606525912\n",
      "Epoch 945 val loss: 0.6531233665974516\n",
      "Epoch 945 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_945.pth\n",
      "Epoch 946 train loss: 0.6600083771831634\n",
      "Epoch 946 train accuracy: 74.91088565944612\n",
      "Epoch 946 val loss: 0.6531088292402657\n",
      "Epoch 946 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_946.pth\n",
      "Epoch 947 train loss: 0.6600470500753114\n",
      "Epoch 947 train accuracy: 74.85604606525912\n",
      "Epoch 947 val loss: 0.6530892209787118\n",
      "Epoch 947 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_947.pth\n",
      "Epoch 948 train loss: 0.6600397133448145\n",
      "Epoch 948 train accuracy: 74.85604606525912\n",
      "Epoch 948 val loss: 0.6530864386770286\n",
      "Epoch 948 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_948.pth\n",
      "Epoch 949 train loss: 0.6600269391609911\n",
      "Epoch 949 train accuracy: 74.91088565944612\n",
      "Epoch 949 val loss: 0.6530913207679987\n",
      "Epoch 949 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_949.pth\n",
      "Epoch 950 train loss: 0.6599840229017693\n",
      "Epoch 950 train accuracy: 74.85604606525912\n",
      "Epoch 950 val loss: 0.6530752769230228\n",
      "Epoch 950 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_950.pth\n",
      "Epoch 951 train loss: 0.6599601086948002\n",
      "Epoch 951 train accuracy: 74.88346586235262\n",
      "Epoch 951 val loss: 0.6530406719171687\n",
      "Epoch 951 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_951.pth\n",
      "Epoch 952 train loss: 0.6599328414324606\n",
      "Epoch 952 train accuracy: 74.85604606525912\n",
      "Epoch 952 val loss: 0.6530409262172485\n",
      "Epoch 952 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_952.pth\n",
      "Epoch 953 train loss: 0.6599910772617972\n",
      "Epoch 953 train accuracy: 74.88346586235262\n",
      "Epoch 953 val loss: 0.6530377439370281\n",
      "Epoch 953 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_953.pth\n",
      "Epoch 954 train loss: 0.6599420208745358\n",
      "Epoch 954 train accuracy: 74.88346586235262\n",
      "Epoch 954 val loss: 0.6530211905115529\n",
      "Epoch 954 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_954.pth\n",
      "Epoch 955 train loss: 0.6599365520503437\n",
      "Epoch 955 train accuracy: 74.85604606525912\n",
      "Epoch 955 val loss: 0.6530281736662513\n",
      "Epoch 955 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_955.pth\n",
      "Epoch 956 train loss: 0.6598828920865791\n",
      "Epoch 956 train accuracy: 74.88346586235262\n",
      "Epoch 956 val loss: 0.6530041390735852\n",
      "Epoch 956 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_956.pth\n",
      "Epoch 957 train loss: 0.6599622236793501\n",
      "Epoch 957 train accuracy: 74.85604606525912\n",
      "Epoch 957 val loss: 0.6529802809420385\n",
      "Epoch 957 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_957.pth\n",
      "Epoch 958 train loss: 0.6599514135077857\n",
      "Epoch 958 train accuracy: 74.88346586235262\n",
      "Epoch 958 val loss: 0.6529957015851611\n",
      "Epoch 958 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_958.pth\n",
      "Epoch 959 train loss: 0.6599174374877884\n",
      "Epoch 959 train accuracy: 74.85604606525912\n",
      "Epoch 959 val loss: 0.6529832904864299\n",
      "Epoch 959 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_959.pth\n",
      "Epoch 960 train loss: 0.6599396651839478\n",
      "Epoch 960 train accuracy: 74.88346586235262\n",
      "Epoch 960 val loss: 0.6529681688468707\n",
      "Epoch 960 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_960.pth\n",
      "Epoch 961 train loss: 0.6598485841562873\n",
      "Epoch 961 train accuracy: 74.88346586235262\n",
      "Epoch 961 val loss: 0.6529623170040155\n",
      "Epoch 961 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_961.pth\n",
      "Epoch 962 train loss: 0.6599140004499963\n",
      "Epoch 962 train accuracy: 74.93830545653962\n",
      "Epoch 962 val loss: 0.6529485962696766\n",
      "Epoch 962 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_962.pth\n",
      "Epoch 963 train loss: 0.6598609837523678\n",
      "Epoch 963 train accuracy: 74.85604606525912\n",
      "Epoch 963 val loss: 0.6529630794140854\n",
      "Epoch 963 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_963.pth\n",
      "Epoch 964 train loss: 0.6598568780249671\n",
      "Epoch 964 train accuracy: 74.88346586235262\n",
      "Epoch 964 val loss: 0.6529190081514811\n",
      "Epoch 964 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_964.pth\n",
      "Epoch 965 train loss: 0.6599090337557229\n",
      "Epoch 965 train accuracy: 74.93830545653962\n",
      "Epoch 965 val loss: 0.6529122852769337\n",
      "Epoch 965 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_965.pth\n",
      "Epoch 966 train loss: 0.6598776471392628\n",
      "Epoch 966 train accuracy: 74.85604606525912\n",
      "Epoch 966 val loss: 0.6529045905917883\n",
      "Epoch 966 val accuracy: 75.98684210526316\n",
      "Saved model to .\\test_modelsv2/MLP_966.pth\n",
      "Epoch 967 train loss: 0.6598395053297281\n",
      "Epoch 967 train accuracy: 74.85604606525912\n",
      "Epoch 967 val loss: 0.6529029511699551\n",
      "Epoch 967 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_967.pth\n",
      "Epoch 968 train loss: 0.6598296847455857\n",
      "Epoch 968 train accuracy: 74.85604606525912\n",
      "Epoch 968 val loss: 0.6529149719955105\n",
      "Epoch 968 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_968.pth\n",
      "Epoch 969 train loss: 0.6598552921950295\n",
      "Epoch 969 train accuracy: 74.91088565944612\n",
      "Epoch 969 val loss: 0.6528998701588103\n",
      "Epoch 969 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_969.pth\n",
      "Epoch 970 train loss: 0.6598443455601993\n",
      "Epoch 970 train accuracy: 74.88346586235262\n",
      "Epoch 970 val loss: 0.6528979512421709\n",
      "Epoch 970 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_970.pth\n",
      "Epoch 971 train loss: 0.6598384376092438\n",
      "Epoch 971 train accuracy: 74.82862626816562\n",
      "Epoch 971 val loss: 0.652898270538763\n",
      "Epoch 971 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_971.pth\n",
      "Epoch 972 train loss: 0.6598104184918236\n",
      "Epoch 972 train accuracy: 74.88346586235262\n",
      "Epoch 972 val loss: 0.652878815994451\n",
      "Epoch 972 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_972.pth\n",
      "Epoch 973 train loss: 0.6597850841323012\n",
      "Epoch 973 train accuracy: 74.88346586235262\n",
      "Epoch 973 val loss: 0.6528715605014249\n",
      "Epoch 973 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_973.pth\n",
      "Epoch 974 train loss: 0.6597678898915387\n",
      "Epoch 974 train accuracy: 74.91088565944612\n",
      "Epoch 974 val loss: 0.6528592576321802\n",
      "Epoch 974 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_974.pth\n",
      "Epoch 975 train loss: 0.6598369836349759\n",
      "Epoch 975 train accuracy: 74.88346586235262\n",
      "Epoch 975 val loss: 0.6528506705439404\n",
      "Epoch 975 val accuracy: 75.90460526315789\n",
      "Saved model to .\\test_modelsv2/MLP_975.pth\n",
      "Epoch 976 train loss: 0.6597924256337839\n",
      "Epoch 976 train accuracy: 74.88346586235262\n",
      "Epoch 976 val loss: 0.6528197951418789\n",
      "Epoch 976 val accuracy: 76.15131578947368\n",
      "Saved model to .\\test_modelsv2/MLP_976.pth\n",
      "Epoch 977 train loss: 0.6597914968927702\n",
      "Epoch 977 train accuracy: 74.88346586235262\n",
      "Epoch 977 val loss: 0.652814071919573\n",
      "Epoch 977 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_977.pth\n",
      "Epoch 978 train loss: 0.659780007378574\n",
      "Epoch 978 train accuracy: 74.85604606525912\n",
      "Epoch 978 val loss: 0.6528194615323293\n",
      "Epoch 978 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_978.pth\n",
      "Epoch 979 train loss: 0.6597639436980611\n",
      "Epoch 979 train accuracy: 74.91088565944612\n",
      "Epoch 979 val loss: 0.6527981940460833\n",
      "Epoch 979 val accuracy: 76.15131578947368\n",
      "Saved model to .\\test_modelsv2/MLP_979.pth\n",
      "Epoch 980 train loss: 0.659760432285175\n",
      "Epoch 980 train accuracy: 74.88346586235262\n",
      "Epoch 980 val loss: 0.6528092499234175\n",
      "Epoch 980 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_980.pth\n",
      "Epoch 981 train loss: 0.6596963090266574\n",
      "Epoch 981 train accuracy: 74.93830545653962\n",
      "Epoch 981 val loss: 0.6528004738257119\n",
      "Epoch 981 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_981.pth\n",
      "Epoch 982 train loss: 0.6597423532879666\n",
      "Epoch 982 train accuracy: 74.91088565944612\n",
      "Epoch 982 val loss: 0.6527856348180457\n",
      "Epoch 982 val accuracy: 76.15131578947368\n",
      "Saved model to .\\test_modelsv2/MLP_982.pth\n",
      "Epoch 983 train loss: 0.6597337891396723\n",
      "Epoch 983 train accuracy: 74.91088565944612\n",
      "Epoch 983 val loss: 0.6527708872760597\n",
      "Epoch 983 val accuracy: 76.3157894736842\n",
      "Saved model to .\\test_modelsv2/MLP_983.pth\n",
      "Epoch 984 train loss: 0.6597242020724112\n",
      "Epoch 984 train accuracy: 74.88346586235262\n",
      "Epoch 984 val loss: 0.652793758891915\n",
      "Epoch 984 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_984.pth\n",
      "Epoch 985 train loss: 0.6596758013035644\n",
      "Epoch 985 train accuracy: 74.85604606525912\n",
      "Epoch 985 val loss: 0.6527734854699749\n",
      "Epoch 985 val accuracy: 76.06907894736842\n",
      "Saved model to .\\test_modelsv2/MLP_985.pth\n",
      "Epoch 986 train loss: 0.6596888309965531\n",
      "Epoch 986 train accuracy: 74.91088565944612\n",
      "Epoch 986 val loss: 0.6527775653490895\n",
      "Epoch 986 val accuracy: 76.15131578947368\n",
      "Saved model to .\\test_modelsv2/MLP_986.pth\n",
      "Epoch 987 train loss: 0.6597652599999779\n",
      "Epoch 987 train accuracy: 74.91088565944612\n",
      "Epoch 987 val loss: 0.6527458697949585\n",
      "Epoch 987 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_modelsv2/MLP_987.pth\n",
      "Epoch 988 train loss: 0.6596554678521658\n",
      "Epoch 988 train accuracy: 74.88346586235262\n",
      "Epoch 988 val loss: 0.6527466800455984\n",
      "Epoch 988 val accuracy: 76.23355263157895\n",
      "Saved model to .\\test_modelsv2/MLP_988.pth\n",
      "Epoch 989 train loss: 0.659742308715195\n",
      "Epoch 989 train accuracy: 74.91088565944612\n",
      "Epoch 989 val loss: 0.6527290130524259\n",
      "Epoch 989 val accuracy: 76.3157894736842\n",
      "Saved model to .\\test_modelsv2/MLP_989.pth\n",
      "Epoch 990 train loss: 0.6596904577393281\n",
      "Epoch 990 train accuracy: 74.91088565944612\n",
      "Epoch 990 val loss: 0.6527234109020547\n",
      "Epoch 990 val accuracy: 76.3157894736842\n",
      "Saved model to .\\test_modelsv2/MLP_990.pth\n",
      "Epoch 991 train loss: 0.6596603483419147\n",
      "Epoch 991 train accuracy: 74.93830545653962\n",
      "Epoch 991 val loss: 0.6527200741203207\n",
      "Epoch 991 val accuracy: 76.3157894736842\n",
      "Saved model to .\\test_modelsv2/MLP_991.pth\n",
      "Epoch 992 train loss: 0.6596493559905834\n",
      "Epoch 992 train accuracy: 74.93830545653962\n",
      "Epoch 992 val loss: 0.6527145320647642\n",
      "Epoch 992 val accuracy: 76.3157894736842\n",
      "Saved model to .\\test_modelsv2/MLP_992.pth\n",
      "Epoch 993 train loss: 0.6596454431613287\n",
      "Epoch 993 train accuracy: 74.88346586235262\n",
      "Epoch 993 val loss: 0.6526968802668547\n",
      "Epoch 993 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_modelsv2/MLP_993.pth\n",
      "Epoch 994 train loss: 0.659634933235091\n",
      "Epoch 994 train accuracy: 74.91088565944612\n",
      "Epoch 994 val loss: 0.6526943655978692\n",
      "Epoch 994 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_modelsv2/MLP_994.pth\n",
      "Epoch 995 train loss: 0.659678830275018\n",
      "Epoch 995 train accuracy: 74.88346586235262\n",
      "Epoch 995 val loss: 0.6526813399242727\n",
      "Epoch 995 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_modelsv2/MLP_995.pth\n",
      "Epoch 996 train loss: 0.6596174477354476\n",
      "Epoch 996 train accuracy: 74.93830545653962\n",
      "Epoch 996 val loss: 0.652673937086212\n",
      "Epoch 996 val accuracy: 76.39802631578948\n",
      "Saved model to .\\test_modelsv2/MLP_996.pth\n",
      "Epoch 997 train loss: 0.6596102740680962\n",
      "Epoch 997 train accuracy: 74.88346586235262\n",
      "Epoch 997 val loss: 0.6526569842704033\n",
      "Epoch 997 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_997.pth\n",
      "Epoch 998 train loss: 0.659600777143057\n",
      "Epoch 998 train accuracy: 74.85604606525912\n",
      "Epoch 998 val loss: 0.6526521162963227\n",
      "Epoch 998 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_998.pth\n",
      "Epoch 999 train loss: 0.6595914478234032\n",
      "Epoch 999 train accuracy: 74.91088565944612\n",
      "Epoch 999 val loss: 0.6526450422641478\n",
      "Epoch 999 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_999.pth\n",
      "Epoch 1000 train loss: 0.6595456216549664\n",
      "Epoch 1000 train accuracy: 74.91088565944612\n",
      "Epoch 1000 val loss: 0.6526371296495199\n",
      "Epoch 1000 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1000.pth\n",
      "Epoch 1001 train loss: 0.6595768827879638\n",
      "Epoch 1001 train accuracy: 74.88346586235262\n",
      "Epoch 1001 val loss: 0.6526215321531421\n",
      "Epoch 1001 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1001.pth\n",
      "Epoch 1002 train loss: 0.6595120010407347\n",
      "Epoch 1002 train accuracy: 74.88346586235262\n",
      "Epoch 1002 val loss: 0.6526186340733579\n",
      "Epoch 1002 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1002.pth\n",
      "Epoch 1003 train loss: 0.6595614568836856\n",
      "Epoch 1003 train accuracy: 74.88346586235262\n",
      "Epoch 1003 val loss: 0.6526251678404055\n",
      "Epoch 1003 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1003.pth\n",
      "Epoch 1004 train loss: 0.6594787692945254\n",
      "Epoch 1004 train accuracy: 74.96572525363312\n",
      "Epoch 1004 val loss: 0.652585780051978\n",
      "Epoch 1004 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1004.pth\n",
      "Epoch 1005 train loss: 0.6595837981358432\n",
      "Epoch 1005 train accuracy: 74.85604606525912\n",
      "Epoch 1005 val loss: 0.6525763988887009\n",
      "Epoch 1005 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1005.pth\n",
      "Epoch 1006 train loss: 0.6595473296678903\n",
      "Epoch 1006 train accuracy: 74.85604606525912\n",
      "Epoch 1006 val loss: 0.6525808702173986\n",
      "Epoch 1006 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1006.pth\n",
      "Epoch 1007 train loss: 0.6594730436213707\n",
      "Epoch 1007 train accuracy: 74.88346586235262\n",
      "Epoch 1007 val loss: 0.6525812623532194\n",
      "Epoch 1007 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1007.pth\n",
      "Epoch 1008 train loss: 0.6595090298276198\n",
      "Epoch 1008 train accuracy: 74.91088565944612\n",
      "Epoch 1008 val loss: 0.6525597269401738\n",
      "Epoch 1008 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1008.pth\n",
      "Epoch 1009 train loss: 0.6594197059278948\n",
      "Epoch 1009 train accuracy: 74.91088565944612\n",
      "Epoch 1009 val loss: 0.6525405723797647\n",
      "Epoch 1009 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1009.pth\n",
      "Epoch 1010 train loss: 0.6594780085183549\n",
      "Epoch 1010 train accuracy: 74.85604606525912\n",
      "Epoch 1010 val loss: 0.6525365463212917\n",
      "Epoch 1010 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1010.pth\n",
      "Epoch 1011 train loss: 0.6594639026412839\n",
      "Epoch 1011 train accuracy: 74.88346586235262\n",
      "Epoch 1011 val loss: 0.6525374511746984\n",
      "Epoch 1011 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1011.pth\n",
      "Epoch 1012 train loss: 0.6594726930192688\n",
      "Epoch 1012 train accuracy: 74.91088565944612\n",
      "Epoch 1012 val loss: 0.6525246649000206\n",
      "Epoch 1012 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1012.pth\n",
      "Epoch 1013 train loss: 0.6594702144757959\n",
      "Epoch 1013 train accuracy: 74.85604606525912\n",
      "Epoch 1013 val loss: 0.6525287200745783\n",
      "Epoch 1013 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1013.pth\n",
      "Epoch 1014 train loss: 0.6594899708829951\n",
      "Epoch 1014 train accuracy: 74.88346586235262\n",
      "Epoch 1014 val loss: 0.6525179986890993\n",
      "Epoch 1014 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1014.pth\n",
      "Epoch 1015 train loss: 0.6594531059984052\n",
      "Epoch 1015 train accuracy: 74.82862626816562\n",
      "Epoch 1015 val loss: 0.652505509261238\n",
      "Epoch 1015 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1015.pth\n",
      "Epoch 1016 train loss: 0.6594108895872507\n",
      "Epoch 1016 train accuracy: 74.88346586235262\n",
      "Epoch 1016 val loss: 0.6524906011396333\n",
      "Epoch 1016 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1016.pth\n",
      "Epoch 1017 train loss: 0.6594126542147837\n",
      "Epoch 1017 train accuracy: 74.80120647107212\n",
      "Epoch 1017 val loss: 0.6524819353301274\n",
      "Epoch 1017 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1017.pth\n",
      "Epoch 1018 train loss: 0.6593951594345925\n",
      "Epoch 1018 train accuracy: 74.88346586235262\n",
      "Epoch 1018 val loss: 0.6524751347146536\n",
      "Epoch 1018 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1018.pth\n",
      "Epoch 1019 train loss: 0.6594176040798948\n",
      "Epoch 1019 train accuracy: 74.88346586235262\n",
      "Epoch 1019 val loss: 0.652484535092586\n",
      "Epoch 1019 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1019.pth\n",
      "Epoch 1020 train loss: 0.6594340965936059\n",
      "Epoch 1020 train accuracy: 74.88346586235262\n",
      "Epoch 1020 val loss: 0.6524769169719595\n",
      "Epoch 1020 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1020.pth\n",
      "Epoch 1021 train loss: 0.659329418125644\n",
      "Epoch 1021 train accuracy: 74.88346586235262\n",
      "Epoch 1021 val loss: 0.652471070520972\n",
      "Epoch 1021 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1021.pth\n",
      "Epoch 1022 train loss: 0.6593901739831556\n",
      "Epoch 1022 train accuracy: 74.91088565944612\n",
      "Epoch 1022 val loss: 0.6524326708167791\n",
      "Epoch 1022 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1022.pth\n",
      "Epoch 1023 train loss: 0.659382939371362\n",
      "Epoch 1023 train accuracy: 74.82862626816562\n",
      "Epoch 1023 val loss: 0.6524310483548202\n",
      "Epoch 1023 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1023.pth\n",
      "Epoch 1024 train loss: 0.6593697166168376\n",
      "Epoch 1024 train accuracy: 74.80120647107212\n",
      "Epoch 1024 val loss: 0.6524202980493244\n",
      "Epoch 1024 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1024.pth\n",
      "Epoch 1025 train loss: 0.6594070760173756\n",
      "Epoch 1025 train accuracy: 74.91088565944612\n",
      "Epoch 1025 val loss: 0.6523926894327527\n",
      "Epoch 1025 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1025.pth\n",
      "Epoch 1026 train loss: 0.6593448778516368\n",
      "Epoch 1026 train accuracy: 74.91088565944612\n",
      "Epoch 1026 val loss: 0.6524009085015247\n",
      "Epoch 1026 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1026.pth\n",
      "Epoch 1027 train loss: 0.659380986698364\n",
      "Epoch 1027 train accuracy: 74.85604606525912\n",
      "Epoch 1027 val loss: 0.6523846286888185\n",
      "Epoch 1027 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1027.pth\n",
      "Epoch 1028 train loss: 0.6593193862783281\n",
      "Epoch 1028 train accuracy: 74.91088565944612\n",
      "Epoch 1028 val loss: 0.6523984641228852\n",
      "Epoch 1028 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1028.pth\n",
      "Epoch 1029 train loss: 0.6593713799262779\n",
      "Epoch 1029 train accuracy: 74.91088565944612\n",
      "Epoch 1029 val loss: 0.6523800245241115\n",
      "Epoch 1029 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1029.pth\n",
      "Epoch 1030 train loss: 0.6593553662430822\n",
      "Epoch 1030 train accuracy: 74.93830545653962\n",
      "Epoch 1030 val loss: 0.6523693060796512\n",
      "Epoch 1030 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1030.pth\n",
      "Epoch 1031 train loss: 0.6593118546236503\n",
      "Epoch 1031 train accuracy: 74.91088565944612\n",
      "Epoch 1031 val loss: 0.6523570051710856\n",
      "Epoch 1031 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1031.pth\n",
      "Epoch 1032 train loss: 0.6592352739616967\n",
      "Epoch 1032 train accuracy: 74.93830545653962\n",
      "Epoch 1032 val loss: 0.6523585593033778\n",
      "Epoch 1032 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1032.pth\n",
      "Epoch 1033 train loss: 0.6592134455251589\n",
      "Epoch 1033 train accuracy: 74.93830545653962\n",
      "Epoch 1033 val loss: 0.6523502046536458\n",
      "Epoch 1033 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1033.pth\n",
      "Epoch 1034 train loss: 0.6592817186917129\n",
      "Epoch 1034 train accuracy: 74.93830545653962\n",
      "Epoch 1034 val loss: 0.6523564161830827\n",
      "Epoch 1034 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1034.pth\n",
      "Epoch 1035 train loss: 0.6593470057113129\n",
      "Epoch 1035 train accuracy: 74.96572525363312\n",
      "Epoch 1035 val loss: 0.6523325485422423\n",
      "Epoch 1035 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1035.pth\n",
      "Epoch 1036 train loss: 0.6592703129311925\n",
      "Epoch 1036 train accuracy: 74.91088565944612\n",
      "Epoch 1036 val loss: 0.6523300375985471\n",
      "Epoch 1036 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1036.pth\n",
      "Epoch 1037 train loss: 0.6592291042927587\n",
      "Epoch 1037 train accuracy: 74.93830545653962\n",
      "Epoch 1037 val loss: 0.6523296479135752\n",
      "Epoch 1037 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1037.pth\n",
      "Epoch 1038 train loss: 0.6592252238147092\n",
      "Epoch 1038 train accuracy: 74.85604606525912\n",
      "Epoch 1038 val loss: 0.6523247178840009\n",
      "Epoch 1038 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1038.pth\n",
      "Epoch 1039 train loss: 0.65921421829415\n",
      "Epoch 1039 train accuracy: 74.91088565944612\n",
      "Epoch 1039 val loss: 0.6523143799093208\n",
      "Epoch 1039 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1039.pth\n",
      "Epoch 1040 train loss: 0.6592357426293587\n",
      "Epoch 1040 train accuracy: 74.93830545653962\n",
      "Epoch 1040 val loss: 0.6523023015378338\n",
      "Epoch 1040 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1040.pth\n",
      "Epoch 1041 train loss: 0.6592273436029229\n",
      "Epoch 1041 train accuracy: 74.96572525363312\n",
      "Epoch 1041 val loss: 0.652291323597494\n",
      "Epoch 1041 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1041.pth\n",
      "Epoch 1042 train loss: 0.6592204458684775\n",
      "Epoch 1042 train accuracy: 74.96572525363312\n",
      "Epoch 1042 val loss: 0.6522835869538156\n",
      "Epoch 1042 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1042.pth\n",
      "Epoch 1043 train loss: 0.6592138090023869\n",
      "Epoch 1043 train accuracy: 74.96572525363312\n",
      "Epoch 1043 val loss: 0.6522593706061965\n",
      "Epoch 1043 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1043.pth\n",
      "Epoch 1044 train loss: 0.6591974149147669\n",
      "Epoch 1044 train accuracy: 74.96572525363312\n",
      "Epoch 1044 val loss: 0.6522556393358269\n",
      "Epoch 1044 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1044.pth\n",
      "Epoch 1045 train loss: 0.6591677234361046\n",
      "Epoch 1045 train accuracy: 75.02056484782013\n",
      "Epoch 1045 val loss: 0.6522515599468821\n",
      "Epoch 1045 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1045.pth\n",
      "Epoch 1046 train loss: 0.6591591492883468\n",
      "Epoch 1046 train accuracy: 74.93830545653962\n",
      "Epoch 1046 val loss: 0.6522582934090966\n",
      "Epoch 1046 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1046.pth\n",
      "Epoch 1047 train loss: 0.6591838098604951\n",
      "Epoch 1047 train accuracy: 74.96572525363312\n",
      "Epoch 1047 val loss: 0.6522512741779026\n",
      "Epoch 1047 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1047.pth\n",
      "Epoch 1048 train loss: 0.6591694295210274\n",
      "Epoch 1048 train accuracy: 74.93830545653962\n",
      "Epoch 1048 val loss: 0.6522271666479739\n",
      "Epoch 1048 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1048.pth\n",
      "Epoch 1049 train loss: 0.6590904267668202\n",
      "Epoch 1049 train accuracy: 74.96572525363312\n",
      "Epoch 1049 val loss: 0.6522390355208987\n",
      "Epoch 1049 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1049.pth\n",
      "Epoch 1050 train loss: 0.659129616690048\n",
      "Epoch 1050 train accuracy: 74.93830545653962\n",
      "Epoch 1050 val loss: 0.6522398843969169\n",
      "Epoch 1050 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1050.pth\n",
      "Epoch 1051 train loss: 0.6591116729796979\n",
      "Epoch 1051 train accuracy: 74.96572525363312\n",
      "Epoch 1051 val loss: 0.6522195393121556\n",
      "Epoch 1051 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1051.pth\n",
      "Epoch 1052 train loss: 0.6591208534021127\n",
      "Epoch 1052 train accuracy: 74.91088565944612\n",
      "Epoch 1052 val loss: 0.6521961218432376\n",
      "Epoch 1052 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1052.pth\n",
      "Epoch 1053 train loss: 0.6590984563686346\n",
      "Epoch 1053 train accuracy: 74.93830545653962\n",
      "Epoch 1053 val loss: 0.6521910500565642\n",
      "Epoch 1053 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1053.pth\n",
      "Epoch 1054 train loss: 0.6591336420949614\n",
      "Epoch 1054 train accuracy: 74.99314505072662\n",
      "Epoch 1054 val loss: 0.6521746494660252\n",
      "Epoch 1054 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1054.pth\n",
      "Epoch 1055 train loss: 0.6590779739056241\n",
      "Epoch 1055 train accuracy: 74.96572525363312\n",
      "Epoch 1055 val loss: 0.6521745134929293\n",
      "Epoch 1055 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1055.pth\n",
      "Epoch 1056 train loss: 0.659117218303053\n",
      "Epoch 1056 train accuracy: 74.96572525363312\n",
      "Epoch 1056 val loss: 0.652156627099765\n",
      "Epoch 1056 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1056.pth\n",
      "Epoch 1057 train loss: 0.6590846119808\n",
      "Epoch 1057 train accuracy: 74.99314505072662\n",
      "Epoch 1057 val loss: 0.6521697187502133\n",
      "Epoch 1057 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1057.pth\n",
      "Epoch 1058 train loss: 0.6590978251279969\n",
      "Epoch 1058 train accuracy: 74.99314505072662\n",
      "Epoch 1058 val loss: 0.6521377138009197\n",
      "Epoch 1058 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1058.pth\n",
      "Epoch 1059 train loss: 0.6590889567803395\n",
      "Epoch 1059 train accuracy: 74.99314505072662\n",
      "Epoch 1059 val loss: 0.6521393711629667\n",
      "Epoch 1059 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1059.pth\n",
      "Epoch 1060 train loss: 0.6590782280096359\n",
      "Epoch 1060 train accuracy: 74.96572525363312\n",
      "Epoch 1060 val loss: 0.6521156227804328\n",
      "Epoch 1060 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1060.pth\n",
      "Epoch 1061 train loss: 0.6590883830529556\n",
      "Epoch 1061 train accuracy: 74.96572525363312\n",
      "Epoch 1061 val loss: 0.6521084822322193\n",
      "Epoch 1061 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1061.pth\n",
      "Epoch 1062 train loss: 0.6591381353179091\n",
      "Epoch 1062 train accuracy: 74.93830545653962\n",
      "Epoch 1062 val loss: 0.6520823144206875\n",
      "Epoch 1062 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1062.pth\n",
      "Epoch 1063 train loss: 0.6590662917873839\n",
      "Epoch 1063 train accuracy: 74.96572525363312\n",
      "Epoch 1063 val loss: 0.6520899350901967\n",
      "Epoch 1063 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1063.pth\n",
      "Epoch 1064 train loss: 0.6590589761341873\n",
      "Epoch 1064 train accuracy: 74.96572525363312\n",
      "Epoch 1064 val loss: 0.6520821373713644\n",
      "Epoch 1064 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1064.pth\n",
      "Epoch 1065 train loss: 0.6590477777154822\n",
      "Epoch 1065 train accuracy: 74.96572525363312\n",
      "Epoch 1065 val loss: 0.6520593435944695\n",
      "Epoch 1065 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1065.pth\n",
      "Epoch 1066 train loss: 0.6590418152903256\n",
      "Epoch 1066 train accuracy: 75.02056484782013\n",
      "Epoch 1066 val loss: 0.6520758570711079\n",
      "Epoch 1066 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1066.pth\n",
      "Epoch 1067 train loss: 0.658989764455902\n",
      "Epoch 1067 train accuracy: 74.96572525363312\n",
      "Epoch 1067 val loss: 0.6520872424895826\n",
      "Epoch 1067 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1067.pth\n",
      "Epoch 1068 train loss: 0.6589723599323055\n",
      "Epoch 1068 train accuracy: 74.96572525363312\n",
      "Epoch 1068 val loss: 0.6521001080737302\n",
      "Epoch 1068 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1068.pth\n",
      "Epoch 1069 train loss: 0.6590177396214322\n",
      "Epoch 1069 train accuracy: 74.96572525363312\n",
      "Epoch 1069 val loss: 0.6520753553823421\n",
      "Epoch 1069 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1069.pth\n",
      "Epoch 1070 train loss: 0.6589777472576028\n",
      "Epoch 1070 train accuracy: 74.96572525363312\n",
      "Epoch 1070 val loss: 0.6520538609474897\n",
      "Epoch 1070 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1070.pth\n",
      "Epoch 1071 train loss: 0.6590006033514153\n",
      "Epoch 1071 train accuracy: 74.96572525363312\n",
      "Epoch 1071 val loss: 0.6520597507294855\n",
      "Epoch 1071 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1071.pth\n",
      "Epoch 1072 train loss: 0.6589853979908583\n",
      "Epoch 1072 train accuracy: 74.99314505072662\n",
      "Epoch 1072 val loss: 0.6520550107877505\n",
      "Epoch 1072 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1072.pth\n",
      "Epoch 1073 train loss: 0.6589865536478005\n",
      "Epoch 1073 train accuracy: 74.96572525363312\n",
      "Epoch 1073 val loss: 0.6520444042980671\n",
      "Epoch 1073 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1073.pth\n",
      "Epoch 1074 train loss: 0.6589786600190819\n",
      "Epoch 1074 train accuracy: 74.99314505072662\n",
      "Epoch 1074 val loss: 0.6520280472346043\n",
      "Epoch 1074 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1074.pth\n",
      "Epoch 1075 train loss: 0.6589094149765738\n",
      "Epoch 1075 train accuracy: 74.99314505072662\n",
      "Epoch 1075 val loss: 0.6520032121946937\n",
      "Epoch 1075 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1075.pth\n",
      "Epoch 1076 train loss: 0.6589858748606945\n",
      "Epoch 1076 train accuracy: 74.96572525363312\n",
      "Epoch 1076 val loss: 0.6519905860094648\n",
      "Epoch 1076 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1076.pth\n",
      "Epoch 1077 train loss: 0.6589597120162165\n",
      "Epoch 1077 train accuracy: 75.02056484782013\n",
      "Epoch 1077 val loss: 0.6519821653828809\n",
      "Epoch 1077 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1077.pth\n",
      "Epoch 1078 train loss: 0.6589609562958542\n",
      "Epoch 1078 train accuracy: 74.96572525363312\n",
      "Epoch 1078 val loss: 0.6519785705757769\n",
      "Epoch 1078 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1078.pth\n",
      "Epoch 1079 train loss: 0.6589097683563044\n",
      "Epoch 1079 train accuracy: 74.96572525363312\n",
      "Epoch 1079 val loss: 0.651974918516843\n",
      "Epoch 1079 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1079.pth\n",
      "Epoch 1080 train loss: 0.6588747806258892\n",
      "Epoch 1080 train accuracy: 74.99314505072662\n",
      "Epoch 1080 val loss: 0.6519747815634075\n",
      "Epoch 1080 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1080.pth\n",
      "Epoch 1081 train loss: 0.6589331978833989\n",
      "Epoch 1081 train accuracy: 74.96572525363312\n",
      "Epoch 1081 val loss: 0.6519604909576868\n",
      "Epoch 1081 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1081.pth\n",
      "Epoch 1082 train loss: 0.6589216309223782\n",
      "Epoch 1082 train accuracy: 75.02056484782013\n",
      "Epoch 1082 val loss: 0.6519431297324205\n",
      "Epoch 1082 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1082.pth\n",
      "Epoch 1083 train loss: 0.6589156978420521\n",
      "Epoch 1083 train accuracy: 75.04798464491363\n",
      "Epoch 1083 val loss: 0.6519535416247029\n",
      "Epoch 1083 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1083.pth\n",
      "Epoch 1084 train loss: 0.6589260837553363\n",
      "Epoch 1084 train accuracy: 74.96572525363312\n",
      "Epoch 1084 val loss: 0.6519598888331338\n",
      "Epoch 1084 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1084.pth\n",
      "Epoch 1085 train loss: 0.6589051981767019\n",
      "Epoch 1085 train accuracy: 74.99314505072662\n",
      "Epoch 1085 val loss: 0.6519544496151962\n",
      "Epoch 1085 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1085.pth\n",
      "Epoch 1086 train loss: 0.6588618450128195\n",
      "Epoch 1086 train accuracy: 75.02056484782013\n",
      "Epoch 1086 val loss: 0.6519349354662394\n",
      "Epoch 1086 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1086.pth\n",
      "Epoch 1087 train loss: 0.6588948471308277\n",
      "Epoch 1087 train accuracy: 74.99314505072662\n",
      "Epoch 1087 val loss: 0.651928284940751\n",
      "Epoch 1087 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1087.pth\n",
      "Epoch 1088 train loss: 0.6589145020565443\n",
      "Epoch 1088 train accuracy: 74.96572525363312\n",
      "Epoch 1088 val loss: 0.6519168700630728\n",
      "Epoch 1088 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1088.pth\n",
      "Epoch 1089 train loss: 0.6588800586760044\n",
      "Epoch 1089 train accuracy: 74.99314505072662\n",
      "Epoch 1089 val loss: 0.6519060838771494\n",
      "Epoch 1089 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1089.pth\n",
      "Epoch 1090 train loss: 0.6588736331384433\n",
      "Epoch 1090 train accuracy: 74.99314505072662\n",
      "Epoch 1090 val loss: 0.6519103086504497\n",
      "Epoch 1090 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1090.pth\n",
      "Epoch 1091 train loss: 0.6587956123903655\n",
      "Epoch 1091 train accuracy: 75.02056484782013\n",
      "Epoch 1091 val loss: 0.6519084830621356\n",
      "Epoch 1091 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1091.pth\n",
      "Epoch 1092 train loss: 0.6588686035390485\n",
      "Epoch 1092 train accuracy: 74.96572525363312\n",
      "Epoch 1092 val loss: 0.6519119411118721\n",
      "Epoch 1092 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1092.pth\n",
      "Epoch 1093 train loss: 0.6587627286646973\n",
      "Epoch 1093 train accuracy: 75.04798464491363\n",
      "Epoch 1093 val loss: 0.6519107203930616\n",
      "Epoch 1093 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1093.pth\n",
      "Epoch 1094 train loss: 0.6588422979898098\n",
      "Epoch 1094 train accuracy: 75.02056484782013\n",
      "Epoch 1094 val loss: 0.6518993596301267\n",
      "Epoch 1094 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1094.pth\n",
      "Epoch 1095 train loss: 0.6588102267695624\n",
      "Epoch 1095 train accuracy: 75.04798464491363\n",
      "Epoch 1095 val loss: 0.651899748628861\n",
      "Epoch 1095 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1095.pth\n",
      "Epoch 1096 train loss: 0.6588252400816009\n",
      "Epoch 1096 train accuracy: 74.99314505072662\n",
      "Epoch 1096 val loss: 0.6519017402866953\n",
      "Epoch 1096 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1096.pth\n",
      "Epoch 1097 train loss: 0.6588158349980388\n",
      "Epoch 1097 train accuracy: 74.99314505072662\n",
      "Epoch 1097 val loss: 0.6518951333863171\n",
      "Epoch 1097 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1097.pth\n",
      "Epoch 1098 train loss: 0.6588126234220046\n",
      "Epoch 1098 train accuracy: 75.02056484782013\n",
      "Epoch 1098 val loss: 0.6518974441446757\n",
      "Epoch 1098 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1098.pth\n",
      "Epoch 1099 train loss: 0.658792250806041\n",
      "Epoch 1099 train accuracy: 74.99314505072662\n",
      "Epoch 1099 val loss: 0.6518769567146113\n",
      "Epoch 1099 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1099.pth\n",
      "Epoch 1100 train loss: 0.6588011820424806\n",
      "Epoch 1100 train accuracy: 75.02056484782013\n",
      "Epoch 1100 val loss: 0.6518457002545658\n",
      "Epoch 1100 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1100.pth\n",
      "Epoch 1101 train loss: 0.6587882624906406\n",
      "Epoch 1101 train accuracy: 75.02056484782013\n",
      "Epoch 1101 val loss: 0.6518496421999053\n",
      "Epoch 1101 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1101.pth\n",
      "Epoch 1102 train loss: 0.658776020925296\n",
      "Epoch 1102 train accuracy: 74.99314505072662\n",
      "Epoch 1102 val loss: 0.6518500211011422\n",
      "Epoch 1102 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1102.pth\n",
      "Epoch 1103 train loss: 0.6587741614172333\n",
      "Epoch 1103 train accuracy: 75.04798464491363\n",
      "Epoch 1103 val loss: 0.65184205682262\n",
      "Epoch 1103 val accuracy: 76.48026315789474\n",
      "Saved model to .\\test_modelsv2/MLP_1103.pth\n",
      "Epoch 1104 train loss: 0.6587681327211229\n",
      "Epoch 1104 train accuracy: 74.93830545653962\n",
      "Epoch 1104 val loss: 0.651827390158647\n",
      "Epoch 1104 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1104.pth\n",
      "Epoch 1105 train loss: 0.6587802669229476\n",
      "Epoch 1105 train accuracy: 74.99314505072662\n",
      "Epoch 1105 val loss: 0.6518072424162376\n",
      "Epoch 1105 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1105.pth\n",
      "Epoch 1106 train loss: 0.6586670980772429\n",
      "Epoch 1106 train accuracy: 75.02056484782013\n",
      "Epoch 1106 val loss: 0.651820881096156\n",
      "Epoch 1106 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1106.pth\n",
      "Epoch 1107 train loss: 0.6587500477111653\n",
      "Epoch 1107 train accuracy: 75.02056484782013\n",
      "Epoch 1107 val loss: 0.6518089414427155\n",
      "Epoch 1107 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1107.pth\n",
      "Epoch 1108 train loss: 0.6586999526541484\n",
      "Epoch 1108 train accuracy: 75.02056484782013\n",
      "Epoch 1108 val loss: 0.6518018543720245\n",
      "Epoch 1108 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1108.pth\n",
      "Epoch 1109 train loss: 0.6587027263615215\n",
      "Epoch 1109 train accuracy: 74.96572525363312\n",
      "Epoch 1109 val loss: 0.6518070601711148\n",
      "Epoch 1109 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1109.pth\n",
      "Epoch 1110 train loss: 0.6586910582948149\n",
      "Epoch 1110 train accuracy: 75.04798464491363\n",
      "Epoch 1110 val loss: 0.6517631894859829\n",
      "Epoch 1110 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1110.pth\n",
      "Epoch 1111 train loss: 0.6586766993921054\n",
      "Epoch 1111 train accuracy: 75.02056484782013\n",
      "Epoch 1111 val loss: 0.6517588493267172\n",
      "Epoch 1111 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1111.pth\n",
      "Epoch 1112 train loss: 0.6587164136336038\n",
      "Epoch 1112 train accuracy: 75.04798464491363\n",
      "Epoch 1112 val loss: 0.6517636084831074\n",
      "Epoch 1112 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1112.pth\n",
      "Epoch 1113 train loss: 0.6587101766153386\n",
      "Epoch 1113 train accuracy: 75.07540444200713\n",
      "Epoch 1113 val loss: 0.6517587180592512\n",
      "Epoch 1113 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1113.pth\n",
      "Epoch 1114 train loss: 0.6586956836021783\n",
      "Epoch 1114 train accuracy: 75.02056484782013\n",
      "Epoch 1114 val loss: 0.6517574211680576\n",
      "Epoch 1114 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1114.pth\n",
      "Epoch 1115 train loss: 0.6586111771890468\n",
      "Epoch 1115 train accuracy: 74.99314505072662\n",
      "Epoch 1115 val loss: 0.6517560135965285\n",
      "Epoch 1115 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1115.pth\n",
      "Epoch 1116 train loss: 0.6586514580014505\n",
      "Epoch 1116 train accuracy: 75.02056484782013\n",
      "Epoch 1116 val loss: 0.6517302711543284\n",
      "Epoch 1116 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1116.pth\n",
      "Epoch 1117 train loss: 0.6586245228127953\n",
      "Epoch 1117 train accuracy: 75.02056484782013\n",
      "Epoch 1117 val loss: 0.6517289940659937\n",
      "Epoch 1117 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1117.pth\n",
      "Epoch 1118 train loss: 0.6586257129123336\n",
      "Epoch 1118 train accuracy: 75.02056484782013\n",
      "Epoch 1118 val loss: 0.6517321933060884\n",
      "Epoch 1118 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1118.pth\n",
      "Epoch 1119 train loss: 0.6586618463655836\n",
      "Epoch 1119 train accuracy: 74.99314505072662\n",
      "Epoch 1119 val loss: 0.6517515391307441\n",
      "Epoch 1119 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1119.pth\n",
      "Epoch 1120 train loss: 0.6586591758552873\n",
      "Epoch 1120 train accuracy: 74.99314505072662\n",
      "Epoch 1120 val loss: 0.6517531602202278\n",
      "Epoch 1120 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1120.pth\n",
      "Epoch 1121 train loss: 0.6586054245565545\n",
      "Epoch 1121 train accuracy: 75.02056484782013\n",
      "Epoch 1121 val loss: 0.651734714249247\n",
      "Epoch 1121 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1121.pth\n",
      "Epoch 1122 train loss: 0.6586374656313605\n",
      "Epoch 1122 train accuracy: 75.02056484782013\n",
      "Epoch 1122 val loss: 0.6517158165378006\n",
      "Epoch 1122 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1122.pth\n",
      "Epoch 1123 train loss: 0.6586315519780966\n",
      "Epoch 1123 train accuracy: 75.04798464491363\n",
      "Epoch 1123 val loss: 0.6517124754425726\n",
      "Epoch 1123 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1123.pth\n",
      "Epoch 1124 train loss: 0.658574367007404\n",
      "Epoch 1124 train accuracy: 75.02056484782013\n",
      "Epoch 1124 val loss: 0.6516976996668076\n",
      "Epoch 1124 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1124.pth\n",
      "Epoch 1125 train loss: 0.658577344723438\n",
      "Epoch 1125 train accuracy: 74.91088565944612\n",
      "Epoch 1125 val loss: 0.6516730921146902\n",
      "Epoch 1125 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1125.pth\n",
      "Epoch 1126 train loss: 0.6586392515649399\n",
      "Epoch 1126 train accuracy: 75.04798464491363\n",
      "Epoch 1126 val loss: 0.6516842777399641\n",
      "Epoch 1126 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1126.pth\n",
      "Epoch 1127 train loss: 0.6586548992383637\n",
      "Epoch 1127 train accuracy: 75.02056484782013\n",
      "Epoch 1127 val loss: 0.6516688390585937\n",
      "Epoch 1127 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1127.pth\n",
      "Epoch 1128 train loss: 0.6585806903609058\n",
      "Epoch 1128 train accuracy: 74.96572525363312\n",
      "Epoch 1128 val loss: 0.6516657462833744\n",
      "Epoch 1128 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1128.pth\n",
      "Epoch 1129 train loss: 0.658601955363625\n",
      "Epoch 1129 train accuracy: 74.99314505072662\n",
      "Epoch 1129 val loss: 0.6516565984409106\n",
      "Epoch 1129 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1129.pth\n",
      "Epoch 1130 train loss: 0.6585547015757153\n",
      "Epoch 1130 train accuracy: 75.04798464491363\n",
      "Epoch 1130 val loss: 0.6516482568296947\n",
      "Epoch 1130 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1130.pth\n",
      "Epoch 1131 train loss: 0.6584954950631711\n",
      "Epoch 1131 train accuracy: 75.02056484782013\n",
      "Epoch 1131 val loss: 0.6516468492581656\n",
      "Epoch 1131 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1131.pth\n",
      "Epoch 1132 train loss: 0.6585413264927634\n",
      "Epoch 1132 train accuracy: 75.07540444200713\n",
      "Epoch 1132 val loss: 0.6516422578378728\n",
      "Epoch 1132 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1132.pth\n",
      "Epoch 1133 train loss: 0.6585787237344081\n",
      "Epoch 1133 train accuracy: 75.07540444200713\n",
      "Epoch 1133 val loss: 0.6516309177601024\n",
      "Epoch 1133 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1133.pth\n",
      "Epoch 1134 train loss: 0.65851841138251\n",
      "Epoch 1134 train accuracy: 74.96572525363312\n",
      "Epoch 1134 val loss: 0.6516234401221338\n",
      "Epoch 1134 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1134.pth\n",
      "Epoch 1135 train loss: 0.6585541421122718\n",
      "Epoch 1135 train accuracy: 75.04798464491363\n",
      "Epoch 1135 val loss: 0.6516267200441737\n",
      "Epoch 1135 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1135.pth\n",
      "Epoch 1136 train loss: 0.6584268261335398\n",
      "Epoch 1136 train accuracy: 75.10282423910063\n",
      "Epoch 1136 val loss: 0.6515935765285241\n",
      "Epoch 1136 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1136.pth\n",
      "Epoch 1137 train loss: 0.658540729694722\n",
      "Epoch 1137 train accuracy: 75.10282423910063\n",
      "Epoch 1137 val loss: 0.6516088686491314\n",
      "Epoch 1137 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1137.pth\n",
      "Epoch 1138 train loss: 0.6585448924778846\n",
      "Epoch 1138 train accuracy: 75.07540444200713\n",
      "Epoch 1138 val loss: 0.6515836396107548\n",
      "Epoch 1138 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1138.pth\n",
      "Epoch 1139 train loss: 0.6585221521294954\n",
      "Epoch 1139 train accuracy: 75.04798464491363\n",
      "Epoch 1139 val loss: 0.6515787592843959\n",
      "Epoch 1139 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1139.pth\n",
      "Epoch 1140 train loss: 0.6585535012969845\n",
      "Epoch 1140 train accuracy: 75.02056484782013\n",
      "Epoch 1140 val loss: 0.651595752784296\n",
      "Epoch 1140 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1140.pth\n",
      "Epoch 1141 train loss: 0.6584913976359785\n",
      "Epoch 1141 train accuracy: 75.04798464491363\n",
      "Epoch 1141 val loss: 0.6515718312247804\n",
      "Epoch 1141 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1141.pth\n",
      "Epoch 1142 train loss: 0.658502973942903\n",
      "Epoch 1142 train accuracy: 74.99314505072662\n",
      "Epoch 1142 val loss: 0.6515664320046964\n",
      "Epoch 1142 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1142.pth\n",
      "Epoch 1143 train loss: 0.6584925345030793\n",
      "Epoch 1143 train accuracy: 75.13024403619413\n",
      "Epoch 1143 val loss: 0.6515703671856931\n",
      "Epoch 1143 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1143.pth\n",
      "Epoch 1144 train loss: 0.6583936661645248\n",
      "Epoch 1144 train accuracy: 75.10282423910063\n",
      "Epoch 1144 val loss: 0.651558432826086\n",
      "Epoch 1144 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1144.pth\n",
      "Epoch 1145 train loss: 0.6585540095703644\n",
      "Epoch 1145 train accuracy: 75.07540444200713\n",
      "Epoch 1145 val loss: 0.6515529405717787\n",
      "Epoch 1145 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1145.pth\n",
      "Epoch 1146 train loss: 0.6584223259175033\n",
      "Epoch 1146 train accuracy: 75.04798464491363\n",
      "Epoch 1146 val loss: 0.6515485900209138\n",
      "Epoch 1146 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1146.pth\n",
      "Epoch 1147 train loss: 0.6584724575085076\n",
      "Epoch 1147 train accuracy: 75.04798464491363\n",
      "Epoch 1147 val loss: 0.6515349786924688\n",
      "Epoch 1147 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1147.pth\n",
      "Epoch 1148 train loss: 0.6584565184128127\n",
      "Epoch 1148 train accuracy: 75.13024403619413\n",
      "Epoch 1148 val loss: 0.6515349327145439\n",
      "Epoch 1148 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1148.pth\n",
      "Epoch 1149 train loss: 0.6584503315389156\n",
      "Epoch 1149 train accuracy: 75.07540444200713\n",
      "Epoch 1149 val loss: 0.6515475247839564\n",
      "Epoch 1149 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1149.pth\n",
      "Epoch 1150 train loss: 0.6584451132241571\n",
      "Epoch 1150 train accuracy: 75.13024403619413\n",
      "Epoch 1150 val loss: 0.6515371286751408\n",
      "Epoch 1150 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1150.pth\n",
      "Epoch 1151 train loss: 0.6584357136631744\n",
      "Epoch 1151 train accuracy: 75.02056484782013\n",
      "Epoch 1151 val loss: 0.6515193661968959\n",
      "Epoch 1151 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1151.pth\n",
      "Epoch 1152 train loss: 0.6584253994780674\n",
      "Epoch 1152 train accuracy: 75.02056484782013\n",
      "Epoch 1152 val loss: 0.6514860494552475\n",
      "Epoch 1152 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1152.pth\n",
      "Epoch 1153 train loss: 0.6583816638183698\n",
      "Epoch 1153 train accuracy: 75.10282423910063\n",
      "Epoch 1153 val loss: 0.6515307361750227\n",
      "Epoch 1153 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1153.pth\n",
      "Epoch 1154 train loss: 0.6583639191823047\n",
      "Epoch 1154 train accuracy: 75.07540444200713\n",
      "Epoch 1154 val loss: 0.6514934173932201\n",
      "Epoch 1154 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1154.pth\n",
      "Epoch 1155 train loss: 0.6583720846918591\n",
      "Epoch 1155 train accuracy: 75.07540444200713\n",
      "Epoch 1155 val loss: 0.6515080781751558\n",
      "Epoch 1155 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1155.pth\n",
      "Epoch 1156 train loss: 0.6584073224742162\n",
      "Epoch 1156 train accuracy: 75.02056484782013\n",
      "Epoch 1156 val loss: 0.6514717629669529\n",
      "Epoch 1156 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1156.pth\n",
      "Epoch 1157 train loss: 0.6584372297909699\n",
      "Epoch 1157 train accuracy: 75.07540444200713\n",
      "Epoch 1157 val loss: 0.6514954752239742\n",
      "Epoch 1157 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1157.pth\n",
      "Epoch 1158 train loss: 0.6583743896662143\n",
      "Epoch 1158 train accuracy: 75.02056484782013\n",
      "Epoch 1158 val loss: 0.6514713223043241\n",
      "Epoch 1158 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1158.pth\n",
      "Epoch 1159 train loss: 0.6583851797081399\n",
      "Epoch 1159 train accuracy: 75.04798464491363\n",
      "Epoch 1159 val loss: 0.6514750907295629\n",
      "Epoch 1159 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1159.pth\n",
      "Epoch 1160 train loss: 0.6583471149532941\n",
      "Epoch 1160 train accuracy: 75.10282423910063\n",
      "Epoch 1160 val loss: 0.651461452833916\n",
      "Epoch 1160 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1160.pth\n",
      "Epoch 1161 train loss: 0.6584089880711154\n",
      "Epoch 1161 train accuracy: 75.04798464491363\n",
      "Epoch 1161 val loss: 0.6514236284910064\n",
      "Epoch 1161 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1161.pth\n",
      "Epoch 1162 train loss: 0.6583661981286448\n",
      "Epoch 1162 train accuracy: 75.07540444200713\n",
      "Epoch 1162 val loss: 0.6514403586226859\n",
      "Epoch 1162 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1162.pth\n",
      "Epoch 1163 train loss: 0.6583556292023052\n",
      "Epoch 1163 train accuracy: 75.15766383328763\n",
      "Epoch 1163 val loss: 0.6514527602611404\n",
      "Epoch 1163 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1163.pth\n",
      "Epoch 1164 train loss: 0.65835268070039\n",
      "Epoch 1164 train accuracy: 75.07540444200713\n",
      "Epoch 1164 val loss: 0.6514574212855414\n",
      "Epoch 1164 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1164.pth\n",
      "Epoch 1165 train loss: 0.6583144088324747\n",
      "Epoch 1165 train accuracy: 75.10282423910063\n",
      "Epoch 1165 val loss: 0.6514367794519976\n",
      "Epoch 1165 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1165.pth\n",
      "Epoch 1166 train loss: 0.658338655439908\n",
      "Epoch 1166 train accuracy: 75.02056484782013\n",
      "Epoch 1166 val loss: 0.6514256568135399\n",
      "Epoch 1166 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1166.pth\n",
      "Epoch 1167 train loss: 0.6583540288796812\n",
      "Epoch 1167 train accuracy: 75.13024403619413\n",
      "Epoch 1167 val loss: 0.6514364126089373\n",
      "Epoch 1167 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1167.pth\n",
      "Epoch 1168 train loss: 0.6584481236181761\n",
      "Epoch 1168 train accuracy: 75.13024403619413\n",
      "Epoch 1168 val loss: 0.6514331804294335\n",
      "Epoch 1168 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1168.pth\n",
      "Epoch 1169 train loss: 0.6583193662788784\n",
      "Epoch 1169 train accuracy: 75.02056484782013\n",
      "Epoch 1169 val loss: 0.6514356890203137\n",
      "Epoch 1169 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1169.pth\n",
      "Epoch 1170 train loss: 0.658300636989767\n",
      "Epoch 1170 train accuracy: 75.10282423910063\n",
      "Epoch 1170 val loss: 0.6514238973981455\n",
      "Epoch 1170 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1170.pth\n",
      "Epoch 1171 train loss: 0.6583054613387376\n",
      "Epoch 1171 train accuracy: 75.13024403619413\n",
      "Epoch 1171 val loss: 0.6514078139474517\n",
      "Epoch 1171 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1171.pth\n",
      "Epoch 1172 train loss: 0.6582221709714647\n",
      "Epoch 1172 train accuracy: 75.04798464491363\n",
      "Epoch 1172 val loss: 0.6514110478915667\n",
      "Epoch 1172 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1172.pth\n",
      "Epoch 1173 train loss: 0.6582956643807784\n",
      "Epoch 1173 train accuracy: 75.10282423910063\n",
      "Epoch 1173 val loss: 0.6513931115010851\n",
      "Epoch 1173 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1173.pth\n",
      "Epoch 1174 train loss: 0.6582572357565687\n",
      "Epoch 1174 train accuracy: 75.10282423910063\n",
      "Epoch 1174 val loss: 0.6514166483753606\n",
      "Epoch 1174 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1174.pth\n",
      "Epoch 1175 train loss: 0.6582783888045111\n",
      "Epoch 1175 train accuracy: 75.04798464491363\n",
      "Epoch 1175 val loss: 0.6513671119648375\n",
      "Epoch 1175 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1175.pth\n",
      "Epoch 1176 train loss: 0.6582385609416586\n",
      "Epoch 1176 train accuracy: 75.07540444200713\n",
      "Epoch 1176 val loss: 0.6513666714492597\n",
      "Epoch 1176 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1176.pth\n",
      "Epoch 1177 train loss: 0.658266421538173\n",
      "Epoch 1177 train accuracy: 75.13024403619413\n",
      "Epoch 1177 val loss: 0.6513580595584292\n",
      "Epoch 1177 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1177.pth\n",
      "Epoch 1178 train loss: 0.6582560062147024\n",
      "Epoch 1178 train accuracy: 75.10282423910063\n",
      "Epoch 1178 val loss: 0.6513384268864205\n",
      "Epoch 1178 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1178.pth\n",
      "Epoch 1179 train loss: 0.6582532931903475\n",
      "Epoch 1179 train accuracy: 75.18508363038113\n",
      "Epoch 1179 val loss: 0.6513513610943368\n",
      "Epoch 1179 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1179.pth\n",
      "Epoch 1180 train loss: 0.6582428230985737\n",
      "Epoch 1180 train accuracy: 75.10282423910063\n",
      "Epoch 1180 val loss: 0.6513552361805188\n",
      "Epoch 1180 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1180.pth\n",
      "Epoch 1181 train loss: 0.6582374117876354\n",
      "Epoch 1181 train accuracy: 75.15766383328763\n",
      "Epoch 1181 val loss: 0.65135413869039\n",
      "Epoch 1181 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1181.pth\n",
      "Epoch 1182 train loss: 0.6581996872106142\n",
      "Epoch 1182 train accuracy: 75.13024403619413\n",
      "Epoch 1182 val loss: 0.6513516151983487\n",
      "Epoch 1182 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1182.pth\n",
      "Epoch 1183 train loss: 0.6581885097711756\n",
      "Epoch 1183 train accuracy: 75.10282423910063\n",
      "Epoch 1183 val loss: 0.6513295654011401\n",
      "Epoch 1183 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1183.pth\n",
      "Epoch 1184 train loss: 0.6582223390016639\n",
      "Epoch 1184 train accuracy: 75.07540444200713\n",
      "Epoch 1184 val loss: 0.6513329549251419\n",
      "Epoch 1184 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1184.pth\n",
      "Epoch 1185 train loss: 0.6581862553496632\n",
      "Epoch 1185 train accuracy: 75.18508363038113\n",
      "Epoch 1185 val loss: 0.651322139132964\n",
      "Epoch 1185 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1185.pth\n",
      "Epoch 1186 train loss: 0.6581768559847485\n",
      "Epoch 1186 train accuracy: 75.10282423910063\n",
      "Epoch 1186 val loss: 0.6513064451221573\n",
      "Epoch 1186 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1186.pth\n",
      "Epoch 1187 train loss: 0.6581985455725277\n",
      "Epoch 1187 train accuracy: 75.10282423910063\n",
      "Epoch 1187 val loss: 0.6513319438029277\n",
      "Epoch 1187 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1187.pth\n",
      "Epoch 1188 train loss: 0.6582017561518833\n",
      "Epoch 1188 train accuracy: 75.04798464491363\n",
      "Epoch 1188 val loss: 0.6513077989220619\n",
      "Epoch 1188 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1188.pth\n",
      "Epoch 1189 train loss: 0.6582592298325739\n",
      "Epoch 1189 train accuracy: 75.15766383328763\n",
      "Epoch 1189 val loss: 0.651308494963144\n",
      "Epoch 1189 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1189.pth\n",
      "Epoch 1190 train loss: 0.6582020583578891\n",
      "Epoch 1190 train accuracy: 75.07540444200713\n",
      "Epoch 1190 val loss: 0.6513042118596403\n",
      "Epoch 1190 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1190.pth\n",
      "Epoch 1191 train loss: 0.6581432949424836\n",
      "Epoch 1191 train accuracy: 75.10282423910063\n",
      "Epoch 1191 val loss: 0.6512901102633852\n",
      "Epoch 1191 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1191.pth\n",
      "Epoch 1192 train loss: 0.6582146896082058\n",
      "Epoch 1192 train accuracy: 75.13024403619413\n",
      "Epoch 1192 val loss: 0.6512683299615195\n",
      "Epoch 1192 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1192.pth\n",
      "Epoch 1193 train loss: 0.6581633600749468\n",
      "Epoch 1193 train accuracy: 75.15766383328763\n",
      "Epoch 1193 val loss: 0.6512584621576887\n",
      "Epoch 1193 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1193.pth\n",
      "Epoch 1194 train loss: 0.6581183869653103\n",
      "Epoch 1194 train accuracy: 75.15766383328763\n",
      "Epoch 1194 val loss: 0.6512568232260252\n",
      "Epoch 1194 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1194.pth\n",
      "Epoch 1195 train loss: 0.6581808497900503\n",
      "Epoch 1195 train accuracy: 75.18508363038113\n",
      "Epoch 1195 val loss: 0.6512392727952254\n",
      "Epoch 1195 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1195.pth\n",
      "Epoch 1196 train loss: 0.6581258411731636\n",
      "Epoch 1196 train accuracy: 75.10282423910063\n",
      "Epoch 1196 val loss: 0.6512443214458855\n",
      "Epoch 1196 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1196.pth\n",
      "Epoch 1197 train loss: 0.6580850440812739\n",
      "Epoch 1197 train accuracy: 75.10282423910063\n",
      "Epoch 1197 val loss: 0.6512380231563982\n",
      "Epoch 1197 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1197.pth\n",
      "Epoch 1198 train loss: 0.6581308830921587\n",
      "Epoch 1198 train accuracy: 75.15766383328763\n",
      "Epoch 1198 val loss: 0.6512330157780334\n",
      "Epoch 1198 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1198.pth\n",
      "Epoch 1199 train loss: 0.6581260601483416\n",
      "Epoch 1199 train accuracy: 75.10282423910063\n",
      "Epoch 1199 val loss: 0.6512269363983682\n",
      "Epoch 1199 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1199.pth\n",
      "Epoch 1200 train loss: 0.6581136430368612\n",
      "Epoch 1200 train accuracy: 75.13024403619413\n",
      "Epoch 1200 val loss: 0.6512191866181398\n",
      "Epoch 1200 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1200.pth\n",
      "Epoch 1201 train loss: 0.6580945332452917\n",
      "Epoch 1201 train accuracy: 75.13024403619413\n",
      "Epoch 1201 val loss: 0.6512356560285154\n",
      "Epoch 1201 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1201.pth\n",
      "Epoch 1202 train loss: 0.658112469929875\n",
      "Epoch 1202 train accuracy: 75.15766383328763\n",
      "Epoch 1202 val loss: 0.651238235988115\n",
      "Epoch 1202 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1202.pth\n",
      "Epoch 1203 train loss: 0.6580617987926591\n",
      "Epoch 1203 train accuracy: 75.13024403619413\n",
      "Epoch 1203 val loss: 0.6512303765078908\n",
      "Epoch 1203 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1203.pth\n",
      "Epoch 1204 train loss: 0.6580925061971995\n",
      "Epoch 1204 train accuracy: 75.15766383328763\n",
      "Epoch 1204 val loss: 0.6512295146913905\n",
      "Epoch 1204 val accuracy: 76.5625\n",
      "Saved model to .\\test_modelsv2/MLP_1204.pth\n",
      "Epoch 1205 train loss: 0.6580889927909562\n",
      "Epoch 1205 train accuracy: 75.13024403619413\n",
      "Epoch 1205 val loss: 0.6512029371959599\n",
      "Epoch 1205 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1205.pth\n",
      "Epoch 1206 train loss: 0.6580857706762719\n",
      "Epoch 1206 train accuracy: 75.10282423910063\n",
      "Epoch 1206 val loss: 0.6511796206039818\n",
      "Epoch 1206 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1206.pth\n",
      "Epoch 1207 train loss: 0.6580484013089485\n",
      "Epoch 1207 train accuracy: 75.10282423910063\n",
      "Epoch 1207 val loss: 0.6511814014888123\n",
      "Epoch 1207 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1207.pth\n",
      "Epoch 1208 train loss: 0.6581694511533306\n",
      "Epoch 1208 train accuracy: 75.07540444200713\n",
      "Epoch 1208 val loss: 0.6511442370124554\n",
      "Epoch 1208 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1208.pth\n",
      "Epoch 1209 train loss: 0.6580300477186316\n",
      "Epoch 1209 train accuracy: 75.10282423910063\n",
      "Epoch 1209 val loss: 0.6511619995887342\n",
      "Epoch 1209 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1209.pth\n",
      "Epoch 1210 train loss: 0.6580291480283466\n",
      "Epoch 1210 train accuracy: 75.13024403619413\n",
      "Epoch 1210 val loss: 0.6511686460948304\n",
      "Epoch 1210 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1210.pth\n",
      "Epoch 1211 train loss: 0.6580486247610104\n",
      "Epoch 1211 train accuracy: 75.10282423910063\n",
      "Epoch 1211 val loss: 0.6511638570380839\n",
      "Epoch 1211 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1211.pth\n",
      "Epoch 1212 train loss: 0.6580567646837026\n",
      "Epoch 1212 train accuracy: 75.10282423910063\n",
      "Epoch 1212 val loss: 0.6511507417614523\n",
      "Epoch 1212 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1212.pth\n",
      "Epoch 1213 train loss: 0.6580122366155449\n",
      "Epoch 1213 train accuracy: 75.13024403619413\n",
      "Epoch 1213 val loss: 0.6511464948324781\n",
      "Epoch 1213 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1213.pth\n",
      "Epoch 1214 train loss: 0.6579993363273772\n",
      "Epoch 1214 train accuracy: 75.10282423910063\n",
      "Epoch 1214 val loss: 0.6511551426037362\n",
      "Epoch 1214 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1214.pth\n",
      "Epoch 1215 train loss: 0.6580670220417935\n",
      "Epoch 1215 train accuracy: 75.13024403619413\n",
      "Epoch 1215 val loss: 0.6511458667289269\n",
      "Epoch 1215 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1215.pth\n",
      "Epoch 1216 train loss: 0.6579779186531117\n",
      "Epoch 1216 train accuracy: 75.04798464491363\n",
      "Epoch 1216 val loss: 0.6511248952071917\n",
      "Epoch 1216 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1216.pth\n",
      "Epoch 1217 train loss: 0.6579786806056896\n",
      "Epoch 1217 train accuracy: 75.13024403619413\n",
      "Epoch 1217 val loss: 0.6511178564672407\n",
      "Epoch 1217 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1217.pth\n",
      "Epoch 1218 train loss: 0.6579680027799648\n",
      "Epoch 1218 train accuracy: 75.21250342747463\n",
      "Epoch 1218 val loss: 0.6511148801563602\n",
      "Epoch 1218 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1218.pth\n",
      "Epoch 1219 train loss: 0.6579232324045479\n",
      "Epoch 1219 train accuracy: 75.15766383328763\n",
      "Epoch 1219 val loss: 0.6511088388138696\n",
      "Epoch 1219 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1219.pth\n",
      "Epoch 1220 train loss: 0.6579450430315837\n",
      "Epoch 1220 train accuracy: 75.07540444200713\n",
      "Epoch 1220 val loss: 0.651098578580116\n",
      "Epoch 1220 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1220.pth\n",
      "Epoch 1221 train loss: 0.6579449727412379\n",
      "Epoch 1221 train accuracy: 75.13024403619413\n",
      "Epoch 1221 val loss: 0.6511011840285439\n",
      "Epoch 1221 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1221.pth\n",
      "Epoch 1222 train loss: 0.6579856520943475\n",
      "Epoch 1222 train accuracy: 75.10282423910063\n",
      "Epoch 1222 val loss: 0.6510977266650451\n",
      "Epoch 1222 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1222.pth\n",
      "Epoch 1223 train loss: 0.6579895613290239\n",
      "Epoch 1223 train accuracy: 75.15766383328763\n",
      "Epoch 1223 val loss: 0.6510741435187427\n",
      "Epoch 1223 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1223.pth\n",
      "Epoch 1224 train loss: 0.6579740907866181\n",
      "Epoch 1224 train accuracy: 75.10282423910063\n",
      "Epoch 1224 val loss: 0.6510872401689228\n",
      "Epoch 1224 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1224.pth\n",
      "Epoch 1225 train loss: 0.6579827829345799\n",
      "Epoch 1225 train accuracy: 75.15766383328763\n",
      "Epoch 1225 val loss: 0.6510672827104205\n",
      "Epoch 1225 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1225.pth\n",
      "Epoch 1226 train loss: 0.6579761106128755\n",
      "Epoch 1226 train accuracy: 75.15766383328763\n",
      "Epoch 1226 val loss: 0.6510830316692591\n",
      "Epoch 1226 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1226.pth\n",
      "Epoch 1227 train loss: 0.6580476870989067\n",
      "Epoch 1227 train accuracy: 75.10282423910063\n",
      "Epoch 1227 val loss: 0.65105978742634\n",
      "Epoch 1227 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1227.pth\n",
      "Epoch 1228 train loss: 0.6579451474704241\n",
      "Epoch 1228 train accuracy: 75.07540444200713\n",
      "Epoch 1228 val loss: 0.6510678205246988\n",
      "Epoch 1228 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1228.pth\n",
      "Epoch 1229 train loss: 0.657947251573205\n",
      "Epoch 1229 train accuracy: 75.15766383328763\n",
      "Epoch 1229 val loss: 0.651068054237648\n",
      "Epoch 1229 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1229.pth\n",
      "Epoch 1230 train loss: 0.6579164528663743\n",
      "Epoch 1230 train accuracy: 75.10282423910063\n",
      "Epoch 1230 val loss: 0.6510491701529214\n",
      "Epoch 1230 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1230.pth\n",
      "Epoch 1231 train loss: 0.6579240542395335\n",
      "Epoch 1231 train accuracy: 75.10282423910063\n",
      "Epoch 1231 val loss: 0.6510533706138009\n",
      "Epoch 1231 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1231.pth\n",
      "Epoch 1232 train loss: 0.6579210619654572\n",
      "Epoch 1232 train accuracy: 75.18508363038113\n",
      "Epoch 1232 val loss: 0.6510577196941564\n",
      "Epoch 1232 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1232.pth\n",
      "Epoch 1233 train loss: 0.6578184177020663\n",
      "Epoch 1233 train accuracy: 75.13024403619413\n",
      "Epoch 1233 val loss: 0.6510474387752382\n",
      "Epoch 1233 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1233.pth\n",
      "Epoch 1234 train loss: 0.657893546611855\n",
      "Epoch 1234 train accuracy: 75.10282423910063\n",
      "Epoch 1234 val loss: 0.651039894866316\n",
      "Epoch 1234 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1234.pth\n",
      "Epoch 1235 train loss: 0.6578703826587451\n",
      "Epoch 1235 train accuracy: 75.07540444200713\n",
      "Epoch 1235 val loss: 0.6510443316870614\n",
      "Epoch 1235 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1235.pth\n",
      "Epoch 1236 train loss: 0.65784462716169\n",
      "Epoch 1236 train accuracy: 75.15766383328763\n",
      "Epoch 1236 val loss: 0.6510265560722664\n",
      "Epoch 1236 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1236.pth\n",
      "Epoch 1237 train loss: 0.6578495876308073\n",
      "Epoch 1237 train accuracy: 75.10282423910063\n",
      "Epoch 1237 val loss: 0.6510117509843487\n",
      "Epoch 1237 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1237.pth\n",
      "Epoch 1238 train loss: 0.657889044990665\n",
      "Epoch 1238 train accuracy: 75.07540444200713\n",
      "Epoch 1238 val loss: 0.6509863138198853\n",
      "Epoch 1238 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1238.pth\n",
      "Epoch 1239 train loss: 0.6578848002511158\n",
      "Epoch 1239 train accuracy: 75.04798464491363\n",
      "Epoch 1239 val loss: 0.651010143619619\n",
      "Epoch 1239 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1239.pth\n",
      "Epoch 1240 train loss: 0.657873903352179\n",
      "Epoch 1240 train accuracy: 75.10282423910063\n",
      "Epoch 1240 val loss: 0.650985532783364\n",
      "Epoch 1240 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1240.pth\n",
      "Epoch 1241 train loss: 0.6578529167658927\n",
      "Epoch 1241 train accuracy: 75.15766383328763\n",
      "Epoch 1241 val loss: 0.6509890766128114\n",
      "Epoch 1241 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1241.pth\n",
      "Epoch 1242 train loss: 0.6578611356059187\n",
      "Epoch 1242 train accuracy: 75.07540444200713\n",
      "Epoch 1242 val loss: 0.6510015591782959\n",
      "Epoch 1242 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1242.pth\n",
      "Epoch 1243 train loss: 0.6578593504892891\n",
      "Epoch 1243 train accuracy: 75.07540444200713\n",
      "Epoch 1243 val loss: 0.6510023796244672\n",
      "Epoch 1243 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1243.pth\n",
      "Epoch 1244 train loss: 0.657780351770813\n",
      "Epoch 1244 train accuracy: 75.13024403619413\n",
      "Epoch 1244 val loss: 0.6510096517832655\n",
      "Epoch 1244 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1244.pth\n",
      "Epoch 1245 train loss: 0.6578972896789772\n",
      "Epoch 1245 train accuracy: 75.07540444200713\n",
      "Epoch 1245 val loss: 0.6510095486515447\n",
      "Epoch 1245 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1245.pth\n",
      "Epoch 1246 train loss: 0.6577973163180184\n",
      "Epoch 1246 train accuracy: 75.18508363038113\n",
      "Epoch 1246 val loss: 0.6509996259486989\n",
      "Epoch 1246 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1246.pth\n",
      "Epoch 1247 train loss: 0.6578063867626744\n",
      "Epoch 1247 train accuracy: 75.13024403619413\n",
      "Epoch 1247 val loss: 0.6509830176242088\n",
      "Epoch 1247 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1247.pth\n",
      "Epoch 1248 train loss: 0.6578279192837184\n",
      "Epoch 1248 train accuracy: 75.13024403619413\n",
      "Epoch 1248 val loss: 0.650963822967912\n",
      "Epoch 1248 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1248.pth\n",
      "Epoch 1249 train loss: 0.6578241554007196\n",
      "Epoch 1249 train accuracy: 75.15766383328763\n",
      "Epoch 1249 val loss: 0.650997381461294\n",
      "Epoch 1249 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1249.pth\n",
      "Epoch 1250 train loss: 0.6578193894473084\n",
      "Epoch 1250 train accuracy: 75.10282423910063\n",
      "Epoch 1250 val loss: 0.6509787481474248\n",
      "Epoch 1250 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1250.pth\n",
      "Epoch 1251 train loss: 0.6577130630612373\n",
      "Epoch 1251 train accuracy: 75.18508363038113\n",
      "Epoch 1251 val loss: 0.6509698802899373\n",
      "Epoch 1251 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1251.pth\n",
      "Epoch 1252 train loss: 0.6578026293335777\n",
      "Epoch 1252 train accuracy: 75.13024403619413\n",
      "Epoch 1252 val loss: 0.6509414884800974\n",
      "Epoch 1252 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1252.pth\n",
      "Epoch 1253 train loss: 0.6577391340805773\n",
      "Epoch 1253 train accuracy: 75.07540444200713\n",
      "Epoch 1253 val loss: 0.6509607794057382\n",
      "Epoch 1253 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1253.pth\n",
      "Epoch 1254 train loss: 0.6577679157061013\n",
      "Epoch 1254 train accuracy: 75.13024403619413\n",
      "Epoch 1254 val loss: 0.6509564521869546\n",
      "Epoch 1254 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1254.pth\n",
      "Epoch 1255 train loss: 0.6577363669741572\n",
      "Epoch 1255 train accuracy: 75.13024403619413\n",
      "Epoch 1255 val loss: 0.6509533868612427\n",
      "Epoch 1255 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1255.pth\n",
      "Epoch 1256 train loss: 0.6577794078998921\n",
      "Epoch 1256 train accuracy: 75.18508363038113\n",
      "Epoch 1256 val loss: 0.6509380828785268\n",
      "Epoch 1256 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1256.pth\n",
      "Epoch 1257 train loss: 0.6577566122603521\n",
      "Epoch 1257 train accuracy: 75.10282423910063\n",
      "Epoch 1257 val loss: 0.6509318422330054\n",
      "Epoch 1257 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1257.pth\n",
      "Epoch 1258 train loss: 0.6577802852384353\n",
      "Epoch 1258 train accuracy: 75.07540444200713\n",
      "Epoch 1258 val loss: 0.650911284708663\n",
      "Epoch 1258 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1258.pth\n",
      "Epoch 1259 train loss: 0.6577597602286882\n",
      "Epoch 1259 train accuracy: 75.18508363038113\n",
      "Epoch 1259 val loss: 0.6509376160408321\n",
      "Epoch 1259 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1259.pth\n",
      "Epoch 1260 train loss: 0.657788180729799\n",
      "Epoch 1260 train accuracy: 75.15766383328763\n",
      "Epoch 1260 val loss: 0.6509244001813626\n",
      "Epoch 1260 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1260.pth\n",
      "Epoch 1261 train loss: 0.6577745755774933\n",
      "Epoch 1261 train accuracy: 75.13024403619413\n",
      "Epoch 1261 val loss: 0.6509325863107255\n",
      "Epoch 1261 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1261.pth\n",
      "Epoch 1262 train loss: 0.6577117887505314\n",
      "Epoch 1262 train accuracy: 75.10282423910063\n",
      "Epoch 1262 val loss: 0.6509188457735275\n",
      "Epoch 1262 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1262.pth\n",
      "Epoch 1263 train loss: 0.6577094421771011\n",
      "Epoch 1263 train accuracy: 75.13024403619413\n",
      "Epoch 1263 val loss: 0.6509209911486036\n",
      "Epoch 1263 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1263.pth\n",
      "Epoch 1264 train loss: 0.6577092044120818\n",
      "Epoch 1264 train accuracy: 75.10282423910063\n",
      "Epoch 1264 val loss: 0.6508950088173151\n",
      "Epoch 1264 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1264.pth\n",
      "Epoch 1265 train loss: 0.6577238754875827\n",
      "Epoch 1265 train accuracy: 75.15766383328763\n",
      "Epoch 1265 val loss: 0.6509067443640608\n",
      "Epoch 1265 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1265.pth\n",
      "Epoch 1266 train loss: 0.6576847293528548\n",
      "Epoch 1266 train accuracy: 75.18508363038113\n",
      "Epoch 1266 val loss: 0.6509137490862295\n",
      "Epoch 1266 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1266.pth\n",
      "Epoch 1267 train loss: 0.6576986085754215\n",
      "Epoch 1267 train accuracy: 75.18508363038113\n",
      "Epoch 1267 val loss: 0.6509080003750952\n",
      "Epoch 1267 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1267.pth\n",
      "Epoch 1268 train loss: 0.6577669334058699\n",
      "Epoch 1268 train accuracy: 75.18508363038113\n",
      "Epoch 1268 val loss: 0.650886139979488\n",
      "Epoch 1268 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1268.pth\n",
      "Epoch 1269 train loss: 0.6577008103526998\n",
      "Epoch 1269 train accuracy: 75.07540444200713\n",
      "Epoch 1269 val loss: 0.650903092011025\n",
      "Epoch 1269 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1269.pth\n",
      "Epoch 1270 train loss: 0.6576918960271174\n",
      "Epoch 1270 train accuracy: 75.07540444200713\n",
      "Epoch 1270 val loss: 0.6509024679268661\n",
      "Epoch 1270 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1270.pth\n",
      "Epoch 1271 train loss: 0.6577160113344067\n",
      "Epoch 1271 train accuracy: 75.10282423910063\n",
      "Epoch 1271 val loss: 0.6508955252601912\n",
      "Epoch 1271 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1271.pth\n",
      "Epoch 1272 train loss: 0.6576863387436197\n",
      "Epoch 1272 train accuracy: 75.18508363038113\n",
      "Epoch 1272 val loss: 0.6508825524268966\n",
      "Epoch 1272 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1272.pth\n",
      "Epoch 1273 train loss: 0.6576725854620076\n",
      "Epoch 1273 train accuracy: 75.18508363038113\n",
      "Epoch 1273 val loss: 0.6508754982956146\n",
      "Epoch 1273 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1273.pth\n",
      "Epoch 1274 train loss: 0.6576418312299147\n",
      "Epoch 1274 train accuracy: 75.15766383328763\n",
      "Epoch 1274 val loss: 0.6508531470439936\n",
      "Epoch 1274 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1274.pth\n",
      "Epoch 1275 train loss: 0.6577154917381051\n",
      "Epoch 1275 train accuracy: 75.10282423910063\n",
      "Epoch 1275 val loss: 0.6508517118268892\n",
      "Epoch 1275 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1275.pth\n",
      "Epoch 1276 train loss: 0.6576623197383525\n",
      "Epoch 1276 train accuracy: 75.15766383328763\n",
      "Epoch 1276 val loss: 0.6508552716358712\n",
      "Epoch 1276 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1276.pth\n",
      "Epoch 1277 train loss: 0.6576635944411943\n",
      "Epoch 1277 train accuracy: 75.15766383328763\n",
      "Epoch 1277 val loss: 0.6508463937789202\n",
      "Epoch 1277 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1277.pth\n",
      "Epoch 1278 train loss: 0.657663746099723\n",
      "Epoch 1278 train accuracy: 75.04798464491363\n",
      "Epoch 1278 val loss: 0.6508490878500437\n",
      "Epoch 1278 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1278.pth\n",
      "Epoch 1279 train loss: 0.6576417733245251\n",
      "Epoch 1279 train accuracy: 75.13024403619413\n",
      "Epoch 1279 val loss: 0.6508508856947485\n",
      "Epoch 1279 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1279.pth\n",
      "Epoch 1280 train loss: 0.6576369072784457\n",
      "Epoch 1280 train accuracy: 75.13024403619413\n",
      "Epoch 1280 val loss: 0.6508534203626608\n",
      "Epoch 1280 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1280.pth\n",
      "Epoch 1281 train loss: 0.6576279332992017\n",
      "Epoch 1281 train accuracy: 75.15766383328763\n",
      "Epoch 1281 val loss: 0.650836977813589\n",
      "Epoch 1281 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1281.pth\n",
      "Epoch 1282 train loss: 0.6576247199422174\n",
      "Epoch 1282 train accuracy: 75.13024403619413\n",
      "Epoch 1282 val loss: 0.6508197983432757\n",
      "Epoch 1282 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1282.pth\n",
      "Epoch 1283 train loss: 0.6576954627965104\n",
      "Epoch 1283 train accuracy: 75.15766383328763\n",
      "Epoch 1283 val loss: 0.6508087640334117\n",
      "Epoch 1283 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1283.pth\n",
      "Epoch 1284 train loss: 0.6576145770387691\n",
      "Epoch 1284 train accuracy: 75.15766383328763\n",
      "Epoch 1284 val loss: 0.6508141391371426\n",
      "Epoch 1284 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1284.pth\n",
      "Epoch 1285 train loss: 0.6575266829316031\n",
      "Epoch 1285 train accuracy: 75.13024403619413\n",
      "Epoch 1285 val loss: 0.6507813112908288\n",
      "Epoch 1285 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1285.pth\n",
      "Epoch 1286 train loss: 0.6575536193620217\n",
      "Epoch 1286 train accuracy: 75.07540444200713\n",
      "Epoch 1286 val loss: 0.6508173972956444\n",
      "Epoch 1286 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1286.pth\n",
      "Epoch 1287 train loss: 0.6575891927309465\n",
      "Epoch 1287 train accuracy: 75.13024403619413\n",
      "Epoch 1287 val loss: 0.6508216789286387\n",
      "Epoch 1287 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1287.pth\n",
      "Epoch 1288 train loss: 0.6575898451632575\n",
      "Epoch 1288 train accuracy: 75.15766383328763\n",
      "Epoch 1288 val loss: 0.6508045703368751\n",
      "Epoch 1288 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1288.pth\n",
      "Epoch 1289 train loss: 0.6575831842461699\n",
      "Epoch 1289 train accuracy: 75.02056484782013\n",
      "Epoch 1289 val loss: 0.6507725673482606\n",
      "Epoch 1289 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1289.pth\n",
      "Epoch 1290 train loss: 0.6575388387499148\n",
      "Epoch 1290 train accuracy: 75.13024403619413\n",
      "Epoch 1290 val loss: 0.6507791377800075\n",
      "Epoch 1290 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1290.pth\n",
      "Epoch 1291 train loss: 0.6575712972696413\n",
      "Epoch 1291 train accuracy: 75.13024403619413\n",
      "Epoch 1291 val loss: 0.6507559901985683\n",
      "Epoch 1291 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1291.pth\n",
      "Epoch 1292 train loss: 0.6575326623983289\n",
      "Epoch 1292 train accuracy: 75.18508363038113\n",
      "Epoch 1292 val loss: 0.6507683709067734\n",
      "Epoch 1292 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1292.pth\n",
      "Epoch 1293 train loss: 0.6575566448532698\n",
      "Epoch 1293 train accuracy: 75.18508363038113\n",
      "Epoch 1293 val loss: 0.6507583694826615\n",
      "Epoch 1293 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1293.pth\n",
      "Epoch 1294 train loss: 0.657546028364123\n",
      "Epoch 1294 train accuracy: 75.13024403619413\n",
      "Epoch 1294 val loss: 0.6507561503860512\n",
      "Epoch 1294 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1294.pth\n",
      "Epoch 1295 train loss: 0.6575190501712393\n",
      "Epoch 1295 train accuracy: 75.10282423910063\n",
      "Epoch 1295 val loss: 0.6507621198696526\n",
      "Epoch 1295 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1295.pth\n",
      "Epoch 1296 train loss: 0.6575049957293168\n",
      "Epoch 1296 train accuracy: 75.10282423910063\n",
      "Epoch 1296 val loss: 0.6507637281166879\n",
      "Epoch 1296 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1296.pth\n",
      "Epoch 1297 train loss: 0.6575247284939938\n",
      "Epoch 1297 train accuracy: 75.13024403619413\n",
      "Epoch 1297 val loss: 0.6507743722514102\n",
      "Epoch 1297 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1297.pth\n",
      "Epoch 1298 train loss: 0.657483758404851\n",
      "Epoch 1298 train accuracy: 75.15766383328763\n",
      "Epoch 1298 val loss: 0.6507524587213993\n",
      "Epoch 1298 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1298.pth\n",
      "Epoch 1299 train loss: 0.65752403604749\n",
      "Epoch 1299 train accuracy: 75.10282423910063\n",
      "Epoch 1299 val loss: 0.6507490288074079\n",
      "Epoch 1299 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1299.pth\n",
      "Epoch 1300 train loss: 0.6574831810828886\n",
      "Epoch 1300 train accuracy: 75.15766383328763\n",
      "Epoch 1300 val loss: 0.6507348323142842\n",
      "Epoch 1300 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1300.pth\n",
      "Epoch 1301 train loss: 0.6574683851121288\n",
      "Epoch 1301 train accuracy: 75.13024403619413\n",
      "Epoch 1301 val loss: 0.6507208509076583\n",
      "Epoch 1301 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1301.pth\n",
      "Epoch 1302 train loss: 0.6575791990351781\n",
      "Epoch 1302 train accuracy: 75.15766383328763\n",
      "Epoch 1302 val loss: 0.650734795551551\n",
      "Epoch 1302 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1302.pth\n",
      "Epoch 1303 train loss: 0.6574503828428293\n",
      "Epoch 1303 train accuracy: 75.10282423910063\n",
      "Epoch 1303 val loss: 0.6507241960222784\n",
      "Epoch 1303 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1303.pth\n",
      "Epoch 1304 train loss: 0.6574993914221985\n",
      "Epoch 1304 train accuracy: 75.13024403619413\n",
      "Epoch 1304 val loss: 0.6507113807295498\n",
      "Epoch 1304 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1304.pth\n",
      "Epoch 1305 train loss: 0.6575022109767847\n",
      "Epoch 1305 train accuracy: 75.07540444200713\n",
      "Epoch 1305 val loss: 0.6506876527870956\n",
      "Epoch 1305 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1305.pth\n",
      "Epoch 1306 train loss: 0.6574842185435588\n",
      "Epoch 1306 train accuracy: 75.10282423910063\n",
      "Epoch 1306 val loss: 0.6507151676832061\n",
      "Epoch 1306 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1306.pth\n",
      "Epoch 1307 train loss: 0.6574698326161557\n",
      "Epoch 1307 train accuracy: 75.13024403619413\n",
      "Epoch 1307 val loss: 0.6507145174239811\n",
      "Epoch 1307 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1307.pth\n",
      "Epoch 1308 train loss: 0.6574724271501365\n",
      "Epoch 1308 train accuracy: 75.10282423910063\n",
      "Epoch 1308 val loss: 0.6507064778553812\n",
      "Epoch 1308 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1308.pth\n",
      "Epoch 1309 train loss: 0.6574717985564157\n",
      "Epoch 1309 train accuracy: 75.10282423910063\n",
      "Epoch 1309 val loss: 0.6506951134651899\n",
      "Epoch 1309 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1309.pth\n",
      "Epoch 1310 train loss: 0.6574704567329925\n",
      "Epoch 1310 train accuracy: 75.13024403619413\n",
      "Epoch 1310 val loss: 0.6506764065278204\n",
      "Epoch 1310 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1310.pth\n",
      "Epoch 1311 train loss: 0.657460899010562\n",
      "Epoch 1311 train accuracy: 75.15766383328763\n",
      "Epoch 1311 val loss: 0.6506604053276149\n",
      "Epoch 1311 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1311.pth\n",
      "Epoch 1312 train loss: 0.6574055248577344\n",
      "Epoch 1312 train accuracy: 75.13024403619413\n",
      "Epoch 1312 val loss: 0.6506761393852925\n",
      "Epoch 1312 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1312.pth\n",
      "Epoch 1313 train loss: 0.6574069785379004\n",
      "Epoch 1313 train accuracy: 75.10282423910063\n",
      "Epoch 1313 val loss: 0.6506745849588984\n",
      "Epoch 1313 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1313.pth\n",
      "Epoch 1314 train loss: 0.6575127488426995\n",
      "Epoch 1314 train accuracy: 75.15766383328763\n",
      "Epoch 1314 val loss: 0.6506571462868076\n",
      "Epoch 1314 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1314.pth\n",
      "Epoch 1315 train loss: 0.6574115707424649\n",
      "Epoch 1315 train accuracy: 75.18508363038113\n",
      "Epoch 1315 val loss: 0.6506690678039664\n",
      "Epoch 1315 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1315.pth\n",
      "Epoch 1316 train loss: 0.6573713567892188\n",
      "Epoch 1316 train accuracy: 75.15766383328763\n",
      "Epoch 1316 val loss: 0.6506582228957039\n",
      "Epoch 1316 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1316.pth\n",
      "Epoch 1317 train loss: 0.6573562381887122\n",
      "Epoch 1317 train accuracy: 75.10282423910063\n",
      "Epoch 1317 val loss: 0.6506465576883209\n",
      "Epoch 1317 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1317.pth\n",
      "Epoch 1318 train loss: 0.6573708545285881\n",
      "Epoch 1318 train accuracy: 75.13024403619413\n",
      "Epoch 1318 val loss: 0.6506344705427948\n",
      "Epoch 1318 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1318.pth\n",
      "Epoch 1319 train loss: 0.657459548331405\n",
      "Epoch 1319 train accuracy: 75.10282423910063\n",
      "Epoch 1319 val loss: 0.6506264255823273\n",
      "Epoch 1319 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1319.pth\n",
      "Epoch 1320 train loss: 0.6573739956345475\n",
      "Epoch 1320 train accuracy: 75.13024403619413\n",
      "Epoch 1320 val loss: 0.6506099488194051\n",
      "Epoch 1320 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1320.pth\n",
      "Epoch 1321 train loss: 0.6573947055363342\n",
      "Epoch 1321 train accuracy: 75.10282423910063\n",
      "Epoch 1321 val loss: 0.6506036478830012\n",
      "Epoch 1321 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1321.pth\n",
      "Epoch 1322 train loss: 0.6573572914655271\n",
      "Epoch 1322 train accuracy: 75.13024403619413\n",
      "Epoch 1322 val loss: 0.6506177917318908\n",
      "Epoch 1322 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1322.pth\n",
      "Epoch 1323 train loss: 0.6573485667702922\n",
      "Epoch 1323 train accuracy: 75.13024403619413\n",
      "Epoch 1323 val loss: 0.6506094636493608\n",
      "Epoch 1323 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1323.pth\n",
      "Epoch 1324 train loss: 0.6573894810127584\n",
      "Epoch 1324 train accuracy: 75.21250342747463\n",
      "Epoch 1324 val loss: 0.6506253019171325\n",
      "Epoch 1324 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1324.pth\n",
      "Epoch 1325 train loss: 0.6573807106010223\n",
      "Epoch 1325 train accuracy: 75.15766383328763\n",
      "Epoch 1325 val loss: 0.6506075741429078\n",
      "Epoch 1325 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1325.pth\n",
      "Epoch 1326 train loss: 0.6573422440049941\n",
      "Epoch 1326 train accuracy: 75.10282423910063\n",
      "Epoch 1326 val loss: 0.6506001460120866\n",
      "Epoch 1326 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1326.pth\n",
      "Epoch 1327 train loss: 0.6573743361718299\n",
      "Epoch 1327 train accuracy: 75.13024403619413\n",
      "Epoch 1327 val loss: 0.6506029071384355\n",
      "Epoch 1327 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1327.pth\n",
      "Epoch 1328 train loss: 0.6573174722950187\n",
      "Epoch 1328 train accuracy: 75.13024403619413\n",
      "Epoch 1328 val loss: 0.6505863102839181\n",
      "Epoch 1328 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1328.pth\n",
      "Epoch 1329 train loss: 0.6573202118212194\n",
      "Epoch 1329 train accuracy: 75.13024403619413\n",
      "Epoch 1329 val loss: 0.6505693070786563\n",
      "Epoch 1329 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1329.pth\n",
      "Epoch 1330 train loss: 0.6574234794008366\n",
      "Epoch 1330 train accuracy: 75.15766383328763\n",
      "Epoch 1330 val loss: 0.6505579713143801\n",
      "Epoch 1330 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1330.pth\n",
      "Epoch 1331 train loss: 0.6573267875467999\n",
      "Epoch 1331 train accuracy: 75.10282423910063\n",
      "Epoch 1331 val loss: 0.6505721953550452\n",
      "Epoch 1331 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1331.pth\n",
      "Epoch 1332 train loss: 0.6573328609463939\n",
      "Epoch 1332 train accuracy: 75.10282423910063\n",
      "Epoch 1332 val loss: 0.6505626951785464\n",
      "Epoch 1332 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1332.pth\n",
      "Epoch 1333 train loss: 0.6573409856411448\n",
      "Epoch 1333 train accuracy: 75.07540444200713\n",
      "Epoch 1333 val loss: 0.6505643230323729\n",
      "Epoch 1333 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1333.pth\n",
      "Epoch 1334 train loss: 0.6572948025964331\n",
      "Epoch 1334 train accuracy: 75.15766383328763\n",
      "Epoch 1334 val loss: 0.6505580490553066\n",
      "Epoch 1334 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1334.pth\n",
      "Epoch 1335 train loss: 0.6573273927757615\n",
      "Epoch 1335 train accuracy: 75.15766383328763\n",
      "Epoch 1335 val loss: 0.650549557452139\n",
      "Epoch 1335 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1335.pth\n",
      "Epoch 1336 train loss: 0.6573397491715456\n",
      "Epoch 1336 train accuracy: 75.13024403619413\n",
      "Epoch 1336 val loss: 0.6505413209333232\n",
      "Epoch 1336 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1336.pth\n",
      "Epoch 1337 train loss: 0.6572756631495921\n",
      "Epoch 1337 train accuracy: 75.15766383328763\n",
      "Epoch 1337 val loss: 0.6505310555037699\n",
      "Epoch 1337 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1337.pth\n",
      "Epoch 1338 train loss: 0.6573062012004748\n",
      "Epoch 1338 train accuracy: 75.10282423910063\n",
      "Epoch 1338 val loss: 0.6505512813792417\n",
      "Epoch 1338 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1338.pth\n",
      "Epoch 1339 train loss: 0.6572763861990288\n",
      "Epoch 1339 train accuracy: 75.18508363038113\n",
      "Epoch 1339 val loss: 0.6505568880391749\n",
      "Epoch 1339 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1339.pth\n",
      "Epoch 1340 train loss: 0.6572750901247848\n",
      "Epoch 1340 train accuracy: 75.13024403619413\n",
      "Epoch 1340 val loss: 0.6505360403343251\n",
      "Epoch 1340 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1340.pth\n",
      "Epoch 1341 train loss: 0.6572940049268174\n",
      "Epoch 1341 train accuracy: 75.15766383328763\n",
      "Epoch 1341 val loss: 0.6505259087211207\n",
      "Epoch 1341 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1341.pth\n",
      "Epoch 1342 train loss: 0.6573230643805704\n",
      "Epoch 1342 train accuracy: 75.10282423910063\n",
      "Epoch 1342 val loss: 0.6505137960377493\n",
      "Epoch 1342 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1342.pth\n",
      "Epoch 1343 train loss: 0.6571991525655776\n",
      "Epoch 1343 train accuracy: 75.13024403619413\n",
      "Epoch 1343 val loss: 0.6505036454059576\n",
      "Epoch 1343 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1343.pth\n",
      "Epoch 1344 train loss: 0.6572483959689475\n",
      "Epoch 1344 train accuracy: 75.13024403619413\n",
      "Epoch 1344 val loss: 0.6505083631920187\n",
      "Epoch 1344 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1344.pth\n",
      "Epoch 1345 train loss: 0.657268217225608\n",
      "Epoch 1345 train accuracy: 75.15766383328763\n",
      "Epoch 1345 val loss: 0.6504982934382401\n",
      "Epoch 1345 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1345.pth\n",
      "Epoch 1346 train loss: 0.6572580904160675\n",
      "Epoch 1346 train accuracy: 75.13024403619413\n",
      "Epoch 1346 val loss: 0.6504915812493939\n",
      "Epoch 1346 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1346.pth\n",
      "Epoch 1347 train loss: 0.6572570637064544\n",
      "Epoch 1347 train accuracy: 75.18508363038113\n",
      "Epoch 1347 val loss: 0.6504918573130118\n",
      "Epoch 1347 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1347.pth\n",
      "Epoch 1348 train loss: 0.657252202071903\n",
      "Epoch 1348 train accuracy: 75.18508363038113\n",
      "Epoch 1348 val loss: 0.650480266464384\n",
      "Epoch 1348 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1348.pth\n",
      "Epoch 1349 train loss: 0.657246750746772\n",
      "Epoch 1349 train accuracy: 75.18508363038113\n",
      "Epoch 1349 val loss: 0.6504720274947191\n",
      "Epoch 1349 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1349.pth\n",
      "Epoch 1350 train loss: 0.6572398029986704\n",
      "Epoch 1350 train accuracy: 75.13024403619413\n",
      "Epoch 1350 val loss: 0.650468964913958\n",
      "Epoch 1350 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1350.pth\n",
      "Epoch 1351 train loss: 0.6572396564379073\n",
      "Epoch 1351 train accuracy: 75.07540444200713\n",
      "Epoch 1351 val loss: 0.6504656587188181\n",
      "Epoch 1351 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1351.pth\n",
      "Epoch 1352 train loss: 0.6572350360322416\n",
      "Epoch 1352 train accuracy: 75.18508363038113\n",
      "Epoch 1352 val loss: 0.6504691442180621\n",
      "Epoch 1352 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1352.pth\n",
      "Epoch 1353 train loss: 0.6572052415525704\n",
      "Epoch 1353 train accuracy: 75.23992322456814\n",
      "Epoch 1353 val loss: 0.6504707021736785\n",
      "Epoch 1353 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1353.pth\n",
      "Epoch 1354 train loss: 0.6571807112021927\n",
      "Epoch 1354 train accuracy: 75.10282423910063\n",
      "Epoch 1354 val loss: 0.6504563484340906\n",
      "Epoch 1354 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1354.pth\n",
      "Epoch 1355 train loss: 0.6571710075398809\n",
      "Epoch 1355 train accuracy: 75.15766383328763\n",
      "Epoch 1355 val loss: 0.6504338979721069\n",
      "Epoch 1355 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1355.pth\n",
      "Epoch 1356 train loss: 0.6572019224823044\n",
      "Epoch 1356 train accuracy: 75.21250342747463\n",
      "Epoch 1356 val loss: 0.6504341966815685\n",
      "Epoch 1356 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1356.pth\n",
      "Epoch 1357 train loss: 0.6571579014130852\n",
      "Epoch 1357 train accuracy: 75.10282423910063\n",
      "Epoch 1357 val loss: 0.6504376692403304\n",
      "Epoch 1357 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1357.pth\n",
      "Epoch 1358 train loss: 0.6572154946625233\n",
      "Epoch 1358 train accuracy: 75.15766383328763\n",
      "Epoch 1358 val loss: 0.6504415564827228\n",
      "Epoch 1358 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1358.pth\n",
      "Epoch 1359 train loss: 0.6571213046186849\n",
      "Epoch 1359 train accuracy: 75.18508363038113\n",
      "Epoch 1359 val loss: 0.6504565779315797\n",
      "Epoch 1359 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1359.pth\n",
      "Epoch 1360 train loss: 0.6571764312030977\n",
      "Epoch 1360 train accuracy: 74.96572525363312\n",
      "Epoch 1360 val loss: 0.6504193805158138\n",
      "Epoch 1360 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1360.pth\n",
      "Epoch 1361 train loss: 0.6571769402280712\n",
      "Epoch 1361 train accuracy: 75.15766383328763\n",
      "Epoch 1361 val loss: 0.6504108292099676\n",
      "Epoch 1361 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1361.pth\n",
      "Epoch 1362 train loss: 0.6572882226880705\n",
      "Epoch 1362 train accuracy: 75.10282423910063\n",
      "Epoch 1362 val loss: 0.6504012926628715\n",
      "Epoch 1362 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1362.pth\n",
      "Epoch 1363 train loss: 0.657102385862616\n",
      "Epoch 1363 train accuracy: 75.23992322456814\n",
      "Epoch 1363 val loss: 0.6504155852292713\n",
      "Epoch 1363 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1363.pth\n",
      "Epoch 1364 train loss: 0.6571627154031343\n",
      "Epoch 1364 train accuracy: 75.10282423910063\n",
      "Epoch 1364 val loss: 0.6504056508603849\n",
      "Epoch 1364 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1364.pth\n",
      "Epoch 1365 train loss: 0.6571458959461827\n",
      "Epoch 1365 train accuracy: 74.99314505072662\n",
      "Epoch 1365 val loss: 0.6503805373060075\n",
      "Epoch 1365 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1365.pth\n",
      "Epoch 1366 train loss: 0.6571058925045165\n",
      "Epoch 1366 train accuracy: 75.13024403619413\n",
      "Epoch 1366 val loss: 0.6504025124013424\n",
      "Epoch 1366 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1366.pth\n",
      "Epoch 1367 train loss: 0.6571364522372422\n",
      "Epoch 1367 train accuracy: 75.21250342747463\n",
      "Epoch 1367 val loss: 0.6503926281278071\n",
      "Epoch 1367 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1367.pth\n",
      "Epoch 1368 train loss: 0.6571437738705099\n",
      "Epoch 1368 train accuracy: 75.21250342747463\n",
      "Epoch 1368 val loss: 0.6503994733487305\n",
      "Epoch 1368 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1368.pth\n",
      "Epoch 1369 train loss: 0.6571321479257262\n",
      "Epoch 1369 train accuracy: 75.10282423910063\n",
      "Epoch 1369 val loss: 0.6503893679105922\n",
      "Epoch 1369 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1369.pth\n",
      "Epoch 1370 train loss: 0.6570971772205412\n",
      "Epoch 1370 train accuracy: 75.23992322456814\n",
      "Epoch 1370 val loss: 0.6503994925633857\n",
      "Epoch 1370 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1370.pth\n",
      "Epoch 1371 train loss: 0.6570541453792861\n",
      "Epoch 1371 train accuracy: 75.23992322456814\n",
      "Epoch 1371 val loss: 0.6503940945197093\n",
      "Epoch 1371 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1371.pth\n",
      "Epoch 1372 train loss: 0.6571169090375566\n",
      "Epoch 1372 train accuracy: 75.04798464491363\n",
      "Epoch 1372 val loss: 0.6503796215708318\n",
      "Epoch 1372 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1372.pth\n",
      "Epoch 1373 train loss: 0.6571042508932582\n",
      "Epoch 1373 train accuracy: 75.04798464491363\n",
      "Epoch 1373 val loss: 0.6503750368168479\n",
      "Epoch 1373 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1373.pth\n",
      "Epoch 1374 train loss: 0.6571019172276321\n",
      "Epoch 1374 train accuracy: 75.10282423910063\n",
      "Epoch 1374 val loss: 0.6503470443973416\n",
      "Epoch 1374 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1374.pth\n",
      "Epoch 1375 train loss: 0.6570578162607393\n",
      "Epoch 1375 train accuracy: 75.29476281875515\n",
      "Epoch 1375 val loss: 0.6503754078753685\n",
      "Epoch 1375 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1375.pth\n",
      "Epoch 1376 train loss: 0.6570855385313431\n",
      "Epoch 1376 train accuracy: 75.10282423910063\n",
      "Epoch 1376 val loss: 0.6503543762588188\n",
      "Epoch 1376 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1376.pth\n",
      "Epoch 1377 train loss: 0.6570504537473122\n",
      "Epoch 1377 train accuracy: 75.21250342747463\n",
      "Epoch 1377 val loss: 0.6503423827847368\n",
      "Epoch 1377 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1377.pth\n",
      "Epoch 1378 train loss: 0.6570301598362756\n",
      "Epoch 1378 train accuracy: 75.13024403619413\n",
      "Epoch 1378 val loss: 0.6503326713450646\n",
      "Epoch 1378 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1378.pth\n",
      "Epoch 1379 train loss: 0.6570505003461189\n",
      "Epoch 1379 train accuracy: 75.15766383328763\n",
      "Epoch 1379 val loss: 0.6503655486985257\n",
      "Epoch 1379 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1379.pth\n",
      "Epoch 1380 train loss: 0.6570528532754172\n",
      "Epoch 1380 train accuracy: 75.13024403619413\n",
      "Epoch 1380 val loss: 0.650353972849093\n",
      "Epoch 1380 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1380.pth\n",
      "Epoch 1381 train loss: 0.6570636459805986\n",
      "Epoch 1381 train accuracy: 75.13024403619413\n",
      "Epoch 1381 val loss: 0.6503235442857993\n",
      "Epoch 1381 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1381.pth\n",
      "Epoch 1382 train loss: 0.6570818251685092\n",
      "Epoch 1382 train accuracy: 75.21250342747463\n",
      "Epoch 1382 val loss: 0.6503201262339166\n",
      "Epoch 1382 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1382.pth\n",
      "Epoch 1383 train loss: 0.6570497762673256\n",
      "Epoch 1383 train accuracy: 75.18508363038113\n",
      "Epoch 1383 val loss: 0.6503254218321097\n",
      "Epoch 1383 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1383.pth\n",
      "Epoch 1384 train loss: 0.6569897262216137\n",
      "Epoch 1384 train accuracy: 75.15766383328763\n",
      "Epoch 1384 val loss: 0.6503467133366748\n",
      "Epoch 1384 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1384.pth\n",
      "Epoch 1385 train loss: 0.6570033232697792\n",
      "Epoch 1385 train accuracy: 75.18508363038113\n",
      "Epoch 1385 val loss: 0.6503470528282618\n",
      "Epoch 1385 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1385.pth\n",
      "Epoch 1386 train loss: 0.6570321711989349\n",
      "Epoch 1386 train accuracy: 75.18508363038113\n",
      "Epoch 1386 val loss: 0.6503361573344782\n",
      "Epoch 1386 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1386.pth\n",
      "Epoch 1387 train loss: 0.657091852898399\n",
      "Epoch 1387 train accuracy: 75.21250342747463\n",
      "Epoch 1387 val loss: 0.650309552977744\n",
      "Epoch 1387 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1387.pth\n",
      "Epoch 1388 train loss: 0.6569794895813653\n",
      "Epoch 1388 train accuracy: 75.15766383328763\n",
      "Epoch 1388 val loss: 0.6503037745623212\n",
      "Epoch 1388 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1388.pth\n",
      "Epoch 1389 train loss: 0.6570248068228626\n",
      "Epoch 1389 train accuracy: 75.21250342747463\n",
      "Epoch 1389 val loss: 0.650311442092061\n",
      "Epoch 1389 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1389.pth\n",
      "Epoch 1390 train loss: 0.6570072056758299\n",
      "Epoch 1390 train accuracy: 75.18508363038113\n",
      "Epoch 1390 val loss: 0.6503010146123799\n",
      "Epoch 1390 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1390.pth\n",
      "Epoch 1391 train loss: 0.6569364812029036\n",
      "Epoch 1391 train accuracy: 75.13024403619413\n",
      "Epoch 1391 val loss: 0.6502980908476993\n",
      "Epoch 1391 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1391.pth\n",
      "Epoch 1392 train loss: 0.6569998310061923\n",
      "Epoch 1392 train accuracy: 75.13024403619413\n",
      "Epoch 1392 val loss: 0.6502962284966519\n",
      "Epoch 1392 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1392.pth\n",
      "Epoch 1393 train loss: 0.6569923562438864\n",
      "Epoch 1393 train accuracy: 75.21250342747463\n",
      "Epoch 1393 val loss: 0.6502921991050243\n",
      "Epoch 1393 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1393.pth\n",
      "Epoch 1394 train loss: 0.6569941916029182\n",
      "Epoch 1394 train accuracy: 75.18508363038113\n",
      "Epoch 1394 val loss: 0.6502727787745627\n",
      "Epoch 1394 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1394.pth\n",
      "Epoch 1395 train loss: 0.6569261972122548\n",
      "Epoch 1395 train accuracy: 75.23992322456814\n",
      "Epoch 1395 val loss: 0.6502887419375935\n",
      "Epoch 1395 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1395.pth\n",
      "Epoch 1396 train loss: 0.6569731596595886\n",
      "Epoch 1396 train accuracy: 75.21250342747463\n",
      "Epoch 1396 val loss: 0.6502962930029944\n",
      "Epoch 1396 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1396.pth\n",
      "Epoch 1397 train loss: 0.6569862650674686\n",
      "Epoch 1397 train accuracy: 75.10282423910063\n",
      "Epoch 1397 val loss: 0.6502710455342343\n",
      "Epoch 1397 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1397.pth\n",
      "Epoch 1398 train loss: 0.6570424090482687\n",
      "Epoch 1398 train accuracy: 75.15766383328763\n",
      "Epoch 1398 val loss: 0.6502512006187126\n",
      "Epoch 1398 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1398.pth\n",
      "Epoch 1399 train loss: 0.6569875609129667\n",
      "Epoch 1399 train accuracy: 75.18508363038113\n",
      "Epoch 1399 val loss: 0.6502509394562558\n",
      "Epoch 1399 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1399.pth\n",
      "Epoch 1400 train loss: 0.656939602473326\n",
      "Epoch 1400 train accuracy: 75.18508363038113\n",
      "Epoch 1400 val loss: 0.6502535458850233\n",
      "Epoch 1400 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1400.pth\n",
      "Epoch 1401 train loss: 0.6569490006618333\n",
      "Epoch 1401 train accuracy: 75.15766383328763\n",
      "Epoch 1401 val loss: 0.6502468542833078\n",
      "Epoch 1401 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1401.pth\n",
      "Epoch 1402 train loss: 0.6569354396901632\n",
      "Epoch 1402 train accuracy: 75.15766383328763\n",
      "Epoch 1402 val loss: 0.6502242010871047\n",
      "Epoch 1402 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1402.pth\n",
      "Epoch 1403 train loss: 0.6569426075735113\n",
      "Epoch 1403 train accuracy: 75.13024403619413\n",
      "Epoch 1403 val loss: 0.6502300636156609\n",
      "Epoch 1403 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1403.pth\n",
      "Epoch 1404 train loss: 0.6568588002078366\n",
      "Epoch 1404 train accuracy: 75.23992322456814\n",
      "Epoch 1404 val loss: 0.6502680580474829\n",
      "Epoch 1404 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1404.pth\n",
      "Epoch 1405 train loss: 0.6569229844761523\n",
      "Epoch 1405 train accuracy: 75.07540444200713\n",
      "Epoch 1405 val loss: 0.6502267231086367\n",
      "Epoch 1405 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1405.pth\n",
      "Epoch 1406 train loss: 0.6568651630363443\n",
      "Epoch 1406 train accuracy: 75.21250342747463\n",
      "Epoch 1406 val loss: 0.650254164087145\n",
      "Epoch 1406 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1406.pth\n",
      "Epoch 1407 train loss: 0.6568901018942135\n",
      "Epoch 1407 train accuracy: 75.18508363038113\n",
      "Epoch 1407 val loss: 0.6502216705366185\n",
      "Epoch 1407 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1407.pth\n",
      "Epoch 1408 train loss: 0.6569078809075188\n",
      "Epoch 1408 train accuracy: 75.21250342747463\n",
      "Epoch 1408 val loss: 0.6502461357924499\n",
      "Epoch 1408 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1408.pth\n",
      "Epoch 1409 train loss: 0.656904329202677\n",
      "Epoch 1409 train accuracy: 75.13024403619413\n",
      "Epoch 1409 val loss: 0.6502260277537923\n",
      "Epoch 1409 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1409.pth\n",
      "Epoch 1410 train loss: 0.6569060701223319\n",
      "Epoch 1410 train accuracy: 75.15766383328763\n",
      "Epoch 1410 val loss: 0.6502153866581226\n",
      "Epoch 1410 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1410.pth\n",
      "Epoch 1411 train loss: 0.656826744803734\n",
      "Epoch 1411 train accuracy: 75.23992322456814\n",
      "Epoch 1411 val loss: 0.650232480348725\n",
      "Epoch 1411 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1411.pth\n",
      "Epoch 1412 train loss: 0.6568138226049772\n",
      "Epoch 1412 train accuracy: 75.21250342747463\n",
      "Epoch 1412 val loss: 0.6502062493052921\n",
      "Epoch 1412 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1412.pth\n",
      "Epoch 1413 train loss: 0.6568865150932157\n",
      "Epoch 1413 train accuracy: 75.10282423910063\n",
      "Epoch 1413 val loss: 0.6501911087451797\n",
      "Epoch 1413 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1413.pth\n",
      "Epoch 1414 train loss: 0.656813785923939\n",
      "Epoch 1414 train accuracy: 75.15766383328763\n",
      "Epoch 1414 val loss: 0.6502023004975758\n",
      "Epoch 1414 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1414.pth\n",
      "Epoch 1415 train loss: 0.6568670891094626\n",
      "Epoch 1415 train accuracy: 75.18508363038113\n",
      "Epoch 1415 val loss: 0.6502133954904581\n",
      "Epoch 1415 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1415.pth\n",
      "Epoch 1416 train loss: 0.6567786842780677\n",
      "Epoch 1416 train accuracy: 75.10282423910063\n",
      "Epoch 1416 val loss: 0.6501813163294604\n",
      "Epoch 1416 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1416.pth\n",
      "Epoch 1417 train loss: 0.6568581450469139\n",
      "Epoch 1417 train accuracy: 75.26734302166165\n",
      "Epoch 1417 val loss: 0.6501910822760117\n",
      "Epoch 1417 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1417.pth\n",
      "Epoch 1418 train loss: 0.6567925299240047\n",
      "Epoch 1418 train accuracy: 75.15766383328763\n",
      "Epoch 1418 val loss: 0.6501885401575189\n",
      "Epoch 1418 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1418.pth\n",
      "Epoch 1419 train loss: 0.656820102104623\n",
      "Epoch 1419 train accuracy: 75.15766383328763\n",
      "Epoch 1419 val loss: 0.6501543855196551\n",
      "Epoch 1419 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1419.pth\n",
      "Epoch 1420 train loss: 0.6568127948660076\n",
      "Epoch 1420 train accuracy: 75.21250342747463\n",
      "Epoch 1420 val loss: 0.6501571646842518\n",
      "Epoch 1420 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1420.pth\n",
      "Epoch 1421 train loss: 0.6569352216299689\n",
      "Epoch 1421 train accuracy: 75.26734302166165\n",
      "Epoch 1421 val loss: 0.6501495938159918\n",
      "Epoch 1421 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1421.pth\n",
      "Epoch 1422 train loss: 0.6568405633759603\n",
      "Epoch 1422 train accuracy: 75.07540444200713\n",
      "Epoch 1422 val loss: 0.6501301292722163\n",
      "Epoch 1422 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1422.pth\n",
      "Epoch 1423 train loss: 0.6568250752527985\n",
      "Epoch 1423 train accuracy: 75.18508363038113\n",
      "Epoch 1423 val loss: 0.6501361151274881\n",
      "Epoch 1423 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1423.pth\n",
      "Epoch 1424 train loss: 0.6568418433399577\n",
      "Epoch 1424 train accuracy: 75.23992322456814\n",
      "Epoch 1424 val loss: 0.6501264395682436\n",
      "Epoch 1424 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1424.pth\n",
      "Epoch 1425 train loss: 0.6568160719450629\n",
      "Epoch 1425 train accuracy: 75.26734302166165\n",
      "Epoch 1425 val loss: 0.6501382625612774\n",
      "Epoch 1425 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1425.pth\n",
      "Epoch 1426 train loss: 0.6568156113161853\n",
      "Epoch 1426 train accuracy: 75.13024403619413\n",
      "Epoch 1426 val loss: 0.6501370287059169\n",
      "Epoch 1426 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1426.pth\n",
      "Epoch 1427 train loss: 0.656877529333558\n",
      "Epoch 1427 train accuracy: 75.18508363038113\n",
      "Epoch 1427 val loss: 0.6501237582415342\n",
      "Epoch 1427 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1427.pth\n",
      "Epoch 1428 train loss: 0.6567812492057943\n",
      "Epoch 1428 train accuracy: 75.26734302166165\n",
      "Epoch 1428 val loss: 0.6501262805571681\n",
      "Epoch 1428 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1428.pth\n",
      "Epoch 1429 train loss: 0.6567834109198629\n",
      "Epoch 1429 train accuracy: 75.18508363038113\n",
      "Epoch 1429 val loss: 0.6501143099249977\n",
      "Epoch 1429 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1429.pth\n",
      "Epoch 1430 train loss: 0.6567877743785319\n",
      "Epoch 1430 train accuracy: 75.21250342747463\n",
      "Epoch 1430 val loss: 0.6501117683947086\n",
      "Epoch 1430 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1430.pth\n",
      "Epoch 1431 train loss: 0.6567544205146923\n",
      "Epoch 1431 train accuracy: 75.21250342747463\n",
      "Epoch 1431 val loss: 0.650123388653523\n",
      "Epoch 1431 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1431.pth\n",
      "Epoch 1432 train loss: 0.6567587470472381\n",
      "Epoch 1432 train accuracy: 75.21250342747463\n",
      "Epoch 1432 val loss: 0.6501180549201212\n",
      "Epoch 1432 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1432.pth\n",
      "Epoch 1433 train loss: 0.6567797534363834\n",
      "Epoch 1433 train accuracy: 75.26734302166165\n",
      "Epoch 1433 val loss: 0.6501168436125705\n",
      "Epoch 1433 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1433.pth\n",
      "Epoch 1434 train loss: 0.656766613912687\n",
      "Epoch 1434 train accuracy: 75.23992322456814\n",
      "Epoch 1434 val loss: 0.6501157612196709\n",
      "Epoch 1434 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1434.pth\n",
      "Epoch 1435 train loss: 0.6567811625437778\n",
      "Epoch 1435 train accuracy: 75.21250342747463\n",
      "Epoch 1435 val loss: 0.650101013481617\n",
      "Epoch 1435 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1435.pth\n",
      "Epoch 1436 train loss: 0.6567728552117682\n",
      "Epoch 1436 train accuracy: 75.21250342747463\n",
      "Epoch 1436 val loss: 0.6500737932755759\n",
      "Epoch 1436 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1436.pth\n",
      "Epoch 1437 train loss: 0.6567598275611537\n",
      "Epoch 1437 train accuracy: 75.23992322456814\n",
      "Epoch 1437 val loss: 0.6500892842090443\n",
      "Epoch 1437 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1437.pth\n",
      "Epoch 1438 train loss: 0.6567461288354376\n",
      "Epoch 1438 train accuracy: 75.23992322456814\n",
      "Epoch 1438 val loss: 0.6500723851158431\n",
      "Epoch 1438 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1438.pth\n",
      "Epoch 1439 train loss: 0.6567027707698575\n",
      "Epoch 1439 train accuracy: 75.21250342747463\n",
      "Epoch 1439 val loss: 0.6500680859347707\n",
      "Epoch 1439 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1439.pth\n",
      "Epoch 1440 train loss: 0.6567456230455846\n",
      "Epoch 1440 train accuracy: 75.23992322456814\n",
      "Epoch 1440 val loss: 0.6500744037330151\n",
      "Epoch 1440 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1440.pth\n",
      "Epoch 1441 train loss: 0.6566465450123998\n",
      "Epoch 1441 train accuracy: 75.26734302166165\n",
      "Epoch 1441 val loss: 0.6500775917972389\n",
      "Epoch 1441 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1441.pth\n",
      "Epoch 1442 train loss: 0.6567301924029986\n",
      "Epoch 1442 train accuracy: 75.29476281875515\n",
      "Epoch 1442 val loss: 0.6500702060170864\n",
      "Epoch 1442 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1442.pth\n",
      "Epoch 1443 train loss: 0.6567197250888536\n",
      "Epoch 1443 train accuracy: 75.18508363038113\n",
      "Epoch 1443 val loss: 0.6500548255678854\n",
      "Epoch 1443 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1443.pth\n",
      "Epoch 1444 train loss: 0.6566922986193707\n",
      "Epoch 1444 train accuracy: 75.21250342747463\n",
      "Epoch 1444 val loss: 0.6500519779755881\n",
      "Epoch 1444 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1444.pth\n",
      "Epoch 1445 train loss: 0.6567047257956705\n",
      "Epoch 1445 train accuracy: 75.23992322456814\n",
      "Epoch 1445 val loss: 0.6500375808069581\n",
      "Epoch 1445 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1445.pth\n",
      "Epoch 1446 train loss: 0.6567142829298973\n",
      "Epoch 1446 train accuracy: 75.23992322456814\n",
      "Epoch 1446 val loss: 0.6500464321947411\n",
      "Epoch 1446 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1446.pth\n",
      "Epoch 1447 train loss: 0.6566473791669858\n",
      "Epoch 1447 train accuracy: 75.26734302166165\n",
      "Epoch 1447 val loss: 0.6500433747117457\n",
      "Epoch 1447 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1447.pth\n",
      "Epoch 1448 train loss: 0.6566968144554841\n",
      "Epoch 1448 train accuracy: 75.29476281875515\n",
      "Epoch 1448 val loss: 0.6500475768392023\n",
      "Epoch 1448 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1448.pth\n",
      "Epoch 1449 train loss: 0.6566506947570464\n",
      "Epoch 1449 train accuracy: 75.13024403619413\n",
      "Epoch 1449 val loss: 0.6500312059529518\n",
      "Epoch 1449 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1449.pth\n",
      "Epoch 1450 train loss: 0.6566850980907156\n",
      "Epoch 1450 train accuracy: 75.21250342747463\n",
      "Epoch 1450 val loss: 0.6500285089408097\n",
      "Epoch 1450 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1450.pth\n",
      "Epoch 1451 train loss: 0.6566644079264319\n",
      "Epoch 1451 train accuracy: 75.26734302166165\n",
      "Epoch 1451 val loss: 0.6500174422797403\n",
      "Epoch 1451 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1451.pth\n",
      "Epoch 1452 train loss: 0.6566209542777455\n",
      "Epoch 1452 train accuracy: 75.21250342747463\n",
      "Epoch 1452 val loss: 0.6500280077912306\n",
      "Epoch 1452 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1452.pth\n",
      "Epoch 1453 train loss: 0.6567134526803305\n",
      "Epoch 1453 train accuracy: 75.32218261584865\n",
      "Epoch 1453 val loss: 0.6500293073293409\n",
      "Epoch 1453 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1453.pth\n",
      "Epoch 1454 train loss: 0.6566709945991374\n",
      "Epoch 1454 train accuracy: 75.29476281875515\n",
      "Epoch 1454 val loss: 0.6500455761622441\n",
      "Epoch 1454 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1454.pth\n",
      "Epoch 1455 train loss: 0.6566222633251495\n",
      "Epoch 1455 train accuracy: 75.18508363038113\n",
      "Epoch 1455 val loss: 0.6500311804641234\n",
      "Epoch 1455 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1455.pth\n",
      "Epoch 1456 train loss: 0.656677495769895\n",
      "Epoch 1456 train accuracy: 75.29476281875515\n",
      "Epoch 1456 val loss: 0.6500214273600202\n",
      "Epoch 1456 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1456.pth\n",
      "Epoch 1457 train loss: 0.6567104884276265\n",
      "Epoch 1457 train accuracy: 75.29476281875515\n",
      "Epoch 1457 val loss: 0.6499986991678414\n",
      "Epoch 1457 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1457.pth\n",
      "Epoch 1458 train loss: 0.6566432459900776\n",
      "Epoch 1458 train accuracy: 75.23992322456814\n",
      "Epoch 1458 val loss: 0.6499906698928067\n",
      "Epoch 1458 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1458.pth\n",
      "Epoch 1459 train loss: 0.6566483060780325\n",
      "Epoch 1459 train accuracy: 75.23992322456814\n",
      "Epoch 1459 val loss: 0.6499920540342206\n",
      "Epoch 1459 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1459.pth\n",
      "Epoch 1460 train loss: 0.6566164859554224\n",
      "Epoch 1460 train accuracy: 75.23992322456814\n",
      "Epoch 1460 val loss: 0.6499762122372263\n",
      "Epoch 1460 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1460.pth\n",
      "Epoch 1461 train loss: 0.6567623002225893\n",
      "Epoch 1461 train accuracy: 75.29476281875515\n",
      "Epoch 1461 val loss: 0.6499804204427883\n",
      "Epoch 1461 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1461.pth\n",
      "Epoch 1462 train loss: 0.6565742845271241\n",
      "Epoch 1462 train accuracy: 75.21250342747463\n",
      "Epoch 1462 val loss: 0.6500139246253591\n",
      "Epoch 1462 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1462.pth\n",
      "Epoch 1463 train loss: 0.6566212998801156\n",
      "Epoch 1463 train accuracy: 75.26734302166165\n",
      "Epoch 1463 val loss: 0.6499983141884992\n",
      "Epoch 1463 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1463.pth\n",
      "Epoch 1464 train loss: 0.6567101879535537\n",
      "Epoch 1464 train accuracy: 75.18508363038113\n",
      "Epoch 1464 val loss: 0.6499763799733237\n",
      "Epoch 1464 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1464.pth\n",
      "Epoch 1465 train loss: 0.6566247110042656\n",
      "Epoch 1465 train accuracy: 75.32218261584865\n",
      "Epoch 1465 val loss: 0.64998722125433\n",
      "Epoch 1465 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1465.pth\n",
      "Epoch 1466 train loss: 0.6565705485838024\n",
      "Epoch 1466 train accuracy: 75.26734302166165\n",
      "Epoch 1466 val loss: 0.6499910822236225\n",
      "Epoch 1466 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1466.pth\n",
      "Epoch 1467 train loss: 0.6566048798461755\n",
      "Epoch 1467 train accuracy: 75.26734302166165\n",
      "Epoch 1467 val loss: 0.6499858039774393\n",
      "Epoch 1467 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1467.pth\n",
      "Epoch 1468 train loss: 0.656592843858035\n",
      "Epoch 1468 train accuracy: 75.18508363038113\n",
      "Epoch 1468 val loss: 0.6499810642317722\n",
      "Epoch 1468 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1468.pth\n",
      "Epoch 1469 train loss: 0.6565837980362407\n",
      "Epoch 1469 train accuracy: 75.34960241294215\n",
      "Epoch 1469 val loss: 0.6499621762256873\n",
      "Epoch 1469 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1469.pth\n",
      "Epoch 1470 train loss: 0.6565863384554783\n",
      "Epoch 1470 train accuracy: 75.32218261584865\n",
      "Epoch 1470 val loss: 0.649978367513732\n",
      "Epoch 1470 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1470.pth\n",
      "Epoch 1471 train loss: 0.6565773006397904\n",
      "Epoch 1471 train accuracy: 75.23992322456814\n",
      "Epoch 1471 val loss: 0.6499700485973766\n",
      "Epoch 1471 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1471.pth\n",
      "Epoch 1472 train loss: 0.656555346752468\n",
      "Epoch 1472 train accuracy: 75.21250342747463\n",
      "Epoch 1472 val loss: 0.6499320532342321\n",
      "Epoch 1472 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1472.pth\n",
      "Epoch 1473 train loss: 0.6565697101320613\n",
      "Epoch 1473 train accuracy: 75.29476281875515\n",
      "Epoch 1473 val loss: 0.6499547902984839\n",
      "Epoch 1473 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1473.pth\n",
      "Epoch 1474 train loss: 0.6565653337329104\n",
      "Epoch 1474 train accuracy: 75.29476281875515\n",
      "Epoch 1474 val loss: 0.6499378620401809\n",
      "Epoch 1474 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1474.pth\n",
      "Epoch 1475 train loss: 0.6566153705250799\n",
      "Epoch 1475 train accuracy: 75.26734302166165\n",
      "Epoch 1475 val loss: 0.6499481718791159\n",
      "Epoch 1475 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1475.pth\n",
      "Epoch 1476 train loss: 0.6565139057735602\n",
      "Epoch 1476 train accuracy: 75.29476281875515\n",
      "Epoch 1476 val loss: 0.6499587788589691\n",
      "Epoch 1476 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1476.pth\n",
      "Epoch 1477 train loss: 0.6565517780550739\n",
      "Epoch 1477 train accuracy: 75.29476281875515\n",
      "Epoch 1477 val loss: 0.6499469896876499\n",
      "Epoch 1477 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1477.pth\n",
      "Epoch 1478 train loss: 0.6565478207347425\n",
      "Epoch 1478 train accuracy: 75.29476281875515\n",
      "Epoch 1478 val loss: 0.6499406756146958\n",
      "Epoch 1478 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1478.pth\n",
      "Epoch 1479 train loss: 0.6565413942331808\n",
      "Epoch 1479 train accuracy: 75.29476281875515\n",
      "Epoch 1479 val loss: 0.6499309405488404\n",
      "Epoch 1479 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1479.pth\n",
      "Epoch 1480 train loss: 0.6565716216634763\n",
      "Epoch 1480 train accuracy: 75.26734302166165\n",
      "Epoch 1480 val loss: 0.649940269950189\n",
      "Epoch 1480 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1480.pth\n",
      "Epoch 1481 train loss: 0.6565242848571455\n",
      "Epoch 1481 train accuracy: 75.29476281875515\n",
      "Epoch 1481 val loss: 0.649952009614361\n",
      "Epoch 1481 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1481.pth\n",
      "Epoch 1482 train loss: 0.6565312203673417\n",
      "Epoch 1482 train accuracy: 75.15766383328763\n",
      "Epoch 1482 val loss: 0.6499245322652554\n",
      "Epoch 1482 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1482.pth\n",
      "Epoch 1483 train loss: 0.6565414470408046\n",
      "Epoch 1483 train accuracy: 75.21250342747463\n",
      "Epoch 1483 val loss: 0.6498914364921419\n",
      "Epoch 1483 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1483.pth\n",
      "Epoch 1484 train loss: 0.6565523932834989\n",
      "Epoch 1484 train accuracy: 75.29476281875515\n",
      "Epoch 1484 val loss: 0.6498869097742596\n",
      "Epoch 1484 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1484.pth\n",
      "Epoch 1485 train loss: 0.6565127068509659\n",
      "Epoch 1485 train accuracy: 75.32218261584865\n",
      "Epoch 1485 val loss: 0.6498896080608431\n",
      "Epoch 1485 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1485.pth\n",
      "Epoch 1486 train loss: 0.6564633637797415\n",
      "Epoch 1486 train accuracy: 75.29476281875515\n",
      "Epoch 1486 val loss: 0.6499015582039168\n",
      "Epoch 1486 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1486.pth\n",
      "Epoch 1487 train loss: 0.6564602014330918\n",
      "Epoch 1487 train accuracy: 75.29476281875515\n",
      "Epoch 1487 val loss: 0.6499148870965368\n",
      "Epoch 1487 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1487.pth\n",
      "Epoch 1488 train loss: 0.6564981528933633\n",
      "Epoch 1488 train accuracy: 75.21250342747463\n",
      "Epoch 1488 val loss: 0.649890234399783\n",
      "Epoch 1488 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1488.pth\n",
      "Epoch 1489 train loss: 0.6564428933095514\n",
      "Epoch 1489 train accuracy: 75.23992322456814\n",
      "Epoch 1489 val loss: 0.6499038143573623\n",
      "Epoch 1489 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1489.pth\n",
      "Epoch 1490 train loss: 0.6565680474761808\n",
      "Epoch 1490 train accuracy: 75.26734302166165\n",
      "Epoch 1490 val loss: 0.6498936095127934\n",
      "Epoch 1490 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1490.pth\n",
      "Epoch 1491 train loss: 0.656427872841034\n",
      "Epoch 1491 train accuracy: 75.29476281875515\n",
      "Epoch 1491 val loss: 0.6498923129157016\n",
      "Epoch 1491 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1491.pth\n",
      "Epoch 1492 train loss: 0.6564217192823427\n",
      "Epoch 1492 train accuracy: 75.23992322456814\n",
      "Epoch 1492 val loss: 0.6498985746385235\n",
      "Epoch 1492 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1492.pth\n",
      "Epoch 1493 train loss: 0.6563674002689751\n",
      "Epoch 1493 train accuracy: 75.23992322456814\n",
      "Epoch 1493 val loss: 0.6498777942830011\n",
      "Epoch 1493 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1493.pth\n",
      "Epoch 1494 train loss: 0.6564632493741157\n",
      "Epoch 1494 train accuracy: 75.29476281875515\n",
      "Epoch 1494 val loss: 0.6498536205801525\n",
      "Epoch 1494 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1494.pth\n",
      "Epoch 1495 train loss: 0.656489013187718\n",
      "Epoch 1495 train accuracy: 75.32218261584865\n",
      "Epoch 1495 val loss: 0.6498591624396411\n",
      "Epoch 1495 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1495.pth\n",
      "Epoch 1496 train loss: 0.6564193788360346\n",
      "Epoch 1496 train accuracy: 75.32218261584865\n",
      "Epoch 1496 val loss: 0.6498445746930022\n",
      "Epoch 1496 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1496.pth\n",
      "Epoch 1497 train loss: 0.6564399186652481\n",
      "Epoch 1497 train accuracy: 75.29476281875515\n",
      "Epoch 1497 val loss: 0.649858122985614\n",
      "Epoch 1497 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1497.pth\n",
      "Epoch 1498 train loss: 0.6564551281105531\n",
      "Epoch 1498 train accuracy: 75.29476281875515\n",
      "Epoch 1498 val loss: 0.6498575416442595\n",
      "Epoch 1498 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1498.pth\n",
      "Epoch 1499 train loss: 0.6563982532866168\n",
      "Epoch 1499 train accuracy: 75.29476281875515\n",
      "Epoch 1499 val loss: 0.6498389451911575\n",
      "Epoch 1499 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1499.pth\n",
      "Epoch 1500 train loss: 0.6564007331535482\n",
      "Epoch 1500 train accuracy: 75.26734302166165\n",
      "Epoch 1500 val loss: 0.6498491635644122\n",
      "Epoch 1500 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1500.pth\n",
      "Epoch 1501 train loss: 0.6564183590704935\n",
      "Epoch 1501 train accuracy: 75.21250342747463\n",
      "Epoch 1501 val loss: 0.6498336508674057\n",
      "Epoch 1501 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1501.pth\n",
      "Epoch 1502 train loss: 0.6564251925600203\n",
      "Epoch 1502 train accuracy: 75.21250342747463\n",
      "Epoch 1502 val loss: 0.6498009075263613\n",
      "Epoch 1502 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1502.pth\n",
      "Epoch 1503 train loss: 0.6564802657812834\n",
      "Epoch 1503 train accuracy: 75.26734302166165\n",
      "Epoch 1503 val loss: 0.649795360471073\n",
      "Epoch 1503 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1503.pth\n",
      "Epoch 1504 train loss: 0.6563752005693683\n",
      "Epoch 1504 train accuracy: 75.34960241294215\n",
      "Epoch 1504 val loss: 0.64980349836773\n",
      "Epoch 1504 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1504.pth\n",
      "Epoch 1505 train loss: 0.6564063941569704\n",
      "Epoch 1505 train accuracy: 75.37702221003565\n",
      "Epoch 1505 val loss: 0.6498088848433996\n",
      "Epoch 1505 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1505.pth\n",
      "Epoch 1506 train loss: 0.6564048354170824\n",
      "Epoch 1506 train accuracy: 75.26734302166165\n",
      "Epoch 1506 val loss: 0.6498201662968648\n",
      "Epoch 1506 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1506.pth\n",
      "Epoch 1507 train loss: 0.6563913494740662\n",
      "Epoch 1507 train accuracy: 75.29476281875515\n",
      "Epoch 1507 val loss: 0.649810957477281\n",
      "Epoch 1507 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1507.pth\n",
      "Epoch 1508 train loss: 0.6564033947100765\n",
      "Epoch 1508 train accuracy: 75.29476281875515\n",
      "Epoch 1508 val loss: 0.6498017013072968\n",
      "Epoch 1508 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1508.pth\n",
      "Epoch 1509 train loss: 0.6564264411858299\n",
      "Epoch 1509 train accuracy: 75.23992322456814\n",
      "Epoch 1509 val loss: 0.6497899819361536\n",
      "Epoch 1509 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1509.pth\n",
      "Epoch 1510 train loss: 0.656398086596215\n",
      "Epoch 1510 train accuracy: 75.29476281875515\n",
      "Epoch 1510 val loss: 0.649788010669382\n",
      "Epoch 1510 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1510.pth\n",
      "Epoch 1511 train loss: 0.6563904667436554\n",
      "Epoch 1511 train accuracy: 75.23992322456814\n",
      "Epoch 1511 val loss: 0.649778165119259\n",
      "Epoch 1511 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1511.pth\n",
      "Epoch 1512 train loss: 0.6563549259383428\n",
      "Epoch 1512 train accuracy: 75.26734302166165\n",
      "Epoch 1512 val loss: 0.6497852946386525\n",
      "Epoch 1512 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1512.pth\n",
      "Epoch 1513 train loss: 0.6563773980004746\n",
      "Epoch 1513 train accuracy: 75.26734302166165\n",
      "Epoch 1513 val loss: 0.649764227729879\n",
      "Epoch 1513 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1513.pth\n",
      "Epoch 1514 train loss: 0.6563733867778067\n",
      "Epoch 1514 train accuracy: 75.26734302166165\n",
      "Epoch 1514 val loss: 0.649756017680231\n",
      "Epoch 1514 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1514.pth\n",
      "Epoch 1515 train loss: 0.6563409842027906\n",
      "Epoch 1515 train accuracy: 75.32218261584865\n",
      "Epoch 1515 val loss: 0.6497442285089117\n",
      "Epoch 1515 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1515.pth\n",
      "Epoch 1516 train loss: 0.6563654915151889\n",
      "Epoch 1516 train accuracy: 75.26734302166165\n",
      "Epoch 1516 val loss: 0.6497306599232712\n",
      "Epoch 1516 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1516.pth\n",
      "Epoch 1517 train loss: 0.6563591837817639\n",
      "Epoch 1517 train accuracy: 75.29476281875515\n",
      "Epoch 1517 val loss: 0.6497251766880876\n",
      "Epoch 1517 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1517.pth\n",
      "Epoch 1518 train loss: 0.656361881088008\n",
      "Epoch 1518 train accuracy: 75.32218261584865\n",
      "Epoch 1518 val loss: 0.6497401304935154\n",
      "Epoch 1518 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1518.pth\n",
      "Epoch 1519 train loss: 0.6563534334857475\n",
      "Epoch 1519 train accuracy: 75.34960241294215\n",
      "Epoch 1519 val loss: 0.649759717481701\n",
      "Epoch 1519 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1519.pth\n",
      "Epoch 1520 train loss: 0.6563201925406853\n",
      "Epoch 1520 train accuracy: 75.32218261584865\n",
      "Epoch 1520 val loss: 0.6497575257365641\n",
      "Epoch 1520 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1520.pth\n",
      "Epoch 1521 train loss: 0.6563434909637037\n",
      "Epoch 1521 train accuracy: 75.29476281875515\n",
      "Epoch 1521 val loss: 0.6497572822202193\n",
      "Epoch 1521 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1521.pth\n",
      "Epoch 1522 train loss: 0.6563404642306921\n",
      "Epoch 1522 train accuracy: 75.21250342747463\n",
      "Epoch 1522 val loss: 0.6497344123689752\n",
      "Epoch 1522 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1522.pth\n",
      "Epoch 1523 train loss: 0.6562804916318048\n",
      "Epoch 1523 train accuracy: 75.23992322456814\n",
      "Epoch 1523 val loss: 0.6497424621821234\n",
      "Epoch 1523 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1523.pth\n",
      "Epoch 1524 train loss: 0.6563163591516122\n",
      "Epoch 1524 train accuracy: 75.26734302166165\n",
      "Epoch 1524 val loss: 0.6497581238417249\n",
      "Epoch 1524 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1524.pth\n",
      "Epoch 1525 train loss: 0.6562939173166167\n",
      "Epoch 1525 train accuracy: 75.29476281875515\n",
      "Epoch 1525 val loss: 0.649744759656881\n",
      "Epoch 1525 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1525.pth\n",
      "Epoch 1526 train loss: 0.6562963501599274\n",
      "Epoch 1526 train accuracy: 75.26734302166165\n",
      "Epoch 1526 val loss: 0.6497233600208634\n",
      "Epoch 1526 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1526.pth\n",
      "Epoch 1527 train loss: 0.6563392825457349\n",
      "Epoch 1527 train accuracy: 75.32218261584865\n",
      "Epoch 1527 val loss: 0.6497146162743631\n",
      "Epoch 1527 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1527.pth\n",
      "Epoch 1528 train loss: 0.6563081268809343\n",
      "Epoch 1528 train accuracy: 75.26734302166165\n",
      "Epoch 1528 val loss: 0.6497103747372565\n",
      "Epoch 1528 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1528.pth\n",
      "Epoch 1529 train loss: 0.6563094709264604\n",
      "Epoch 1529 train accuracy: 75.26734302166165\n",
      "Epoch 1529 val loss: 0.6497038717528707\n",
      "Epoch 1529 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1529.pth\n",
      "Epoch 1530 train loss: 0.6563079762027452\n",
      "Epoch 1530 train accuracy: 75.29476281875515\n",
      "Epoch 1530 val loss: 0.6496979053083219\n",
      "Epoch 1530 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1530.pth\n",
      "Epoch 1531 train loss: 0.6562970243067595\n",
      "Epoch 1531 train accuracy: 75.26734302166165\n",
      "Epoch 1531 val loss: 0.649704147032217\n",
      "Epoch 1531 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1531.pth\n",
      "Epoch 1532 train loss: 0.6562722708964557\n",
      "Epoch 1532 train accuracy: 75.26734302166165\n",
      "Epoch 1532 val loss: 0.6496985562537846\n",
      "Epoch 1532 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1532.pth\n",
      "Epoch 1533 train loss: 0.6562864914569154\n",
      "Epoch 1533 train accuracy: 75.21250342747463\n",
      "Epoch 1533 val loss: 0.6496931921298567\n",
      "Epoch 1533 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1533.pth\n",
      "Epoch 1534 train loss: 0.6562839875716651\n",
      "Epoch 1534 train accuracy: 75.32218261584865\n",
      "Epoch 1534 val loss: 0.6496985910558387\n",
      "Epoch 1534 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1534.pth\n",
      "Epoch 1535 train loss: 0.6562782954751399\n",
      "Epoch 1535 train accuracy: 75.26734302166165\n",
      "Epoch 1535 val loss: 0.6497113190003132\n",
      "Epoch 1535 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1535.pth\n",
      "Epoch 1536 train loss: 0.6562708264968374\n",
      "Epoch 1536 train accuracy: 75.26734302166165\n",
      "Epoch 1536 val loss: 0.649713252474995\n",
      "Epoch 1536 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1536.pth\n",
      "Epoch 1537 train loss: 0.6562647009758573\n",
      "Epoch 1537 train accuracy: 75.29476281875515\n",
      "Epoch 1537 val loss: 0.6497055051946327\n",
      "Epoch 1537 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1537.pth\n",
      "Epoch 1538 train loss: 0.6562628324486708\n",
      "Epoch 1538 train accuracy: 75.23992322456814\n",
      "Epoch 1538 val loss: 0.6497016161876289\n",
      "Epoch 1538 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1538.pth\n",
      "Epoch 1539 train loss: 0.6563377725450616\n",
      "Epoch 1539 train accuracy: 75.29476281875515\n",
      "Epoch 1539 val loss: 0.6497042362431162\n",
      "Epoch 1539 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1539.pth\n",
      "Epoch 1540 train loss: 0.6562547646462917\n",
      "Epoch 1540 train accuracy: 75.26734302166165\n",
      "Epoch 1540 val loss: 0.6497209343667093\n",
      "Epoch 1540 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1540.pth\n",
      "Epoch 1541 train loss: 0.6562310284036293\n",
      "Epoch 1541 train accuracy: 75.23992322456814\n",
      "Epoch 1541 val loss: 0.649699663155173\n",
      "Epoch 1541 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1541.pth\n",
      "Epoch 1542 train loss: 0.6562425127547038\n",
      "Epoch 1542 train accuracy: 75.32218261584865\n",
      "Epoch 1542 val loss: 0.6497084303317886\n",
      "Epoch 1542 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1542.pth\n",
      "Epoch 1543 train loss: 0.6563163995089238\n",
      "Epoch 1543 train accuracy: 75.23992322456814\n",
      "Epoch 1543 val loss: 0.6497053495167118\n",
      "Epoch 1543 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1543.pth\n",
      "Epoch 1544 train loss: 0.6562339139187283\n",
      "Epoch 1544 train accuracy: 75.04798464491363\n",
      "Epoch 1544 val loss: 0.6496819180289382\n",
      "Epoch 1544 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1544.pth\n",
      "Epoch 1545 train loss: 0.6562315770343208\n",
      "Epoch 1545 train accuracy: 75.29476281875515\n",
      "Epoch 1545 val loss: 0.6496808081865311\n",
      "Epoch 1545 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1545.pth\n",
      "Epoch 1546 train loss: 0.6562277288094425\n",
      "Epoch 1546 train accuracy: 75.18508363038113\n",
      "Epoch 1546 val loss: 0.6497004016449577\n",
      "Epoch 1546 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1546.pth\n",
      "Epoch 1547 train loss: 0.6562261984013674\n",
      "Epoch 1547 train accuracy: 75.29476281875515\n",
      "Epoch 1547 val loss: 0.6496980853966976\n",
      "Epoch 1547 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1547.pth\n",
      "Epoch 1548 train loss: 0.6562104210453598\n",
      "Epoch 1548 train accuracy: 75.29476281875515\n",
      "Epoch 1548 val loss: 0.6497193955277142\n",
      "Epoch 1548 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1548.pth\n",
      "Epoch 1549 train loss: 0.6561587369559627\n",
      "Epoch 1549 train accuracy: 75.21250342747463\n",
      "Epoch 1549 val loss: 0.6497048464064535\n",
      "Epoch 1549 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1549.pth\n",
      "Epoch 1550 train loss: 0.6562038191937303\n",
      "Epoch 1550 train accuracy: 75.21250342747463\n",
      "Epoch 1550 val loss: 0.6496846138646728\n",
      "Epoch 1550 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1550.pth\n",
      "Epoch 1551 train loss: 0.6561647226151667\n",
      "Epoch 1551 train accuracy: 75.21250342747463\n",
      "Epoch 1551 val loss: 0.6496800533250758\n",
      "Epoch 1551 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1551.pth\n",
      "Epoch 1552 train loss: 0.656257877322404\n",
      "Epoch 1552 train accuracy: 75.21250342747463\n",
      "Epoch 1552 val loss: 0.64965325956674\n",
      "Epoch 1552 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1552.pth\n",
      "Epoch 1553 train loss: 0.6561709330662301\n",
      "Epoch 1553 train accuracy: 75.18508363038113\n",
      "Epoch 1553 val loss: 0.6496496641714322\n",
      "Epoch 1553 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1553.pth\n",
      "Epoch 1554 train loss: 0.6561931310254231\n",
      "Epoch 1554 train accuracy: 75.29476281875515\n",
      "Epoch 1554 val loss: 0.6496593992372877\n",
      "Epoch 1554 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1554.pth\n",
      "Epoch 1555 train loss: 0.6561833299827158\n",
      "Epoch 1555 train accuracy: 75.21250342747463\n",
      "Epoch 1555 val loss: 0.6496563323430324\n",
      "Epoch 1555 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1555.pth\n",
      "Epoch 1556 train loss: 0.6561723104759789\n",
      "Epoch 1556 train accuracy: 75.23992322456814\n",
      "Epoch 1556 val loss: 0.6496360326479924\n",
      "Epoch 1556 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1556.pth\n",
      "Epoch 1557 train loss: 0.6561792984016632\n",
      "Epoch 1557 train accuracy: 75.18508363038113\n",
      "Epoch 1557 val loss: 0.6496376364834999\n",
      "Epoch 1557 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1557.pth\n",
      "Epoch 1558 train loss: 0.6561666838497969\n",
      "Epoch 1558 train accuracy: 75.21250342747463\n",
      "Epoch 1558 val loss: 0.6496478832866016\n",
      "Epoch 1558 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1558.pth\n",
      "Epoch 1559 train loss: 0.6561483657477718\n",
      "Epoch 1559 train accuracy: 75.23992322456814\n",
      "Epoch 1559 val loss: 0.6496390004299188\n",
      "Epoch 1559 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1559.pth\n",
      "Epoch 1560 train loss: 0.6561606743683418\n",
      "Epoch 1560 train accuracy: 75.23992322456814\n",
      "Epoch 1560 val loss: 0.6496523326556933\n",
      "Epoch 1560 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1560.pth\n",
      "Epoch 1561 train loss: 0.6561077201183427\n",
      "Epoch 1561 train accuracy: 75.21250342747463\n",
      "Epoch 1561 val loss: 0.6496591231736698\n",
      "Epoch 1561 val accuracy: 76.64473684210526\n",
      "Saved model to .\\test_modelsv2/MLP_1561.pth\n",
      "Epoch 1562 train loss: 0.656152229298625\n",
      "Epoch 1562 train accuracy: 75.18508363038113\n",
      "Epoch 1562 val loss: 0.6496327978215719\n",
      "Epoch 1562 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1562.pth\n",
      "Epoch 1563 train loss: 0.6561192067241982\n",
      "Epoch 1563 train accuracy: 75.15766383328763\n",
      "Epoch 1563 val loss: 0.649610201387029\n",
      "Epoch 1563 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1563.pth\n",
      "Epoch 1564 train loss: 0.6561629166009656\n",
      "Epoch 1564 train accuracy: 75.29476281875515\n",
      "Epoch 1564 val loss: 0.6496326905724249\n",
      "Epoch 1564 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1564.pth\n",
      "Epoch 1565 train loss: 0.6561305910479605\n",
      "Epoch 1565 train accuracy: 75.18508363038113\n",
      "Epoch 1565 val loss: 0.649633999619829\n",
      "Epoch 1565 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1565.pth\n",
      "Epoch 1566 train loss: 0.6561336641428632\n",
      "Epoch 1566 train accuracy: 75.23992322456814\n",
      "Epoch 1566 val loss: 0.6496245730668306\n",
      "Epoch 1566 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1566.pth\n",
      "Epoch 1567 train loss: 0.6561884812422489\n",
      "Epoch 1567 train accuracy: 75.21250342747463\n",
      "Epoch 1567 val loss: 0.6495960818505601\n",
      "Epoch 1567 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1567.pth\n",
      "Epoch 1568 train loss: 0.6560681111979902\n",
      "Epoch 1568 train accuracy: 75.18508363038113\n",
      "Epoch 1568 val loss: 0.6496044477741969\n",
      "Epoch 1568 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1568.pth\n",
      "Epoch 1569 train loss: 0.65607798599491\n",
      "Epoch 1569 train accuracy: 75.23992322456814\n",
      "Epoch 1569 val loss: 0.6496071132194055\n",
      "Epoch 1569 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1569.pth\n",
      "Epoch 1570 train loss: 0.6561086638912297\n",
      "Epoch 1570 train accuracy: 75.21250342747463\n",
      "Epoch 1570 val loss: 0.6496091166413144\n",
      "Epoch 1570 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1570.pth\n",
      "Epoch 1571 train loss: 0.65601811107052\n",
      "Epoch 1571 train accuracy: 75.21250342747463\n",
      "Epoch 1571 val loss: 0.6495954149255627\n",
      "Epoch 1571 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1571.pth\n",
      "Epoch 1572 train loss: 0.6561199235158008\n",
      "Epoch 1572 train accuracy: 75.15766383328763\n",
      "Epoch 1572 val loss: 0.6495926839936721\n",
      "Epoch 1572 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1572.pth\n",
      "Epoch 1573 train loss: 0.6560993591617597\n",
      "Epoch 1573 train accuracy: 75.13024403619413\n",
      "Epoch 1573 val loss: 0.6495853044876927\n",
      "Epoch 1573 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1573.pth\n",
      "Epoch 1574 train loss: 0.6560571290095124\n",
      "Epoch 1574 train accuracy: 75.13024403619413\n",
      "Epoch 1574 val loss: 0.649570770855797\n",
      "Epoch 1574 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1574.pth\n",
      "Epoch 1575 train loss: 0.6560885411148009\n",
      "Epoch 1575 train accuracy: 75.21250342747463\n",
      "Epoch 1575 val loss: 0.6495661251246929\n",
      "Epoch 1575 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1575.pth\n",
      "Epoch 1576 train loss: 0.6560429918596096\n",
      "Epoch 1576 train accuracy: 75.18508363038113\n",
      "Epoch 1576 val loss: 0.6495783703499719\n",
      "Epoch 1576 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1576.pth\n",
      "Epoch 1577 train loss: 0.656077031470966\n",
      "Epoch 1577 train accuracy: 75.18508363038113\n",
      "Epoch 1577 val loss: 0.6495618481973284\n",
      "Epoch 1577 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1577.pth\n",
      "Epoch 1578 train loss: 0.6560594437872631\n",
      "Epoch 1578 train accuracy: 75.23992322456814\n",
      "Epoch 1578 val loss: 0.6495686381271011\n",
      "Epoch 1578 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1578.pth\n",
      "Epoch 1579 train loss: 0.6560236978949162\n",
      "Epoch 1579 train accuracy: 75.21250342747463\n",
      "Epoch 1579 val loss: 0.6495765451537935\n",
      "Epoch 1579 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1579.pth\n",
      "Epoch 1580 train loss: 0.6560198061102838\n",
      "Epoch 1580 train accuracy: 75.15766383328763\n",
      "Epoch 1580 val loss: 0.6495497453173524\n",
      "Epoch 1580 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1580.pth\n",
      "Epoch 1581 train loss: 0.6560715240540734\n",
      "Epoch 1581 train accuracy: 75.21250342747463\n",
      "Epoch 1581 val loss: 0.649542604524054\n",
      "Epoch 1581 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1581.pth\n",
      "Epoch 1582 train loss: 0.6559602863138967\n",
      "Epoch 1582 train accuracy: 75.21250342747463\n",
      "Epoch 1582 val loss: 0.6495473046640032\n",
      "Epoch 1582 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1582.pth\n",
      "Epoch 1583 train loss: 0.6559862456562227\n",
      "Epoch 1583 train accuracy: 75.21250342747463\n",
      "Epoch 1583 val loss: 0.6495413956673521\n",
      "Epoch 1583 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1583.pth\n",
      "Epoch 1584 train loss: 0.6560075782370149\n",
      "Epoch 1584 train accuracy: 75.21250342747463\n",
      "Epoch 1584 val loss: 0.6495430256779257\n",
      "Epoch 1584 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1584.pth\n",
      "Epoch 1585 train loss: 0.6559985407154288\n",
      "Epoch 1585 train accuracy: 75.21250342747463\n",
      "Epoch 1585 val loss: 0.6495470646768808\n",
      "Epoch 1585 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1585.pth\n",
      "Epoch 1586 train loss: 0.656037176060572\n",
      "Epoch 1586 train accuracy: 75.21250342747463\n",
      "Epoch 1586 val loss: 0.6495411746988171\n",
      "Epoch 1586 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1586.pth\n",
      "Epoch 1587 train loss: 0.6560321303182527\n",
      "Epoch 1587 train accuracy: 75.21250342747463\n",
      "Epoch 1587 val loss: 0.6495251044827072\n",
      "Epoch 1587 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1587.pth\n",
      "Epoch 1588 train loss: 0.6560221530431718\n",
      "Epoch 1588 train accuracy: 75.21250342747463\n",
      "Epoch 1588 val loss: 0.6495217667206338\n",
      "Epoch 1588 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1588.pth\n",
      "Epoch 1589 train loss: 0.6560245570971778\n",
      "Epoch 1589 train accuracy: 75.29476281875515\n",
      "Epoch 1589 val loss: 0.6495350267934171\n",
      "Epoch 1589 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1589.pth\n",
      "Epoch 1590 train loss: 0.6560197285327473\n",
      "Epoch 1590 train accuracy: 75.18508363038113\n",
      "Epoch 1590 val loss: 0.6495188888358442\n",
      "Epoch 1590 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1590.pth\n",
      "Epoch 1591 train loss: 0.6559683260949034\n",
      "Epoch 1591 train accuracy: 75.18508363038113\n",
      "Epoch 1591 val loss: 0.6495138627329939\n",
      "Epoch 1591 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1591.pth\n",
      "Epoch 1592 train loss: 0.6560024033186206\n",
      "Epoch 1592 train accuracy: 75.21250342747463\n",
      "Epoch 1592 val loss: 0.6495416951610854\n",
      "Epoch 1592 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1592.pth\n",
      "Epoch 1593 train loss: 0.6560356680042388\n",
      "Epoch 1593 train accuracy: 75.21250342747463\n",
      "Epoch 1593 val loss: 0.6495286241958016\n",
      "Epoch 1593 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1593.pth\n",
      "Epoch 1594 train loss: 0.6560036428926284\n",
      "Epoch 1594 train accuracy: 75.13024403619413\n",
      "Epoch 1594 val loss: 0.6495373840198705\n",
      "Epoch 1594 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1594.pth\n",
      "Epoch 1595 train loss: 0.655953231218614\n",
      "Epoch 1595 train accuracy: 75.21250342747463\n",
      "Epoch 1595 val loss: 0.6495179992267176\n",
      "Epoch 1595 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1595.pth\n",
      "Epoch 1596 train loss: 0.6559937537827513\n",
      "Epoch 1596 train accuracy: 75.10282423910063\n",
      "Epoch 1596 val loss: 0.6494930474773833\n",
      "Epoch 1596 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1596.pth\n",
      "Epoch 1597 train loss: 0.6559412303266295\n",
      "Epoch 1597 train accuracy: 75.18508363038113\n",
      "Epoch 1597 val loss: 0.6495069808473712\n",
      "Epoch 1597 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1597.pth\n",
      "Epoch 1598 train loss: 0.6559711342775508\n",
      "Epoch 1598 train accuracy: 75.21250342747463\n",
      "Epoch 1598 val loss: 0.6495015052588362\n",
      "Epoch 1598 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1598.pth\n",
      "Epoch 1599 train loss: 0.6560310354096848\n",
      "Epoch 1599 train accuracy: 75.23992322456814\n",
      "Epoch 1599 val loss: 0.6495135269666973\n",
      "Epoch 1599 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1599.pth\n",
      "Epoch 1600 train loss: 0.6560082104579922\n",
      "Epoch 1600 train accuracy: 75.21250342747463\n",
      "Epoch 1600 val loss: 0.6494984672845978\n",
      "Epoch 1600 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1600.pth\n",
      "Epoch 1601 train loss: 0.6559854425293835\n",
      "Epoch 1601 train accuracy: 75.18508363038113\n",
      "Epoch 1601 val loss: 0.6494840005118596\n",
      "Epoch 1601 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1601.pth\n",
      "Epoch 1602 train loss: 0.6559339995708382\n",
      "Epoch 1602 train accuracy: 75.18508363038113\n",
      "Epoch 1602 val loss: 0.6494700262617124\n",
      "Epoch 1602 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1602.pth\n",
      "Epoch 1603 train loss: 0.6559633242064401\n",
      "Epoch 1603 train accuracy: 75.23992322456814\n",
      "Epoch 1603 val loss: 0.6494818131782507\n",
      "Epoch 1603 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1603.pth\n",
      "Epoch 1604 train loss: 0.6559066893369482\n",
      "Epoch 1604 train accuracy: 75.29476281875515\n",
      "Epoch 1604 val loss: 0.6495072355395869\n",
      "Epoch 1604 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1604.pth\n",
      "Epoch 1605 train loss: 0.6559397195090066\n",
      "Epoch 1605 train accuracy: 75.15766383328763\n",
      "Epoch 1605 val loss: 0.64949314257032\n",
      "Epoch 1605 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1605.pth\n",
      "Epoch 1606 train loss: 0.6559439581867895\n",
      "Epoch 1606 train accuracy: 75.21250342747463\n",
      "Epoch 1606 val loss: 0.6494829613029173\n",
      "Epoch 1606 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1606.pth\n",
      "Epoch 1607 train loss: 0.6558889900906044\n",
      "Epoch 1607 train accuracy: 75.21250342747463\n",
      "Epoch 1607 val loss: 0.6494837031748734\n",
      "Epoch 1607 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1607.pth\n",
      "Epoch 1608 train loss: 0.6558758564162672\n",
      "Epoch 1608 train accuracy: 75.21250342747463\n",
      "Epoch 1608 val loss: 0.6494513107953888\n",
      "Epoch 1608 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1608.pth\n",
      "Epoch 1609 train loss: 0.6559378821076008\n",
      "Epoch 1609 train accuracy: 75.15766383328763\n",
      "Epoch 1609 val loss: 0.6494608386174628\n",
      "Epoch 1609 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1609.pth\n",
      "Epoch 1610 train loss: 0.6559162955208305\n",
      "Epoch 1610 train accuracy: 75.18508363038113\n",
      "Epoch 1610 val loss: 0.6494633118180853\n",
      "Epoch 1610 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1610.pth\n",
      "Epoch 1611 train loss: 0.6558882779719537\n",
      "Epoch 1611 train accuracy: 75.23992322456814\n",
      "Epoch 1611 val loss: 0.649466837119115\n",
      "Epoch 1611 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1611.pth\n",
      "Epoch 1612 train loss: 0.6559375650657896\n",
      "Epoch 1612 train accuracy: 75.18508363038113\n",
      "Epoch 1612 val loss: 0.6494532136344596\n",
      "Epoch 1612 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1612.pth\n",
      "Epoch 1613 train loss: 0.6559139261381668\n",
      "Epoch 1613 train accuracy: 75.18508363038113\n",
      "Epoch 1613 val loss: 0.6494643859761325\n",
      "Epoch 1613 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1613.pth\n",
      "Epoch 1614 train loss: 0.6558598936126944\n",
      "Epoch 1614 train accuracy: 75.26734302166165\n",
      "Epoch 1614 val loss: 0.6494446781120802\n",
      "Epoch 1614 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1614.pth\n",
      "Epoch 1615 train loss: 0.6558949359480226\n",
      "Epoch 1615 train accuracy: 75.29476281875515\n",
      "Epoch 1615 val loss: 0.6494699114639508\n",
      "Epoch 1615 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1615.pth\n",
      "Epoch 1616 train loss: 0.6558722425578979\n",
      "Epoch 1616 train accuracy: 75.18508363038113\n",
      "Epoch 1616 val loss: 0.6494640444258326\n",
      "Epoch 1616 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1616.pth\n",
      "Epoch 1617 train loss: 0.6558909937085813\n",
      "Epoch 1617 train accuracy: 75.18508363038113\n",
      "Epoch 1617 val loss: 0.6494213963221562\n",
      "Epoch 1617 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1617.pth\n",
      "Epoch 1618 train loss: 0.6558595430432704\n",
      "Epoch 1618 train accuracy: 75.21250342747463\n",
      "Epoch 1618 val loss: 0.6494157313320198\n",
      "Epoch 1618 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1618.pth\n",
      "Epoch 1619 train loss: 0.6558860025384969\n",
      "Epoch 1619 train accuracy: 75.21250342747463\n",
      "Epoch 1619 val loss: 0.6494269811205173\n",
      "Epoch 1619 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1619.pth\n",
      "Epoch 1620 train loss: 0.6558829659040559\n",
      "Epoch 1620 train accuracy: 75.29476281875515\n",
      "Epoch 1620 val loss: 0.6494385359906837\n",
      "Epoch 1620 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1620.pth\n",
      "Epoch 1621 train loss: 0.6558155504855931\n",
      "Epoch 1621 train accuracy: 75.23992322456814\n",
      "Epoch 1621 val loss: 0.6494362918954146\n",
      "Epoch 1621 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1621.pth\n",
      "Epoch 1622 train loss: 0.6558718236914852\n",
      "Epoch 1622 train accuracy: 75.18508363038113\n",
      "Epoch 1622 val loss: 0.6494136958530075\n",
      "Epoch 1622 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1622.pth\n",
      "Epoch 1623 train loss: 0.6557754814101938\n",
      "Epoch 1623 train accuracy: 75.21250342747463\n",
      "Epoch 1623 val loss: 0.649418458832722\n",
      "Epoch 1623 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1623.pth\n",
      "Epoch 1624 train loss: 0.6558330610002342\n",
      "Epoch 1624 train accuracy: 75.21250342747463\n",
      "Epoch 1624 val loss: 0.649403803148552\n",
      "Epoch 1624 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1624.pth\n",
      "Epoch 1625 train loss: 0.6558935378531092\n",
      "Epoch 1625 train accuracy: 75.21250342747463\n",
      "Epoch 1625 val loss: 0.6493954983981032\n",
      "Epoch 1625 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1625.pth\n",
      "Epoch 1626 train loss: 0.6558710876852274\n",
      "Epoch 1626 train accuracy: 75.23992322456814\n",
      "Epoch 1626 val loss: 0.6493948742159104\n",
      "Epoch 1626 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1626.pth\n",
      "Epoch 1627 train loss: 0.6558466003064001\n",
      "Epoch 1627 train accuracy: 75.26734302166165\n",
      "Epoch 1627 val loss: 0.6494124683208371\n",
      "Epoch 1627 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1627.pth\n",
      "Epoch 1628 train loss: 0.6558094889971248\n",
      "Epoch 1628 train accuracy: 75.23992322456814\n",
      "Epoch 1628 val loss: 0.6494276555941293\n",
      "Epoch 1628 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1628.pth\n",
      "Epoch 1629 train loss: 0.6558966613456345\n",
      "Epoch 1629 train accuracy: 75.23992322456814\n",
      "Epoch 1629 val loss: 0.6494188918487022\n",
      "Epoch 1629 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1629.pth\n",
      "Epoch 1630 train loss: 0.6557965665532831\n",
      "Epoch 1630 train accuracy: 75.21250342747463\n",
      "Epoch 1630 val loss: 0.6494094318661251\n",
      "Epoch 1630 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1630.pth\n",
      "Epoch 1631 train loss: 0.655842972853989\n",
      "Epoch 1631 train accuracy: 75.26734302166165\n",
      "Epoch 1631 val loss: 0.6494154512490097\n",
      "Epoch 1631 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1631.pth\n",
      "Epoch 1632 train loss: 0.655835616385989\n",
      "Epoch 1632 train accuracy: 75.21250342747463\n",
      "Epoch 1632 val loss: 0.6493987394006628\n",
      "Epoch 1632 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1632.pth\n",
      "Epoch 1633 train loss: 0.6558081677281543\n",
      "Epoch 1633 train accuracy: 75.15766383328763\n",
      "Epoch 1633 val loss: 0.6493815774784276\n",
      "Epoch 1633 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1633.pth\n",
      "Epoch 1634 train loss: 0.6558238535204477\n",
      "Epoch 1634 train accuracy: 75.21250342747463\n",
      "Epoch 1634 val loss: 0.6493581458926201\n",
      "Epoch 1634 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1634.pth\n",
      "Epoch 1635 train loss: 0.655817052839618\n",
      "Epoch 1635 train accuracy: 75.26734302166165\n",
      "Epoch 1635 val loss: 0.6493567312626463\n",
      "Epoch 1635 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1635.pth\n",
      "Epoch 1636 train loss: 0.6557585283819782\n",
      "Epoch 1636 train accuracy: 75.23992322456814\n",
      "Epoch 1636 val loss: 0.6493652806078133\n",
      "Epoch 1636 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1636.pth\n",
      "Epoch 1637 train loss: 0.6558093320774404\n",
      "Epoch 1637 train accuracy: 75.23992322456814\n",
      "Epoch 1637 val loss: 0.6493653630543696\n",
      "Epoch 1637 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1637.pth\n",
      "Epoch 1638 train loss: 0.6558380787701983\n",
      "Epoch 1638 train accuracy: 75.32218261584865\n",
      "Epoch 1638 val loss: 0.6493736955484277\n",
      "Epoch 1638 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1638.pth\n",
      "Epoch 1639 train loss: 0.6557915045700052\n",
      "Epoch 1639 train accuracy: 75.26734302166165\n",
      "Epoch 1639 val loss: 0.6493935620314196\n",
      "Epoch 1639 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1639.pth\n",
      "Epoch 1640 train loss: 0.6557941368470589\n",
      "Epoch 1640 train accuracy: 75.23992322456814\n",
      "Epoch 1640 val loss: 0.6493897836067175\n",
      "Epoch 1640 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1640.pth\n",
      "Epoch 1641 train loss: 0.6557872696338516\n",
      "Epoch 1641 train accuracy: 75.21250342747463\n",
      "Epoch 1641 val loss: 0.6493574750462645\n",
      "Epoch 1641 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1641.pth\n",
      "Epoch 1642 train loss: 0.6557625888993865\n",
      "Epoch 1642 train accuracy: 75.23992322456814\n",
      "Epoch 1642 val loss: 0.6493378082584393\n",
      "Epoch 1642 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1642.pth\n",
      "Epoch 1643 train loss: 0.6557907985294598\n",
      "Epoch 1643 train accuracy: 75.29476281875515\n",
      "Epoch 1643 val loss: 0.6493615975701496\n",
      "Epoch 1643 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1643.pth\n",
      "Epoch 1644 train loss: 0.6557763876360759\n",
      "Epoch 1644 train accuracy: 75.18508363038113\n",
      "Epoch 1644 val loss: 0.6493686557208237\n",
      "Epoch 1644 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1644.pth\n",
      "Epoch 1645 train loss: 0.6557648931875041\n",
      "Epoch 1645 train accuracy: 75.18508363038113\n",
      "Epoch 1645 val loss: 0.64933433873873\n",
      "Epoch 1645 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1645.pth\n",
      "Epoch 1646 train loss: 0.6557657414426407\n",
      "Epoch 1646 train accuracy: 75.23992322456814\n",
      "Epoch 1646 val loss: 0.6493361653073838\n",
      "Epoch 1646 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1646.pth\n",
      "Epoch 1647 train loss: 0.6557299932301567\n",
      "Epoch 1647 train accuracy: 75.26734302166165\n",
      "Epoch 1647 val loss: 0.6493402594994557\n",
      "Epoch 1647 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1647.pth\n",
      "Epoch 1648 train loss: 0.6557310709501045\n",
      "Epoch 1648 train accuracy: 75.23992322456814\n",
      "Epoch 1648 val loss: 0.6493395810064516\n",
      "Epoch 1648 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1648.pth\n",
      "Epoch 1649 train loss: 0.6557534041307997\n",
      "Epoch 1649 train accuracy: 75.32218261584865\n",
      "Epoch 1649 val loss: 0.6493423007624713\n",
      "Epoch 1649 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1649.pth\n",
      "Epoch 1650 train loss: 0.6557179200544692\n",
      "Epoch 1650 train accuracy: 75.23992322456814\n",
      "Epoch 1650 val loss: 0.6493410150471487\n",
      "Epoch 1650 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1650.pth\n",
      "Epoch 1651 train loss: 0.655696403496621\n",
      "Epoch 1651 train accuracy: 75.29476281875515\n",
      "Epoch 1651 val loss: 0.6493337181837935\n",
      "Epoch 1651 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1651.pth\n",
      "Epoch 1652 train loss: 0.6557451676119838\n",
      "Epoch 1652 train accuracy: 75.29476281875515\n",
      "Epoch 1652 val loss: 0.649333086649054\n",
      "Epoch 1652 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1652.pth\n",
      "Epoch 1653 train loss: 0.6557367776536889\n",
      "Epoch 1653 train accuracy: 75.26734302166165\n",
      "Epoch 1653 val loss: 0.6493279217301231\n",
      "Epoch 1653 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1653.pth\n",
      "Epoch 1654 train loss: 0.6556992283287016\n",
      "Epoch 1654 train accuracy: 75.23992322456814\n",
      "Epoch 1654 val loss: 0.6493201733223701\n",
      "Epoch 1654 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1654.pth\n",
      "Epoch 1655 train loss: 0.6557289586778272\n",
      "Epoch 1655 train accuracy: 75.26734302166165\n",
      "Epoch 1655 val loss: 0.6493340731647453\n",
      "Epoch 1655 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1655.pth\n",
      "Epoch 1656 train loss: 0.6557441245307002\n",
      "Epoch 1656 train accuracy: 75.32218261584865\n",
      "Epoch 1656 val loss: 0.6493334996661073\n",
      "Epoch 1656 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1656.pth\n",
      "Epoch 1657 train loss: 0.6557172995322106\n",
      "Epoch 1657 train accuracy: 75.29476281875515\n",
      "Epoch 1657 val loss: 0.6493298735861716\n",
      "Epoch 1657 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1657.pth\n",
      "Epoch 1658 train loss: 0.6556890939215296\n",
      "Epoch 1658 train accuracy: 75.32218261584865\n",
      "Epoch 1658 val loss: 0.6493237594044522\n",
      "Epoch 1658 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1658.pth\n",
      "Epoch 1659 train loss: 0.655758064730387\n",
      "Epoch 1659 train accuracy: 75.26734302166165\n",
      "Epoch 1659 val loss: 0.6493453547162445\n",
      "Epoch 1659 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1659.pth\n",
      "Epoch 1660 train loss: 0.6557099176734164\n",
      "Epoch 1660 train accuracy: 75.23992322456814\n",
      "Epoch 1660 val loss: 0.6493215697180283\n",
      "Epoch 1660 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1660.pth\n",
      "Epoch 1661 train loss: 0.6556567046137756\n",
      "Epoch 1661 train accuracy: 75.26734302166165\n",
      "Epoch 1661 val loss: 0.6493073345995263\n",
      "Epoch 1661 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1661.pth\n",
      "Epoch 1662 train loss: 0.6556642850566852\n",
      "Epoch 1662 train accuracy: 75.32218261584865\n",
      "Epoch 1662 val loss: 0.6493048008139196\n",
      "Epoch 1662 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1662.pth\n",
      "Epoch 1663 train loss: 0.655634838303453\n",
      "Epoch 1663 train accuracy: 75.26734302166165\n",
      "Epoch 1663 val loss: 0.649300184885138\n",
      "Epoch 1663 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1663.pth\n",
      "Epoch 1664 train loss: 0.6557208467274904\n",
      "Epoch 1664 train accuracy: 75.29476281875515\n",
      "Epoch 1664 val loss: 0.6493083329773263\n",
      "Epoch 1664 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1664.pth\n",
      "Epoch 1665 train loss: 0.6557320969571409\n",
      "Epoch 1665 train accuracy: 75.23992322456814\n",
      "Epoch 1665 val loss: 0.6492877782959687\n",
      "Epoch 1665 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1665.pth\n",
      "Epoch 1666 train loss: 0.6557290693908407\n",
      "Epoch 1666 train accuracy: 75.32218261584865\n",
      "Epoch 1666 val loss: 0.649315061733911\n",
      "Epoch 1666 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1666.pth\n",
      "Epoch 1667 train loss: 0.6556478907076413\n",
      "Epoch 1667 train accuracy: 75.32218261584865\n",
      "Epoch 1667 val loss: 0.6493061087829503\n",
      "Epoch 1667 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1667.pth\n",
      "Epoch 1668 train loss: 0.6556716925023418\n",
      "Epoch 1668 train accuracy: 75.32218261584865\n",
      "Epoch 1668 val loss: 0.6492909330286478\n",
      "Epoch 1668 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1668.pth\n",
      "Epoch 1669 train loss: 0.6556713011181146\n",
      "Epoch 1669 train accuracy: 75.29476281875515\n",
      "Epoch 1669 val loss: 0.6493039403698946\n",
      "Epoch 1669 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1669.pth\n",
      "Epoch 1670 train loss: 0.6556418418328751\n",
      "Epoch 1670 train accuracy: 75.21250342747463\n",
      "Epoch 1670 val loss: 0.6492783128234901\n",
      "Epoch 1670 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1670.pth\n",
      "Epoch 1671 train loss: 0.6556642673125392\n",
      "Epoch 1671 train accuracy: 75.34960241294215\n",
      "Epoch 1671 val loss: 0.6492946224385187\n",
      "Epoch 1671 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1671.pth\n",
      "Epoch 1672 train loss: 0.6555743654372922\n",
      "Epoch 1672 train accuracy: 75.29476281875515\n",
      "Epoch 1672 val loss: 0.6492643826886227\n",
      "Epoch 1672 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1672.pth\n",
      "Epoch 1673 train loss: 0.6556232169826042\n",
      "Epoch 1673 train accuracy: 75.26734302166165\n",
      "Epoch 1673 val loss: 0.6492823181967986\n",
      "Epoch 1673 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1673.pth\n",
      "Epoch 1674 train loss: 0.6555925882176349\n",
      "Epoch 1674 train accuracy: 75.34960241294215\n",
      "Epoch 1674 val loss: 0.6492905618230763\n",
      "Epoch 1674 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1674.pth\n",
      "Epoch 1675 train loss: 0.6556540214244211\n",
      "Epoch 1675 train accuracy: 75.32218261584865\n",
      "Epoch 1675 val loss: 0.6492842231926165\n",
      "Epoch 1675 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1675.pth\n",
      "Epoch 1676 train loss: 0.6556401718407869\n",
      "Epoch 1676 train accuracy: 75.26734302166165\n",
      "Epoch 1676 val loss: 0.649264658066003\n",
      "Epoch 1676 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1676.pth\n",
      "Epoch 1677 train loss: 0.6556287601982292\n",
      "Epoch 1677 train accuracy: 75.29476281875515\n",
      "Epoch 1677 val loss: 0.6492775524721334\n",
      "Epoch 1677 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1677.pth\n",
      "Epoch 1678 train loss: 0.6556157925607342\n",
      "Epoch 1678 train accuracy: 75.29476281875515\n",
      "Epoch 1678 val loss: 0.6492528981088024\n",
      "Epoch 1678 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1678.pth\n",
      "Epoch 1679 train loss: 0.6556222525082136\n",
      "Epoch 1679 train accuracy: 75.34960241294215\n",
      "Epoch 1679 val loss: 0.6492273543814295\n",
      "Epoch 1679 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1679.pth\n",
      "Epoch 1680 train loss: 0.6556248726290569\n",
      "Epoch 1680 train accuracy: 75.29476281875515\n",
      "Epoch 1680 val loss: 0.649225549086144\n",
      "Epoch 1680 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1680.pth\n",
      "Epoch 1681 train loss: 0.6556190148388085\n",
      "Epoch 1681 train accuracy: 75.34960241294215\n",
      "Epoch 1681 val loss: 0.6492248893176255\n",
      "Epoch 1681 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1681.pth\n",
      "Epoch 1682 train loss: 0.6554971191574607\n",
      "Epoch 1682 train accuracy: 75.34960241294215\n",
      "Epoch 1682 val loss: 0.6492377385301026\n",
      "Epoch 1682 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1682.pth\n",
      "Epoch 1683 train loss: 0.6556338425072139\n",
      "Epoch 1683 train accuracy: 75.34960241294215\n",
      "Epoch 1683 val loss: 0.6492232173485192\n",
      "Epoch 1683 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1683.pth\n",
      "Epoch 1684 train loss: 0.6556067599735239\n",
      "Epoch 1684 train accuracy: 75.32218261584865\n",
      "Epoch 1684 val loss: 0.6492379178342066\n",
      "Epoch 1684 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1684.pth\n",
      "Epoch 1685 train loss: 0.6555556211816637\n",
      "Epoch 1685 train accuracy: 75.37702221003565\n",
      "Epoch 1685 val loss: 0.64923944745801\n",
      "Epoch 1685 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1685.pth\n",
      "Epoch 1686 train loss: 0.6555958166064924\n",
      "Epoch 1686 train accuracy: 75.32218261584865\n",
      "Epoch 1686 val loss: 0.6492242607239046\n",
      "Epoch 1686 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1686.pth\n",
      "Epoch 1687 train loss: 0.6555936921126487\n",
      "Epoch 1687 train accuracy: 75.29476281875515\n",
      "Epoch 1687 val loss: 0.6492267466689411\n",
      "Epoch 1687 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1687.pth\n",
      "Epoch 1688 train loss: 0.6555533121879163\n",
      "Epoch 1688 train accuracy: 75.32218261584865\n",
      "Epoch 1688 val loss: 0.6491989584541634\n",
      "Epoch 1688 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1688.pth\n",
      "Epoch 1689 train loss: 0.655555305348938\n",
      "Epoch 1689 train accuracy: 75.34960241294215\n",
      "Epoch 1689 val loss: 0.6492006901749655\n",
      "Epoch 1689 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1689.pth\n",
      "Epoch 1690 train loss: 0.655534418626574\n",
      "Epoch 1690 train accuracy: 75.34960241294215\n",
      "Epoch 1690 val loss: 0.6491786853263253\n",
      "Epoch 1690 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1690.pth\n",
      "Epoch 1691 train loss: 0.6555440371300567\n",
      "Epoch 1691 train accuracy: 75.32218261584865\n",
      "Epoch 1691 val loss: 0.6491935222752785\n",
      "Epoch 1691 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1691.pth\n",
      "Epoch 1692 train loss: 0.655550236797385\n",
      "Epoch 1692 train accuracy: 75.34960241294215\n",
      "Epoch 1692 val loss: 0.649194134105193\n",
      "Epoch 1692 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1692.pth\n",
      "Epoch 1693 train loss: 0.6555642038583755\n",
      "Epoch 1693 train accuracy: 75.37702221003565\n",
      "Epoch 1693 val loss: 0.6491847003957159\n",
      "Epoch 1693 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_1693.pth\n",
      "Epoch 1694 train loss: 0.6555015993418923\n",
      "Epoch 1694 train accuracy: 75.34960241294215\n",
      "Epoch 1694 val loss: 0.6491944101688109\n",
      "Epoch 1694 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1694.pth\n",
      "Epoch 1695 train loss: 0.6555215045156186\n",
      "Epoch 1695 train accuracy: 75.32218261584865\n",
      "Epoch 1695 val loss: 0.6492111731908823\n",
      "Epoch 1695 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1695.pth\n",
      "Epoch 1696 train loss: 0.6555334151836864\n",
      "Epoch 1696 train accuracy: 75.32218261584865\n",
      "Epoch 1696 val loss: 0.6492064870697888\n",
      "Epoch 1696 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1696.pth\n",
      "Epoch 1697 train loss: 0.655527852802423\n",
      "Epoch 1697 train accuracy: 75.32218261584865\n",
      "Epoch 1697 val loss: 0.6492084103979563\n",
      "Epoch 1697 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1697.pth\n",
      "Epoch 1698 train loss: 0.655564958066271\n",
      "Epoch 1698 train accuracy: 75.34960241294215\n",
      "Epoch 1698 val loss: 0.6492210482492259\n",
      "Epoch 1698 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1698.pth\n",
      "Epoch 1699 train loss: 0.6555428877472878\n",
      "Epoch 1699 train accuracy: 75.37702221003565\n",
      "Epoch 1699 val loss: 0.6492067204886361\n",
      "Epoch 1699 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1699.pth\n",
      "Epoch 1700 train loss: 0.6555382290757016\n",
      "Epoch 1700 train accuracy: 75.34960241294215\n",
      "Epoch 1700 val loss: 0.6492021498515418\n",
      "Epoch 1700 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1700.pth\n",
      "Epoch 1701 train loss: 0.6555383298546076\n",
      "Epoch 1701 train accuracy: 75.34960241294215\n",
      "Epoch 1701 val loss: 0.6491936384455154\n",
      "Epoch 1701 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1701.pth\n",
      "Epoch 1702 train loss: 0.6555297935806346\n",
      "Epoch 1702 train accuracy: 75.29476281875515\n",
      "Epoch 1702 val loss: 0.649183590161173\n",
      "Epoch 1702 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1702.pth\n",
      "Epoch 1703 train loss: 0.6554723973794464\n",
      "Epoch 1703 train accuracy: 75.32218261584865\n",
      "Epoch 1703 val loss: 0.6491979779185433\n",
      "Epoch 1703 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1703.pth\n",
      "Epoch 1704 train loss: 0.6555210845054764\n",
      "Epoch 1704 train accuracy: 75.29476281875515\n",
      "Epoch 1704 val loss: 0.649187132520111\n",
      "Epoch 1704 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1704.pth\n",
      "Epoch 1705 train loss: 0.6555322215876036\n",
      "Epoch 1705 train accuracy: 75.34960241294215\n",
      "Epoch 1705 val loss: 0.6491736997114984\n",
      "Epoch 1705 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1705.pth\n",
      "Epoch 1706 train loss: 0.6554683500476051\n",
      "Epoch 1706 train accuracy: 75.37702221003565\n",
      "Epoch 1706 val loss: 0.6491620297494688\n",
      "Epoch 1706 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1706.pth\n",
      "Epoch 1707 train loss: 0.6554834796605926\n",
      "Epoch 1707 train accuracy: 75.43186180422265\n",
      "Epoch 1707 val loss: 0.6491816899690189\n",
      "Epoch 1707 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1707.pth\n",
      "Epoch 1708 train loss: 0.6554794135389098\n",
      "Epoch 1708 train accuracy: 75.32218261584865\n",
      "Epoch 1708 val loss: 0.6491737245140892\n",
      "Epoch 1708 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1708.pth\n",
      "Epoch 1709 train loss: 0.6554764590569233\n",
      "Epoch 1709 train accuracy: 75.32218261584865\n",
      "Epoch 1709 val loss: 0.6491572211839651\n",
      "Epoch 1709 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1709.pth\n",
      "Epoch 1710 train loss: 0.6555007653343573\n",
      "Epoch 1710 train accuracy: 75.34960241294215\n",
      "Epoch 1710 val loss: 0.6491658141542422\n",
      "Epoch 1710 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1710.pth\n",
      "Epoch 1711 train loss: 0.6554596262346757\n",
      "Epoch 1711 train accuracy: 75.32218261584865\n",
      "Epoch 1711 val loss: 0.6491392889109097\n",
      "Epoch 1711 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1711.pth\n",
      "Epoch 1712 train loss: 0.6554615475041302\n",
      "Epoch 1712 train accuracy: 75.34960241294215\n",
      "Epoch 1712 val loss: 0.6491296607020655\n",
      "Epoch 1712 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1712.pth\n",
      "Epoch 1713 train loss: 0.6554639534207812\n",
      "Epoch 1713 train accuracy: 75.37702221003565\n",
      "Epoch 1713 val loss: 0.6491534319755278\n",
      "Epoch 1713 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1713.pth\n",
      "Epoch 1714 train loss: 0.655476293216149\n",
      "Epoch 1714 train accuracy: 75.37702221003565\n",
      "Epoch 1714 val loss: 0.6491618309366075\n",
      "Epoch 1714 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1714.pth\n",
      "Epoch 1715 train loss: 0.6554372151006471\n",
      "Epoch 1715 train accuracy: 75.37702221003565\n",
      "Epoch 1715 val loss: 0.6491630170494318\n",
      "Epoch 1715 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1715.pth\n",
      "Epoch 1716 train loss: 0.6554630243529876\n",
      "Epoch 1716 train accuracy: 75.37702221003565\n",
      "Epoch 1716 val loss: 0.649151377968098\n",
      "Epoch 1716 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1716.pth\n",
      "Epoch 1717 train loss: 0.655421743136749\n",
      "Epoch 1717 train accuracy: 75.37702221003565\n",
      "Epoch 1717 val loss: 0.6491797713464812\n",
      "Epoch 1717 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1717.pth\n",
      "Epoch 1718 train loss: 0.6555123031792933\n",
      "Epoch 1718 train accuracy: 75.34960241294215\n",
      "Epoch 1718 val loss: 0.6491436679896555\n",
      "Epoch 1718 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1718.pth\n",
      "Epoch 1719 train loss: 0.6555272280647043\n",
      "Epoch 1719 train accuracy: 75.34960241294215\n",
      "Epoch 1719 val loss: 0.6491202481679226\n",
      "Epoch 1719 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1719.pth\n",
      "Epoch 1720 train loss: 0.655433832716785\n",
      "Epoch 1720 train accuracy: 75.29476281875515\n",
      "Epoch 1720 val loss: 0.6491232553594991\n",
      "Epoch 1720 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1720.pth\n",
      "Epoch 1721 train loss: 0.6554245618743855\n",
      "Epoch 1721 train accuracy: 75.37702221003565\n",
      "Epoch 1721 val loss: 0.6491363026005658\n",
      "Epoch 1721 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1721.pth\n",
      "Epoch 1722 train loss: 0.6554468710367617\n",
      "Epoch 1722 train accuracy: 75.48670139840965\n",
      "Epoch 1722 val loss: 0.6491135335282275\n",
      "Epoch 1722 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1722.pth\n",
      "Epoch 1723 train loss: 0.6554347375701917\n",
      "Epoch 1723 train accuracy: 75.34960241294215\n",
      "Epoch 1723 val loss: 0.649130568006321\n",
      "Epoch 1723 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1723.pth\n",
      "Epoch 1724 train loss: 0.6554332055445564\n",
      "Epoch 1724 train accuracy: 75.32218261584865\n",
      "Epoch 1724 val loss: 0.6490992736071348\n",
      "Epoch 1724 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1724.pth\n",
      "Epoch 1725 train loss: 0.6553977587701458\n",
      "Epoch 1725 train accuracy: 75.34960241294215\n",
      "Epoch 1725 val loss: 0.6491193442948555\n",
      "Epoch 1725 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1725.pth\n",
      "Epoch 1726 train loss: 0.6554688086504477\n",
      "Epoch 1726 train accuracy: 75.37702221003565\n",
      "Epoch 1726 val loss: 0.6491090186724537\n",
      "Epoch 1726 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1726.pth\n",
      "Epoch 1727 train loss: 0.6554269315838291\n",
      "Epoch 1727 train accuracy: 75.40444200712915\n",
      "Epoch 1727 val loss: 0.6491183786603966\n",
      "Epoch 1727 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1727.pth\n",
      "Epoch 1728 train loss: 0.6554173734039068\n",
      "Epoch 1728 train accuracy: 75.43186180422265\n",
      "Epoch 1728 val loss: 0.6490996663311595\n",
      "Epoch 1728 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1728.pth\n",
      "Epoch 1729 train loss: 0.6554167377844191\n",
      "Epoch 1729 train accuracy: 75.37702221003565\n",
      "Epoch 1729 val loss: 0.6490738850675131\n",
      "Epoch 1729 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1729.pth\n",
      "Epoch 1730 train loss: 0.6553130640991425\n",
      "Epoch 1730 train accuracy: 75.43186180422265\n",
      "Epoch 1730 val loss: 0.6490926239639521\n",
      "Epoch 1730 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1730.pth\n",
      "Epoch 1731 train loss: 0.6553327551340324\n",
      "Epoch 1731 train accuracy: 75.34960241294215\n",
      "Epoch 1731 val loss: 0.6490816494548007\n",
      "Epoch 1731 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1731.pth\n",
      "Epoch 1732 train loss: 0.655359943805818\n",
      "Epoch 1732 train accuracy: 75.37702221003565\n",
      "Epoch 1732 val loss: 0.64909002312312\n",
      "Epoch 1732 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1732.pth\n",
      "Epoch 1733 train loss: 0.6553971913169351\n",
      "Epoch 1733 train accuracy: 75.29476281875515\n",
      "Epoch 1733 val loss: 0.6490858516802913\n",
      "Epoch 1733 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1733.pth\n",
      "Epoch 1734 train loss: 0.6553996824904492\n",
      "Epoch 1734 train accuracy: 75.34960241294215\n",
      "Epoch 1734 val loss: 0.6490988892159963\n",
      "Epoch 1734 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1734.pth\n",
      "Epoch 1735 train loss: 0.6554323974670025\n",
      "Epoch 1735 train accuracy: 75.29476281875515\n",
      "Epoch 1735 val loss: 0.6490811904598224\n",
      "Epoch 1735 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1735.pth\n",
      "Epoch 1736 train loss: 0.6554192945099714\n",
      "Epoch 1736 train accuracy: 75.34960241294215\n",
      "Epoch 1736 val loss: 0.6490926172976431\n",
      "Epoch 1736 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1736.pth\n",
      "Epoch 1737 train loss: 0.6554597245627328\n",
      "Epoch 1737 train accuracy: 75.37702221003565\n",
      "Epoch 1737 val loss: 0.6490791188062806\n",
      "Epoch 1737 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1737.pth\n",
      "Epoch 1738 train loss: 0.6553188907799491\n",
      "Epoch 1738 train accuracy: 75.34960241294215\n",
      "Epoch 1738 val loss: 0.6491046661609098\n",
      "Epoch 1738 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1738.pth\n",
      "Epoch 1739 train loss: 0.6553412309537331\n",
      "Epoch 1739 train accuracy: 75.40444200712915\n",
      "Epoch 1739 val loss: 0.6490926605306173\n",
      "Epoch 1739 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1739.pth\n",
      "Epoch 1740 train loss: 0.6554970747807569\n",
      "Epoch 1740 train accuracy: 75.40444200712915\n",
      "Epoch 1740 val loss: 0.6490802139435944\n",
      "Epoch 1740 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1740.pth\n",
      "Epoch 1741 train loss: 0.6553751302458215\n",
      "Epoch 1741 train accuracy: 75.34960241294215\n",
      "Epoch 1741 val loss: 0.6490554724280772\n",
      "Epoch 1741 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1741.pth\n",
      "Epoch 1742 train loss: 0.6553330930243981\n",
      "Epoch 1742 train accuracy: 75.34960241294215\n",
      "Epoch 1742 val loss: 0.649049907236507\n",
      "Epoch 1742 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1742.pth\n",
      "Epoch 1743 train loss: 0.6553085881628489\n",
      "Epoch 1743 train accuracy: 75.37702221003565\n",
      "Epoch 1743 val loss: 0.6490512826528988\n",
      "Epoch 1743 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1743.pth\n",
      "Epoch 1744 train loss: 0.6553135323746685\n",
      "Epoch 1744 train accuracy: 75.43186180422265\n",
      "Epoch 1744 val loss: 0.6490684811417994\n",
      "Epoch 1744 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1744.pth\n",
      "Epoch 1745 train loss: 0.6552848013673436\n",
      "Epoch 1745 train accuracy: 75.40444200712915\n",
      "Epoch 1745 val loss: 0.6490770413687355\n",
      "Epoch 1745 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1745.pth\n",
      "Epoch 1746 train loss: 0.6553864113725069\n",
      "Epoch 1746 train accuracy: 75.40444200712915\n",
      "Epoch 1746 val loss: 0.649049590096662\n",
      "Epoch 1746 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1746.pth\n",
      "Epoch 1747 train loss: 0.6553443993458099\n",
      "Epoch 1747 train accuracy: 75.32218261584865\n",
      "Epoch 1747 val loss: 0.6490247377047413\n",
      "Epoch 1747 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1747.pth\n",
      "Epoch 1748 train loss: 0.655396182253434\n",
      "Epoch 1748 train accuracy: 75.37702221003565\n",
      "Epoch 1748 val loss: 0.6490310052115666\n",
      "Epoch 1748 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1748.pth\n",
      "Epoch 1749 train loss: 0.6553383865965563\n",
      "Epoch 1749 train accuracy: 75.37702221003565\n",
      "Epoch 1749 val loss: 0.6490201588327947\n",
      "Epoch 1749 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1749.pth\n",
      "Epoch 1750 train loss: 0.6553356912509914\n",
      "Epoch 1750 train accuracy: 75.37702221003565\n",
      "Epoch 1750 val loss: 0.6490477675474003\n",
      "Epoch 1750 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1750.pth\n",
      "Epoch 1751 train loss: 0.6553142033190581\n",
      "Epoch 1751 train accuracy: 75.37702221003565\n",
      "Epoch 1751 val loss: 0.6490463024299395\n",
      "Epoch 1751 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1751.pth\n",
      "Epoch 1752 train loss: 0.6553182891128879\n",
      "Epoch 1752 train accuracy: 75.34960241294215\n",
      "Epoch 1752 val loss: 0.649021811097076\n",
      "Epoch 1752 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1752.pth\n",
      "Epoch 1753 train loss: 0.6553256673117479\n",
      "Epoch 1753 train accuracy: 75.40444200712915\n",
      "Epoch 1753 val loss: 0.6490286962178192\n",
      "Epoch 1753 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1753.pth\n",
      "Epoch 1754 train loss: 0.6552697782192314\n",
      "Epoch 1754 train accuracy: 75.37702221003565\n",
      "Epoch 1754 val loss: 0.649016171595768\n",
      "Epoch 1754 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1754.pth\n",
      "Epoch 1755 train loss: 0.6553484053073222\n",
      "Epoch 1755 train accuracy: 75.34960241294215\n",
      "Epoch 1755 val loss: 0.6490390083115352\n",
      "Epoch 1755 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1755.pth\n",
      "Epoch 1756 train loss: 0.6553079861853468\n",
      "Epoch 1756 train accuracy: 75.40444200712915\n",
      "Epoch 1756 val loss: 0.6490337725140547\n",
      "Epoch 1756 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1756.pth\n",
      "Epoch 1757 train loss: 0.6553107357273499\n",
      "Epoch 1757 train accuracy: 75.37702221003565\n",
      "Epoch 1757 val loss: 0.64905487069566\n",
      "Epoch 1757 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1757.pth\n",
      "Epoch 1758 train loss: 0.6552845877840331\n",
      "Epoch 1758 train accuracy: 75.32218261584865\n",
      "Epoch 1758 val loss: 0.6490207919360775\n",
      "Epoch 1758 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1758.pth\n",
      "Epoch 1759 train loss: 0.6553035485313127\n",
      "Epoch 1759 train accuracy: 75.37702221003565\n",
      "Epoch 1759 val loss: 0.6490104213160904\n",
      "Epoch 1759 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1759.pth\n",
      "Epoch 1760 train loss: 0.6552730177186037\n",
      "Epoch 1760 train accuracy: 75.34960241294215\n",
      "Epoch 1760 val loss: 0.6490208274243694\n",
      "Epoch 1760 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1760.pth\n",
      "Epoch 1761 train loss: 0.6553351818012041\n",
      "Epoch 1761 train accuracy: 75.29476281875515\n",
      "Epoch 1761 val loss: 0.6489858150874314\n",
      "Epoch 1761 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1761.pth\n",
      "Epoch 1762 train loss: 0.655271245950931\n",
      "Epoch 1762 train accuracy: 75.32218261584865\n",
      "Epoch 1762 val loss: 0.6489933219395185\n",
      "Epoch 1762 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1762.pth\n",
      "Epoch 1763 train loss: 0.6552805363674435\n",
      "Epoch 1763 train accuracy: 75.34960241294215\n",
      "Epoch 1763 val loss: 0.6489958199427316\n",
      "Epoch 1763 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1763.pth\n",
      "Epoch 1764 train loss: 0.6553476094349957\n",
      "Epoch 1764 train accuracy: 75.40444200712915\n",
      "Epoch 1764 val loss: 0.6489833413966393\n",
      "Epoch 1764 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1764.pth\n",
      "Epoch 1765 train loss: 0.6552723168901968\n",
      "Epoch 1765 train accuracy: 75.34960241294215\n",
      "Epoch 1765 val loss: 0.648987243442159\n",
      "Epoch 1765 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1765.pth\n",
      "Epoch 1766 train loss: 0.6552741391943735\n",
      "Epoch 1766 train accuracy: 75.34960241294215\n",
      "Epoch 1766 val loss: 0.6489973004515234\n",
      "Epoch 1766 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1766.pth\n",
      "Epoch 1767 train loss: 0.6552312641584298\n",
      "Epoch 1767 train accuracy: 75.32218261584865\n",
      "Epoch 1767 val loss: 0.6489712255761811\n",
      "Epoch 1767 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1767.pth\n",
      "Epoch 1768 train loss: 0.6553034677186556\n",
      "Epoch 1768 train accuracy: 75.32218261584865\n",
      "Epoch 1768 val loss: 0.6489492263644934\n",
      "Epoch 1768 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1768.pth\n",
      "Epoch 1769 train loss: 0.6553172967805151\n",
      "Epoch 1769 train accuracy: 75.34960241294215\n",
      "Epoch 1769 val loss: 0.6489518164215904\n",
      "Epoch 1769 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1769.pth\n",
      "Epoch 1770 train loss: 0.6553153687467178\n",
      "Epoch 1770 train accuracy: 75.37702221003565\n",
      "Epoch 1770 val loss: 0.6489696882076954\n",
      "Epoch 1770 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1770.pth\n",
      "Epoch 1771 train loss: 0.6551804283405083\n",
      "Epoch 1771 train accuracy: 75.40444200712915\n",
      "Epoch 1771 val loss: 0.6489563664715541\n",
      "Epoch 1771 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1771.pth\n",
      "Epoch 1772 train loss: 0.655194501899052\n",
      "Epoch 1772 train accuracy: 75.37702221003565\n",
      "Epoch 1772 val loss: 0.6489635425570764\n",
      "Epoch 1772 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1772.pth\n",
      "Epoch 1773 train loss: 0.6552484118167246\n",
      "Epoch 1773 train accuracy: 75.37702221003565\n",
      "Epoch 1773 val loss: 0.6489578629598806\n",
      "Epoch 1773 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1773.pth\n",
      "Epoch 1774 train loss: 0.655240406560009\n",
      "Epoch 1774 train accuracy: 75.37702221003565\n",
      "Epoch 1774 val loss: 0.6489668659081584\n",
      "Epoch 1774 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1774.pth\n",
      "Epoch 1775 train loss: 0.6552326923987845\n",
      "Epoch 1775 train accuracy: 75.40444200712915\n",
      "Epoch 1775 val loss: 0.6489536310301015\n",
      "Epoch 1775 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1775.pth\n",
      "Epoch 1776 train loss: 0.6552357032502952\n",
      "Epoch 1776 train accuracy: 75.37702221003565\n",
      "Epoch 1776 val loss: 0.6489691797545866\n",
      "Epoch 1776 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1776.pth\n",
      "Epoch 1777 train loss: 0.6552116298688608\n",
      "Epoch 1777 train accuracy: 75.40444200712915\n",
      "Epoch 1777 val loss: 0.6489623325239671\n",
      "Epoch 1777 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1777.pth\n",
      "Epoch 1778 train loss: 0.6552301229614961\n",
      "Epoch 1778 train accuracy: 75.34960241294215\n",
      "Epoch 1778 val loss: 0.6489436349978572\n",
      "Epoch 1778 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1778.pth\n",
      "Epoch 1779 train loss: 0.6551876302743167\n",
      "Epoch 1779 train accuracy: 75.37702221003565\n",
      "Epoch 1779 val loss: 0.6489418767588703\n",
      "Epoch 1779 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1779.pth\n",
      "Epoch 1780 train loss: 0.6551608696187797\n",
      "Epoch 1780 train accuracy: 75.32218261584865\n",
      "Epoch 1780 val loss: 0.6489347842963118\n",
      "Epoch 1780 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1780.pth\n",
      "Epoch 1781 train loss: 0.6552160919170108\n",
      "Epoch 1781 train accuracy: 75.40444200712915\n",
      "Epoch 1781 val loss: 0.6489301002339313\n",
      "Epoch 1781 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1781.pth\n",
      "Epoch 1782 train loss: 0.6552140893774074\n",
      "Epoch 1782 train accuracy: 75.40444200712915\n",
      "Epoch 1782 val loss: 0.6489358231621353\n",
      "Epoch 1782 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1782.pth\n",
      "Epoch 1783 train loss: 0.6551443178272038\n",
      "Epoch 1783 train accuracy: 75.37702221003565\n",
      "Epoch 1783 val loss: 0.6489474990062023\n",
      "Epoch 1783 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1783.pth\n",
      "Epoch 1784 train loss: 0.6551980711356328\n",
      "Epoch 1784 train accuracy: 75.34960241294215\n",
      "Epoch 1784 val loss: 0.6489405043815312\n",
      "Epoch 1784 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1784.pth\n",
      "Epoch 1785 train loss: 0.655201759777571\n",
      "Epoch 1785 train accuracy: 75.37702221003565\n",
      "Epoch 1785 val loss: 0.6489411557191297\n",
      "Epoch 1785 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1785.pth\n",
      "Epoch 1786 train loss: 0.6551951907509774\n",
      "Epoch 1786 train accuracy: 75.43186180422265\n",
      "Epoch 1786 val loss: 0.6489282820961977\n",
      "Epoch 1786 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1786.pth\n",
      "Epoch 1787 train loss: 0.6551981705584025\n",
      "Epoch 1787 train accuracy: 75.32218261584865\n",
      "Epoch 1787 val loss: 0.6489242827029604\n",
      "Epoch 1787 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1787.pth\n",
      "Epoch 1788 train loss: 0.6551830060126489\n",
      "Epoch 1788 train accuracy: 75.32218261584865\n",
      "Epoch 1788 val loss: 0.6488950561339918\n",
      "Epoch 1788 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1788.pth\n",
      "Epoch 1789 train loss: 0.6551596148821869\n",
      "Epoch 1789 train accuracy: 75.34960241294215\n",
      "Epoch 1789 val loss: 0.6488754781649301\n",
      "Epoch 1789 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1789.pth\n",
      "Epoch 1790 train loss: 0.6551837095043116\n",
      "Epoch 1790 train accuracy: 75.43186180422265\n",
      "Epoch 1790 val loss: 0.6488889542065168\n",
      "Epoch 1790 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1790.pth\n",
      "Epoch 1791 train loss: 0.6551645262199536\n",
      "Epoch 1791 train accuracy: 75.37702221003565\n",
      "Epoch 1791 val loss: 0.6489165736068236\n",
      "Epoch 1791 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1791.pth\n",
      "Epoch 1792 train loss: 0.6551797670688022\n",
      "Epoch 1792 train accuracy: 75.43186180422265\n",
      "Epoch 1792 val loss: 0.6489247505209947\n",
      "Epoch 1792 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1792.pth\n",
      "Epoch 1793 train loss: 0.6551976383647375\n",
      "Epoch 1793 train accuracy: 75.29476281875515\n",
      "Epoch 1793 val loss: 0.6488935158244873\n",
      "Epoch 1793 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1793.pth\n",
      "Epoch 1794 train loss: 0.6551275193821966\n",
      "Epoch 1794 train accuracy: 75.43186180422265\n",
      "Epoch 1794 val loss: 0.6489149271265456\n",
      "Epoch 1794 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1794.pth\n",
      "Epoch 1795 train loss: 0.6551291093949163\n",
      "Epoch 1795 train accuracy: 75.34960241294215\n",
      "Epoch 1795 val loss: 0.6488807568032491\n",
      "Epoch 1795 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1795.pth\n",
      "Epoch 1796 train loss: 0.6551584616434156\n",
      "Epoch 1796 train accuracy: 75.45928160131615\n",
      "Epoch 1796 val loss: 0.6489130997736203\n",
      "Epoch 1796 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1796.pth\n",
      "Epoch 1797 train loss: 0.6552109636627791\n",
      "Epoch 1797 train accuracy: 75.43186180422265\n",
      "Epoch 1797 val loss: 0.6489075943827629\n",
      "Epoch 1797 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1797.pth\n",
      "Epoch 1798 train loss: 0.6551515001868993\n",
      "Epoch 1798 train accuracy: 75.40444200712915\n",
      "Epoch 1798 val loss: 0.6489007071052727\n",
      "Epoch 1798 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1798.pth\n",
      "Epoch 1799 train loss: 0.6550825681668102\n",
      "Epoch 1799 train accuracy: 75.37702221003565\n",
      "Epoch 1799 val loss: 0.648887443209165\n",
      "Epoch 1799 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1799.pth\n",
      "Epoch 1800 train loss: 0.6551460556424501\n",
      "Epoch 1800 train accuracy: 75.40444200712915\n",
      "Epoch 1800 val loss: 0.6488916931771919\n",
      "Epoch 1800 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1800.pth\n",
      "Epoch 1801 train loss: 0.6550754964874502\n",
      "Epoch 1801 train accuracy: 75.40444200712915\n",
      "Epoch 1801 val loss: 0.6488803993714484\n",
      "Epoch 1801 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1801.pth\n",
      "Epoch 1802 train loss: 0.6552011990560251\n",
      "Epoch 1802 train accuracy: 75.37702221003565\n",
      "Epoch 1802 val loss: 0.6488880336676773\n",
      "Epoch 1802 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1802.pth\n",
      "Epoch 1803 train loss: 0.6550966080997074\n",
      "Epoch 1803 train accuracy: 75.29476281875515\n",
      "Epoch 1803 val loss: 0.6488657741758385\n",
      "Epoch 1803 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1803.pth\n",
      "Epoch 1804 train loss: 0.6551354751971207\n",
      "Epoch 1804 train accuracy: 75.37702221003565\n",
      "Epoch 1804 val loss: 0.6488398667915087\n",
      "Epoch 1804 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1804.pth\n",
      "Epoch 1805 train loss: 0.6551273166479772\n",
      "Epoch 1805 train accuracy: 75.40444200712915\n",
      "Epoch 1805 val loss: 0.6488601246260499\n",
      "Epoch 1805 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1805.pth\n",
      "Epoch 1806 train loss: 0.655099365468088\n",
      "Epoch 1806 train accuracy: 75.34960241294215\n",
      "Epoch 1806 val loss: 0.6488600074264564\n",
      "Epoch 1806 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1806.pth\n",
      "Epoch 1807 train loss: 0.6550530038055098\n",
      "Epoch 1807 train accuracy: 75.40444200712915\n",
      "Epoch 1807 val loss: 0.6488473916328267\n",
      "Epoch 1807 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1807.pth\n",
      "Epoch 1808 train loss: 0.6550644659355545\n",
      "Epoch 1808 train accuracy: 75.34960241294215\n",
      "Epoch 1808 val loss: 0.6488336295281586\n",
      "Epoch 1808 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1808.pth\n",
      "Epoch 1809 train loss: 0.6551130956300256\n",
      "Epoch 1809 train accuracy: 75.43186180422265\n",
      "Epoch 1809 val loss: 0.648835038570197\n",
      "Epoch 1809 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1809.pth\n",
      "Epoch 1810 train loss: 0.6551103727532583\n",
      "Epoch 1810 train accuracy: 75.45928160131615\n",
      "Epoch 1810 val loss: 0.6488400581047723\n",
      "Epoch 1810 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1810.pth\n",
      "Epoch 1811 train loss: 0.6550872223615124\n",
      "Epoch 1811 train accuracy: 75.43186180422265\n",
      "Epoch 1811 val loss: 0.6488544928204072\n",
      "Epoch 1811 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1811.pth\n",
      "Epoch 1812 train loss: 0.6551112424124751\n",
      "Epoch 1812 train accuracy: 75.43186180422265\n",
      "Epoch 1812 val loss: 0.6488432491100148\n",
      "Epoch 1812 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1812.pth\n",
      "Epoch 1813 train loss: 0.6550954610043973\n",
      "Epoch 1813 train accuracy: 75.34960241294215\n",
      "Epoch 1813 val loss: 0.6488339291199258\n",
      "Epoch 1813 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1813.pth\n",
      "Epoch 1814 train loss: 0.6550084025713435\n",
      "Epoch 1814 train accuracy: 75.40444200712915\n",
      "Epoch 1814 val loss: 0.648827051939933\n",
      "Epoch 1814 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1814.pth\n",
      "Epoch 1815 train loss: 0.6550545654537385\n",
      "Epoch 1815 train accuracy: 75.43186180422265\n",
      "Epoch 1815 val loss: 0.6488235433046755\n",
      "Epoch 1815 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1815.pth\n",
      "Epoch 1816 train loss: 0.6550896238993135\n",
      "Epoch 1816 train accuracy: 75.40444200712915\n",
      "Epoch 1816 val loss: 0.6488415186636542\n",
      "Epoch 1816 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1816.pth\n",
      "Epoch 1817 train loss: 0.6550830927465046\n",
      "Epoch 1817 train accuracy: 75.43186180422265\n",
      "Epoch 1817 val loss: 0.6488318388889495\n",
      "Epoch 1817 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1817.pth\n",
      "Epoch 1818 train loss: 0.6550827087801799\n",
      "Epoch 1818 train accuracy: 75.34960241294215\n",
      "Epoch 1818 val loss: 0.6488529658435207\n",
      "Epoch 1818 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1818.pth\n",
      "Epoch 1819 train loss: 0.6550732464774659\n",
      "Epoch 1819 train accuracy: 75.34960241294215\n",
      "Epoch 1819 val loss: 0.6488330161297008\n",
      "Epoch 1819 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1819.pth\n",
      "Epoch 1820 train loss: 0.655052944233543\n",
      "Epoch 1820 train accuracy: 75.43186180422265\n",
      "Epoch 1820 val loss: 0.6488278055269467\n",
      "Epoch 1820 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1820.pth\n",
      "Epoch 1821 train loss: 0.6550675280261458\n",
      "Epoch 1821 train accuracy: 75.43186180422265\n",
      "Epoch 1821 val loss: 0.6488209096224684\n",
      "Epoch 1821 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1821.pth\n",
      "Epoch 1822 train loss: 0.6550199119210766\n",
      "Epoch 1822 train accuracy: 75.43186180422265\n",
      "Epoch 1822 val loss: 0.6488193243153786\n",
      "Epoch 1822 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1822.pth\n",
      "Epoch 1823 train loss: 0.6550589361015642\n",
      "Epoch 1823 train accuracy: 75.29476281875515\n",
      "Epoch 1823 val loss: 0.6487952561950997\n",
      "Epoch 1823 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1823.pth\n",
      "Epoch 1824 train loss: 0.6550531582089892\n",
      "Epoch 1824 train accuracy: 75.43186180422265\n",
      "Epoch 1824 val loss: 0.6487824070806566\n",
      "Epoch 1824 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1824.pth\n",
      "Epoch 1825 train loss: 0.6550346560318742\n",
      "Epoch 1825 train accuracy: 75.37702221003565\n",
      "Epoch 1825 val loss: 0.6487771095217842\n",
      "Epoch 1825 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1825.pth\n",
      "Epoch 1826 train loss: 0.6550462253457099\n",
      "Epoch 1826 train accuracy: 75.40444200712915\n",
      "Epoch 1826 val loss: 0.6488019694623194\n",
      "Epoch 1826 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1826.pth\n",
      "Epoch 1827 train loss: 0.6550887202549922\n",
      "Epoch 1827 train accuracy: 75.43186180422265\n",
      "Epoch 1827 val loss: 0.6487925298708049\n",
      "Epoch 1827 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1827.pth\n",
      "Epoch 1828 train loss: 0.655086047555271\n",
      "Epoch 1828 train accuracy: 75.34960241294215\n",
      "Epoch 1828 val loss: 0.6487858382690894\n",
      "Epoch 1828 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1828.pth\n",
      "Epoch 1829 train loss: 0.6550371516005773\n",
      "Epoch 1829 train accuracy: 75.45928160131615\n",
      "Epoch 1829 val loss: 0.6487921196967363\n",
      "Epoch 1829 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1829.pth\n",
      "Epoch 1830 train loss: 0.6551186912284609\n",
      "Epoch 1830 train accuracy: 75.40444200712915\n",
      "Epoch 1830 val loss: 0.6487892825940722\n",
      "Epoch 1830 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1830.pth\n",
      "Epoch 1831 train loss: 0.654974516579195\n",
      "Epoch 1831 train accuracy: 75.34960241294215\n",
      "Epoch 1831 val loss: 0.6487952120798198\n",
      "Epoch 1831 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1831.pth\n",
      "Epoch 1832 train loss: 0.6549750733303658\n",
      "Epoch 1832 train accuracy: 75.45928160131615\n",
      "Epoch 1832 val loss: 0.6487662450067306\n",
      "Epoch 1832 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1832.pth\n",
      "Epoch 1833 train loss: 0.6550482237352091\n",
      "Epoch 1833 train accuracy: 75.37702221003565\n",
      "Epoch 1833 val loss: 0.6487574008734602\n",
      "Epoch 1833 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1833.pth\n",
      "Epoch 1834 train loss: 0.6550111393525935\n",
      "Epoch 1834 train accuracy: 75.37702221003565\n",
      "Epoch 1834 val loss: 0.6487738700877679\n",
      "Epoch 1834 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1834.pth\n",
      "Epoch 1835 train loss: 0.654976539738607\n",
      "Epoch 1835 train accuracy: 75.40444200712915\n",
      "Epoch 1835 val loss: 0.6487607904954961\n",
      "Epoch 1835 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1835.pth\n",
      "Epoch 1836 train loss: 0.6550096982861298\n",
      "Epoch 1836 train accuracy: 75.34960241294215\n",
      "Epoch 1836 val loss: 0.6487553457876569\n",
      "Epoch 1836 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1836.pth\n",
      "Epoch 1837 train loss: 0.6550066383849633\n",
      "Epoch 1837 train accuracy: 75.43186180422265\n",
      "Epoch 1837 val loss: 0.6487650149746945\n",
      "Epoch 1837 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1837.pth\n",
      "Epoch 1838 train loss: 0.6549762718444854\n",
      "Epoch 1838 train accuracy: 75.37702221003565\n",
      "Epoch 1838 val loss: 0.6487772882376847\n",
      "Epoch 1838 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1838.pth\n",
      "Epoch 1839 train loss: 0.6549580943885079\n",
      "Epoch 1839 train accuracy: 75.40444200712915\n",
      "Epoch 1839 val loss: 0.6487496361920708\n",
      "Epoch 1839 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1839.pth\n",
      "Epoch 1840 train loss: 0.6549934290284127\n",
      "Epoch 1840 train accuracy: 75.45928160131615\n",
      "Epoch 1840 val loss: 0.6487806077654424\n",
      "Epoch 1840 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1840.pth\n",
      "Epoch 1841 train loss: 0.654996999261672\n",
      "Epoch 1841 train accuracy: 75.40444200712915\n",
      "Epoch 1841 val loss: 0.6487532813886279\n",
      "Epoch 1841 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1841.pth\n",
      "Epoch 1842 train loss: 0.6549282318732718\n",
      "Epoch 1842 train accuracy: 75.45928160131615\n",
      "Epoch 1842 val loss: 0.6487741118395015\n",
      "Epoch 1842 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1842.pth\n",
      "Epoch 1843 train loss: 0.654938300254575\n",
      "Epoch 1843 train accuracy: 75.40444200712915\n",
      "Epoch 1843 val loss: 0.6487682750938755\n",
      "Epoch 1843 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1843.pth\n",
      "Epoch 1844 train loss: 0.6549210044833129\n",
      "Epoch 1844 train accuracy: 75.43186180422265\n",
      "Epoch 1844 val loss: 0.648763636715318\n",
      "Epoch 1844 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1844.pth\n",
      "Epoch 1845 train loss: 0.6549658100202418\n",
      "Epoch 1845 train accuracy: 75.45928160131615\n",
      "Epoch 1845 val loss: 0.6487490647521458\n",
      "Epoch 1845 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1845.pth\n",
      "Epoch 1846 train loss: 0.6549686239705536\n",
      "Epoch 1846 train accuracy: 75.40444200712915\n",
      "Epoch 1846 val loss: 0.6487452859353078\n",
      "Epoch 1846 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1846.pth\n",
      "Epoch 1847 train loss: 0.654979545786454\n",
      "Epoch 1847 train accuracy: 75.40444200712915\n",
      "Epoch 1847 val loss: 0.6487368985422348\n",
      "Epoch 1847 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1847.pth\n",
      "Epoch 1848 train loss: 0.6549310406768009\n",
      "Epoch 1848 train accuracy: 75.40444200712915\n",
      "Epoch 1848 val loss: 0.6487379039784795\n",
      "Epoch 1848 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1848.pth\n",
      "Epoch 1849 train loss: 0.6549601518924821\n",
      "Epoch 1849 train accuracy: 75.40444200712915\n",
      "Epoch 1849 val loss: 0.6487522925201216\n",
      "Epoch 1849 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1849.pth\n",
      "Epoch 1850 train loss: 0.6549716787412763\n",
      "Epoch 1850 train accuracy: 75.37702221003565\n",
      "Epoch 1850 val loss: 0.648729051512323\n",
      "Epoch 1850 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1850.pth\n",
      "Epoch 1851 train loss: 0.6549387100038299\n",
      "Epoch 1851 train accuracy: 75.37702221003565\n",
      "Epoch 1851 val loss: 0.6487182614050413\n",
      "Epoch 1851 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1851.pth\n",
      "Epoch 1852 train loss: 0.6548505259775802\n",
      "Epoch 1852 train accuracy: 75.37702221003565\n",
      "Epoch 1852 val loss: 0.6487048488894576\n",
      "Epoch 1852 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1852.pth\n",
      "Epoch 1853 train loss: 0.6549011206483109\n",
      "Epoch 1853 train accuracy: 75.43186180422265\n",
      "Epoch 1853 val loss: 0.6487304330068199\n",
      "Epoch 1853 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1853.pth\n",
      "Epoch 1854 train loss: 0.6549473864663589\n",
      "Epoch 1854 train accuracy: 75.40444200712915\n",
      "Epoch 1854 val loss: 0.6487022054038549\n",
      "Epoch 1854 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1854.pth\n",
      "Epoch 1855 train loss: 0.654931780244959\n",
      "Epoch 1855 train accuracy: 75.34960241294215\n",
      "Epoch 1855 val loss: 0.6487099865549489\n",
      "Epoch 1855 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1855.pth\n",
      "Epoch 1856 train loss: 0.6549012235512859\n",
      "Epoch 1856 train accuracy: 75.37702221003565\n",
      "Epoch 1856 val loss: 0.6487009895867423\n",
      "Epoch 1856 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1856.pth\n",
      "Epoch 1857 train loss: 0.654930192944512\n",
      "Epoch 1857 train accuracy: 75.32218261584865\n",
      "Epoch 1857 val loss: 0.6486944125867203\n",
      "Epoch 1857 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1857.pth\n",
      "Epoch 1858 train loss: 0.6549301151382295\n",
      "Epoch 1858 train accuracy: 75.43186180422265\n",
      "Epoch 1858 val loss: 0.6486970589153076\n",
      "Epoch 1858 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1858.pth\n",
      "Epoch 1859 train loss: 0.6549412561743929\n",
      "Epoch 1859 train accuracy: 75.34960241294215\n",
      "Epoch 1859 val loss: 0.6487084054633191\n",
      "Epoch 1859 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1859.pth\n",
      "Epoch 1860 train loss: 0.6549365914573795\n",
      "Epoch 1860 train accuracy: 75.34960241294215\n",
      "Epoch 1860 val loss: 0.6486957057526237\n",
      "Epoch 1860 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1860.pth\n",
      "Epoch 1861 train loss: 0.6548858809431917\n",
      "Epoch 1861 train accuracy: 75.40444200712915\n",
      "Epoch 1861 val loss: 0.648692230743013\n",
      "Epoch 1861 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1861.pth\n",
      "Epoch 1862 train loss: 0.6548480046096078\n",
      "Epoch 1862 train accuracy: 75.43186180422265\n",
      "Epoch 1862 val loss: 0.648690058898769\n",
      "Epoch 1862 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1862.pth\n",
      "Epoch 1863 train loss: 0.6549562952040058\n",
      "Epoch 1863 train accuracy: 75.34960241294215\n",
      "Epoch 1863 val loss: 0.6486778818070889\n",
      "Epoch 1863 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1863.pth\n",
      "Epoch 1864 train loss: 0.6549027728145582\n",
      "Epoch 1864 train accuracy: 75.40444200712915\n",
      "Epoch 1864 val loss: 0.6486831070169022\n",
      "Epoch 1864 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1864.pth\n",
      "Epoch 1865 train loss: 0.6549018911951989\n",
      "Epoch 1865 train accuracy: 75.34960241294215\n",
      "Epoch 1865 val loss: 0.6486868145630548\n",
      "Epoch 1865 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1865.pth\n",
      "Epoch 1866 train loss: 0.6548879866798719\n",
      "Epoch 1866 train accuracy: 75.34960241294215\n",
      "Epoch 1866 val loss: 0.6486753176309561\n",
      "Epoch 1866 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1866.pth\n",
      "Epoch 1867 train loss: 0.6549218398633233\n",
      "Epoch 1867 train accuracy: 75.37702221003565\n",
      "Epoch 1867 val loss: 0.6486846232100537\n",
      "Epoch 1867 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1867.pth\n",
      "Epoch 1868 train loss: 0.654902775559509\n",
      "Epoch 1868 train accuracy: 75.32218261584865\n",
      "Epoch 1868 val loss: 0.6486773291896832\n",
      "Epoch 1868 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1868.pth\n",
      "Epoch 1869 train loss: 0.6548796654270407\n",
      "Epoch 1869 train accuracy: 75.48670139840965\n",
      "Epoch 1869 val loss: 0.6486990219472271\n",
      "Epoch 1869 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1869.pth\n",
      "Epoch 1870 train loss: 0.654872367452634\n",
      "Epoch 1870 train accuracy: 75.32218261584865\n",
      "Epoch 1870 val loss: 0.6486611931927895\n",
      "Epoch 1870 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1870.pth\n",
      "Epoch 1871 train loss: 0.6548717833663288\n",
      "Epoch 1871 train accuracy: 75.34960241294215\n",
      "Epoch 1871 val loss: 0.6486854694391552\n",
      "Epoch 1871 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1871.pth\n",
      "Epoch 1872 train loss: 0.6548936425528505\n",
      "Epoch 1872 train accuracy: 75.40444200712915\n",
      "Epoch 1872 val loss: 0.6486993783006543\n",
      "Epoch 1872 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1872.pth\n",
      "Epoch 1873 train loss: 0.654882983647679\n",
      "Epoch 1873 train accuracy: 75.34960241294215\n",
      "Epoch 1873 val loss: 0.648677539864653\n",
      "Epoch 1873 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1873.pth\n",
      "Epoch 1874 train loss: 0.654866178111549\n",
      "Epoch 1874 train accuracy: 75.26734302166165\n",
      "Epoch 1874 val loss: 0.648671159912881\n",
      "Epoch 1874 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1874.pth\n",
      "Epoch 1875 train loss: 0.6547482586057302\n",
      "Epoch 1875 train accuracy: 75.37702221003565\n",
      "Epoch 1875 val loss: 0.648681117417781\n",
      "Epoch 1875 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1875.pth\n",
      "Epoch 1876 train loss: 0.6548569867256702\n",
      "Epoch 1876 train accuracy: 75.43186180422265\n",
      "Epoch 1876 val loss: 0.648654820887666\n",
      "Epoch 1876 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1876.pth\n",
      "Epoch 1877 train loss: 0.6548061794356296\n",
      "Epoch 1877 train accuracy: 75.40444200712915\n",
      "Epoch 1877 val loss: 0.6486709614921558\n",
      "Epoch 1877 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1877.pth\n",
      "Epoch 1878 train loss: 0.6548978661497434\n",
      "Epoch 1878 train accuracy: 75.34960241294215\n",
      "Epoch 1878 val loss: 0.6486610432988719\n",
      "Epoch 1878 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1878.pth\n",
      "Epoch 1879 train loss: 0.6547959062940719\n",
      "Epoch 1879 train accuracy: 75.48670139840965\n",
      "Epoch 1879 val loss: 0.6486833008300317\n",
      "Epoch 1879 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1879.pth\n",
      "Epoch 1880 train loss: 0.65484275417239\n",
      "Epoch 1880 train accuracy: 75.26734302166165\n",
      "Epoch 1880 val loss: 0.6486671085616476\n",
      "Epoch 1880 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1880.pth\n",
      "Epoch 1881 train loss: 0.6548351698244611\n",
      "Epoch 1881 train accuracy: 75.34960241294215\n",
      "Epoch 1881 val loss: 0.6486615385664137\n",
      "Epoch 1881 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1881.pth\n",
      "Epoch 1882 train loss: 0.6548307439018237\n",
      "Epoch 1882 train accuracy: 75.34960241294215\n",
      "Epoch 1882 val loss: 0.6486490852150478\n",
      "Epoch 1882 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1882.pth\n",
      "Epoch 1883 train loss: 0.6548559612088036\n",
      "Epoch 1883 train accuracy: 75.37702221003565\n",
      "Epoch 1883 val loss: 0.648644084306924\n",
      "Epoch 1883 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1883.pth\n",
      "Epoch 1884 train loss: 0.6548279389216188\n",
      "Epoch 1884 train accuracy: 75.34960241294215\n",
      "Epoch 1884 val loss: 0.648642551546034\n",
      "Epoch 1884 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1884.pth\n",
      "Epoch 1885 train loss: 0.6547783124342299\n",
      "Epoch 1885 train accuracy: 75.40444200712915\n",
      "Epoch 1885 val loss: 0.6486337098636126\n",
      "Epoch 1885 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1885.pth\n",
      "Epoch 1886 train loss: 0.6548015403708345\n",
      "Epoch 1886 train accuracy: 75.37702221003565\n",
      "Epoch 1886 val loss: 0.6486492223645511\n",
      "Epoch 1886 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1886.pth\n",
      "Epoch 1887 train loss: 0.6548304071878654\n",
      "Epoch 1887 train accuracy: 75.37702221003565\n",
      "Epoch 1887 val loss: 0.648647723131274\n",
      "Epoch 1887 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1887.pth\n",
      "Epoch 1888 train loss: 0.6548092593030449\n",
      "Epoch 1888 train accuracy: 75.48670139840965\n",
      "Epoch 1888 val loss: 0.6486606878277502\n",
      "Epoch 1888 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1888.pth\n",
      "Epoch 1889 train loss: 0.6548082382467232\n",
      "Epoch 1889 train accuracy: 75.34960241294215\n",
      "Epoch 1889 val loss: 0.648646253896387\n",
      "Epoch 1889 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1889.pth\n",
      "Epoch 1890 train loss: 0.6547187558914486\n",
      "Epoch 1890 train accuracy: 75.34960241294215\n",
      "Epoch 1890 val loss: 0.6486399612928692\n",
      "Epoch 1890 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1890.pth\n",
      "Epoch 1891 train loss: 0.6547999642462584\n",
      "Epoch 1891 train accuracy: 75.40444200712915\n",
      "Epoch 1891 val loss: 0.6486525098352056\n",
      "Epoch 1891 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1891.pth\n",
      "Epoch 1892 train loss: 0.6547837036808855\n",
      "Epoch 1892 train accuracy: 75.32218261584865\n",
      "Epoch 1892 val loss: 0.6486240747923914\n",
      "Epoch 1892 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1892.pth\n",
      "Epoch 1893 train loss: 0.6547902868897245\n",
      "Epoch 1893 train accuracy: 75.40444200712915\n",
      "Epoch 1893 val loss: 0.6486164643184135\n",
      "Epoch 1893 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1893.pth\n",
      "Epoch 1894 train loss: 0.6547875156985563\n",
      "Epoch 1894 train accuracy: 75.40444200712915\n",
      "Epoch 1894 val loss: 0.6486198461957668\n",
      "Epoch 1894 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1894.pth\n",
      "Epoch 1895 train loss: 0.6547836329330478\n",
      "Epoch 1895 train accuracy: 75.34960241294215\n",
      "Epoch 1895 val loss: 0.648616620780606\n",
      "Epoch 1895 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1895.pth\n",
      "Epoch 1896 train loss: 0.6547219189243358\n",
      "Epoch 1896 train accuracy: 75.34960241294215\n",
      "Epoch 1896 val loss: 0.6486092737238658\n",
      "Epoch 1896 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1896.pth\n",
      "Epoch 1897 train loss: 0.6547378426777166\n",
      "Epoch 1897 train accuracy: 75.40444200712915\n",
      "Epoch 1897 val loss: 0.6486144769740733\n",
      "Epoch 1897 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1897.pth\n",
      "Epoch 1898 train loss: 0.6548068223096299\n",
      "Epoch 1898 train accuracy: 75.34960241294215\n",
      "Epoch 1898 val loss: 0.6485916001624182\n",
      "Epoch 1898 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1898.pth\n",
      "Epoch 1899 train loss: 0.6547322365406313\n",
      "Epoch 1899 train accuracy: 75.37702221003565\n",
      "Epoch 1899 val loss: 0.6486357226477641\n",
      "Epoch 1899 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1899.pth\n",
      "Epoch 1900 train loss: 0.6547442614019179\n",
      "Epoch 1900 train accuracy: 75.37702221003565\n",
      "Epoch 1900 val loss: 0.6486131281248833\n",
      "Epoch 1900 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1900.pth\n",
      "Epoch 1901 train loss: 0.6547619303394305\n",
      "Epoch 1901 train accuracy: 75.34960241294215\n",
      "Epoch 1901 val loss: 0.648597150746929\n",
      "Epoch 1901 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1901.pth\n",
      "Epoch 1902 train loss: 0.6547575991339328\n",
      "Epoch 1902 train accuracy: 75.43186180422265\n",
      "Epoch 1902 val loss: 0.6486179248282784\n",
      "Epoch 1902 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1902.pth\n",
      "Epoch 1903 train loss: 0.6549148993697345\n",
      "Epoch 1903 train accuracy: 75.37702221003565\n",
      "Epoch 1903 val loss: 0.6485870969726851\n",
      "Epoch 1903 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1903.pth\n",
      "Epoch 1904 train loss: 0.6547092185927588\n",
      "Epoch 1904 train accuracy: 75.37702221003565\n",
      "Epoch 1904 val loss: 0.6486011903340879\n",
      "Epoch 1904 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1904.pth\n",
      "Epoch 1905 train loss: 0.6547410894642797\n",
      "Epoch 1905 train accuracy: 75.51412119550315\n",
      "Epoch 1905 val loss: 0.6486393960290834\n",
      "Epoch 1905 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1905.pth\n",
      "Epoch 1906 train loss: 0.654710671880789\n",
      "Epoch 1906 train accuracy: 75.32218261584865\n",
      "Epoch 1906 val loss: 0.6486086017991367\n",
      "Epoch 1906 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1906.pth\n",
      "Epoch 1907 train loss: 0.6547860147823629\n",
      "Epoch 1907 train accuracy: 75.34960241294215\n",
      "Epoch 1907 val loss: 0.6486045977983036\n",
      "Epoch 1907 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1907.pth\n",
      "Epoch 1908 train loss: 0.6547337252352583\n",
      "Epoch 1908 train accuracy: 75.37702221003565\n",
      "Epoch 1908 val loss: 0.6486140522909792\n",
      "Epoch 1908 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_1908.pth\n",
      "Epoch 1909 train loss: 0.654734330055745\n",
      "Epoch 1909 train accuracy: 75.40444200712915\n",
      "Epoch 1909 val loss: 0.6485990152547234\n",
      "Epoch 1909 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1909.pth\n",
      "Epoch 1910 train loss: 0.6546996327182442\n",
      "Epoch 1910 train accuracy: 75.37702221003565\n",
      "Epoch 1910 val loss: 0.6486000819621902\n",
      "Epoch 1910 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1910.pth\n",
      "Epoch 1911 train loss: 0.6547503734759071\n",
      "Epoch 1911 train accuracy: 75.40444200712915\n",
      "Epoch 1911 val loss: 0.6485830497388777\n",
      "Epoch 1911 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1911.pth\n",
      "Epoch 1912 train loss: 0.6547196024146519\n",
      "Epoch 1912 train accuracy: 75.43186180422265\n",
      "Epoch 1912 val loss: 0.6486071062911498\n",
      "Epoch 1912 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1912.pth\n",
      "Epoch 1913 train loss: 0.6546721008785984\n",
      "Epoch 1913 train accuracy: 75.34960241294215\n",
      "Epoch 1913 val loss: 0.6485736844571013\n",
      "Epoch 1913 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1913.pth\n",
      "Epoch 1914 train loss: 0.6547103901965576\n",
      "Epoch 1914 train accuracy: 75.40444200712915\n",
      "Epoch 1914 val loss: 0.6485902141583594\n",
      "Epoch 1914 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1914.pth\n",
      "Epoch 1915 train loss: 0.65468497304736\n",
      "Epoch 1915 train accuracy: 75.37702221003565\n",
      "Epoch 1915 val loss: 0.6485673111716383\n",
      "Epoch 1915 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1915.pth\n",
      "Epoch 1916 train loss: 0.654695361591222\n",
      "Epoch 1916 train accuracy: 75.34960241294215\n",
      "Epoch 1916 val loss: 0.648553063700858\n",
      "Epoch 1916 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1916.pth\n",
      "Epoch 1917 train loss: 0.6547018387273216\n",
      "Epoch 1917 train accuracy: 75.45928160131615\n",
      "Epoch 1917 val loss: 0.6485434228456334\n",
      "Epoch 1917 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1917.pth\n",
      "Epoch 1918 train loss: 0.6547089082662735\n",
      "Epoch 1918 train accuracy: 75.37702221003565\n",
      "Epoch 1918 val loss: 0.6485584985072675\n",
      "Epoch 1918 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1918.pth\n",
      "Epoch 1919 train loss: 0.6546972398891261\n",
      "Epoch 1919 train accuracy: 75.43186180422265\n",
      "Epoch 1919 val loss: 0.6485819197014758\n",
      "Epoch 1919 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1919.pth\n",
      "Epoch 1920 train loss: 0.6546546677290871\n",
      "Epoch 1920 train accuracy: 75.32218261584865\n",
      "Epoch 1920 val loss: 0.6485606817234504\n",
      "Epoch 1920 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1920.pth\n",
      "Epoch 1921 train loss: 0.6546597971597261\n",
      "Epoch 1921 train accuracy: 75.43186180422265\n",
      "Epoch 1921 val loss: 0.6485609683747354\n",
      "Epoch 1921 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1921.pth\n",
      "Epoch 1922 train loss: 0.654646332849536\n",
      "Epoch 1922 train accuracy: 75.45928160131615\n",
      "Epoch 1922 val loss: 0.648570363949004\n",
      "Epoch 1922 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1922.pth\n",
      "Epoch 1923 train loss: 0.6546360026195384\n",
      "Epoch 1923 train accuracy: 75.43186180422265\n",
      "Epoch 1923 val loss: 0.6485902254322642\n",
      "Epoch 1923 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1923.pth\n",
      "Epoch 1924 train loss: 0.6546479293978528\n",
      "Epoch 1924 train accuracy: 75.37702221003565\n",
      "Epoch 1924 val loss: 0.6485711949338254\n",
      "Epoch 1924 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1924.pth\n",
      "Epoch 1925 train loss: 0.6546798468028244\n",
      "Epoch 1925 train accuracy: 75.45928160131615\n",
      "Epoch 1925 val loss: 0.6485778050203073\n",
      "Epoch 1925 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1925.pth\n",
      "Epoch 1926 train loss: 0.6546398597981846\n",
      "Epoch 1926 train accuracy: 75.43186180422265\n",
      "Epoch 1926 val loss: 0.6485624507461724\n",
      "Epoch 1926 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1926.pth\n",
      "Epoch 1927 train loss: 0.6546747108692663\n",
      "Epoch 1927 train accuracy: 75.45928160131615\n",
      "Epoch 1927 val loss: 0.6485640110546037\n",
      "Epoch 1927 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1927.pth\n",
      "Epoch 1928 train loss: 0.6546679356282479\n",
      "Epoch 1928 train accuracy: 75.40444200712915\n",
      "Epoch 1928 val loss: 0.6485547669427959\n",
      "Epoch 1928 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1928.pth\n",
      "Epoch 1929 train loss: 0.654661973644244\n",
      "Epoch 1929 train accuracy: 75.43186180422265\n",
      "Epoch 1929 val loss: 0.6485520634604128\n",
      "Epoch 1929 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1929.pth\n",
      "Epoch 1930 train loss: 0.6546168839068789\n",
      "Epoch 1930 train accuracy: 75.40444200712915\n",
      "Epoch 1930 val loss: 0.6485357883533365\n",
      "Epoch 1930 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1930.pth\n",
      "Epoch 1931 train loss: 0.6546497080279025\n",
      "Epoch 1931 train accuracy: 75.43186180422265\n",
      "Epoch 1931 val loss: 0.6485356785553066\n",
      "Epoch 1931 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1931.pth\n",
      "Epoch 1932 train loss: 0.654670474887417\n",
      "Epoch 1932 train accuracy: 75.45928160131615\n",
      "Epoch 1932 val loss: 0.6485570389777422\n",
      "Epoch 1932 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1932.pth\n",
      "Epoch 1933 train loss: 0.6546937963810929\n",
      "Epoch 1933 train accuracy: 75.34960241294215\n",
      "Epoch 1933 val loss: 0.6485380426441368\n",
      "Epoch 1933 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1933.pth\n",
      "Epoch 1934 train loss: 0.654618727272017\n",
      "Epoch 1934 train accuracy: 75.43186180422265\n",
      "Epoch 1934 val loss: 0.6485208914076027\n",
      "Epoch 1934 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1934.pth\n",
      "Epoch 1935 train loss: 0.654642849637751\n",
      "Epoch 1935 train accuracy: 75.43186180422265\n",
      "Epoch 1935 val loss: 0.6485361480399182\n",
      "Epoch 1935 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1935.pth\n",
      "Epoch 1936 train loss: 0.6546218878540554\n",
      "Epoch 1936 train accuracy: 75.40444200712915\n",
      "Epoch 1936 val loss: 0.6485159675541677\n",
      "Epoch 1936 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1936.pth\n",
      "Epoch 1937 train loss: 0.6546419739657849\n",
      "Epoch 1937 train accuracy: 75.43186180422265\n",
      "Epoch 1937 val loss: 0.6485204146684784\n",
      "Epoch 1937 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1937.pth\n",
      "Epoch 1938 train loss: 0.6545943808986953\n",
      "Epoch 1938 train accuracy: 75.48670139840965\n",
      "Epoch 1938 val loss: 0.648516630361739\n",
      "Epoch 1938 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1938.pth\n",
      "Epoch 1939 train loss: 0.6546179181324285\n",
      "Epoch 1939 train accuracy: 75.45928160131615\n",
      "Epoch 1939 val loss: 0.6485304321701589\n",
      "Epoch 1939 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1939.pth\n",
      "Epoch 1940 train loss: 0.6546295400904981\n",
      "Epoch 1940 train accuracy: 75.40444200712915\n",
      "Epoch 1940 val loss: 0.648515776485989\n",
      "Epoch 1940 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1940.pth\n",
      "Epoch 1941 train loss: 0.6545909686634938\n",
      "Epoch 1941 train accuracy: 75.40444200712915\n",
      "Epoch 1941 val loss: 0.6485088596022442\n",
      "Epoch 1941 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1941.pth\n",
      "Epoch 1942 train loss: 0.6546692329932723\n",
      "Epoch 1942 train accuracy: 75.45928160131615\n",
      "Epoch 1942 val loss: 0.648496667609403\n",
      "Epoch 1942 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1942.pth\n",
      "Epoch 1943 train loss: 0.6546163109637666\n",
      "Epoch 1943 train accuracy: 75.45928160131615\n",
      "Epoch 1943 val loss: 0.6485054561574208\n",
      "Epoch 1943 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1943.pth\n",
      "Epoch 1944 train loss: 0.6545779652109271\n",
      "Epoch 1944 train accuracy: 75.40444200712915\n",
      "Epoch 1944 val loss: 0.6484959284333807\n",
      "Epoch 1944 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1944.pth\n",
      "Epoch 1945 train loss: 0.6546074830387768\n",
      "Epoch 1945 train accuracy: 75.51412119550315\n",
      "Epoch 1945 val loss: 0.6485218333178445\n",
      "Epoch 1945 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1945.pth\n",
      "Epoch 1946 train loss: 0.6545912362635136\n",
      "Epoch 1946 train accuracy: 75.37702221003565\n",
      "Epoch 1946 val loss: 0.6485119594359084\n",
      "Epoch 1946 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1946.pth\n",
      "Epoch 1947 train loss: 0.6546038909112675\n",
      "Epoch 1947 train accuracy: 75.43186180422265\n",
      "Epoch 1947 val loss: 0.6485162771453983\n",
      "Epoch 1947 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1947.pth\n",
      "Epoch 1948 train loss: 0.6545996962180525\n",
      "Epoch 1948 train accuracy: 75.40444200712915\n",
      "Epoch 1948 val loss: 0.6485188914168822\n",
      "Epoch 1948 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1948.pth\n",
      "Epoch 1949 train loss: 0.654517015769032\n",
      "Epoch 1949 train accuracy: 75.48670139840965\n",
      "Epoch 1949 val loss: 0.6484995210837377\n",
      "Epoch 1949 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1949.pth\n",
      "Epoch 1950 train loss: 0.6545464230309191\n",
      "Epoch 1950 train accuracy: 75.40444200712915\n",
      "Epoch 1950 val loss: 0.6485006319064843\n",
      "Epoch 1950 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1950.pth\n",
      "Epoch 1951 train loss: 0.6545614520774076\n",
      "Epoch 1951 train accuracy: 75.43186180422265\n",
      "Epoch 1951 val loss: 0.6484871577275427\n",
      "Epoch 1951 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1951.pth\n",
      "Epoch 1952 train loss: 0.6545913629397228\n",
      "Epoch 1952 train accuracy: 75.45928160131615\n",
      "Epoch 1952 val loss: 0.6484950413241198\n",
      "Epoch 1952 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1952.pth\n",
      "Epoch 1953 train loss: 0.6545229604827207\n",
      "Epoch 1953 train accuracy: 75.48670139840965\n",
      "Epoch 1953 val loss: 0.6485239810457355\n",
      "Epoch 1953 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1953.pth\n",
      "Epoch 1954 train loss: 0.6546203988489875\n",
      "Epoch 1954 train accuracy: 75.45928160131615\n",
      "Epoch 1954 val loss: 0.6484990170421568\n",
      "Epoch 1954 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1954.pth\n",
      "Epoch 1955 train loss: 0.6546184398037823\n",
      "Epoch 1955 train accuracy: 75.45928160131615\n",
      "Epoch 1955 val loss: 0.6485028906088126\n",
      "Epoch 1955 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1955.pth\n",
      "Epoch 1956 train loss: 0.6544664974340744\n",
      "Epoch 1956 train accuracy: 75.40444200712915\n",
      "Epoch 1956 val loss: 0.6485041610308384\n",
      "Epoch 1956 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1956.pth\n",
      "Epoch 1957 train loss: 0.6545649939134979\n",
      "Epoch 1957 train accuracy: 75.45928160131615\n",
      "Epoch 1957 val loss: 0.6485095693680801\n",
      "Epoch 1957 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1957.pth\n",
      "Epoch 1958 train loss: 0.6545522781579118\n",
      "Epoch 1958 train accuracy: 75.48670139840965\n",
      "Epoch 1958 val loss: 0.6485116453351158\n",
      "Epoch 1958 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1958.pth\n",
      "Epoch 1959 train loss: 0.6545155212087067\n",
      "Epoch 1959 train accuracy: 75.40444200712915\n",
      "Epoch 1959 val loss: 0.6484731267157354\n",
      "Epoch 1959 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1959.pth\n",
      "Epoch 1960 train loss: 0.6545573501079752\n",
      "Epoch 1960 train accuracy: 75.45928160131615\n",
      "Epoch 1960 val loss: 0.648482583267124\n",
      "Epoch 1960 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1960.pth\n",
      "Epoch 1961 train loss: 0.6545585520369442\n",
      "Epoch 1961 train accuracy: 75.51412119550315\n",
      "Epoch 1961 val loss: 0.6484888019530397\n",
      "Epoch 1961 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1961.pth\n",
      "Epoch 1962 train loss: 0.6545766655747828\n",
      "Epoch 1962 train accuracy: 75.45928160131615\n",
      "Epoch 1962 val loss: 0.648489543383843\n",
      "Epoch 1962 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1962.pth\n",
      "Epoch 1963 train loss: 0.6545713455334567\n",
      "Epoch 1963 train accuracy: 75.48670139840965\n",
      "Epoch 1963 val loss: 0.6484845458088737\n",
      "Epoch 1963 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1963.pth\n",
      "Epoch 1964 train loss: 0.6545065192407683\n",
      "Epoch 1964 train accuracy: 75.45928160131615\n",
      "Epoch 1964 val loss: 0.6484753315974223\n",
      "Epoch 1964 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1964.pth\n",
      "Epoch 1965 train loss: 0.6545665315270686\n",
      "Epoch 1965 train accuracy: 75.45928160131615\n",
      "Epoch 1965 val loss: 0.6484838135932621\n",
      "Epoch 1965 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1965.pth\n",
      "Epoch 1966 train loss: 0.6546109102731734\n",
      "Epoch 1966 train accuracy: 75.48670139840965\n",
      "Epoch 1966 val loss: 0.6484797869465853\n",
      "Epoch 1966 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1966.pth\n",
      "Epoch 1967 train loss: 0.6546427858830021\n",
      "Epoch 1967 train accuracy: 75.40444200712915\n",
      "Epoch 1967 val loss: 0.6484545305567352\n",
      "Epoch 1967 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1967.pth\n",
      "Epoch 1968 train loss: 0.6545289929041214\n",
      "Epoch 1968 train accuracy: 75.48670139840965\n",
      "Epoch 1968 val loss: 0.6484579631176434\n",
      "Epoch 1968 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1968.pth\n",
      "Epoch 1969 train loss: 0.654531437184727\n",
      "Epoch 1969 train accuracy: 75.45928160131615\n",
      "Epoch 1969 val loss: 0.6484821911313032\n",
      "Epoch 1969 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1969.pth\n",
      "Epoch 1970 train loss: 0.6545785185799264\n",
      "Epoch 1970 train accuracy: 75.45928160131615\n",
      "Epoch 1970 val loss: 0.6484780674310107\n",
      "Epoch 1970 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1970.pth\n",
      "Epoch 1971 train loss: 0.6545359372046956\n",
      "Epoch 1971 train accuracy: 75.37702221003565\n",
      "Epoch 1971 val loss: 0.6484668543072123\n",
      "Epoch 1971 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1971.pth\n",
      "Epoch 1972 train loss: 0.6544029626733902\n",
      "Epoch 1972 train accuracy: 75.45928160131615\n",
      "Epoch 1972 val loss: 0.64845261967888\n",
      "Epoch 1972 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1972.pth\n",
      "Epoch 1973 train loss: 0.6544811855838225\n",
      "Epoch 1973 train accuracy: 75.48670139840965\n",
      "Epoch 1973 val loss: 0.6484374750993753\n",
      "Epoch 1973 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1973.pth\n",
      "Epoch 1974 train loss: 0.6545166946097947\n",
      "Epoch 1974 train accuracy: 75.45928160131615\n",
      "Epoch 1974 val loss: 0.6484570939485964\n",
      "Epoch 1974 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1974.pth\n",
      "Epoch 1975 train loss: 0.6544846278991092\n",
      "Epoch 1975 train accuracy: 75.51412119550315\n",
      "Epoch 1975 val loss: 0.6484740686259771\n",
      "Epoch 1975 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1975.pth\n",
      "Epoch 1976 train loss: 0.65446905102254\n",
      "Epoch 1976 train accuracy: 75.51412119550315\n",
      "Epoch 1976 val loss: 0.6484497340494081\n",
      "Epoch 1976 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1976.pth\n",
      "Epoch 1977 train loss: 0.6545022186218646\n",
      "Epoch 1977 train accuracy: 75.45928160131615\n",
      "Epoch 1977 val loss: 0.6484497554208103\n",
      "Epoch 1977 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1977.pth\n",
      "Epoch 1978 train loss: 0.6544694573406065\n",
      "Epoch 1978 train accuracy: 75.48670139840965\n",
      "Epoch 1978 val loss: 0.648438612293256\n",
      "Epoch 1978 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1978.pth\n",
      "Epoch 1979 train loss: 0.6545050759848795\n",
      "Epoch 1979 train accuracy: 75.45928160131615\n",
      "Epoch 1979 val loss: 0.6484441678774985\n",
      "Epoch 1979 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1979.pth\n",
      "Epoch 1980 train loss: 0.6544587012511074\n",
      "Epoch 1980 train accuracy: 75.48670139840965\n",
      "Epoch 1980 val loss: 0.6484534484579375\n",
      "Epoch 1980 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1980.pth\n",
      "Epoch 1981 train loss: 0.6544892337957495\n",
      "Epoch 1981 train accuracy: 75.54154099259665\n",
      "Epoch 1981 val loss: 0.6484493730883849\n",
      "Epoch 1981 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1981.pth\n",
      "Epoch 1982 train loss: 0.6544301195331571\n",
      "Epoch 1982 train accuracy: 75.45928160131615\n",
      "Epoch 1982 val loss: 0.6484798145921606\n",
      "Epoch 1982 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1982.pth\n",
      "Epoch 1983 train loss: 0.6545372730153695\n",
      "Epoch 1983 train accuracy: 75.51412119550315\n",
      "Epoch 1983 val loss: 0.6484387716964671\n",
      "Epoch 1983 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1983.pth\n",
      "Epoch 1984 train loss: 0.6544225261334264\n",
      "Epoch 1984 train accuracy: 75.51412119550315\n",
      "Epoch 1984 val loss: 0.648436689945428\n",
      "Epoch 1984 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1984.pth\n",
      "Epoch 1985 train loss: 0.6544368827486771\n",
      "Epoch 1985 train accuracy: 75.48670139840965\n",
      "Epoch 1985 val loss: 0.6484272593730375\n",
      "Epoch 1985 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1985.pth\n",
      "Epoch 1986 train loss: 0.6543914978964287\n",
      "Epoch 1986 train accuracy: 75.45928160131615\n",
      "Epoch 1986 val loss: 0.648448875958198\n",
      "Epoch 1986 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1986.pth\n",
      "Epoch 1987 train loss: 0.6544856492495328\n",
      "Epoch 1987 train accuracy: 75.45928160131615\n",
      "Epoch 1987 val loss: 0.6484556452028061\n",
      "Epoch 1987 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1987.pth\n",
      "Epoch 1988 train loss: 0.6544749861615792\n",
      "Epoch 1988 train accuracy: 75.48670139840965\n",
      "Epoch 1988 val loss: 0.6484344032053885\n",
      "Epoch 1988 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1988.pth\n",
      "Epoch 1989 train loss: 0.6544657213646069\n",
      "Epoch 1989 train accuracy: 75.51412119550315\n",
      "Epoch 1989 val loss: 0.6484196350762719\n",
      "Epoch 1989 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1989.pth\n",
      "Epoch 1990 train loss: 0.6544624823390653\n",
      "Epoch 1990 train accuracy: 75.48670139840965\n",
      "Epoch 1990 val loss: 0.6484525297817431\n",
      "Epoch 1990 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1990.pth\n",
      "Epoch 1991 train loss: 0.6544577653209368\n",
      "Epoch 1991 train accuracy: 75.48670139840965\n",
      "Epoch 1991 val loss: 0.6484216240871894\n",
      "Epoch 1991 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1991.pth\n",
      "Epoch 1992 train loss: 0.6545164460283622\n",
      "Epoch 1992 train accuracy: 75.45928160131615\n",
      "Epoch 1992 val loss: 0.6484094210165111\n",
      "Epoch 1992 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1992.pth\n",
      "Epoch 1993 train loss: 0.6544492432128703\n",
      "Epoch 1993 train accuracy: 75.45928160131615\n",
      "Epoch 1993 val loss: 0.6484269328219326\n",
      "Epoch 1993 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_1993.pth\n",
      "Epoch 1994 train loss: 0.6544522765631738\n",
      "Epoch 1994 train accuracy: 75.51412119550315\n",
      "Epoch 1994 val loss: 0.6484156387220872\n",
      "Epoch 1994 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1994.pth\n",
      "Epoch 1995 train loss: 0.6545052274146623\n",
      "Epoch 1995 train accuracy: 75.48670139840965\n",
      "Epoch 1995 val loss: 0.648414745926857\n",
      "Epoch 1995 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1995.pth\n",
      "Epoch 1996 train loss: 0.6544364513012401\n",
      "Epoch 1996 train accuracy: 75.48670139840965\n",
      "Epoch 1996 val loss: 0.6484106279125339\n",
      "Epoch 1996 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1996.pth\n",
      "Epoch 1997 train loss: 0.6544280834659412\n",
      "Epoch 1997 train accuracy: 75.54154099259665\n",
      "Epoch 1997 val loss: 0.6483953691234714\n",
      "Epoch 1997 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1997.pth\n",
      "Epoch 1998 train loss: 0.6543830963047711\n",
      "Epoch 1998 train accuracy: 75.51412119550315\n",
      "Epoch 1998 val loss: 0.6483969847230535\n",
      "Epoch 1998 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1998.pth\n",
      "Epoch 1999 train loss: 0.6544546031703552\n",
      "Epoch 1999 train accuracy: 75.45928160131615\n",
      "Epoch 1999 val loss: 0.6483897184462923\n",
      "Epoch 1999 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_1999.pth\n",
      "Epoch 2000 train loss: 0.6545518597816689\n",
      "Epoch 2000 train accuracy: 75.54154099259665\n",
      "Epoch 2000 val loss: 0.6483901219540521\n",
      "Epoch 2000 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2000.pth\n",
      "Epoch 2001 train loss: 0.6544191908222019\n",
      "Epoch 2001 train accuracy: 75.48670139840965\n",
      "Epoch 2001 val loss: 0.6483935072625938\n",
      "Epoch 2001 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2001.pth\n",
      "Epoch 2002 train loss: 0.6543739049842483\n",
      "Epoch 2002 train accuracy: 75.51412119550315\n",
      "Epoch 2002 val loss: 0.6484023274755791\n",
      "Epoch 2002 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2002.pth\n",
      "Epoch 2003 train loss: 0.6543729483689132\n",
      "Epoch 2003 train accuracy: 75.51412119550315\n",
      "Epoch 2003 val loss: 0.6483955965622475\n",
      "Epoch 2003 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2003.pth\n",
      "Epoch 2004 train loss: 0.6544079443668587\n",
      "Epoch 2004 train accuracy: 75.48670139840965\n",
      "Epoch 2004 val loss: 0.6484142347778145\n",
      "Epoch 2004 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2004.pth\n",
      "Epoch 2005 train loss: 0.6545102314271948\n",
      "Epoch 2005 train accuracy: 75.51412119550315\n",
      "Epoch 2005 val loss: 0.6484043731501228\n",
      "Epoch 2005 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2005.pth\n",
      "Epoch 2006 train loss: 0.654410461470354\n",
      "Epoch 2006 train accuracy: 75.48670139840965\n",
      "Epoch 2006 val loss: 0.64840207170499\n",
      "Epoch 2006 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2006.pth\n",
      "Epoch 2007 train loss: 0.6543498695419546\n",
      "Epoch 2007 train accuracy: 75.48670139840965\n",
      "Epoch 2007 val loss: 0.648395140116152\n",
      "Epoch 2007 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2007.pth\n",
      "Epoch 2008 train loss: 0.6543613341228481\n",
      "Epoch 2008 train accuracy: 75.48670139840965\n",
      "Epoch 2008 val loss: 0.64839478984083\n",
      "Epoch 2008 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2008.pth\n",
      "Epoch 2009 train loss: 0.6543656783341839\n",
      "Epoch 2009 train accuracy: 75.48670139840965\n",
      "Epoch 2009 val loss: 0.6483819862141421\n",
      "Epoch 2009 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2009.pth\n",
      "Epoch 2010 train loss: 0.6543920079997757\n",
      "Epoch 2010 train accuracy: 75.48670139840965\n",
      "Epoch 2010 val loss: 0.648372661714491\n",
      "Epoch 2010 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2010.pth\n",
      "Epoch 2011 train loss: 0.6543949668606123\n",
      "Epoch 2011 train accuracy: 75.48670139840965\n",
      "Epoch 2011 val loss: 0.6483714145265127\n",
      "Epoch 2011 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2011.pth\n",
      "Epoch 2012 train loss: 0.6543857650667951\n",
      "Epoch 2012 train accuracy: 75.48670139840965\n",
      "Epoch 2012 val loss: 0.6483681647989311\n",
      "Epoch 2012 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2012.pth\n",
      "Epoch 2013 train loss: 0.6543544591976362\n",
      "Epoch 2013 train accuracy: 75.48670139840965\n",
      "Epoch 2013 val loss: 0.6483719013631344\n",
      "Epoch 2013 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2013.pth\n",
      "Epoch 2014 train loss: 0.6543828991094702\n",
      "Epoch 2014 train accuracy: 75.48670139840965\n",
      "Epoch 2014 val loss: 0.6483741173226583\n",
      "Epoch 2014 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2014.pth\n",
      "Epoch 2015 train loss: 0.6543772786757663\n",
      "Epoch 2015 train accuracy: 75.48670139840965\n",
      "Epoch 2015 val loss: 0.6483845375478268\n",
      "Epoch 2015 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2015.pth\n",
      "Epoch 2016 train loss: 0.6543696314227163\n",
      "Epoch 2016 train accuracy: 75.54154099259665\n",
      "Epoch 2016 val loss: 0.6483725048601627\n",
      "Epoch 2016 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2016.pth\n",
      "Epoch 2017 train loss: 0.6543741378802479\n",
      "Epoch 2017 train accuracy: 75.48670139840965\n",
      "Epoch 2017 val loss: 0.6483732663879269\n",
      "Epoch 2017 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2017.pth\n",
      "Epoch 2018 train loss: 0.6543659353792145\n",
      "Epoch 2018 train accuracy: 75.48670139840965\n",
      "Epoch 2018 val loss: 0.6483744170124593\n",
      "Epoch 2018 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2018.pth\n",
      "Epoch 2019 train loss: 0.6543431279429218\n",
      "Epoch 2019 train accuracy: 75.48670139840965\n",
      "Epoch 2019 val loss: 0.6483769905998519\n",
      "Epoch 2019 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2019.pth\n",
      "Epoch 2020 train loss: 0.6543227224365661\n",
      "Epoch 2020 train accuracy: 75.51412119550315\n",
      "Epoch 2020 val loss: 0.6483991275492468\n",
      "Epoch 2020 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2020.pth\n",
      "Epoch 2021 train loss: 0.6543621025129891\n",
      "Epoch 2021 train accuracy: 75.54154099259665\n",
      "Epoch 2021 val loss: 0.6483932926172489\n",
      "Epoch 2021 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2021.pth\n",
      "Epoch 2022 train loss: 0.6543476810319382\n",
      "Epoch 2022 train accuracy: 75.48670139840965\n",
      "Epoch 2022 val loss: 0.648371490698896\n",
      "Epoch 2022 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2022.pth\n",
      "Epoch 2023 train loss: 0.6543091638177111\n",
      "Epoch 2023 train accuracy: 75.48670139840965\n",
      "Epoch 2023 val loss: 0.6483767421818093\n",
      "Epoch 2023 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2023.pth\n",
      "Epoch 2024 train loss: 0.6543238335207366\n",
      "Epoch 2024 train accuracy: 75.45928160131615\n",
      "Epoch 2024 val loss: 0.6483659773672882\n",
      "Epoch 2024 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2024.pth\n",
      "Epoch 2025 train loss: 0.6543923943842712\n",
      "Epoch 2025 train accuracy: 75.56896078969015\n",
      "Epoch 2025 val loss: 0.6483712675736139\n",
      "Epoch 2025 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2025.pth\n",
      "Epoch 2026 train loss: 0.6543469069885057\n",
      "Epoch 2026 train accuracy: 75.45928160131615\n",
      "Epoch 2026 val loss: 0.6483579316225491\n",
      "Epoch 2026 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2026.pth\n",
      "Epoch 2027 train loss: 0.6542909533242908\n",
      "Epoch 2027 train accuracy: 75.54154099259665\n",
      "Epoch 2027 val loss: 0.6483551609869066\n",
      "Epoch 2027 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2027.pth\n",
      "Epoch 2028 train loss: 0.6543460031481165\n",
      "Epoch 2028 train accuracy: 75.51412119550315\n",
      "Epoch 2028 val loss: 0.6483484711498022\n",
      "Epoch 2028 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2028.pth\n",
      "Epoch 2029 train loss: 0.6542795681509009\n",
      "Epoch 2029 train accuracy: 75.51412119550315\n",
      "Epoch 2029 val loss: 0.6483410855657176\n",
      "Epoch 2029 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2029.pth\n",
      "Epoch 2030 train loss: 0.6543181921731223\n",
      "Epoch 2030 train accuracy: 75.48670139840965\n",
      "Epoch 2030 val loss: 0.6483462047027914\n",
      "Epoch 2030 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2030.pth\n",
      "Epoch 2031 train loss: 0.6542714136865055\n",
      "Epoch 2031 train accuracy: 75.45928160131615\n",
      "Epoch 2031 val loss: 0.6483595601626133\n",
      "Epoch 2031 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2031.pth\n",
      "Epoch 2032 train loss: 0.654275951122767\n",
      "Epoch 2032 train accuracy: 75.51412119550315\n",
      "Epoch 2032 val loss: 0.6483870233948293\n",
      "Epoch 2032 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2032.pth\n",
      "Epoch 2033 train loss: 0.6543188211426401\n",
      "Epoch 2033 train accuracy: 75.48670139840965\n",
      "Epoch 2033 val loss: 0.6483749109075257\n",
      "Epoch 2033 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2033.pth\n",
      "Epoch 2034 train loss: 0.6542968748039321\n",
      "Epoch 2034 train accuracy: 75.48670139840965\n",
      "Epoch 2034 val loss: 0.6483782645510999\n",
      "Epoch 2034 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2034.pth\n",
      "Epoch 2035 train loss: 0.654347878439646\n",
      "Epoch 2035 train accuracy: 75.51412119550315\n",
      "Epoch 2035 val loss: 0.6483674734634789\n",
      "Epoch 2035 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2035.pth\n",
      "Epoch 2036 train loss: 0.6542845863620179\n",
      "Epoch 2036 train accuracy: 75.48670139840965\n",
      "Epoch 2036 val loss: 0.6483653832815195\n",
      "Epoch 2036 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2036.pth\n",
      "Epoch 2037 train loss: 0.6542888474568986\n",
      "Epoch 2037 train accuracy: 75.48670139840965\n",
      "Epoch 2037 val loss: 0.648358345717976\n",
      "Epoch 2037 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2037.pth\n",
      "Epoch 2038 train loss: 0.6542902624790083\n",
      "Epoch 2038 train accuracy: 75.48670139840965\n",
      "Epoch 2038 val loss: 0.6483578348630353\n",
      "Epoch 2038 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2038.pth\n",
      "Epoch 2039 train loss: 0.6543002546879283\n",
      "Epoch 2039 train accuracy: 75.51412119550315\n",
      "Epoch 2039 val loss: 0.6483462579352292\n",
      "Epoch 2039 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2039.pth\n",
      "Epoch 2040 train loss: 0.6542222661440048\n",
      "Epoch 2040 train accuracy: 75.45928160131615\n",
      "Epoch 2040 val loss: 0.6483510194444343\n",
      "Epoch 2040 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2040.pth\n",
      "Epoch 2041 train loss: 0.6541879141147722\n",
      "Epoch 2041 train accuracy: 75.48670139840965\n",
      "Epoch 2041 val loss: 0.6483463429306683\n",
      "Epoch 2041 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2041.pth\n",
      "Epoch 2042 train loss: 0.6542853715649822\n",
      "Epoch 2042 train accuracy: 75.48670139840965\n",
      "Epoch 2042 val loss: 0.6483513499168974\n",
      "Epoch 2042 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2042.pth\n",
      "Epoch 2043 train loss: 0.654254550081596\n",
      "Epoch 2043 train accuracy: 75.48670139840965\n",
      "Epoch 2043 val loss: 0.6483483194912735\n",
      "Epoch 2043 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2043.pth\n",
      "Epoch 2044 train loss: 0.6542246370788729\n",
      "Epoch 2044 train accuracy: 75.45928160131615\n",
      "Epoch 2044 val loss: 0.6483370207838322\n",
      "Epoch 2044 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2044.pth\n",
      "Epoch 2045 train loss: 0.6542676915659716\n",
      "Epoch 2045 train accuracy: 75.48670139840965\n",
      "Epoch 2045 val loss: 0.6483418222908911\n",
      "Epoch 2045 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2045.pth\n",
      "Epoch 2046 train loss: 0.6542780132343372\n",
      "Epoch 2046 train accuracy: 75.45928160131615\n",
      "Epoch 2046 val loss: 0.6483345989530024\n",
      "Epoch 2046 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2046.pth\n",
      "Epoch 2047 train loss: 0.6542729772954133\n",
      "Epoch 2047 train accuracy: 75.48670139840965\n",
      "Epoch 2047 val loss: 0.6483282957618174\n",
      "Epoch 2047 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2047.pth\n",
      "Epoch 2048 train loss: 0.6542070595907015\n",
      "Epoch 2048 train accuracy: 75.43186180422265\n",
      "Epoch 2048 val loss: 0.6483135460630843\n",
      "Epoch 2048 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2048.pth\n",
      "Epoch 2049 train loss: 0.6542663381418639\n",
      "Epoch 2049 train accuracy: 75.48670139840965\n",
      "Epoch 2049 val loss: 0.6483259812781685\n",
      "Epoch 2049 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2049.pth\n",
      "Epoch 2050 train loss: 0.6542648679919933\n",
      "Epoch 2050 train accuracy: 75.51412119550315\n",
      "Epoch 2050 val loss: 0.6483198320983272\n",
      "Epoch 2050 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2050.pth\n",
      "Epoch 2051 train loss: 0.654220914794949\n",
      "Epoch 2051 train accuracy: 75.45928160131615\n",
      "Epoch 2051 val loss: 0.6483263141034465\n",
      "Epoch 2051 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2051.pth\n",
      "Epoch 2052 train loss: 0.654286906858416\n",
      "Epoch 2052 train accuracy: 75.48670139840965\n",
      "Epoch 2052 val loss: 0.6483202080585455\n",
      "Epoch 2052 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2052.pth\n",
      "Epoch 2053 train loss: 0.6542537045387322\n",
      "Epoch 2053 train accuracy: 75.34960241294215\n",
      "Epoch 2053 val loss: 0.6483143694502743\n",
      "Epoch 2053 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2053.pth\n",
      "Epoch 2054 train loss: 0.6542244882633289\n",
      "Epoch 2054 train accuracy: 75.40444200712915\n",
      "Epoch 2054 val loss: 0.6483077240225515\n",
      "Epoch 2054 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2054.pth\n",
      "Epoch 2055 train loss: 0.6542169418055237\n",
      "Epoch 2055 train accuracy: 75.48670139840965\n",
      "Epoch 2055 val loss: 0.648319302616935\n",
      "Epoch 2055 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2055.pth\n",
      "Epoch 2056 train loss: 0.6542385374114179\n",
      "Epoch 2056 train accuracy: 75.48670139840965\n",
      "Epoch 2056 val loss: 0.6483188306814746\n",
      "Epoch 2056 val accuracy: 77.22039473684211\n",
      "Saved model to .\\test_modelsv2/MLP_2056.pth\n",
      "Epoch 2057 train loss: 0.6542770700823319\n",
      "Epoch 2057 train accuracy: 75.48670139840965\n",
      "Epoch 2057 val loss: 0.6483059919586307\n",
      "Epoch 2057 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2057.pth\n",
      "Epoch 2058 train loss: 0.6542585146727792\n",
      "Epoch 2058 train accuracy: 75.48670139840965\n",
      "Epoch 2058 val loss: 0.6483191057647529\n",
      "Epoch 2058 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2058.pth\n",
      "Epoch 2059 train loss: 0.6542405970394611\n",
      "Epoch 2059 train accuracy: 75.51412119550315\n",
      "Epoch 2059 val loss: 0.648316342677725\n",
      "Epoch 2059 val accuracy: 77.22039473684211\n",
      "Saved model to .\\test_modelsv2/MLP_2059.pth\n",
      "Epoch 2060 train loss: 0.6542268663383367\n",
      "Epoch 2060 train accuracy: 75.45928160131615\n",
      "Epoch 2060 val loss: 0.648309008169331\n",
      "Epoch 2060 val accuracy: 77.22039473684211\n",
      "Saved model to .\\test_modelsv2/MLP_2060.pth\n",
      "Epoch 2061 train loss: 0.654222605357829\n",
      "Epoch 2061 train accuracy: 75.48670139840965\n",
      "Epoch 2061 val loss: 0.6483134793019608\n",
      "Epoch 2061 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2061.pth\n",
      "Epoch 2062 train loss: 0.6542238164039558\n",
      "Epoch 2062 train accuracy: 75.45928160131615\n",
      "Epoch 2062 val loss: 0.6483029474161173\n",
      "Epoch 2062 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2062.pth\n",
      "Epoch 2063 train loss: 0.6542268313075367\n",
      "Epoch 2063 train accuracy: 75.45928160131615\n",
      "Epoch 2063 val loss: 0.6482966571654144\n",
      "Epoch 2063 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2063.pth\n",
      "Epoch 2064 train loss: 0.6541868798565447\n",
      "Epoch 2064 train accuracy: 75.51412119550315\n",
      "Epoch 2064 val loss: 0.6482954454657278\n",
      "Epoch 2064 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2064.pth\n",
      "Epoch 2065 train loss: 0.6541789466221082\n",
      "Epoch 2065 train accuracy: 75.43186180422265\n",
      "Epoch 2065 val loss: 0.6482882737917336\n",
      "Epoch 2065 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2065.pth\n",
      "Epoch 2066 train loss: 0.6542150631481618\n",
      "Epoch 2066 train accuracy: 75.45928160131615\n",
      "Epoch 2066 val loss: 0.6482756428028408\n",
      "Epoch 2066 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2066.pth\n",
      "Epoch 2067 train loss: 0.6541503183543682\n",
      "Epoch 2067 train accuracy: 75.45928160131615\n",
      "Epoch 2067 val loss: 0.6482836498241675\n",
      "Epoch 2067 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2067.pth\n",
      "Epoch 2068 train loss: 0.6541952071548031\n",
      "Epoch 2068 train accuracy: 75.45928160131615\n",
      "Epoch 2068 val loss: 0.6482794544610538\n",
      "Epoch 2068 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2068.pth\n",
      "Epoch 2069 train loss: 0.6541992433352821\n",
      "Epoch 2069 train accuracy: 75.48670139840965\n",
      "Epoch 2069 val loss: 0.6482822963673818\n",
      "Epoch 2069 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2069.pth\n",
      "Epoch 2070 train loss: 0.6541934253876669\n",
      "Epoch 2070 train accuracy: 75.45928160131615\n",
      "Epoch 2070 val loss: 0.6482921701512838\n",
      "Epoch 2070 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2070.pth\n",
      "Epoch 2071 train loss: 0.6541948201821038\n",
      "Epoch 2071 train accuracy: 75.48670139840965\n",
      "Epoch 2071 val loss: 0.6482891522740063\n",
      "Epoch 2071 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2071.pth\n",
      "Epoch 2072 train loss: 0.6541913528191415\n",
      "Epoch 2072 train accuracy: 75.51412119550315\n",
      "Epoch 2072 val loss: 0.6482913378430041\n",
      "Epoch 2072 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2072.pth\n",
      "Epoch 2073 train loss: 0.6542105799900335\n",
      "Epoch 2073 train accuracy: 75.43186180422265\n",
      "Epoch 2073 val loss: 0.6482846825138519\n",
      "Epoch 2073 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2073.pth\n",
      "Epoch 2074 train loss: 0.6541871523909402\n",
      "Epoch 2074 train accuracy: 75.43186180422265\n",
      "Epoch 2074 val loss: 0.6482818301178908\n",
      "Epoch 2074 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2074.pth\n",
      "Epoch 2075 train loss: 0.6541578563812532\n",
      "Epoch 2075 train accuracy: 75.48670139840965\n",
      "Epoch 2075 val loss: 0.6482802186357347\n",
      "Epoch 2075 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2075.pth\n",
      "Epoch 2076 train loss: 0.6541624393706259\n",
      "Epoch 2076 train accuracy: 75.45928160131615\n",
      "Epoch 2076 val loss: 0.6482706063083912\n",
      "Epoch 2076 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2076.pth\n",
      "Epoch 2077 train loss: 0.6542321397155001\n",
      "Epoch 2077 train accuracy: 75.48670139840965\n",
      "Epoch 2077 val loss: 0.6482808000751232\n",
      "Epoch 2077 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2077.pth\n",
      "Epoch 2078 train loss: 0.6541212449797935\n",
      "Epoch 2078 train accuracy: 75.45928160131615\n",
      "Epoch 2078 val loss: 0.6482680806596028\n",
      "Epoch 2078 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2078.pth\n",
      "Epoch 2079 train loss: 0.6541404513838259\n",
      "Epoch 2079 train accuracy: 75.48670139840965\n",
      "Epoch 2079 val loss: 0.6482825396386417\n",
      "Epoch 2079 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2079.pth\n",
      "Epoch 2080 train loss: 0.6540654499018401\n",
      "Epoch 2080 train accuracy: 75.48670139840965\n",
      "Epoch 2080 val loss: 0.6482915843003675\n",
      "Epoch 2080 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2080.pth\n",
      "Epoch 2081 train loss: 0.6541431481508833\n",
      "Epoch 2081 train accuracy: 75.45928160131615\n",
      "Epoch 2081 val loss: 0.6482831536743202\n",
      "Epoch 2081 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2081.pth\n",
      "Epoch 2082 train loss: 0.6541809753694555\n",
      "Epoch 2082 train accuracy: 75.43186180422265\n",
      "Epoch 2082 val loss: 0.6482829719193672\n",
      "Epoch 2082 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2082.pth\n",
      "Epoch 2083 train loss: 0.6542176368662662\n",
      "Epoch 2083 train accuracy: 75.48670139840965\n",
      "Epoch 2083 val loss: 0.6482879943949612\n",
      "Epoch 2083 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2083.pth\n",
      "Epoch 2084 train loss: 0.6541647274831408\n",
      "Epoch 2084 train accuracy: 75.45928160131615\n",
      "Epoch 2084 val loss: 0.6482829732918426\n",
      "Epoch 2084 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2084.pth\n",
      "Epoch 2085 train loss: 0.6541520850896313\n",
      "Epoch 2085 train accuracy: 75.43186180422265\n",
      "Epoch 2085 val loss: 0.6482871995356522\n",
      "Epoch 2085 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2085.pth\n",
      "Epoch 2086 train loss: 0.6541556372192868\n",
      "Epoch 2086 train accuracy: 75.43186180422265\n",
      "Epoch 2086 val loss: 0.6482767024518628\n",
      "Epoch 2086 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2086.pth\n",
      "Epoch 2087 train loss: 0.6541472231283\n",
      "Epoch 2087 train accuracy: 75.45928160131615\n",
      "Epoch 2087 val loss: 0.6482726343368229\n",
      "Epoch 2087 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2087.pth\n",
      "Epoch 2088 train loss: 0.6540815301500914\n",
      "Epoch 2088 train accuracy: 75.45928160131615\n",
      "Epoch 2088 val loss: 0.6482604652839271\n",
      "Epoch 2088 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2088.pth\n",
      "Epoch 2089 train loss: 0.6541427740859881\n",
      "Epoch 2089 train accuracy: 75.48670139840965\n",
      "Epoch 2089 val loss: 0.6482516283071355\n",
      "Epoch 2089 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2089.pth\n",
      "Epoch 2090 train loss: 0.6540800421417021\n",
      "Epoch 2090 train accuracy: 75.45928160131615\n",
      "Epoch 2090 val loss: 0.6482782822690512\n",
      "Epoch 2090 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2090.pth\n",
      "Epoch 2091 train loss: 0.654093883408789\n",
      "Epoch 2091 train accuracy: 75.51412119550315\n",
      "Epoch 2091 val loss: 0.6482756054519039\n",
      "Epoch 2091 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2091.pth\n",
      "Epoch 2092 train loss: 0.6541325703851486\n",
      "Epoch 2092 train accuracy: 75.45928160131615\n",
      "Epoch 2092 val loss: 0.6482753374760872\n",
      "Epoch 2092 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2092.pth\n",
      "Epoch 2093 train loss: 0.6540854314113396\n",
      "Epoch 2093 train accuracy: 75.43186180422265\n",
      "Epoch 2093 val loss: 0.6482632618005338\n",
      "Epoch 2093 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2093.pth\n",
      "Epoch 2094 train loss: 0.6540635019671499\n",
      "Epoch 2094 train accuracy: 75.45928160131615\n",
      "Epoch 2094 val loss: 0.6482748128473759\n",
      "Epoch 2094 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2094.pth\n",
      "Epoch 2095 train loss: 0.654122327764829\n",
      "Epoch 2095 train accuracy: 75.45928160131615\n",
      "Epoch 2095 val loss: 0.6482746930498826\n",
      "Epoch 2095 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2095.pth\n",
      "Epoch 2096 train loss: 0.6541143894326269\n",
      "Epoch 2096 train accuracy: 75.45928160131615\n",
      "Epoch 2096 val loss: 0.6482725872805244\n",
      "Epoch 2096 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2096.pth\n",
      "Epoch 2097 train loss: 0.6540772626666647\n",
      "Epoch 2097 train accuracy: 75.45928160131615\n",
      "Epoch 2097 val loss: 0.6482556800505048\n",
      "Epoch 2097 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2097.pth\n",
      "Epoch 2098 train loss: 0.6541113099573475\n",
      "Epoch 2098 train accuracy: 75.45928160131615\n",
      "Epoch 2098 val loss: 0.6482629121134156\n",
      "Epoch 2098 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2098.pth\n",
      "Epoch 2099 train loss: 0.6541083928262978\n",
      "Epoch 2099 train accuracy: 75.51412119550315\n",
      "Epoch 2099 val loss: 0.6482597186573242\n",
      "Epoch 2099 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2099.pth\n",
      "Epoch 2100 train loss: 0.654109999455773\n",
      "Epoch 2100 train accuracy: 75.45928160131615\n",
      "Epoch 2100 val loss: 0.6482539192626351\n",
      "Epoch 2100 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2100.pth\n",
      "Epoch 2101 train loss: 0.654102522651093\n",
      "Epoch 2101 train accuracy: 75.45928160131615\n",
      "Epoch 2101 val loss: 0.6482623579274667\n",
      "Epoch 2101 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2101.pth\n",
      "Epoch 2102 train loss: 0.6540502543446788\n",
      "Epoch 2102 train accuracy: 75.48670139840965\n",
      "Epoch 2102 val loss: 0.6482537838777429\n",
      "Epoch 2102 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2102.pth\n",
      "Epoch 2103 train loss: 0.654099899916011\n",
      "Epoch 2103 train accuracy: 75.45928160131615\n",
      "Epoch 2103 val loss: 0.6482504585659817\n",
      "Epoch 2103 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2103.pth\n",
      "Epoch 2104 train loss: 0.6540916797035096\n",
      "Epoch 2104 train accuracy: 75.48670139840965\n",
      "Epoch 2104 val loss: 0.6482385912616002\n",
      "Epoch 2104 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2104.pth\n",
      "Epoch 2105 train loss: 0.6540796981895702\n",
      "Epoch 2105 train accuracy: 75.43186180422265\n",
      "Epoch 2105 val loss: 0.6482413271932226\n",
      "Epoch 2105 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2105.pth\n",
      "Epoch 2106 train loss: 0.6540915979431909\n",
      "Epoch 2106 train accuracy: 75.43186180422265\n",
      "Epoch 2106 val loss: 0.6482489250208202\n",
      "Epoch 2106 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2106.pth\n",
      "Epoch 2107 train loss: 0.6541149095354373\n",
      "Epoch 2107 train accuracy: 75.45928160131615\n",
      "Epoch 2107 val loss: 0.6482538932836369\n",
      "Epoch 2107 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2107.pth\n",
      "Epoch 2108 train loss: 0.654095875850895\n",
      "Epoch 2108 train accuracy: 75.48670139840965\n",
      "Epoch 2108 val loss: 0.648250541208606\n",
      "Epoch 2108 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2108.pth\n",
      "Epoch 2109 train loss: 0.6540652222669961\n",
      "Epoch 2109 train accuracy: 75.43186180422265\n",
      "Epoch 2109 val loss: 0.6482645140862778\n",
      "Epoch 2109 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2109.pth\n",
      "Epoch 2110 train loss: 0.6540721251645631\n",
      "Epoch 2110 train accuracy: 75.43186180422265\n",
      "Epoch 2110 val loss: 0.6482618058982649\n",
      "Epoch 2110 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2110.pth\n",
      "Epoch 2111 train loss: 0.6539987621730879\n",
      "Epoch 2111 train accuracy: 75.45928160131615\n",
      "Epoch 2111 val loss: 0.6482804841116855\n",
      "Epoch 2111 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2111.pth\n",
      "Epoch 2112 train loss: 0.6540746006526446\n",
      "Epoch 2112 train accuracy: 75.37702221003565\n",
      "Epoch 2112 val loss: 0.6482642057694887\n",
      "Epoch 2112 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2112.pth\n",
      "Epoch 2113 train loss: 0.6540253057160921\n",
      "Epoch 2113 train accuracy: 75.43186180422265\n",
      "Epoch 2113 val loss: 0.6482541211145488\n",
      "Epoch 2113 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2113.pth\n",
      "Epoch 2114 train loss: 0.6540126642048881\n",
      "Epoch 2114 train accuracy: 75.45928160131615\n",
      "Epoch 2114 val loss: 0.6482446730921143\n",
      "Epoch 2114 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2114.pth\n",
      "Epoch 2115 train loss: 0.6540599924495869\n",
      "Epoch 2115 train accuracy: 75.45928160131615\n",
      "Epoch 2115 val loss: 0.6482290555968097\n",
      "Epoch 2115 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2115.pth\n",
      "Epoch 2116 train loss: 0.6540441616650736\n",
      "Epoch 2116 train accuracy: 75.45928160131615\n",
      "Epoch 2116 val loss: 0.6482388162495274\n",
      "Epoch 2116 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2116.pth\n",
      "Epoch 2117 train loss: 0.6540466780006363\n",
      "Epoch 2117 train accuracy: 75.45928160131615\n",
      "Epoch 2117 val loss: 0.6482255294134742\n",
      "Epoch 2117 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2117.pth\n",
      "Epoch 2118 train loss: 0.654022978618741\n",
      "Epoch 2118 train accuracy: 75.43186180422265\n",
      "Epoch 2118 val loss: 0.6482238170543784\n",
      "Epoch 2118 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2118.pth\n",
      "Epoch 2119 train loss: 0.6540511357352922\n",
      "Epoch 2119 train accuracy: 75.45928160131615\n",
      "Epoch 2119 val loss: 0.6482197581545303\n",
      "Epoch 2119 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2119.pth\n",
      "Epoch 2120 train loss: 0.6539979335247424\n",
      "Epoch 2120 train accuracy: 75.43186180422265\n",
      "Epoch 2120 val loss: 0.6482410361304095\n",
      "Epoch 2120 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2120.pth\n",
      "Epoch 2121 train loss: 0.6540401079283472\n",
      "Epoch 2121 train accuracy: 75.43186180422265\n",
      "Epoch 2121 val loss: 0.6482233179635123\n",
      "Epoch 2121 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2121.pth\n",
      "Epoch 2122 train loss: 0.654041084771355\n",
      "Epoch 2122 train accuracy: 75.51412119550315\n",
      "Epoch 2122 val loss: 0.6482282193671716\n",
      "Epoch 2122 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2122.pth\n",
      "Epoch 2123 train loss: 0.6540302666590402\n",
      "Epoch 2123 train accuracy: 75.45928160131615\n",
      "Epoch 2123 val loss: 0.6482283090682406\n",
      "Epoch 2123 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2123.pth\n",
      "Epoch 2124 train loss: 0.6540369624108598\n",
      "Epoch 2124 train accuracy: 75.43186180422265\n",
      "Epoch 2124 val loss: 0.6482140916938844\n",
      "Epoch 2124 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2124.pth\n",
      "Epoch 2125 train loss: 0.6540433928501188\n",
      "Epoch 2125 train accuracy: 75.56896078969015\n",
      "Epoch 2125 val loss: 0.6481986835010742\n",
      "Epoch 2125 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2125.pth\n",
      "Epoch 2126 train loss: 0.6540301646383708\n",
      "Epoch 2126 train accuracy: 75.40444200712915\n",
      "Epoch 2126 val loss: 0.6482248354311052\n",
      "Epoch 2126 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2126.pth\n",
      "Epoch 2127 train loss: 0.6539790730335211\n",
      "Epoch 2127 train accuracy: 75.45928160131615\n",
      "Epoch 2127 val loss: 0.6482094899800263\n",
      "Epoch 2127 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2127.pth\n",
      "Epoch 2128 train loss: 0.654021386906766\n",
      "Epoch 2128 train accuracy: 75.43186180422265\n",
      "Epoch 2128 val loss: 0.6481981770576615\n",
      "Epoch 2128 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2128.pth\n",
      "Epoch 2129 train loss: 0.6540239010365647\n",
      "Epoch 2129 train accuracy: 75.43186180422265\n",
      "Epoch 2129 val loss: 0.6482066559164148\n",
      "Epoch 2129 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2129.pth\n",
      "Epoch 2130 train loss: 0.6540453249359863\n",
      "Epoch 2130 train accuracy: 75.43186180422265\n",
      "Epoch 2130 val loss: 0.6482067995361591\n",
      "Epoch 2130 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2130.pth\n",
      "Epoch 2131 train loss: 0.6540098133774703\n",
      "Epoch 2131 train accuracy: 75.40444200712915\n",
      "Epoch 2131 val loss: 0.6482040561539563\n",
      "Epoch 2131 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2131.pth\n",
      "Epoch 2132 train loss: 0.6540086114811793\n",
      "Epoch 2132 train accuracy: 75.45928160131615\n",
      "Epoch 2132 val loss: 0.648204531618639\n",
      "Epoch 2132 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2132.pth\n",
      "Epoch 2133 train loss: 0.654005166110501\n",
      "Epoch 2133 train accuracy: 75.45928160131615\n",
      "Epoch 2133 val loss: 0.6482012206198353\n",
      "Epoch 2133 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2133.pth\n",
      "Epoch 2134 train loss: 0.654008907478368\n",
      "Epoch 2134 train accuracy: 75.43186180422265\n",
      "Epoch 2134 val loss: 0.6482060388907006\n",
      "Epoch 2134 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2134.pth\n",
      "Epoch 2135 train loss: 0.6540009071233502\n",
      "Epoch 2135 train accuracy: 75.45928160131615\n",
      "Epoch 2135 val loss: 0.6482079069277173\n",
      "Epoch 2135 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2135.pth\n",
      "Epoch 2136 train loss: 0.6539907869474407\n",
      "Epoch 2136 train accuracy: 75.48670139840965\n",
      "Epoch 2136 val loss: 0.6482012230706843\n",
      "Epoch 2136 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2136.pth\n",
      "Epoch 2137 train loss: 0.6539926761924698\n",
      "Epoch 2137 train accuracy: 75.45928160131615\n",
      "Epoch 2137 val loss: 0.6482066126834405\n",
      "Epoch 2137 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2137.pth\n",
      "Epoch 2138 train loss: 0.6539876433252766\n",
      "Epoch 2138 train accuracy: 75.45928160131615\n",
      "Epoch 2138 val loss: 0.6482020867498297\n",
      "Epoch 2138 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2138.pth\n",
      "Epoch 2139 train loss: 0.653965531995422\n",
      "Epoch 2139 train accuracy: 75.48670139840965\n",
      "Epoch 2139 val loss: 0.6482016385385865\n",
      "Epoch 2139 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2139.pth\n",
      "Epoch 2140 train loss: 0.6539575187326\n",
      "Epoch 2140 train accuracy: 75.45928160131615\n",
      "Epoch 2140 val loss: 0.6482129103847241\n",
      "Epoch 2140 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2140.pth\n",
      "Epoch 2141 train loss: 0.6538834270220577\n",
      "Epoch 2141 train accuracy: 75.43186180422265\n",
      "Epoch 2141 val loss: 0.6482100672039547\n",
      "Epoch 2141 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2141.pth\n",
      "Epoch 2142 train loss: 0.6539572102524209\n",
      "Epoch 2142 train accuracy: 75.45928160131615\n",
      "Epoch 2142 val loss: 0.648201917641257\n",
      "Epoch 2142 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2142.pth\n",
      "Epoch 2143 train loss: 0.6539945612873947\n",
      "Epoch 2143 train accuracy: 75.48670139840965\n",
      "Epoch 2143 val loss: 0.6481894354679083\n",
      "Epoch 2143 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2143.pth\n",
      "Epoch 2144 train loss: 0.6539688156100741\n",
      "Epoch 2144 train accuracy: 75.45928160131615\n",
      "Epoch 2144 val loss: 0.6482062864264375\n",
      "Epoch 2144 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2144.pth\n",
      "Epoch 2145 train loss: 0.653947616257427\n",
      "Epoch 2145 train accuracy: 75.45928160131615\n",
      "Epoch 2145 val loss: 0.648207268530601\n",
      "Epoch 2145 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2145.pth\n",
      "Epoch 2146 train loss: 0.6539664104776947\n",
      "Epoch 2146 train accuracy: 75.43186180422265\n",
      "Epoch 2146 val loss: 0.6481935600505063\n",
      "Epoch 2146 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2146.pth\n",
      "Epoch 2147 train loss: 0.6539245906955841\n",
      "Epoch 2147 train accuracy: 75.51412119550315\n",
      "Epoch 2147 val loss: 0.6482068249269536\n",
      "Epoch 2147 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2147.pth\n",
      "Epoch 2148 train loss: 0.6539678839280417\n",
      "Epoch 2148 train accuracy: 75.43186180422265\n",
      "Epoch 2148 val loss: 0.6482116608439308\n",
      "Epoch 2148 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2148.pth\n",
      "Epoch 2149 train loss: 0.6539533671253083\n",
      "Epoch 2149 train accuracy: 75.45928160131615\n",
      "Epoch 2149 val loss: 0.6481983967517552\n",
      "Epoch 2149 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2149.pth\n",
      "Epoch 2150 train loss: 0.6539412755192372\n",
      "Epoch 2150 train accuracy: 75.45928160131615\n",
      "Epoch 2150 val loss: 0.6481954343616962\n",
      "Epoch 2150 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2150.pth\n",
      "Epoch 2151 train loss: 0.653946348743742\n",
      "Epoch 2151 train accuracy: 75.40444200712915\n",
      "Epoch 2151 val loss: 0.6481889896094799\n",
      "Epoch 2151 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2151.pth\n",
      "Epoch 2152 train loss: 0.6539148782102162\n",
      "Epoch 2152 train accuracy: 75.43186180422265\n",
      "Epoch 2152 val loss: 0.6481924805986253\n",
      "Epoch 2152 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2152.pth\n",
      "Epoch 2153 train loss: 0.6538930727789799\n",
      "Epoch 2153 train accuracy: 75.45928160131615\n",
      "Epoch 2153 val loss: 0.6481969923173126\n",
      "Epoch 2153 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2153.pth\n",
      "Epoch 2154 train loss: 0.6539288632440985\n",
      "Epoch 2154 train accuracy: 75.48670139840965\n",
      "Epoch 2154 val loss: 0.6481794847273513\n",
      "Epoch 2154 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2154.pth\n",
      "Epoch 2155 train loss: 0.6539440604351592\n",
      "Epoch 2155 train accuracy: 75.43186180422265\n",
      "Epoch 2155 val loss: 0.6481956661139664\n",
      "Epoch 2155 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2155.pth\n",
      "Epoch 2156 train loss: 0.6538828730648547\n",
      "Epoch 2156 train accuracy: 75.45928160131615\n",
      "Epoch 2156 val loss: 0.6482050696289853\n",
      "Epoch 2156 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2156.pth\n",
      "Epoch 2157 train loss: 0.6539267908716411\n",
      "Epoch 2157 train accuracy: 75.45928160131615\n",
      "Epoch 2157 val loss: 0.6481952054524108\n",
      "Epoch 2157 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2157.pth\n",
      "Epoch 2158 train loss: 0.6539298887773041\n",
      "Epoch 2158 train accuracy: 75.51412119550315\n",
      "Epoch 2158 val loss: 0.6482139946402687\n",
      "Epoch 2158 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2158.pth\n",
      "Epoch 2159 train loss: 0.65389003823593\n",
      "Epoch 2159 train accuracy: 75.51412119550315\n",
      "Epoch 2159 val loss: 0.648195596901994\n",
      "Epoch 2159 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2159.pth\n",
      "Epoch 2160 train loss: 0.6539035183622649\n",
      "Epoch 2160 train accuracy: 75.48670139840965\n",
      "Epoch 2160 val loss: 0.6481855273442833\n",
      "Epoch 2160 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2160.pth\n",
      "Epoch 2161 train loss: 0.6539236974101841\n",
      "Epoch 2161 train accuracy: 75.45928160131615\n",
      "Epoch 2161 val loss: 0.6481867067907986\n",
      "Epoch 2161 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2161.pth\n",
      "Epoch 2162 train loss: 0.6540357661351823\n",
      "Epoch 2162 train accuracy: 75.43186180422265\n",
      "Epoch 2162 val loss: 0.6481963540182302\n",
      "Epoch 2162 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2162.pth\n",
      "Epoch 2163 train loss: 0.6539139009342251\n",
      "Epoch 2163 train accuracy: 75.43186180422265\n",
      "Epoch 2163 val loss: 0.6481897954485918\n",
      "Epoch 2163 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2163.pth\n",
      "Epoch 2164 train loss: 0.6539119003961483\n",
      "Epoch 2164 train accuracy: 75.43186180422265\n",
      "Epoch 2164 val loss: 0.6481963236277041\n",
      "Epoch 2164 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2164.pth\n",
      "Epoch 2165 train loss: 0.6539000293011206\n",
      "Epoch 2165 train accuracy: 75.45928160131615\n",
      "Epoch 2165 val loss: 0.6481788100086545\n",
      "Epoch 2165 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2165.pth\n",
      "Epoch 2166 train loss: 0.6538913196214197\n",
      "Epoch 2166 train accuracy: 75.48670139840965\n",
      "Epoch 2166 val loss: 0.6481648467873272\n",
      "Epoch 2166 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2166.pth\n",
      "Epoch 2167 train loss: 0.6539076111818615\n",
      "Epoch 2167 train accuracy: 75.43186180422265\n",
      "Epoch 2167 val loss: 0.6481752231913177\n",
      "Epoch 2167 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2167.pth\n",
      "Epoch 2168 train loss: 0.6538718470225209\n",
      "Epoch 2168 train accuracy: 75.43186180422265\n",
      "Epoch 2168 val loss: 0.6481821022339558\n",
      "Epoch 2168 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2168.pth\n",
      "Epoch 2169 train loss: 0.6538816132631741\n",
      "Epoch 2169 train accuracy: 75.43186180422265\n",
      "Epoch 2169 val loss: 0.6481836708752733\n",
      "Epoch 2169 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2169.pth\n",
      "Epoch 2170 train loss: 0.6538476643005484\n",
      "Epoch 2170 train accuracy: 75.48670139840965\n",
      "Epoch 2170 val loss: 0.6481815050111005\n",
      "Epoch 2170 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2170.pth\n",
      "Epoch 2171 train loss: 0.653905453650575\n",
      "Epoch 2171 train accuracy: 75.51412119550315\n",
      "Epoch 2171 val loss: 0.6481789800485498\n",
      "Epoch 2171 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2171.pth\n",
      "Epoch 2172 train loss: 0.6538923355963147\n",
      "Epoch 2172 train accuracy: 75.43186180422265\n",
      "Epoch 2172 val loss: 0.6481878899626041\n",
      "Epoch 2172 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2172.pth\n",
      "Epoch 2173 train loss: 0.6538301758925643\n",
      "Epoch 2173 train accuracy: 75.45928160131615\n",
      "Epoch 2173 val loss: 0.648199075636895\n",
      "Epoch 2173 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2173.pth\n",
      "Epoch 2174 train loss: 0.653883807328448\n",
      "Epoch 2174 train accuracy: 75.48670139840965\n",
      "Epoch 2174 val loss: 0.6481813679596311\n",
      "Epoch 2174 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2174.pth\n",
      "Epoch 2175 train loss: 0.6538155312208753\n",
      "Epoch 2175 train accuracy: 75.48670139840965\n",
      "Epoch 2175 val loss: 0.6481705675587842\n",
      "Epoch 2175 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2175.pth\n",
      "Epoch 2176 train loss: 0.6538543108393226\n",
      "Epoch 2176 train accuracy: 75.45928160131615\n",
      "Epoch 2176 val loss: 0.6481826388718266\n",
      "Epoch 2176 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2176.pth\n",
      "Epoch 2177 train loss: 0.653875785275248\n",
      "Epoch 2177 train accuracy: 75.51412119550315\n",
      "Epoch 2177 val loss: 0.6481901835650206\n",
      "Epoch 2177 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2177.pth\n",
      "Epoch 2178 train loss: 0.6539274377323556\n",
      "Epoch 2178 train accuracy: 75.45928160131615\n",
      "Epoch 2178 val loss: 0.6481694048760753\n",
      "Epoch 2178 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2178.pth\n",
      "Epoch 2179 train loss: 0.6538696404089007\n",
      "Epoch 2179 train accuracy: 75.45928160131615\n",
      "Epoch 2179 val loss: 0.6481723904021477\n",
      "Epoch 2179 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2179.pth\n",
      "Epoch 2180 train loss: 0.6538080433546974\n",
      "Epoch 2180 train accuracy: 75.51412119550315\n",
      "Epoch 2180 val loss: 0.6481650488353089\n",
      "Epoch 2180 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2180.pth\n",
      "Epoch 2181 train loss: 0.653833629040603\n",
      "Epoch 2181 train accuracy: 75.48670139840965\n",
      "Epoch 2181 val loss: 0.6481695693770522\n",
      "Epoch 2181 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2181.pth\n",
      "Epoch 2182 train loss: 0.6538520697504282\n",
      "Epoch 2182 train accuracy: 75.45928160131615\n",
      "Epoch 2182 val loss: 0.648179671384002\n",
      "Epoch 2182 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2182.pth\n",
      "Epoch 2183 train loss: 0.6538843636711439\n",
      "Epoch 2183 train accuracy: 75.45928160131615\n",
      "Epoch 2183 val loss: 0.6481810297424856\n",
      "Epoch 2183 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2183.pth\n",
      "Epoch 2184 train loss: 0.6538731495670059\n",
      "Epoch 2184 train accuracy: 75.40444200712915\n",
      "Epoch 2184 val loss: 0.6481744142151192\n",
      "Epoch 2184 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2184.pth\n",
      "Epoch 2185 train loss: 0.6538643511012197\n",
      "Epoch 2185 train accuracy: 75.51412119550315\n",
      "Epoch 2185 val loss: 0.648172297662026\n",
      "Epoch 2185 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2185.pth\n",
      "Epoch 2186 train loss: 0.6537851354499397\n",
      "Epoch 2186 train accuracy: 75.48670139840965\n",
      "Epoch 2186 val loss: 0.6481816546109161\n",
      "Epoch 2186 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2186.pth\n",
      "Epoch 2187 train loss: 0.6537564461887405\n",
      "Epoch 2187 train accuracy: 75.48670139840965\n",
      "Epoch 2187 val loss: 0.6481868397248419\n",
      "Epoch 2187 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2187.pth\n",
      "Epoch 2188 train loss: 0.6537964736160479\n",
      "Epoch 2188 train accuracy: 75.45928160131615\n",
      "Epoch 2188 val loss: 0.648185396763055\n",
      "Epoch 2188 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2188.pth\n",
      "Epoch 2189 train loss: 0.6537835012729231\n",
      "Epoch 2189 train accuracy: 75.45928160131615\n",
      "Epoch 2189 val loss: 0.6481827750409904\n",
      "Epoch 2189 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2189.pth\n",
      "Epoch 2190 train loss: 0.6538322793744635\n",
      "Epoch 2190 train accuracy: 75.48670139840965\n",
      "Epoch 2190 val loss: 0.6481747316490662\n",
      "Epoch 2190 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2190.pth\n",
      "Epoch 2191 train loss: 0.6538374730500213\n",
      "Epoch 2191 train accuracy: 75.48670139840965\n",
      "Epoch 2191 val loss: 0.6481715939742955\n",
      "Epoch 2191 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2191.pth\n",
      "Epoch 2192 train loss: 0.6537968852933038\n",
      "Epoch 2192 train accuracy: 75.48670139840965\n",
      "Epoch 2192 val loss: 0.6481863606329027\n",
      "Epoch 2192 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2192.pth\n",
      "Epoch 2193 train loss: 0.6538396336203605\n",
      "Epoch 2193 train accuracy: 75.45928160131615\n",
      "Epoch 2193 val loss: 0.6481658900646787\n",
      "Epoch 2193 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2193.pth\n",
      "Epoch 2194 train loss: 0.653772642215093\n",
      "Epoch 2194 train accuracy: 75.45928160131615\n",
      "Epoch 2194 val loss: 0.6481668534443566\n",
      "Epoch 2194 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2194.pth\n",
      "Epoch 2195 train loss: 0.6538220923393965\n",
      "Epoch 2195 train accuracy: 75.43186180422265\n",
      "Epoch 2195 val loss: 0.6481526600883195\n",
      "Epoch 2195 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2195.pth\n",
      "Epoch 2196 train loss: 0.6538178572398529\n",
      "Epoch 2196 train accuracy: 75.48670139840965\n",
      "Epoch 2196 val loss: 0.6481561607828266\n",
      "Epoch 2196 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2196.pth\n",
      "Epoch 2197 train loss: 0.6537341964022633\n",
      "Epoch 2197 train accuracy: 75.40444200712915\n",
      "Epoch 2197 val loss: 0.6481554612125221\n",
      "Epoch 2197 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2197.pth\n",
      "Epoch 2198 train loss: 0.6537898917796842\n",
      "Epoch 2198 train accuracy: 75.48670139840965\n",
      "Epoch 2198 val loss: 0.64816394291426\n",
      "Epoch 2198 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2198.pth\n",
      "Epoch 2199 train loss: 0.6538139842777398\n",
      "Epoch 2199 train accuracy: 75.51412119550315\n",
      "Epoch 2199 val loss: 0.6481515407366188\n",
      "Epoch 2199 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2199.pth\n",
      "Epoch 2200 train loss: 0.6537962789696298\n",
      "Epoch 2200 train accuracy: 75.51412119550315\n",
      "Epoch 2200 val loss: 0.6481652333352127\n",
      "Epoch 2200 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2200.pth\n",
      "Epoch 2201 train loss: 0.6537757262652903\n",
      "Epoch 2201 train accuracy: 75.48670139840965\n",
      "Epoch 2201 val loss: 0.6481691869465929\n",
      "Epoch 2201 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2201.pth\n",
      "Epoch 2202 train loss: 0.6537824784193123\n",
      "Epoch 2202 train accuracy: 75.48670139840965\n",
      "Epoch 2202 val loss: 0.6481613907963037\n",
      "Epoch 2202 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2202.pth\n",
      "Epoch 2203 train loss: 0.653759492691933\n",
      "Epoch 2203 train accuracy: 75.48670139840965\n",
      "Epoch 2203 val loss: 0.6481647775753548\n",
      "Epoch 2203 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2203.pth\n",
      "Epoch 2204 train loss: 0.6537938748666069\n",
      "Epoch 2204 train accuracy: 75.48670139840965\n",
      "Epoch 2204 val loss: 0.648175649442955\n",
      "Epoch 2204 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2204.pth\n",
      "Epoch 2205 train loss: 0.6537469551620776\n",
      "Epoch 2205 train accuracy: 75.51412119550315\n",
      "Epoch 2205 val loss: 0.6481711532136327\n",
      "Epoch 2205 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2205.pth\n",
      "Epoch 2206 train loss: 0.6537846236309984\n",
      "Epoch 2206 train accuracy: 75.51412119550315\n",
      "Epoch 2206 val loss: 0.6481717211243353\n",
      "Epoch 2206 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2206.pth\n",
      "Epoch 2207 train loss: 0.6537493105749028\n",
      "Epoch 2207 train accuracy: 75.48670139840965\n",
      "Epoch 2207 val loss: 0.648177287198211\n",
      "Epoch 2207 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2207.pth\n",
      "Epoch 2208 train loss: 0.6537704476923273\n",
      "Epoch 2208 train accuracy: 75.45928160131615\n",
      "Epoch 2208 val loss: 0.6481910656745496\n",
      "Epoch 2208 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2208.pth\n",
      "Epoch 2209 train loss: 0.6537834469784509\n",
      "Epoch 2209 train accuracy: 75.48670139840965\n",
      "Epoch 2209 val loss: 0.6481761172609893\n",
      "Epoch 2209 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2209.pth\n",
      "Epoch 2210 train loss: 0.6538283454679084\n",
      "Epoch 2210 train accuracy: 75.43186180422265\n",
      "Epoch 2210 val loss: 0.6481558579559389\n",
      "Epoch 2210 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2210.pth\n",
      "Epoch 2211 train loss: 0.6537724551989844\n",
      "Epoch 2211 train accuracy: 75.43186180422265\n",
      "Epoch 2211 val loss: 0.6481393216864059\n",
      "Epoch 2211 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2211.pth\n",
      "Epoch 2212 train loss: 0.6537341330723282\n",
      "Epoch 2212 train accuracy: 75.54154099259665\n",
      "Epoch 2212 val loss: 0.6481511385033005\n",
      "Epoch 2212 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2212.pth\n",
      "Epoch 2213 train loss: 0.6537764259499678\n",
      "Epoch 2213 train accuracy: 75.40444200712915\n",
      "Epoch 2213 val loss: 0.6481449316794935\n",
      "Epoch 2213 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2213.pth\n",
      "Epoch 2214 train loss: 0.6537648667499685\n",
      "Epoch 2214 train accuracy: 75.48670139840965\n",
      "Epoch 2214 val loss: 0.6481460839706031\n",
      "Epoch 2214 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2214.pth\n",
      "Epoch 2215 train loss: 0.6537708312174991\n",
      "Epoch 2215 train accuracy: 75.48670139840965\n",
      "Epoch 2215 val loss: 0.6481440138856047\n",
      "Epoch 2215 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2215.pth\n",
      "Epoch 2216 train loss: 0.6538168479802838\n",
      "Epoch 2216 train accuracy: 75.54154099259665\n",
      "Epoch 2216 val loss: 0.6481505952971546\n",
      "Epoch 2216 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2216.pth\n",
      "Epoch 2217 train loss: 0.6536981558852029\n",
      "Epoch 2217 train accuracy: 75.48670139840965\n",
      "Epoch 2217 val loss: 0.6481589609266896\n",
      "Epoch 2217 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2217.pth\n",
      "Epoch 2218 train loss: 0.6537578816345909\n",
      "Epoch 2218 train accuracy: 75.45928160131615\n",
      "Epoch 2218 val loss: 0.6481547421824775\n",
      "Epoch 2218 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2218.pth\n",
      "Epoch 2219 train loss: 0.6537516161538007\n",
      "Epoch 2219 train accuracy: 75.48670139840965\n",
      "Epoch 2219 val loss: 0.6481547690927982\n",
      "Epoch 2219 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2219.pth\n",
      "Epoch 2220 train loss: 0.6537195845392713\n",
      "Epoch 2220 train accuracy: 75.51412119550315\n",
      "Epoch 2220 val loss: 0.6481600814547978\n",
      "Epoch 2220 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2220.pth\n",
      "Epoch 2221 train loss: 0.6537597532008301\n",
      "Epoch 2221 train accuracy: 75.48670139840965\n",
      "Epoch 2221 val loss: 0.6481566299733362\n",
      "Epoch 2221 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2221.pth\n",
      "Epoch 2222 train loss: 0.6537230021990182\n",
      "Epoch 2222 train accuracy: 75.54154099259665\n",
      "Epoch 2222 val loss: 0.648150463049349\n",
      "Epoch 2222 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2222.pth\n",
      "Epoch 2223 train loss: 0.6537488707292237\n",
      "Epoch 2223 train accuracy: 75.48670139840965\n",
      "Epoch 2223 val loss: 0.648133786689294\n",
      "Epoch 2223 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2223.pth\n",
      "Epoch 2224 train loss: 0.6537368724024609\n",
      "Epoch 2224 train accuracy: 75.43186180422265\n",
      "Epoch 2224 val loss: 0.6481472661620692\n",
      "Epoch 2224 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2224.pth\n",
      "Epoch 2225 train loss: 0.6537501695320794\n",
      "Epoch 2225 train accuracy: 75.48670139840965\n",
      "Epoch 2225 val loss: 0.6481641893716235\n",
      "Epoch 2225 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2225.pth\n",
      "Epoch 2226 train loss: 0.6536995534245905\n",
      "Epoch 2226 train accuracy: 75.43186180422265\n",
      "Epoch 2226 val loss: 0.6481505889249476\n",
      "Epoch 2226 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2226.pth\n",
      "Epoch 2227 train loss: 0.6537210080576571\n",
      "Epoch 2227 train accuracy: 75.48670139840965\n",
      "Epoch 2227 val loss: 0.6481492079206204\n",
      "Epoch 2227 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2227.pth\n",
      "Epoch 2228 train loss: 0.6536802497218576\n",
      "Epoch 2228 train accuracy: 75.51412119550315\n",
      "Epoch 2228 val loss: 0.6481560006933776\n",
      "Epoch 2228 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2228.pth\n",
      "Epoch 2229 train loss: 0.6536613803095462\n",
      "Epoch 2229 train accuracy: 75.51412119550315\n",
      "Epoch 2229 val loss: 0.648158975239647\n",
      "Epoch 2229 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2229.pth\n",
      "Epoch 2230 train loss: 0.6537261572257992\n",
      "Epoch 2230 train accuracy: 75.40444200712915\n",
      "Epoch 2230 val loss: 0.6481594560961974\n",
      "Epoch 2230 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2230.pth\n",
      "Epoch 2231 train loss: 0.6537257033285865\n",
      "Epoch 2231 train accuracy: 75.51412119550315\n",
      "Epoch 2231 val loss: 0.6481431120712506\n",
      "Epoch 2231 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2231.pth\n",
      "Epoch 2232 train loss: 0.6537434343052538\n",
      "Epoch 2232 train accuracy: 75.43186180422265\n",
      "Epoch 2232 val loss: 0.648139516283807\n",
      "Epoch 2232 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2232.pth\n",
      "Epoch 2233 train loss: 0.6536705316322153\n",
      "Epoch 2233 train accuracy: 75.51412119550315\n",
      "Epoch 2233 val loss: 0.6481321027600452\n",
      "Epoch 2233 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2233.pth\n",
      "Epoch 2234 train loss: 0.6537120524761185\n",
      "Epoch 2234 train accuracy: 75.51412119550315\n",
      "Epoch 2234 val loss: 0.6481666290446332\n",
      "Epoch 2234 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2234.pth\n",
      "Epoch 2235 train loss: 0.6537072232908063\n",
      "Epoch 2235 train accuracy: 75.40444200712915\n",
      "Epoch 2235 val loss: 0.6481400299817324\n",
      "Epoch 2235 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2235.pth\n",
      "Epoch 2236 train loss: 0.6537090046821457\n",
      "Epoch 2236 train accuracy: 75.48670139840965\n",
      "Epoch 2236 val loss: 0.648145464886176\n",
      "Epoch 2236 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2236.pth\n",
      "Epoch 2237 train loss: 0.6536741824330468\n",
      "Epoch 2237 train accuracy: 75.56896078969015\n",
      "Epoch 2237 val loss: 0.6481520839427647\n",
      "Epoch 2237 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2237.pth\n",
      "Epoch 2238 train loss: 0.6537594940970864\n",
      "Epoch 2238 train accuracy: 75.43186180422265\n",
      "Epoch 2238 val loss: 0.6481324163706679\n",
      "Epoch 2238 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2238.pth\n",
      "Epoch 2239 train loss: 0.6536943253064365\n",
      "Epoch 2239 train accuracy: 75.51412119550315\n",
      "Epoch 2239 val loss: 0.6481371695469869\n",
      "Epoch 2239 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2239.pth\n",
      "Epoch 2240 train loss: 0.653689857899097\n",
      "Epoch 2240 train accuracy: 75.48670139840965\n",
      "Epoch 2240 val loss: 0.6481178299965042\n",
      "Epoch 2240 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2240.pth\n",
      "Epoch 2241 train loss: 0.6536029411904645\n",
      "Epoch 2241 train accuracy: 75.51412119550315\n",
      "Epoch 2241 val loss: 0.6481262988557941\n",
      "Epoch 2241 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2241.pth\n",
      "Epoch 2242 train loss: 0.6536186143200386\n",
      "Epoch 2242 train accuracy: 75.51412119550315\n",
      "Epoch 2242 val loss: 0.6481383560519469\n",
      "Epoch 2242 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2242.pth\n",
      "Epoch 2243 train loss: 0.6536868442699575\n",
      "Epoch 2243 train accuracy: 75.48670139840965\n",
      "Epoch 2243 val loss: 0.648140786215663\n",
      "Epoch 2243 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2243.pth\n",
      "Epoch 2244 train loss: 0.6536833696524825\n",
      "Epoch 2244 train accuracy: 75.45928160131615\n",
      "Epoch 2244 val loss: 0.6481242690627512\n",
      "Epoch 2244 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2244.pth\n",
      "Epoch 2245 train loss: 0.6536849443065492\n",
      "Epoch 2245 train accuracy: 75.45928160131615\n",
      "Epoch 2245 val loss: 0.6481107291030256\n",
      "Epoch 2245 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2245.pth\n",
      "Epoch 2246 train loss: 0.6536810052041945\n",
      "Epoch 2246 train accuracy: 75.43186180422265\n",
      "Epoch 2246 val loss: 0.6481236052748404\n",
      "Epoch 2246 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2246.pth\n",
      "Epoch 2247 train loss: 0.6535995662408439\n",
      "Epoch 2247 train accuracy: 75.40444200712915\n",
      "Epoch 2247 val loss: 0.6481145025279961\n",
      "Epoch 2247 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2247.pth\n",
      "Epoch 2248 train loss: 0.6536733701890498\n",
      "Epoch 2248 train accuracy: 75.54154099259665\n",
      "Epoch 2248 val loss: 0.6481129325142032\n",
      "Epoch 2248 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2248.pth\n",
      "Epoch 2249 train loss: 0.6536211107710475\n",
      "Epoch 2249 train accuracy: 75.51412119550315\n",
      "Epoch 2249 val loss: 0.6481429773725962\n",
      "Epoch 2249 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2249.pth\n",
      "Epoch 2250 train loss: 0.6536731314110128\n",
      "Epoch 2250 train accuracy: 75.45928160131615\n",
      "Epoch 2250 val loss: 0.6481237917354232\n",
      "Epoch 2250 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2250.pth\n",
      "Epoch 2251 train loss: 0.6536192163302187\n",
      "Epoch 2251 train accuracy: 75.48670139840965\n",
      "Epoch 2251 val loss: 0.6481346505645075\n",
      "Epoch 2251 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2251.pth\n",
      "Epoch 2252 train loss: 0.6536644245252797\n",
      "Epoch 2252 train accuracy: 75.40444200712915\n",
      "Epoch 2252 val loss: 0.648124718352368\n",
      "Epoch 2252 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2252.pth\n",
      "Epoch 2253 train loss: 0.6536168304124945\n",
      "Epoch 2253 train accuracy: 75.45928160131615\n",
      "Epoch 2253 val loss: 0.6481131566198248\n",
      "Epoch 2253 val accuracy: 77.13815789473684\n",
      "Saved model to .\\test_modelsv2/MLP_2253.pth\n",
      "Epoch 2254 train loss: 0.6536968360867417\n",
      "Epoch 2254 train accuracy: 75.51412119550315\n",
      "Epoch 2254 val loss: 0.6481182946774521\n",
      "Epoch 2254 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2254.pth\n",
      "Epoch 2255 train loss: 0.6536509151684872\n",
      "Epoch 2255 train accuracy: 75.54154099259665\n",
      "Epoch 2255 val loss: 0.6481165665348894\n",
      "Epoch 2255 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2255.pth\n",
      "Epoch 2256 train loss: 0.6536481906578206\n",
      "Epoch 2256 train accuracy: 75.54154099259665\n",
      "Epoch 2256 val loss: 0.6481095515191555\n",
      "Epoch 2256 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2256.pth\n",
      "Epoch 2257 train loss: 0.6535929598959914\n",
      "Epoch 2257 train accuracy: 75.51412119550315\n",
      "Epoch 2257 val loss: 0.6481160290147129\n",
      "Epoch 2257 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2257.pth\n",
      "Epoch 2258 train loss: 0.6536332128667518\n",
      "Epoch 2258 train accuracy: 75.45928160131615\n",
      "Epoch 2258 val loss: 0.6481132496540484\n",
      "Epoch 2258 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2258.pth\n",
      "Epoch 2259 train loss: 0.6536115193576143\n",
      "Epoch 2259 train accuracy: 75.43186180422265\n",
      "Epoch 2259 val loss: 0.6480964178121403\n",
      "Epoch 2259 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2259.pth\n",
      "Epoch 2260 train loss: 0.6536367786231271\n",
      "Epoch 2260 train accuracy: 75.59638058678365\n",
      "Epoch 2260 val loss: 0.648113679532942\n",
      "Epoch 2260 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2260.pth\n",
      "Epoch 2261 train loss: 0.653656255421147\n",
      "Epoch 2261 train accuracy: 75.40444200712915\n",
      "Epoch 2261 val loss: 0.6480981887955415\n",
      "Epoch 2261 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2261.pth\n",
      "Epoch 2262 train loss: 0.6536328634410574\n",
      "Epoch 2262 train accuracy: 75.51412119550315\n",
      "Epoch 2262 val loss: 0.6481037549674511\n",
      "Epoch 2262 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2262.pth\n",
      "Epoch 2263 train loss: 0.653674133808205\n",
      "Epoch 2263 train accuracy: 75.43186180422265\n",
      "Epoch 2263 val loss: 0.648095297578134\n",
      "Epoch 2263 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2263.pth\n",
      "Epoch 2264 train loss: 0.6536314385175183\n",
      "Epoch 2264 train accuracy: 75.51412119550315\n",
      "Epoch 2264 val loss: 0.6480904105854662\n",
      "Epoch 2264 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2264.pth\n",
      "Epoch 2265 train loss: 0.6535862004547789\n",
      "Epoch 2265 train accuracy: 75.51412119550315\n",
      "Epoch 2265 val loss: 0.6481119758988682\n",
      "Epoch 2265 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2265.pth\n",
      "Epoch 2266 train loss: 0.6535635350370094\n",
      "Epoch 2266 train accuracy: 75.37702221003565\n",
      "Epoch 2266 val loss: 0.6480918439399255\n",
      "Epoch 2266 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2266.pth\n",
      "Epoch 2267 train loss: 0.6536148796021416\n",
      "Epoch 2267 train accuracy: 75.48670139840965\n",
      "Epoch 2267 val loss: 0.6480988600340328\n",
      "Epoch 2267 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2267.pth\n",
      "Epoch 2268 train loss: 0.653705982687442\n",
      "Epoch 2268 train accuracy: 75.54154099259665\n",
      "Epoch 2268 val loss: 0.6481035166469059\n",
      "Epoch 2268 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2268.pth\n",
      "Epoch 2269 train loss: 0.6537060237963471\n",
      "Epoch 2269 train accuracy: 75.54154099259665\n",
      "Epoch 2269 val loss: 0.6480913842587095\n",
      "Epoch 2269 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2269.pth\n",
      "Epoch 2270 train loss: 0.653619397382595\n",
      "Epoch 2270 train accuracy: 75.45928160131615\n",
      "Epoch 2270 val loss: 0.648101583221241\n",
      "Epoch 2270 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2270.pth\n",
      "Epoch 2271 train loss: 0.6537106495612023\n",
      "Epoch 2271 train accuracy: 75.43186180422265\n",
      "Epoch 2271 val loss: 0.6480881452168289\n",
      "Epoch 2271 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2271.pth\n",
      "Epoch 2272 train loss: 0.6536138318479061\n",
      "Epoch 2272 train accuracy: 75.43186180422265\n",
      "Epoch 2272 val loss: 0.648084948672668\n",
      "Epoch 2272 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2272.pth\n",
      "Epoch 2273 train loss: 0.6535879106571277\n",
      "Epoch 2273 train accuracy: 75.54154099259665\n",
      "Epoch 2273 val loss: 0.6480822491606599\n",
      "Epoch 2273 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2273.pth\n",
      "Epoch 2274 train loss: 0.6535903563428866\n",
      "Epoch 2274 train accuracy: 75.51412119550315\n",
      "Epoch 2274 val loss: 0.648078803022049\n",
      "Epoch 2274 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2274.pth\n",
      "Epoch 2275 train loss: 0.6536086773042354\n",
      "Epoch 2275 train accuracy: 75.51412119550315\n",
      "Epoch 2275 val loss: 0.6480811919624868\n",
      "Epoch 2275 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2275.pth\n",
      "Epoch 2276 train loss: 0.6536239152937605\n",
      "Epoch 2276 train accuracy: 75.54154099259665\n",
      "Epoch 2276 val loss: 0.648096573980231\n",
      "Epoch 2276 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2276.pth\n",
      "Epoch 2277 train loss: 0.6535143014370349\n",
      "Epoch 2277 train accuracy: 75.43186180422265\n",
      "Epoch 2277 val loss: 0.6480906323382729\n",
      "Epoch 2277 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2277.pth\n",
      "Epoch 2278 train loss: 0.6536023307330253\n",
      "Epoch 2278 train accuracy: 75.48670139840965\n",
      "Epoch 2278 val loss: 0.6480799771257137\n",
      "Epoch 2278 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2278.pth\n",
      "Epoch 2279 train loss: 0.6535988730264076\n",
      "Epoch 2279 train accuracy: 75.43186180422265\n",
      "Epoch 2279 val loss: 0.6480776485251752\n",
      "Epoch 2279 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2279.pth\n",
      "Epoch 2280 train loss: 0.6535946380739149\n",
      "Epoch 2280 train accuracy: 75.51412119550315\n",
      "Epoch 2280 val loss: 0.6480809771700909\n",
      "Epoch 2280 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2280.pth\n",
      "Epoch 2281 train loss: 0.6535364026040361\n",
      "Epoch 2281 train accuracy: 75.40444200712915\n",
      "Epoch 2281 val loss: 0.6480818303596032\n",
      "Epoch 2281 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2281.pth\n",
      "Epoch 2282 train loss: 0.6535900223412012\n",
      "Epoch 2282 train accuracy: 75.48670139840965\n",
      "Epoch 2282 val loss: 0.6480768124916052\n",
      "Epoch 2282 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2282.pth\n",
      "Epoch 2283 train loss: 0.6535291121128881\n",
      "Epoch 2283 train accuracy: 75.48670139840965\n",
      "Epoch 2283 val loss: 0.6480783531932455\n",
      "Epoch 2283 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2283.pth\n",
      "Epoch 2284 train loss: 0.6535899800558885\n",
      "Epoch 2284 train accuracy: 75.48670139840965\n",
      "Epoch 2284 val loss: 0.6480788415003764\n",
      "Epoch 2284 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2284.pth\n",
      "Epoch 2285 train loss: 0.6535770574486569\n",
      "Epoch 2285 train accuracy: 75.51412119550315\n",
      "Epoch 2285 val loss: 0.6480737031486473\n",
      "Epoch 2285 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2285.pth\n",
      "Epoch 2286 train loss: 0.653524322075802\n",
      "Epoch 2286 train accuracy: 75.48670139840965\n",
      "Epoch 2286 val loss: 0.648070109125815\n",
      "Epoch 2286 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2286.pth\n",
      "Epoch 2287 train loss: 0.6535212189743393\n",
      "Epoch 2287 train accuracy: 75.51412119550315\n",
      "Epoch 2287 val loss: 0.6480580312444976\n",
      "Epoch 2287 val accuracy: 77.05592105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2287.pth\n",
      "Epoch 2288 train loss: 0.6535790394991636\n",
      "Epoch 2288 train accuracy: 75.43186180422265\n",
      "Epoch 2288 val loss: 0.6480615407620606\n",
      "Epoch 2288 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2288.pth\n",
      "Epoch 2289 train loss: 0.6535628769023899\n",
      "Epoch 2289 train accuracy: 75.48670139840965\n",
      "Epoch 2289 val loss: 0.6480726087956052\n",
      "Epoch 2289 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2289.pth\n",
      "Epoch 2290 train loss: 0.6535643471502944\n",
      "Epoch 2290 train accuracy: 75.45928160131615\n",
      "Epoch 2290 val loss: 0.6480588342406248\n",
      "Epoch 2290 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2290.pth\n",
      "Epoch 2291 train loss: 0.6535468820090357\n",
      "Epoch 2291 train accuracy: 75.51412119550315\n",
      "Epoch 2291 val loss: 0.6480601609341408\n",
      "Epoch 2291 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2291.pth\n",
      "Epoch 2292 train loss: 0.6535770800618226\n",
      "Epoch 2292 train accuracy: 75.48670139840965\n",
      "Epoch 2292 val loss: 0.6480704769492149\n",
      "Epoch 2292 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2292.pth\n",
      "Epoch 2293 train loss: 0.653543761522885\n",
      "Epoch 2293 train accuracy: 75.51412119550315\n",
      "Epoch 2293 val loss: 0.6480692785821462\n",
      "Epoch 2293 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2293.pth\n",
      "Epoch 2294 train loss: 0.6535650024092511\n",
      "Epoch 2294 train accuracy: 75.34960241294215\n",
      "Epoch 2294 val loss: 0.648065196056115\n",
      "Epoch 2294 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2294.pth\n",
      "Epoch 2295 train loss: 0.6534994675598124\n",
      "Epoch 2295 train accuracy: 75.45928160131615\n",
      "Epoch 2295 val loss: 0.6480519146119293\n",
      "Epoch 2295 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2295.pth\n",
      "Epoch 2296 train loss: 0.6535589251209769\n",
      "Epoch 2296 train accuracy: 75.51412119550315\n",
      "Epoch 2296 val loss: 0.6480612414643953\n",
      "Epoch 2296 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2296.pth\n",
      "Epoch 2297 train loss: 0.6536238998043955\n",
      "Epoch 2297 train accuracy: 75.45928160131615\n",
      "Epoch 2297 val loss: 0.6480475014173671\n",
      "Epoch 2297 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2297.pth\n",
      "Epoch 2298 train loss: 0.6536182662504807\n",
      "Epoch 2298 train accuracy: 75.43186180422265\n",
      "Epoch 2298 val loss: 0.6480510589715681\n",
      "Epoch 2298 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2298.pth\n",
      "Epoch 2299 train loss: 0.6535027149345791\n",
      "Epoch 2299 train accuracy: 75.59638058678365\n",
      "Epoch 2299 val loss: 0.6480612240143513\n",
      "Epoch 2299 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2299.pth\n",
      "Epoch 2300 train loss: 0.6534954468605289\n",
      "Epoch 2300 train accuracy: 75.48670139840965\n",
      "Epoch 2300 val loss: 0.6480524190946629\n",
      "Epoch 2300 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2300.pth\n",
      "Epoch 2301 train loss: 0.6535446325545771\n",
      "Epoch 2301 train accuracy: 75.43186180422265\n",
      "Epoch 2301 val loss: 0.6480575569562221\n",
      "Epoch 2301 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2301.pth\n",
      "Epoch 2302 train loss: 0.6535478626426897\n",
      "Epoch 2302 train accuracy: 75.45928160131615\n",
      "Epoch 2302 val loss: 0.6480532561085726\n",
      "Epoch 2302 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2302.pth\n",
      "Epoch 2303 train loss: 0.6535358043681634\n",
      "Epoch 2303 train accuracy: 75.45928160131615\n",
      "Epoch 2303 val loss: 0.6480516574688648\n",
      "Epoch 2303 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2303.pth\n",
      "Epoch 2304 train loss: 0.6535694527913604\n",
      "Epoch 2304 train accuracy: 75.45928160131615\n",
      "Epoch 2304 val loss: 0.6480381674084225\n",
      "Epoch 2304 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2304.pth\n",
      "Epoch 2305 train loss: 0.6535079971838155\n",
      "Epoch 2305 train accuracy: 75.54154099259665\n",
      "Epoch 2305 val loss: 0.6480525516365704\n",
      "Epoch 2305 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2305.pth\n",
      "Epoch 2306 train loss: 0.6534365056115284\n",
      "Epoch 2306 train accuracy: 75.37702221003565\n",
      "Epoch 2306 val loss: 0.6480406024738362\n",
      "Epoch 2306 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2306.pth\n",
      "Epoch 2307 train loss: 0.6534183323056552\n",
      "Epoch 2307 train accuracy: 75.48670139840965\n",
      "Epoch 2307 val loss: 0.6480398645722553\n",
      "Epoch 2307 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2307.pth\n",
      "Epoch 2308 train loss: 0.6536382470083865\n",
      "Epoch 2308 train accuracy: 75.48670139840965\n",
      "Epoch 2308 val loss: 0.6480380682960937\n",
      "Epoch 2308 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2308.pth\n",
      "Epoch 2309 train loss: 0.6535213046233382\n",
      "Epoch 2309 train accuracy: 75.48670139840965\n",
      "Epoch 2309 val loss: 0.6480484849920398\n",
      "Epoch 2309 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2309.pth\n",
      "Epoch 2310 train loss: 0.6535711293680626\n",
      "Epoch 2310 train accuracy: 75.40444200712915\n",
      "Epoch 2310 val loss: 0.648044388349119\n",
      "Epoch 2310 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2310.pth\n",
      "Epoch 2311 train loss: 0.6535210830992774\n",
      "Epoch 2311 train accuracy: 75.43186180422265\n",
      "Epoch 2311 val loss: 0.6480538572527861\n",
      "Epoch 2311 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2311.pth\n",
      "Epoch 2312 train loss: 0.6535184302024151\n",
      "Epoch 2312 train accuracy: 75.48670139840965\n",
      "Epoch 2312 val loss: 0.6480555862776542\n",
      "Epoch 2312 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2312.pth\n",
      "Epoch 2313 train loss: 0.6535130888877208\n",
      "Epoch 2313 train accuracy: 75.48670139840965\n",
      "Epoch 2313 val loss: 0.6480490552555573\n",
      "Epoch 2313 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2313.pth\n",
      "Epoch 2314 train loss: 0.6535271531003609\n",
      "Epoch 2314 train accuracy: 75.51412119550315\n",
      "Epoch 2314 val loss: 0.6480591410869047\n",
      "Epoch 2314 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2314.pth\n",
      "Epoch 2315 train loss: 0.6534861080152424\n",
      "Epoch 2315 train accuracy: 75.34960241294215\n",
      "Epoch 2315 val loss: 0.6480594352868042\n",
      "Epoch 2315 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2315.pth\n",
      "Epoch 2316 train loss: 0.653502710719119\n",
      "Epoch 2316 train accuracy: 75.45928160131615\n",
      "Epoch 2316 val loss: 0.6480486233669677\n",
      "Epoch 2316 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2316.pth\n",
      "Epoch 2317 train loss: 0.6535064011420074\n",
      "Epoch 2317 train accuracy: 75.48670139840965\n",
      "Epoch 2317 val loss: 0.6480527737815129\n",
      "Epoch 2317 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2317.pth\n",
      "Epoch 2318 train loss: 0.6535027068957948\n",
      "Epoch 2318 train accuracy: 75.43186180422265\n",
      "Epoch 2318 val loss: 0.6480431070453242\n",
      "Epoch 2318 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2318.pth\n",
      "Epoch 2319 train loss: 0.6535035232408789\n",
      "Epoch 2319 train accuracy: 75.45928160131615\n",
      "Epoch 2319 val loss: 0.6480536622632491\n",
      "Epoch 2319 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2319.pth\n",
      "Epoch 2320 train loss: 0.6535382166570216\n",
      "Epoch 2320 train accuracy: 75.48670139840965\n",
      "Epoch 2320 val loss: 0.6480555238300248\n",
      "Epoch 2320 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2320.pth\n",
      "Epoch 2321 train loss: 0.6534954973480158\n",
      "Epoch 2321 train accuracy: 75.54154099259665\n",
      "Epoch 2321 val loss: 0.6480562577122136\n",
      "Epoch 2321 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2321.pth\n",
      "Epoch 2322 train loss: 0.6534684269051803\n",
      "Epoch 2322 train accuracy: 75.34960241294215\n",
      "Epoch 2322 val loss: 0.648040889811359\n",
      "Epoch 2322 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2322.pth\n",
      "Epoch 2323 train loss: 0.6534896400479371\n",
      "Epoch 2323 train accuracy: 75.51412119550315\n",
      "Epoch 2323 val loss: 0.6480374628383863\n",
      "Epoch 2323 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2323.pth\n",
      "Epoch 2324 train loss: 0.6534602039477282\n",
      "Epoch 2324 train accuracy: 75.56896078969015\n",
      "Epoch 2324 val loss: 0.6480679824752243\n",
      "Epoch 2324 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2324.pth\n",
      "Epoch 2325 train loss: 0.6534683806331534\n",
      "Epoch 2325 train accuracy: 75.51412119550315\n",
      "Epoch 2325 val loss: 0.64806885458529\n",
      "Epoch 2325 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2325.pth\n",
      "Epoch 2326 train loss: 0.6534911944743311\n",
      "Epoch 2326 train accuracy: 75.43186180422265\n",
      "Epoch 2326 val loss: 0.6480611290194487\n",
      "Epoch 2326 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2326.pth\n",
      "Epoch 2327 train loss: 0.6534462102215018\n",
      "Epoch 2327 train accuracy: 75.37702221003565\n",
      "Epoch 2327 val loss: 0.6480412988090202\n",
      "Epoch 2327 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2327.pth\n",
      "Epoch 2328 train loss: 0.6534439217822071\n",
      "Epoch 2328 train accuracy: 75.48670139840965\n",
      "Epoch 2328 val loss: 0.6480344255503855\n",
      "Epoch 2328 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2328.pth\n",
      "Epoch 2329 train loss: 0.6534693434573057\n",
      "Epoch 2329 train accuracy: 75.37702221003565\n",
      "Epoch 2329 val loss: 0.6480220837616607\n",
      "Epoch 2329 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2329.pth\n",
      "Epoch 2330 train loss: 0.6534748704156332\n",
      "Epoch 2330 train accuracy: 75.51412119550315\n",
      "Epoch 2330 val loss: 0.6480248824350143\n",
      "Epoch 2330 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2330.pth\n",
      "Epoch 2331 train loss: 0.6534048864585266\n",
      "Epoch 2331 train accuracy: 75.54154099259665\n",
      "Epoch 2331 val loss: 0.6480362933913344\n",
      "Epoch 2331 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2331.pth\n",
      "Epoch 2332 train loss: 0.6534578547273812\n",
      "Epoch 2332 train accuracy: 75.43186180422265\n",
      "Epoch 2332 val loss: 0.6480407499169049\n",
      "Epoch 2332 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2332.pth\n",
      "Epoch 2333 train loss: 0.6534572276695255\n",
      "Epoch 2333 train accuracy: 75.34960241294215\n",
      "Epoch 2333 val loss: 0.6480113675719813\n",
      "Epoch 2333 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2333.pth\n",
      "Epoch 2334 train loss: 0.6535512134922963\n",
      "Epoch 2334 train accuracy: 75.51412119550315\n",
      "Epoch 2334 val loss: 0.6480272474061501\n",
      "Epoch 2334 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2334.pth\n",
      "Epoch 2335 train loss: 0.6534610817110852\n",
      "Epoch 2335 train accuracy: 75.54154099259665\n",
      "Epoch 2335 val loss: 0.6480337301955411\n",
      "Epoch 2335 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2335.pth\n",
      "Epoch 2336 train loss: 0.65347282359736\n",
      "Epoch 2336 train accuracy: 75.45928160131615\n",
      "Epoch 2336 val loss: 0.6480500629465831\n",
      "Epoch 2336 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2336.pth\n",
      "Epoch 2337 train loss: 0.6534948092313451\n",
      "Epoch 2337 train accuracy: 75.32218261584865\n",
      "Epoch 2337 val loss: 0.6480300731368756\n",
      "Epoch 2337 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2337.pth\n",
      "Epoch 2338 train loss: 0.6534149020975619\n",
      "Epoch 2338 train accuracy: 75.43186180422265\n",
      "Epoch 2338 val loss: 0.6480304840952158\n",
      "Epoch 2338 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2338.pth\n",
      "Epoch 2339 train loss: 0.6533875197106809\n",
      "Epoch 2339 train accuracy: 75.45928160131615\n",
      "Epoch 2339 val loss: 0.6480162275072775\n",
      "Epoch 2339 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2339.pth\n",
      "Epoch 2340 train loss: 0.6534501431477174\n",
      "Epoch 2340 train accuracy: 75.48670139840965\n",
      "Epoch 2340 val loss: 0.6480259644357782\n",
      "Epoch 2340 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2340.pth\n",
      "Epoch 2341 train loss: 0.6534081395846187\n",
      "Epoch 2341 train accuracy: 75.48670139840965\n",
      "Epoch 2341 val loss: 0.6480280502062095\n",
      "Epoch 2341 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2341.pth\n",
      "Epoch 2342 train loss: 0.6534461497345514\n",
      "Epoch 2342 train accuracy: 75.43186180422265\n",
      "Epoch 2342 val loss: 0.6480251515382215\n",
      "Epoch 2342 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2342.pth\n",
      "Epoch 2343 train loss: 0.6533844354317376\n",
      "Epoch 2343 train accuracy: 75.34960241294215\n",
      "Epoch 2343 val loss: 0.6480196485982129\n",
      "Epoch 2343 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2343.pth\n",
      "Epoch 2344 train loss: 0.6534611503348539\n",
      "Epoch 2344 train accuracy: 75.56896078969015\n",
      "Epoch 2344 val loss: 0.6480346745566318\n",
      "Epoch 2344 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2344.pth\n",
      "Epoch 2345 train loss: 0.6534501402883938\n",
      "Epoch 2345 train accuracy: 75.40444200712915\n",
      "Epoch 2345 val loss: 0.648029500618577\n",
      "Epoch 2345 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2345.pth\n",
      "Epoch 2346 train loss: 0.6534382857120874\n",
      "Epoch 2346 train accuracy: 75.48670139840965\n",
      "Epoch 2346 val loss: 0.6480281839245244\n",
      "Epoch 2346 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2346.pth\n",
      "Epoch 2347 train loss: 0.6534062453725359\n",
      "Epoch 2347 train accuracy: 75.51412119550315\n",
      "Epoch 2347 val loss: 0.6480187335492749\n",
      "Epoch 2347 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2347.pth\n",
      "Epoch 2348 train loss: 0.6534171107372171\n",
      "Epoch 2348 train accuracy: 75.43186180422265\n",
      "Epoch 2348 val loss: 0.6480171731428096\n",
      "Epoch 2348 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2348.pth\n",
      "Epoch 2349 train loss: 0.6534248871173252\n",
      "Epoch 2349 train accuracy: 75.48670139840965\n",
      "Epoch 2349 val loss: 0.6480097577564026\n",
      "Epoch 2349 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2349.pth\n",
      "Epoch 2350 train loss: 0.653427659256155\n",
      "Epoch 2350 train accuracy: 75.48670139840965\n",
      "Epoch 2350 val loss: 0.6480240742430875\n",
      "Epoch 2350 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2350.pth\n",
      "Epoch 2351 train loss: 0.6534218981927424\n",
      "Epoch 2351 train accuracy: 75.37702221003565\n",
      "Epoch 2351 val loss: 0.6480248337121386\n",
      "Epoch 2351 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2351.pth\n",
      "Epoch 2352 train loss: 0.6533985291852763\n",
      "Epoch 2352 train accuracy: 75.37702221003565\n",
      "Epoch 2352 val loss: 0.6480267681181431\n",
      "Epoch 2352 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2352.pth\n",
      "Epoch 2353 train loss: 0.6533839901288351\n",
      "Epoch 2353 train accuracy: 75.37702221003565\n",
      "Epoch 2353 val loss: 0.6480172924501332\n",
      "Epoch 2353 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2353.pth\n",
      "Epoch 2354 train loss: 0.6533857106901052\n",
      "Epoch 2354 train accuracy: 75.45928160131615\n",
      "Epoch 2354 val loss: 0.648029143725963\n",
      "Epoch 2354 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2354.pth\n",
      "Epoch 2355 train loss: 0.6533489616816504\n",
      "Epoch 2355 train accuracy: 75.32218261584865\n",
      "Epoch 2355 val loss: 0.648008990640703\n",
      "Epoch 2355 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2355.pth\n",
      "Epoch 2356 train loss: 0.6533644509812196\n",
      "Epoch 2356 train accuracy: 75.54154099259665\n",
      "Epoch 2356 val loss: 0.6480091770032519\n",
      "Epoch 2356 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2356.pth\n",
      "Epoch 2357 train loss: 0.6534015989551941\n",
      "Epoch 2357 train accuracy: 75.45928160131615\n",
      "Epoch 2357 val loss: 0.6480131479666421\n",
      "Epoch 2357 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2357.pth\n",
      "Epoch 2358 train loss: 0.6533962962005222\n",
      "Epoch 2358 train accuracy: 75.43186180422265\n",
      "Epoch 2358 val loss: 0.6480124676109928\n",
      "Epoch 2358 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2358.pth\n",
      "Epoch 2359 train loss: 0.6533798866562153\n",
      "Epoch 2359 train accuracy: 75.40444200712915\n",
      "Epoch 2359 val loss: 0.6480254950492006\n",
      "Epoch 2359 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2359.pth\n",
      "Epoch 2360 train loss: 0.6534989179651204\n",
      "Epoch 2360 train accuracy: 75.48670139840965\n",
      "Epoch 2360 val loss: 0.6480060015854082\n",
      "Epoch 2360 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2360.pth\n",
      "Epoch 2361 train loss: 0.653399504132961\n",
      "Epoch 2361 train accuracy: 75.40444200712915\n",
      "Epoch 2361 val loss: 0.6479975330202203\n",
      "Epoch 2361 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2361.pth\n",
      "Epoch 2362 train loss: 0.6533958919738468\n",
      "Epoch 2362 train accuracy: 75.37702221003565\n",
      "Epoch 2362 val loss: 0.6479996734935987\n",
      "Epoch 2362 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2362.pth\n",
      "Epoch 2363 train loss: 0.6533860280586962\n",
      "Epoch 2363 train accuracy: 75.40444200712915\n",
      "Epoch 2363 val loss: 0.6479995178156778\n",
      "Epoch 2363 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2363.pth\n",
      "Epoch 2364 train loss: 0.6533297795736999\n",
      "Epoch 2364 train accuracy: 75.40444200712915\n",
      "Epoch 2364 val loss: 0.6479776049719045\n",
      "Epoch 2364 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2364.pth\n",
      "Epoch 2365 train loss: 0.6533962154532211\n",
      "Epoch 2365 train accuracy: 75.51412119550315\n",
      "Epoch 2365 val loss: 0.6479911164037491\n",
      "Epoch 2365 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2365.pth\n",
      "Epoch 2366 train loss: 0.6533822629175949\n",
      "Epoch 2366 train accuracy: 75.40444200712915\n",
      "Epoch 2366 val loss: 0.6479883807662287\n",
      "Epoch 2366 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2366.pth\n",
      "Epoch 2367 train loss: 0.6533989256019133\n",
      "Epoch 2367 train accuracy: 75.56896078969015\n",
      "Epoch 2367 val loss: 0.6480000434737456\n",
      "Epoch 2367 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2367.pth\n",
      "Epoch 2368 train loss: 0.6533837426911321\n",
      "Epoch 2368 train accuracy: 75.40444200712915\n",
      "Epoch 2368 val loss: 0.6480040268874482\n",
      "Epoch 2368 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2368.pth\n",
      "Epoch 2369 train loss: 0.6533239662581891\n",
      "Epoch 2369 train accuracy: 75.40444200712915\n",
      "Epoch 2369 val loss: 0.6479972321540117\n",
      "Epoch 2369 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2369.pth\n",
      "Epoch 2370 train loss: 0.6533712238204061\n",
      "Epoch 2370 train accuracy: 75.43186180422265\n",
      "Epoch 2370 val loss: 0.6480009064666534\n",
      "Epoch 2370 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2370.pth\n",
      "Epoch 2371 train loss: 0.6533237884572723\n",
      "Epoch 2371 train accuracy: 75.43186180422265\n",
      "Epoch 2371 val loss: 0.6479946014128233\n",
      "Epoch 2371 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2371.pth\n",
      "Epoch 2372 train loss: 0.653348124112215\n",
      "Epoch 2372 train accuracy: 75.51412119550315\n",
      "Epoch 2372 val loss: 0.6480073488660549\n",
      "Epoch 2372 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2372.pth\n",
      "Epoch 2373 train loss: 0.6533652410368648\n",
      "Epoch 2373 train accuracy: 75.34960241294215\n",
      "Epoch 2373 val loss: 0.6479783541473904\n",
      "Epoch 2373 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2373.pth\n",
      "Epoch 2374 train loss: 0.6533704732234279\n",
      "Epoch 2374 train accuracy: 75.43186180422265\n",
      "Epoch 2374 val loss: 0.6479723072169643\n",
      "Epoch 2374 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2374.pth\n",
      "Epoch 2375 train loss: 0.6533643951018652\n",
      "Epoch 2375 train accuracy: 75.40444200712915\n",
      "Epoch 2375 val loss: 0.6479950521239325\n",
      "Epoch 2375 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2375.pth\n",
      "Epoch 2376 train loss: 0.6533305152858558\n",
      "Epoch 2376 train accuracy: 75.37702221003565\n",
      "Epoch 2376 val loss: 0.6479781538640198\n",
      "Epoch 2376 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2376.pth\n",
      "Epoch 2377 train loss: 0.6533146331969061\n",
      "Epoch 2377 train accuracy: 75.34960241294215\n",
      "Epoch 2377 val loss: 0.6479700350839841\n",
      "Epoch 2377 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2377.pth\n",
      "Epoch 2378 train loss: 0.6532943690881917\n",
      "Epoch 2378 train accuracy: 75.56896078969015\n",
      "Epoch 2378 val loss: 0.6479880911739249\n",
      "Epoch 2378 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2378.pth\n",
      "Epoch 2379 train loss: 0.6533512640581057\n",
      "Epoch 2379 train accuracy: 75.45928160131615\n",
      "Epoch 2379 val loss: 0.6479756095887799\n",
      "Epoch 2379 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2379.pth\n",
      "Epoch 2380 train loss: 0.6533486694097519\n",
      "Epoch 2380 train accuracy: 75.34960241294215\n",
      "Epoch 2380 val loss: 0.6479612587902107\n",
      "Epoch 2380 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2380.pth\n",
      "Epoch 2381 train loss: 0.653356067215403\n",
      "Epoch 2381 train accuracy: 75.48670139840965\n",
      "Epoch 2381 val loss: 0.6479578857849303\n",
      "Epoch 2381 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2381.pth\n",
      "Epoch 2382 train loss: 0.6533091331652382\n",
      "Epoch 2382 train accuracy: 75.37702221003565\n",
      "Epoch 2382 val loss: 0.647956353906346\n",
      "Epoch 2382 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2382.pth\n",
      "Epoch 2383 train loss: 0.653293140265241\n",
      "Epoch 2383 train accuracy: 75.34960241294215\n",
      "Epoch 2383 val loss: 0.6479530221733608\n",
      "Epoch 2383 val accuracy: 76.97368421052632\n",
      "Saved model to .\\test_modelsv2/MLP_2383.pth\n",
      "Epoch 2384 train loss: 0.6533121146719184\n",
      "Epoch 2384 train accuracy: 75.40444200712915\n",
      "Epoch 2384 val loss: 0.6479578593647793\n",
      "Epoch 2384 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2384.pth\n",
      "Epoch 2385 train loss: 0.6533196482382584\n",
      "Epoch 2385 train accuracy: 75.43186180422265\n",
      "Epoch 2385 val loss: 0.6479716579380789\n",
      "Epoch 2385 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2385.pth\n",
      "Epoch 2386 train loss: 0.6533356858907562\n",
      "Epoch 2386 train accuracy: 75.45928160131615\n",
      "Epoch 2386 val loss: 0.6479742227024153\n",
      "Epoch 2386 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2386.pth\n",
      "Epoch 2387 train loss: 0.6533320873910398\n",
      "Epoch 2387 train accuracy: 75.37702221003565\n",
      "Epoch 2387 val loss: 0.6479679516663677\n",
      "Epoch 2387 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2387.pth\n",
      "Epoch 2388 train loss: 0.6533288527933652\n",
      "Epoch 2388 train accuracy: 75.37702221003565\n",
      "Epoch 2388 val loss: 0.6479746256219713\n",
      "Epoch 2388 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2388.pth\n",
      "Epoch 2389 train loss: 0.6532799489796162\n",
      "Epoch 2389 train accuracy: 75.48670139840965\n",
      "Epoch 2389 val loss: 0.6479541096640261\n",
      "Epoch 2389 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2389.pth\n",
      "Epoch 2390 train loss: 0.6533241972588656\n",
      "Epoch 2390 train accuracy: 75.48670139840965\n",
      "Epoch 2390 val loss: 0.6479566324698297\n",
      "Epoch 2390 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2390.pth\n",
      "Epoch 2391 train loss: 0.6533281890381324\n",
      "Epoch 2391 train accuracy: 75.43186180422265\n",
      "Epoch 2391 val loss: 0.6479538005629653\n",
      "Epoch 2391 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2391.pth\n",
      "Epoch 2392 train loss: 0.6533194097543233\n",
      "Epoch 2392 train accuracy: 75.45928160131615\n",
      "Epoch 2392 val loss: 0.6479550458882984\n",
      "Epoch 2392 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2392.pth\n",
      "Epoch 2393 train loss: 0.6533037356770875\n",
      "Epoch 2393 train accuracy: 75.51412119550315\n",
      "Epoch 2393 val loss: 0.6479733292209474\n",
      "Epoch 2393 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2393.pth\n",
      "Epoch 2394 train loss: 0.6533442008913609\n",
      "Epoch 2394 train accuracy: 75.43186180422265\n",
      "Epoch 2394 val loss: 0.647972231142615\n",
      "Epoch 2394 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2394.pth\n",
      "Epoch 2395 train loss: 0.6533246811217907\n",
      "Epoch 2395 train accuracy: 75.48670139840965\n",
      "Epoch 2395 val loss: 0.6479793845822936\n",
      "Epoch 2395 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2395.pth\n",
      "Epoch 2396 train loss: 0.6532110425790674\n",
      "Epoch 2396 train accuracy: 75.43186180422265\n",
      "Epoch 2396 val loss: 0.6479888398592409\n",
      "Epoch 2396 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2396.pth\n",
      "Epoch 2397 train loss: 0.6533109446693408\n",
      "Epoch 2397 train accuracy: 75.34960241294215\n",
      "Epoch 2397 val loss: 0.6479532596116003\n",
      "Epoch 2397 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2397.pth\n",
      "Epoch 2398 train loss: 0.6533123632860288\n",
      "Epoch 2398 train accuracy: 75.51412119550315\n",
      "Epoch 2398 val loss: 0.6479625259771159\n",
      "Epoch 2398 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2398.pth\n",
      "Epoch 2399 train loss: 0.6532870631403568\n",
      "Epoch 2399 train accuracy: 75.43186180422265\n",
      "Epoch 2399 val loss: 0.6479725753398318\n",
      "Epoch 2399 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2399.pth\n",
      "Epoch 2400 train loss: 0.65325362003294\n",
      "Epoch 2400 train accuracy: 75.40444200712915\n",
      "Epoch 2400 val loss: 0.6479686353551714\n",
      "Epoch 2400 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2400.pth\n",
      "Epoch 2401 train loss: 0.6532587493328672\n",
      "Epoch 2401 train accuracy: 75.54154099259665\n",
      "Epoch 2401 val loss: 0.6479758547717019\n",
      "Epoch 2401 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2401.pth\n",
      "Epoch 2402 train loss: 0.6533338182131972\n",
      "Epoch 2402 train accuracy: 75.51412119550315\n",
      "Epoch 2402 val loss: 0.6479696782403871\n",
      "Epoch 2402 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2402.pth\n",
      "Epoch 2403 train loss: 0.6532766298113162\n",
      "Epoch 2403 train accuracy: 75.40444200712915\n",
      "Epoch 2403 val loss: 0.6479687831903759\n",
      "Epoch 2403 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2403.pth\n",
      "Epoch 2404 train loss: 0.6532764645914236\n",
      "Epoch 2404 train accuracy: 75.48670139840965\n",
      "Epoch 2404 val loss: 0.6479606722530565\n",
      "Epoch 2404 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2404.pth\n",
      "Epoch 2405 train loss: 0.6532501833546057\n",
      "Epoch 2405 train accuracy: 75.34960241294215\n",
      "Epoch 2405 val loss: 0.6479454010136818\n",
      "Epoch 2405 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2405.pth\n",
      "Epoch 2406 train loss: 0.6532848154178315\n",
      "Epoch 2406 train accuracy: 75.40444200712915\n",
      "Epoch 2406 val loss: 0.647952712974266\n",
      "Epoch 2406 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2406.pth\n",
      "Epoch 2407 train loss: 0.6532853187895135\n",
      "Epoch 2407 train accuracy: 75.37702221003565\n",
      "Epoch 2407 val loss: 0.6479383461961621\n",
      "Epoch 2407 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2407.pth\n",
      "Epoch 2408 train loss: 0.6532850930173146\n",
      "Epoch 2408 train accuracy: 75.45928160131615\n",
      "Epoch 2408 val loss: 0.6479410267385998\n",
      "Epoch 2408 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2408.pth\n",
      "Epoch 2409 train loss: 0.6532855558356172\n",
      "Epoch 2409 train accuracy: 75.54154099259665\n",
      "Epoch 2409 val loss: 0.6479546387532824\n",
      "Epoch 2409 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2409.pth\n",
      "Epoch 2410 train loss: 0.6532489195335329\n",
      "Epoch 2410 train accuracy: 75.40444200712915\n",
      "Epoch 2410 val loss: 0.6479582028757584\n",
      "Epoch 2410 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2410.pth\n",
      "Epoch 2411 train loss: 0.6532807250490837\n",
      "Epoch 2411 train accuracy: 75.43186180422265\n",
      "Epoch 2411 val loss: 0.6479410537959713\n",
      "Epoch 2411 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2411.pth\n",
      "Epoch 2412 train loss: 0.6532845031143281\n",
      "Epoch 2412 train accuracy: 75.40444200712915\n",
      "Epoch 2412 val loss: 0.6479458271672851\n",
      "Epoch 2412 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2412.pth\n",
      "Epoch 2413 train loss: 0.6532533283002282\n",
      "Epoch 2413 train accuracy: 75.48670139840965\n",
      "Epoch 2413 val loss: 0.6479569671577529\n",
      "Epoch 2413 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2413.pth\n",
      "Epoch 2414 train loss: 0.6532670116672913\n",
      "Epoch 2414 train accuracy: 75.40444200712915\n",
      "Epoch 2414 val loss: 0.6479419205141695\n",
      "Epoch 2414 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2414.pth\n",
      "Epoch 2415 train loss: 0.6532591841461366\n",
      "Epoch 2415 train accuracy: 75.40444200712915\n",
      "Epoch 2415 val loss: 0.6479236144376429\n",
      "Epoch 2415 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2415.pth\n",
      "Epoch 2416 train loss: 0.6532440235054022\n",
      "Epoch 2416 train accuracy: 75.56896078969015\n",
      "Epoch 2416 val loss: 0.6479327902197838\n",
      "Epoch 2416 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2416.pth\n",
      "Epoch 2417 train loss: 0.6531804012820909\n",
      "Epoch 2417 train accuracy: 75.37702221003565\n",
      "Epoch 2417 val loss: 0.6479369769559095\n",
      "Epoch 2417 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2417.pth\n",
      "Epoch 2418 train loss: 0.6532625903685888\n",
      "Epoch 2418 train accuracy: 75.40444200712915\n",
      "Epoch 2418 val loss: 0.6479455141448661\n",
      "Epoch 2418 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2418.pth\n",
      "Epoch 2419 train loss: 0.6532618284813667\n",
      "Epoch 2419 train accuracy: 75.51412119550315\n",
      "Epoch 2419 val loss: 0.6479512180544829\n",
      "Epoch 2419 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2419.pth\n",
      "Epoch 2420 train loss: 0.6532607138679739\n",
      "Epoch 2420 train accuracy: 75.43186180422265\n",
      "Epoch 2420 val loss: 0.6479591273359562\n",
      "Epoch 2420 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2420.pth\n",
      "Epoch 2421 train loss: 0.6532609998003432\n",
      "Epoch 2421 train accuracy: 75.43186180422265\n",
      "Epoch 2421 val loss: 0.6479517406734981\n",
      "Epoch 2421 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2421.pth\n",
      "Epoch 2422 train loss: 0.6532062129035854\n",
      "Epoch 2422 train accuracy: 75.37702221003565\n",
      "Epoch 2422 val loss: 0.6479459611797019\n",
      "Epoch 2422 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2422.pth\n",
      "Epoch 2423 train loss: 0.6531603352673221\n",
      "Epoch 2423 train accuracy: 75.40444200712915\n",
      "Epoch 2423 val loss: 0.6479324873928961\n",
      "Epoch 2423 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2423.pth\n",
      "Epoch 2424 train loss: 0.6533005166668118\n",
      "Epoch 2424 train accuracy: 75.40444200712915\n",
      "Epoch 2424 val loss: 0.6479249194656548\n",
      "Epoch 2424 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2424.pth\n",
      "Epoch 2425 train loss: 0.6532052730193787\n",
      "Epoch 2425 train accuracy: 75.45928160131615\n",
      "Epoch 2425 val loss: 0.6479332705861643\n",
      "Epoch 2425 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2425.pth\n",
      "Epoch 2426 train loss: 0.6532466807974535\n",
      "Epoch 2426 train accuracy: 75.40444200712915\n",
      "Epoch 2426 val loss: 0.6479356268322781\n",
      "Epoch 2426 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2426.pth\n",
      "Epoch 2427 train loss: 0.6532433130860067\n",
      "Epoch 2427 train accuracy: 75.40444200712915\n",
      "Epoch 2427 val loss: 0.6479310744294995\n",
      "Epoch 2427 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2427.pth\n",
      "Epoch 2428 train loss: 0.6532432326818245\n",
      "Epoch 2428 train accuracy: 75.40444200712915\n",
      "Epoch 2428 val loss: 0.6479115942983251\n",
      "Epoch 2428 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2428.pth\n",
      "Epoch 2429 train loss: 0.6532422143050975\n",
      "Epoch 2429 train accuracy: 75.43186180422265\n",
      "Epoch 2429 val loss: 0.6478999014943838\n",
      "Epoch 2429 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2429.pth\n",
      "Epoch 2430 train loss: 0.6532357987996779\n",
      "Epoch 2430 train accuracy: 75.45928160131615\n",
      "Epoch 2430 val loss: 0.647916870779897\n",
      "Epoch 2430 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2430.pth\n",
      "Epoch 2431 train loss: 0.653162772326093\n",
      "Epoch 2431 train accuracy: 75.37702221003565\n",
      "Epoch 2431 val loss: 0.647912481407586\n",
      "Epoch 2431 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2431.pth\n",
      "Epoch 2432 train loss: 0.6531751046708801\n",
      "Epoch 2432 train accuracy: 75.43186180422265\n",
      "Epoch 2432 val loss: 0.6478929966688156\n",
      "Epoch 2432 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2432.pth\n",
      "Epoch 2433 train loss: 0.653227934417756\n",
      "Epoch 2433 train accuracy: 75.48670139840965\n",
      "Epoch 2433 val loss: 0.6479035099282077\n",
      "Epoch 2433 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2433.pth\n",
      "Epoch 2434 train loss: 0.6532287604845407\n",
      "Epoch 2434 train accuracy: 75.37702221003565\n",
      "Epoch 2434 val loss: 0.6478893051021978\n",
      "Epoch 2434 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2434.pth\n",
      "Epoch 2435 train loss: 0.6531654424769314\n",
      "Epoch 2435 train accuracy: 75.54154099259665\n",
      "Epoch 2435 val loss: 0.6479218258081298\n",
      "Epoch 2435 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2435.pth\n",
      "Epoch 2436 train loss: 0.6531891246702064\n",
      "Epoch 2436 train accuracy: 75.40444200712915\n",
      "Epoch 2436 val loss: 0.6479005999863148\n",
      "Epoch 2436 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2436.pth\n",
      "Epoch 2437 train loss: 0.6532270579288403\n",
      "Epoch 2437 train accuracy: 75.48670139840965\n",
      "Epoch 2437 val loss: 0.6479130038795503\n",
      "Epoch 2437 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2437.pth\n",
      "Epoch 2438 train loss: 0.6532126422971487\n",
      "Epoch 2438 train accuracy: 75.40444200712915\n",
      "Epoch 2438 val loss: 0.6479026797766748\n",
      "Epoch 2438 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2438.pth\n",
      "Epoch 2439 train loss: 0.6532178693532682\n",
      "Epoch 2439 train accuracy: 75.40444200712915\n",
      "Epoch 2439 val loss: 0.6478988354731547\n",
      "Epoch 2439 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2439.pth\n",
      "Epoch 2440 train loss: 0.6531925181482445\n",
      "Epoch 2440 train accuracy: 75.40444200712915\n",
      "Epoch 2440 val loss: 0.6478966766674268\n",
      "Epoch 2440 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2440.pth\n",
      "Epoch 2441 train loss: 0.6532109595116293\n",
      "Epoch 2441 train accuracy: 75.40444200712915\n",
      "Epoch 2441 val loss: 0.6478918865323067\n",
      "Epoch 2441 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2441.pth\n",
      "Epoch 2442 train loss: 0.6532081603072584\n",
      "Epoch 2442 train accuracy: 75.37702221003565\n",
      "Epoch 2442 val loss: 0.6478845472202489\n",
      "Epoch 2442 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2442.pth\n",
      "Epoch 2443 train loss: 0.6532338435777969\n",
      "Epoch 2443 train accuracy: 75.40444200712915\n",
      "Epoch 2443 val loss: 0.6478802934288979\n",
      "Epoch 2443 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2443.pth\n",
      "Epoch 2444 train loss: 0.6531806437200621\n",
      "Epoch 2444 train accuracy: 75.40444200712915\n",
      "Epoch 2444 val loss: 0.6479026409552285\n",
      "Epoch 2444 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2444.pth\n",
      "Epoch 2445 train loss: 0.6531086850323176\n",
      "Epoch 2445 train accuracy: 75.37702221003565\n",
      "Epoch 2445 val loss: 0.6478813632734512\n",
      "Epoch 2445 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2445.pth\n",
      "Epoch 2446 train loss: 0.6532057043687817\n",
      "Epoch 2446 train accuracy: 75.40444200712915\n",
      "Epoch 2446 val loss: 0.6478859217543351\n",
      "Epoch 2446 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2446.pth\n",
      "Epoch 2447 train loss: 0.6531605766269198\n",
      "Epoch 2447 train accuracy: 75.43186180422265\n",
      "Epoch 2447 val loss: 0.6478939139725346\n",
      "Epoch 2447 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2447.pth\n",
      "Epoch 2448 train loss: 0.6531764816231372\n",
      "Epoch 2448 train accuracy: 75.40444200712915\n",
      "Epoch 2448 val loss: 0.6478782050115498\n",
      "Epoch 2448 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2448.pth\n",
      "Epoch 2449 train loss: 0.6531814895897058\n",
      "Epoch 2449 train accuracy: 75.40444200712915\n",
      "Epoch 2449 val loss: 0.6478689576646215\n",
      "Epoch 2449 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2449.pth\n",
      "Epoch 2450 train loss: 0.6532087649561857\n",
      "Epoch 2450 train accuracy: 75.40444200712915\n",
      "Epoch 2450 val loss: 0.6478814148393116\n",
      "Epoch 2450 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2450.pth\n",
      "Epoch 2451 train loss: 0.6531723506029761\n",
      "Epoch 2451 train accuracy: 75.48670139840965\n",
      "Epoch 2451 val loss: 0.6478956397622824\n",
      "Epoch 2451 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2451.pth\n",
      "Epoch 2452 train loss: 0.653169147670269\n",
      "Epoch 2452 train accuracy: 75.48670139840965\n",
      "Epoch 2452 val loss: 0.6478933712565585\n",
      "Epoch 2452 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2452.pth\n",
      "Epoch 2453 train loss: 0.653180589507285\n",
      "Epoch 2453 train accuracy: 75.40444200712915\n",
      "Epoch 2453 val loss: 0.6478870557130951\n",
      "Epoch 2453 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2453.pth\n",
      "Epoch 2454 train loss: 0.6531817568956237\n",
      "Epoch 2454 train accuracy: 75.40444200712915\n",
      "Epoch 2454 val loss: 0.6478812738664841\n",
      "Epoch 2454 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2454.pth\n",
      "Epoch 2455 train loss: 0.6531691315600223\n",
      "Epoch 2455 train accuracy: 75.43186180422265\n",
      "Epoch 2455 val loss: 0.6478975600023803\n",
      "Epoch 2455 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2455.pth\n",
      "Epoch 2456 train loss: 0.6531405766543589\n",
      "Epoch 2456 train accuracy: 75.37702221003565\n",
      "Epoch 2456 val loss: 0.6478980392413703\n",
      "Epoch 2456 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2456.pth\n",
      "Epoch 2457 train loss: 0.6531592184645042\n",
      "Epoch 2457 train accuracy: 75.43186180422265\n",
      "Epoch 2457 val loss: 0.6478886593525347\n",
      "Epoch 2457 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2457.pth\n",
      "Epoch 2458 train loss: 0.6531609971272317\n",
      "Epoch 2458 train accuracy: 75.40444200712915\n",
      "Epoch 2458 val loss: 0.6478874338790774\n",
      "Epoch 2458 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2458.pth\n",
      "Epoch 2459 train loss: 0.653167284338882\n",
      "Epoch 2459 train accuracy: 75.43186180422265\n",
      "Epoch 2459 val loss: 0.6478968371490115\n",
      "Epoch 2459 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2459.pth\n",
      "Epoch 2460 train loss: 0.6531661504128\n",
      "Epoch 2460 train accuracy: 75.34960241294215\n",
      "Epoch 2460 val loss: 0.6478712362678427\n",
      "Epoch 2460 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2460.pth\n",
      "Epoch 2461 train loss: 0.6531933302288515\n",
      "Epoch 2461 train accuracy: 75.48670139840965\n",
      "Epoch 2461 val loss: 0.6478773810361561\n",
      "Epoch 2461 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2461.pth\n",
      "Epoch 2462 train loss: 0.6531622136632601\n",
      "Epoch 2462 train accuracy: 75.40444200712915\n",
      "Epoch 2462 val loss: 0.6478568911552429\n",
      "Epoch 2462 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2462.pth\n",
      "Epoch 2463 train loss: 0.6531272817958604\n",
      "Epoch 2463 train accuracy: 75.54154099259665\n",
      "Epoch 2463 val loss: 0.6478755726037841\n",
      "Epoch 2463 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2463.pth\n",
      "Epoch 2464 train loss: 0.6531438478677157\n",
      "Epoch 2464 train accuracy: 75.51412119550315\n",
      "Epoch 2464 val loss: 0.6478858177403086\n",
      "Epoch 2464 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2464.pth\n",
      "Epoch 2465 train loss: 0.6531690509107552\n",
      "Epoch 2465 train accuracy: 75.48670139840965\n",
      "Epoch 2465 val loss: 0.6478768094981971\n",
      "Epoch 2465 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2465.pth\n",
      "Epoch 2466 train loss: 0.6531563666894248\n",
      "Epoch 2466 train accuracy: 75.37702221003565\n",
      "Epoch 2466 val loss: 0.647862016174354\n",
      "Epoch 2466 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2466.pth\n",
      "Epoch 2467 train loss: 0.6531423319850052\n",
      "Epoch 2467 train accuracy: 75.40444200712915\n",
      "Epoch 2467 val loss: 0.6478788375266289\n",
      "Epoch 2467 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2467.pth\n",
      "Epoch 2468 train loss: 0.6530904086600793\n",
      "Epoch 2468 train accuracy: 75.37702221003565\n",
      "Epoch 2468 val loss: 0.647856380790472\n",
      "Epoch 2468 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2468.pth\n",
      "Epoch 2469 train loss: 0.6531134608218021\n",
      "Epoch 2469 train accuracy: 75.45928160131615\n",
      "Epoch 2469 val loss: 0.6478595497380746\n",
      "Epoch 2469 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2469.pth\n",
      "Epoch 2470 train loss: 0.6531407240974275\n",
      "Epoch 2470 train accuracy: 75.45928160131615\n",
      "Epoch 2470 val loss: 0.6478541482632098\n",
      "Epoch 2470 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2470.pth\n",
      "Epoch 2471 train loss: 0.6531506432056949\n",
      "Epoch 2471 train accuracy: 75.40444200712915\n",
      "Epoch 2471 val loss: 0.6478464514213172\n",
      "Epoch 2471 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2471.pth\n",
      "Epoch 2472 train loss: 0.6531510844565275\n",
      "Epoch 2472 train accuracy: 75.48670139840965\n",
      "Epoch 2472 val loss: 0.6478561322743955\n",
      "Epoch 2472 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2472.pth\n",
      "Epoch 2473 train loss: 0.6531444075599051\n",
      "Epoch 2473 train accuracy: 75.43186180422265\n",
      "Epoch 2473 val loss: 0.6478681780986095\n",
      "Epoch 2473 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2473.pth\n",
      "Epoch 2474 train loss: 0.6531405858858897\n",
      "Epoch 2474 train accuracy: 75.45928160131615\n",
      "Epoch 2474 val loss: 0.6478436588260689\n",
      "Epoch 2474 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2474.pth\n",
      "Epoch 2475 train loss: 0.6531539748079682\n",
      "Epoch 2475 train accuracy: 75.54154099259665\n",
      "Epoch 2475 val loss: 0.6478688672773147\n",
      "Epoch 2475 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2475.pth\n",
      "Epoch 2476 train loss: 0.653140315916716\n",
      "Epoch 2476 train accuracy: 75.43186180422265\n",
      "Epoch 2476 val loss: 0.647861385914056\n",
      "Epoch 2476 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2476.pth\n",
      "Epoch 2477 train loss: 0.6531305815370982\n",
      "Epoch 2477 train accuracy: 75.37702221003565\n",
      "Epoch 2477 val loss: 0.6478649155285797\n",
      "Epoch 2477 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2477.pth\n",
      "Epoch 2478 train loss: 0.6531324358820393\n",
      "Epoch 2478 train accuracy: 75.43186180422265\n",
      "Epoch 2478 val loss: 0.6478716027187673\n",
      "Epoch 2478 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2478.pth\n",
      "Epoch 2479 train loss: 0.6531040674369586\n",
      "Epoch 2479 train accuracy: 75.37702221003565\n",
      "Epoch 2479 val loss: 0.6478462848616274\n",
      "Epoch 2479 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2479.pth\n",
      "Epoch 2480 train loss: 0.6531175331196242\n",
      "Epoch 2480 train accuracy: 75.40444200712915\n",
      "Epoch 2480 val loss: 0.6478213080156007\n",
      "Epoch 2480 val accuracy: 76.89144736842105\n",
      "Saved model to .\\test_modelsv2/MLP_2480.pth\n",
      "Epoch 2481 train loss: 0.653081822650213\n",
      "Epoch 2481 train accuracy: 75.40444200712915\n",
      "Epoch 2481 val loss: 0.6478351107553432\n",
      "Epoch 2481 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2481.pth\n",
      "Epoch 2482 train loss: 0.6530802561002865\n",
      "Epoch 2482 train accuracy: 75.51412119550315\n",
      "Epoch 2482 val loss: 0.6478533827650704\n",
      "Epoch 2482 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2482.pth\n",
      "Epoch 2483 train loss: 0.6530679162559018\n",
      "Epoch 2483 train accuracy: 75.43186180422265\n",
      "Epoch 2483 val loss: 0.6478360978592383\n",
      "Epoch 2483 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2483.pth\n",
      "Epoch 2484 train loss: 0.653124097146486\n",
      "Epoch 2484 train accuracy: 75.51412119550315\n",
      "Epoch 2484 val loss: 0.6478626186910429\n",
      "Epoch 2484 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2484.pth\n",
      "Epoch 2485 train loss: 0.6530137781315205\n",
      "Epoch 2485 train accuracy: 75.43186180422265\n",
      "Epoch 2485 val loss: 0.6478515294821638\n",
      "Epoch 2485 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2485.pth\n",
      "Epoch 2486 train loss: 0.6531240984209274\n",
      "Epoch 2486 train accuracy: 75.45928160131615\n",
      "Epoch 2486 val loss: 0.6478537028949511\n",
      "Epoch 2486 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2486.pth\n",
      "Epoch 2487 train loss: 0.6531592236603039\n",
      "Epoch 2487 train accuracy: 75.45928160131615\n",
      "Epoch 2487 val loss: 0.6478393017069289\n",
      "Epoch 2487 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2487.pth\n",
      "Epoch 2488 train loss: 0.6531479866815764\n",
      "Epoch 2488 train accuracy: 75.43186180422265\n",
      "Epoch 2488 val loss: 0.6478529954329133\n",
      "Epoch 2488 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2488.pth\n",
      "Epoch 2489 train loss: 0.6531095417673912\n",
      "Epoch 2489 train accuracy: 75.45928160131615\n",
      "Epoch 2489 val loss: 0.6478412889532352\n",
      "Epoch 2489 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2489.pth\n",
      "Epoch 2490 train loss: 0.653104408104953\n",
      "Epoch 2490 train accuracy: 75.48670139840965\n",
      "Epoch 2490 val loss: 0.6478392379848581\n",
      "Epoch 2490 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2490.pth\n",
      "Epoch 2491 train loss: 0.6531031978757758\n",
      "Epoch 2491 train accuracy: 75.45928160131615\n",
      "Epoch 2491 val loss: 0.6478423253682098\n",
      "Epoch 2491 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2491.pth\n",
      "Epoch 2492 train loss: 0.6531036824412775\n",
      "Epoch 2492 train accuracy: 75.51412119550315\n",
      "Epoch 2492 val loss: 0.6478354223072529\n",
      "Epoch 2492 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2492.pth\n",
      "Epoch 2493 train loss: 0.6530428521269769\n",
      "Epoch 2493 train accuracy: 75.40444200712915\n",
      "Epoch 2493 val loss: 0.6478394992453488\n",
      "Epoch 2493 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2493.pth\n",
      "Epoch 2494 train loss: 0.653070827619287\n",
      "Epoch 2494 train accuracy: 75.37702221003565\n",
      "Epoch 2494 val loss: 0.6478331612521097\n",
      "Epoch 2494 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2494.pth\n",
      "Epoch 2495 train loss: 0.6530775266715831\n",
      "Epoch 2495 train accuracy: 75.45928160131615\n",
      "Epoch 2495 val loss: 0.6478310267588026\n",
      "Epoch 2495 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2495.pth\n",
      "Epoch 2496 train loss: 0.6531397768606743\n",
      "Epoch 2496 train accuracy: 75.45928160131615\n",
      "Epoch 2496 val loss: 0.6478083371920021\n",
      "Epoch 2496 val accuracy: 76.8092105263158\n",
      "Saved model to .\\test_modelsv2/MLP_2496.pth\n",
      "Epoch 2497 train loss: 0.6531963430083635\n",
      "Epoch 2497 train accuracy: 75.51412119550315\n",
      "Epoch 2497 val loss: 0.6478236215679269\n",
      "Epoch 2497 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2497.pth\n",
      "Epoch 2498 train loss: 0.6530951255965128\n",
      "Epoch 2498 train accuracy: 75.34960241294215\n",
      "Epoch 2498 val loss: 0.6478229767005694\n",
      "Epoch 2498 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2498.pth\n",
      "Epoch 2499 train loss: 0.6530592126052892\n",
      "Epoch 2499 train accuracy: 75.45928160131615\n",
      "Epoch 2499 val loss: 0.6478186759509539\n",
      "Epoch 2499 val accuracy: 76.72697368421052\n",
      "Saved model to .\\test_modelsv2/MLP_2499.pth\n"
     ]
    }
   ],
   "source": [
    "train_loss_values_v2, train_acc_values_v2, val_loss_values_v2, val_acc_values_v2 = training_loop(hyperparams, model, train_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x2700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define figure\n",
    "fig, axes = plt.subplots(2, 1, figsize=(4, 9), dpi=300, facecolor='w')\n",
    "\n",
    "train_loss_values = np.array(train_loss_values_v2)\n",
    "train_acc_values = np.array(train_acc_values_v2)\n",
    "val_loss_values = np.array(val_loss_values_v2)\n",
    "val_acc_values = np.array(val_acc_values_v2)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "\n",
    "    if (i % 2) == 0:\n",
    "\n",
    "        train_acc, = ax.plot(np.arange(0,2500,1),train_acc_values, label='Training Accuracy')\n",
    "        val_acc, = ax.plot(np.arange(0,2500,1),val_acc_values, label='Validation Accuracy')\n",
    "\n",
    "        # make legend \n",
    "        ax.legend(handles=[train_acc, val_acc], fontsize=6)\n",
    "        \n",
    "        # Hide the right and top spines\n",
    "        ax.spines.right.set_visible(False)\n",
    "        ax.spines.top.set_visible(False)\n",
    "        \n",
    "        # make the labels\n",
    "        ax.set_xlabel(\"epochs\")\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "        ax.set_title('Accuracy of One-layer Neural Net with reduced data', fontweight='bold', fontsize=8, pad=14)\n",
    "\n",
    "    else:\n",
    "        train_loss, = ax.plot(np.arange(0,2500,1),train_loss_values, label='Training Accuracy')\n",
    "        val_loss, = ax.plot(np.arange(0,2500,1),val_loss_values, label='Validation Accuracy')\n",
    "\n",
    "        # make legend \n",
    "        ax.legend(handles=[train_loss, val_loss], fontsize=6)\n",
    "        \n",
    "        # Hide the right and top spines\n",
    "        ax.spines.right.set_visible(False)\n",
    "        ax.spines.top.set_visible(False)\n",
    "        \n",
    "        # make the labels\n",
    "        ax.set_xlabel(\"epochs\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_title('Loss of One-layer Neural Net with reduced data', fontweight='bold', fontsize=8, pad=14)\n",
    "\n",
    "\n",
    "# set the spacing between subplots\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.8, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VelaMoneyball",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80ed5ba3da40db5a0a7dbb542c9aa0e25491f3ab9c3c3dfba5c7eb8a9581f88b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
